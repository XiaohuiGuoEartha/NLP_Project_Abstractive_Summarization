{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence to Sequence Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name: Xiaohui Guo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNI: xg2225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.4\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The version of keras is \"2.0.4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7506524066601813976\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 309723136\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 11546559095746642287\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"\n",
      ", name: \"/device:GPU:1\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 357957632\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 7269598334004712426\n",
      "physical_device_desc: \"device: 1, name: Tesla K80, pci bus id: 0000:00:05.0, compute capability: 3.7\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import operator\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding,Dense, Dropout, Reshape, RepeatVector,Merge, BatchNormalization, TimeDistributed, Lambda, Activation, LSTM, Flatten, Convolution1D, GRU, MaxPooling1D\n",
    "from numpy import argmax\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from rouge import Rouge\n",
    "from keras.models import model_from_json\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: All code should be in Python3. Keras version should be 2.0.4. The directory structure on the bitbucket repo should be exactly same as the hw4.zip provided to you (with the exception of data directory. Do not upload it). To push the code to remote repo, use the same instructions as given in HW0. **Double check you remote repo for correct directory structure. We won't consider any regrade requests based on wrong directory structure penalty. Again, do not upload data to your bitbucket repo ** <br>\n",
    "**The data provided to you should not be used for any other purpose than this course. You must not distribute it or upload it to any public platform.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](seq2seq.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we are going to solve the problem of summarization using a sequence to sequence model. In a sequence to sequence problem, we have an encoder and a decoder. We feed the sequence of word embeddings to an encoder and train decoder to learn the summaries. We will be seeing 2 types of encoder decoder architectures in this assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part of the assignment is to prepare data. You are given training data in train_article.txt, in which each line is the first sentence from an article, and training summary sentences in train_title.txt, which are the corresponding titles of the article. You will be training the model to predict the title of an article given the first sentence of that article, where title generation is a summarization task. Let us limit the maximum vocabulary size to 20000 and maximum length of article to 200 (These are just initial params to get you started and we recommend experimenting, to improve your scores after you are done with your first implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 36\n",
    "VOCAB_SIZE = 12000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function which takes article file, summary file, maximum length of sentence and vocabulary size and does the following\n",
    "* Create vocabulary: Take most frequent VOCAB_SIZE number of words from article file. Add two special symbols ZERO at start and UNK at end to finally have VOCAB_SIZE + 2 words. Use this array as idx2word. Repeat the process for summary data to create another idx2word corresponding to it. \n",
    "* Using the above idx2word for both article and summary data, create word2idx, which will map every word to its index in idx2word array. \n",
    "* Convert the words in the article and summary data to their corresponding index from word2idx. If a word is not present in the vocab, use the index of UNK. \n",
    "* After the above preprocessing, each sentence in article and summary data should be a list of indices\n",
    "* Now find the max length of a sentence (which is basically number of indices in a sentence) in article data. Pad every sentence in article data to that length, so that all sentences are of same length. You may use pad_sequences function provided by keras. Do the same for title data.\n",
    "* return the following outputs transformed article data, vocab size of article data, idx2word(articledata), word2idx(articledata),transformed summary data, vocab size of summary data, idx2word(summarydata), word2idx(summarydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(article, summary, max_len, vocab_size):\n",
    "    # get article vocabulary\n",
    "    tokenizer_1 = Tokenizer()\n",
    "    tokenizer_1.fit_on_texts(article)\n",
    "    counts_1=dict(tokenizer_1.word_counts)\n",
    "    words_1=sorted(counts_1.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    vocabWord_1=[x[0] for x in words_1][:vocab_size]\n",
    "    vocabWord_1.insert(0,'ZERO')\n",
    "    vocabIdx_1=list(range(0,vocab_size))\n",
    "    artVocabulary = dict(zip(vocabWord_1,vocabIdx_1))\n",
    "    \n",
    "    # get summary vocabulary\n",
    "    tokenizer_2 = Tokenizer()\n",
    "    tokenizer_2.fit_on_texts(summary)\n",
    "    counts_2=dict(tokenizer_2.word_counts)\n",
    "    words_2=sorted(counts_2.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    vocabWord_2=[x[0] for x in words_2][:vocab_size]\n",
    "    vocabWord_2.insert(0,'ZERO')\n",
    "    vocabIdx_2=list(range(0,vocab_size))\n",
    "    sumVococabulary = dict(zip(vocabWord_2,vocabIdx_2))\n",
    "    \n",
    "    #\n",
    "    unk_idx_article = artVocabulary.get('unk')\n",
    "    artMapData=[]   \n",
    "    for i in range(len(article)):\n",
    "        x=text_to_word_sequence(article[i],filters='',lower=True,split=\" \")\n",
    "        d=[artVocabulary[n] if n in artVocabulary else unk_idx_article for n in x] \n",
    "        artMapData.append(d)\n",
    "        \n",
    "    #\n",
    "    unk_idx_summary = sumVococabulary.get('unk')\n",
    "    sumMapData=[]   \n",
    "    for i in range(len(summary)):\n",
    "        x=text_to_word_sequence(summary[i],filters='',lower=True,split=\" \")\n",
    "        d=[sumVococabulary[n] if n in sumVococabulary else unk_idx_summary for n in x] \n",
    "        sumMapData.append(d)\n",
    "    \n",
    "    \n",
    "    artPadData = pad_sequences(artMapData,maxlen=max_len, padding='post', truncating='post') \n",
    "    sumPadData=pad_sequences(sumMapData,maxlen= max_len, padding='post', truncating='post')\n",
    "    \n",
    "    len_of_artVoc = len(artVocabulary)\n",
    "    len_of_sumVoc = len(sumVococabulary)\n",
    "    \n",
    "    idx2word_articledata = {v: k for k, v in artVocabulary.items()}\n",
    "    idx2word_summarydata = {v: k for k, v in sumVococabulary.items()}\n",
    "    \n",
    "    return artPadData,len_of_artVoc, artVocabulary,idx2word_articledata,sumPadData,len_of_sumVoc,sumVococabulary,idx2word_summarydata\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the above function to load the training data from article and summary (i.e. title) files. Do note that, based on your model architecture, you may need to further one-hot vectorize your input to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TO-DO \n",
    "article_text_train =  open('data/train_article.txt', 'r')\n",
    "summary_text_train =  open('data/train_title.txt', 'r')\n",
    "\n",
    "\n",
    "articleTrain_data=article_text_train.read().splitlines()\n",
    "summaryTrain_data=summary_text_train.read().splitlines()\n",
    "\n",
    "\n",
    "\n",
    "training_article_data = load_data(articleTrain_data,summaryTrain_data,MAX_LEN,VOCAB_SIZE)\n",
    "\n",
    "\n",
    "\n",
    "transformed_article_data_train = training_article_data[0]\n",
    "Vocab_size_of_article_train = training_article_data[1]\n",
    "word2idx_article_train = training_article_data[2]\n",
    "dx2word_articl_train = training_article_data[3]\n",
    "transformed_summary_data_train = training_article_data[4]\n",
    "Vocab_size_of_summary_train = training_article_data[5]\n",
    "word2idx_summary_train = training_article_data[6]\n",
    "idx2word_summary_train = training_article_data[7]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unidirectional LSTM Encoder Decoder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the parameters for your LSTM encoder decoder model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 35\n",
    "NUM_LAYERS = 1\n",
    "HIDDEN_DIM = 30\n",
    "EPOCHS = 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Unidirectional encoder decoder LSTM model in create_model function. The model should have a LSTM Unidirectional layer as encoder and a LSTM decoder.\n",
    "Use categorical_cross_entropy loss and experiment with different optimizers to improve your score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_UniLSTM(X_vocab_len, X_max_len, y_vocab_len, y_max_len, hidden_size, num_layers):\n",
    "    # TO-DO\n",
    "    # create and return the model for unidirectional LSTM encoder decoder\n",
    "   \n",
    "    model = Sequential()\n",
    "    #encoder\n",
    "    #Add embedding layer\n",
    "    model.add(Embedding(input_dim=X_vocab_len, output_dim=200, input_length=MAX_LEN,mask_zero=True,trainable=False))\n",
    "    #Add LSTM Layer as encoder\n",
    "    model.add(LSTM(hidden_size))\n",
    "    #Add RepeatVector Layer\n",
    "    model.add(RepeatVector(MAX_LEN))\n",
    "    \n",
    "    #decoder\n",
    "    #Add LSTM layer as decoder\n",
    "    model.add(LSTM(hidden_size, return_sequences=True))\n",
    "    #Add timedistributed dense layer\n",
    "    model.add(TimeDistributed(Dense(y_vocab_len)))\n",
    "    #Add activation layer\n",
    "    model.add(Activation('softmax'))\n",
    "    #Add compile layer\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])    \n",
    "    #Add summary layer\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "# reference: https://machinelearningmastery.com/encoder-decoder-attention-sequence-to-sequence-prediction-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have everything in place, we can run our model. We recommend training the model in batches instead of training on all 50,000 article-title pairs at once, if you encounter memory contraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 36, 200)           2400000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 30)                27720     \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 36, 30)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 36, 30)            7320      \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 36, 12000)         372000    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 36, 12000)         0         \n",
      "=================================================================\n",
      "Total params: 2,807,040\n",
      "Trainable params: 407,040\n",
      "Non-trainable params: 2,400,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# TO-DO\n",
    "\n",
    "model=create_UniLSTM(Vocab_size_of_article_train,MAX_LEN,Vocab_size_of_summary_train,MAX_LEN,HIDDEN_DIM,NUM_LAYERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "# model_json = model_without_attention.to_json()\n",
    "# with open(\"./without_attention_model_json_folder1/without_attention_model.json\", \"w\") as json_file:\n",
    "#    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medel is training: epoch 1th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7710 - acc: 0.7801     \n",
      "Medel is training: epoch 1th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6165 - acc: 0.8034     \n",
      "Medel is training: epoch 5th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4850 - acc: 0.8137     \n",
      "Medel is training: epoch 5th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6881 - acc: 0.7944     \n",
      "Medel is training: epoch 5th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5287 - acc: 0.8122     \n",
      "Medel is training: epoch 5th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6112 - acc: 0.8020     \n",
      "Medel is training: epoch 5th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6523 - acc: 0.8004     \n",
      "Medel is training: epoch 5th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4959 - acc: 0.8142     \n",
      "Medel is training: epoch 5th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7244 - acc: 0.7893     \n",
      "Medel is training: epoch 5th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6074 - acc: 0.8056     \n",
      "Medel is training: epoch 5th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4754 - acc: 0.8151     \n",
      "Medel is training: epoch 5th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6714 - acc: 0.7964     \n",
      "Medel is training: epoch 5th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6168 - acc: 0.8058     \n",
      "Medel is training: epoch 5th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4519 - acc: 0.8175     \n",
      "Medel is training: epoch 5th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6902 - acc: 0.7935     \n",
      "Medel is training: epoch 5th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5989 - acc: 0.8091     \n",
      "Medel is training: epoch 5th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4804 - acc: 0.8160     \n",
      "Medel is training: epoch 5th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6567 - acc: 0.7973     \n",
      "Medel is training: epoch 5th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6464 - acc: 0.8015     \n",
      "Medel is training: epoch 5th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5327 - acc: 0.8097     \n",
      "Medel is training: epoch 5th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5165 - acc: 0.8103     \n",
      "Medel is training: epoch 5th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7112 - acc: 0.7933     \n",
      "Medel is training: epoch 5th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6146 - acc: 0.8055     \n",
      "Medel is training: epoch 5th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3767 - acc: 0.8235     \n",
      "Medel is training: epoch 5th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7280 - acc: 0.7918     \n",
      "Medel is training: epoch 5th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6132 - acc: 0.8050     \n",
      "Medel is training: epoch 5th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4253 - acc: 0.8179     \n",
      "Medel is training: epoch 5th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5335 - acc: 0.8090     \n",
      "Medel is training: epoch 5th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7019 - acc: 0.7933     \n",
      "Medel is training: epoch 5th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6285 - acc: 0.8042     \n",
      "Medel is training: epoch 5th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3417 - acc: 0.8221     \n",
      "Medel is training: epoch 5th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6727 - acc: 0.7962     \n",
      "Medel is training: epoch 5th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6442 - acc: 0.8030     \n",
      "Medel is training: epoch 5th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5602 - acc: 0.8083     \n",
      "Medel is training: epoch 5th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3515 - acc: 0.8226     \n",
      "Medel is training: epoch 5th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7411 - acc: 0.7889     \n",
      "Medel is training: epoch 5th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5864 - acc: 0.8101     \n",
      "Medel is training: epoch 5th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6067 - acc: 0.8020     \n",
      "Medel is training: epoch 5th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3499 - acc: 0.8221     \n",
      "Medel is training: epoch 5th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7230 - acc: 0.7903     \n",
      "Medel is training: epoch 5th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6254 - acc: 0.8043     \n",
      "Medel is training: epoch 5th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5453 - acc: 0.8076     \n",
      "Medel is training: epoch 5th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3579 - acc: 0.8209     \n",
      "Medel is training: epoch 5th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7185 - acc: 0.7902     \n",
      "Medel is training: epoch 5th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6760 - acc: 0.7980     \n",
      "Medel is training: epoch 5th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.9374 - acc: 0.9722\n",
      "Medel is training: epoch 6th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7110 - acc: 0.7930     \n",
      "Medel is training: epoch 6th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5258 - acc: 0.8124     \n",
      "Medel is training: epoch 6th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5842 - acc: 0.8029     \n",
      "Medel is training: epoch 6th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5912 - acc: 0.8071     \n",
      "Medel is training: epoch 6th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4883 - acc: 0.8146     \n",
      "Medel is training: epoch 6th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6753 - acc: 0.7960     \n",
      "Medel is training: epoch 6th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6134 - acc: 0.8032     \n",
      "Medel is training: epoch 6th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4795 - acc: 0.8138     \n",
      "Medel is training: epoch 6th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6849 - acc: 0.7944     \n",
      "Medel is training: epoch 6th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5216 - acc: 0.8123     \n",
      "Medel is training: epoch 6th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6058 - acc: 0.8020     \n",
      "Medel is training: epoch 6th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6496 - acc: 0.8005     \n",
      "Medel is training: epoch 6th 12000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.4911 - acc: 0.8144     \n",
      "Medel is training: epoch 6th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7208 - acc: 0.7893     \n",
      "Medel is training: epoch 6th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6026 - acc: 0.8060     \n",
      "Medel is training: epoch 6th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4693 - acc: 0.8151     \n",
      "Medel is training: epoch 6th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6673 - acc: 0.7964     \n",
      "Medel is training: epoch 6th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6125 - acc: 0.8057     \n",
      "Medel is training: epoch 6th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4490 - acc: 0.8175     \n",
      "Medel is training: epoch 6th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6857 - acc: 0.7935     \n",
      "Medel is training: epoch 6th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5932 - acc: 0.8091     \n",
      "Medel is training: epoch 6th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4763 - acc: 0.8161     \n",
      "Medel is training: epoch 6th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6504 - acc: 0.7973     \n",
      "Medel is training: epoch 6th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6423 - acc: 0.8016     \n",
      "Medel is training: epoch 6th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5285 - acc: 0.8099     \n",
      "Medel is training: epoch 6th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5098 - acc: 0.8103     \n",
      "Medel is training: epoch 6th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7083 - acc: 0.7932     \n",
      "Medel is training: epoch 6th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6108 - acc: 0.8056     \n",
      "Medel is training: epoch 6th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3722 - acc: 0.8235     \n",
      "Medel is training: epoch 6th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7239 - acc: 0.7918     \n",
      "Medel is training: epoch 6th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6056 - acc: 0.8048     \n",
      "Medel is training: epoch 6th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4216 - acc: 0.8182     \n",
      "Medel is training: epoch 6th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5265 - acc: 0.8090     \n",
      "Medel is training: epoch 6th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6997 - acc: 0.7936     \n",
      "Medel is training: epoch 6th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6256 - acc: 0.8043     \n",
      "Medel is training: epoch 6th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3375 - acc: 0.8221     \n",
      "Medel is training: epoch 6th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6697 - acc: 0.7962     \n",
      "Medel is training: epoch 6th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6362 - acc: 0.8028     \n",
      "Medel is training: epoch 6th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5578 - acc: 0.8087     \n",
      "Medel is training: epoch 6th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3456 - acc: 0.8226     \n",
      "Medel is training: epoch 6th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7417 - acc: 0.7889     \n",
      "Medel is training: epoch 6th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5789 - acc: 0.8101     \n",
      "Medel is training: epoch 6th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6034 - acc: 0.8028     \n",
      "Medel is training: epoch 6th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3449 - acc: 0.8221     \n",
      "Medel is training: epoch 6th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7226 - acc: 0.7903     \n",
      "Medel is training: epoch 6th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6209 - acc: 0.8043     \n",
      "Medel is training: epoch 6th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5419 - acc: 0.8075     \n",
      "Medel is training: epoch 6th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3521 - acc: 0.8209     \n",
      "Medel is training: epoch 6th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7164 - acc: 0.7901     \n",
      "Medel is training: epoch 6th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6728 - acc: 0.7979     \n",
      "Medel is training: epoch 6th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.8567 - acc: 0.9722\n",
      "Medel is training: epoch 7th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7068 - acc: 0.7937     \n",
      "Medel is training: epoch 7th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5216 - acc: 0.8127     \n",
      "Medel is training: epoch 7th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5804 - acc: 0.8029     \n",
      "Medel is training: epoch 7th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5890 - acc: 0.8071     \n",
      "Medel is training: epoch 7th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4845 - acc: 0.8146     \n",
      "Medel is training: epoch 7th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6733 - acc: 0.7960     \n",
      "Medel is training: epoch 7th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6088 - acc: 0.8034     \n",
      "Medel is training: epoch 7th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4758 - acc: 0.8140     \n",
      "Medel is training: epoch 7th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6797 - acc: 0.7945     \n",
      "Medel is training: epoch 7th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5158 - acc: 0.8127     \n",
      "Medel is training: epoch 7th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5998 - acc: 0.8020     \n",
      "Medel is training: epoch 7th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6462 - acc: 0.8005     \n",
      "Medel is training: epoch 7th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4854 - acc: 0.8145     \n",
      "Medel is training: epoch 7th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7149 - acc: 0.7893     \n",
      "Medel is training: epoch 7th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6002 - acc: 0.8061     \n",
      "Medel is training: epoch 7th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4654 - acc: 0.8151     \n",
      "Medel is training: epoch 7th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6638 - acc: 0.7964     \n",
      "Medel is training: epoch 7th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6075 - acc: 0.8059     \n",
      "Medel is training: epoch 7th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4450 - acc: 0.8175     \n",
      "Medel is training: epoch 7th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6776 - acc: 0.7935     \n",
      "Medel is training: epoch 7th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5887 - acc: 0.8089     \n",
      "Medel is training: epoch 7th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4712 - acc: 0.8160     \n",
      "Medel is training: epoch 7th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6450 - acc: 0.7973     \n",
      "Medel is training: epoch 7th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6390 - acc: 0.8016     \n",
      "Medel is training: epoch 7th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5243 - acc: 0.8101     \n",
      "Medel is training: epoch 7th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5042 - acc: 0.8103     \n",
      "Medel is training: epoch 7th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7046 - acc: 0.7935     \n",
      "Medel is training: epoch 7th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6075 - acc: 0.8056     \n",
      "Medel is training: epoch 7th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3670 - acc: 0.8235     \n",
      "Medel is training: epoch 7th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7201 - acc: 0.7918     \n",
      "Medel is training: epoch 7th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6019 - acc: 0.8051     \n",
      "Medel is training: epoch 7th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4185 - acc: 0.8179     \n",
      "Medel is training: epoch 7th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5209 - acc: 0.8090     \n",
      "Medel is training: epoch 7th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6975 - acc: 0.7937     \n",
      "Medel is training: epoch 7th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6225 - acc: 0.8043     \n",
      "Medel is training: epoch 7th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3323 - acc: 0.8220     \n",
      "Medel is training: epoch 7th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6648 - acc: 0.7962     \n",
      "Medel is training: epoch 7th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6333 - acc: 0.8028     \n",
      "Medel is training: epoch 7th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5550 - acc: 0.8084     \n",
      "Medel is training: epoch 7th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3407 - acc: 0.8226     \n",
      "Medel is training: epoch 7th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 6s - loss: 1.7352 - acc: 0.7889     \n",
      "Medel is training: epoch 7th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5765 - acc: 0.8101     \n",
      "Medel is training: epoch 7th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6005 - acc: 0.8030     \n",
      "Medel is training: epoch 7th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3396 - acc: 0.8223     \n",
      "Medel is training: epoch 7th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7172 - acc: 0.7903     \n",
      "Medel is training: epoch 7th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6179 - acc: 0.8043     \n",
      "Medel is training: epoch 7th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5384 - acc: 0.8082     \n",
      "Medel is training: epoch 7th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3466 - acc: 0.8209     \n",
      "Medel is training: epoch 7th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7127 - acc: 0.7904     \n",
      "Medel is training: epoch 7th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6700 - acc: 0.7979     \n",
      "Medel is training: epoch 7th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.7879 - acc: 0.9722\n",
      "Medel is training: epoch 8th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7038 - acc: 0.7937     \n",
      "Medel is training: epoch 8th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5185 - acc: 0.8126     \n",
      "Medel is training: epoch 8th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5764 - acc: 0.8029     \n",
      "Medel is training: epoch 8th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5860 - acc: 0.8070     \n",
      "Medel is training: epoch 8th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4805 - acc: 0.8150     \n",
      "Medel is training: epoch 8th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6681 - acc: 0.7959     \n",
      "Medel is training: epoch 8th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6049 - acc: 0.8036     \n",
      "Medel is training: epoch 8th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4705 - acc: 0.8142     \n",
      "Medel is training: epoch 8th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6757 - acc: 0.7947     \n",
      "Medel is training: epoch 8th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5133 - acc: 0.8124     \n",
      "Medel is training: epoch 8th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5962 - acc: 0.8024     \n",
      "Medel is training: epoch 8th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6437 - acc: 0.8007     \n",
      "Medel is training: epoch 8th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4819 - acc: 0.8144     \n",
      "Medel is training: epoch 8th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7094 - acc: 0.7896     \n",
      "Medel is training: epoch 8th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5982 - acc: 0.8058     \n",
      "Medel is training: epoch 8th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4604 - acc: 0.8152     \n",
      "Medel is training: epoch 8th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6580 - acc: 0.7964     \n",
      "Medel is training: epoch 8th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6061 - acc: 0.8058     \n",
      "Medel is training: epoch 8th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4418 - acc: 0.8175     \n",
      "Medel is training: epoch 8th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6743 - acc: 0.7935     \n",
      "Medel is training: epoch 8th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5856 - acc: 0.8094     \n",
      "Medel is training: epoch 8th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4665 - acc: 0.8159     \n",
      "Medel is training: epoch 8th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6399 - acc: 0.7973     \n",
      "Medel is training: epoch 8th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6364 - acc: 0.8017     \n",
      "Medel is training: epoch 8th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5201 - acc: 0.8104     \n",
      "Medel is training: epoch 8th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4996 - acc: 0.8103     \n",
      "Medel is training: epoch 8th 26000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.7017 - acc: 0.7941     \n",
      "Medel is training: epoch 8th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6044 - acc: 0.8056     \n",
      "Medel is training: epoch 8th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3613 - acc: 0.8236     \n",
      "Medel is training: epoch 8th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7142 - acc: 0.7918     \n",
      "Medel is training: epoch 8th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5994 - acc: 0.8049     \n",
      "Medel is training: epoch 8th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4123 - acc: 0.8181     \n",
      "Medel is training: epoch 8th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5156 - acc: 0.8090     \n",
      "Medel is training: epoch 8th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6930 - acc: 0.7936     \n",
      "Medel is training: epoch 8th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6196 - acc: 0.8043     \n",
      "Medel is training: epoch 8th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3276 - acc: 0.8216     \n",
      "Medel is training: epoch 8th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6603 - acc: 0.7962     \n",
      "Medel is training: epoch 8th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6307 - acc: 0.8027     \n",
      "Medel is training: epoch 8th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5523 - acc: 0.8084     \n",
      "Medel is training: epoch 8th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3353 - acc: 0.8228     \n",
      "Medel is training: epoch 8th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7295 - acc: 0.7893     \n",
      "Medel is training: epoch 8th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5743 - acc: 0.8101     \n",
      "Medel is training: epoch 8th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5981 - acc: 0.8030     \n",
      "Medel is training: epoch 8th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3353 - acc: 0.8223     \n",
      "Medel is training: epoch 8th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7144 - acc: 0.7904     \n",
      "Medel is training: epoch 8th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6146 - acc: 0.8043     \n",
      "Medel is training: epoch 8th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5349 - acc: 0.8082     \n",
      "Medel is training: epoch 8th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3414 - acc: 0.8210     \n",
      "Medel is training: epoch 8th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7065 - acc: 0.7907     \n",
      "Medel is training: epoch 8th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6657 - acc: 0.7979     \n",
      "Medel is training: epoch 8th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.7284 - acc: 0.9722\n",
      "Medel is training: epoch 9th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7012 - acc: 0.7937     \n",
      "Medel is training: epoch 9th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5166 - acc: 0.8129     \n",
      "Medel is training: epoch 9th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5739 - acc: 0.8032     \n",
      "Medel is training: epoch 9th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5841 - acc: 0.8070     \n",
      "Medel is training: epoch 9th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4774 - acc: 0.8152     \n",
      "Medel is training: epoch 9th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6656 - acc: 0.7966     \n",
      "Medel is training: epoch 9th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6030 - acc: 0.8037     \n",
      "Medel is training: epoch 9th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4674 - acc: 0.8146     \n",
      "Medel is training: epoch 9th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6735 - acc: 0.7956     \n",
      "Medel is training: epoch 9th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5099 - acc: 0.8124     \n",
      "Medel is training: epoch 9th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5928 - acc: 0.8033     \n",
      "Medel is training: epoch 9th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6414 - acc: 0.8009     \n",
      "Medel is training: epoch 9th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4788 - acc: 0.8147     \n",
      "Medel is training: epoch 9th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7056 - acc: 0.7901     \n",
      "Medel is training: epoch 9th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5953 - acc: 0.8058     \n",
      "Medel is training: epoch 9th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4565 - acc: 0.8154     \n",
      "Medel is training: epoch 9th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6542 - acc: 0.7964     \n",
      "Medel is training: epoch 9th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6038 - acc: 0.8057     \n",
      "Medel is training: epoch 9th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4372 - acc: 0.8176     \n",
      "Medel is training: epoch 9th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6701 - acc: 0.7936     \n",
      "Medel is training: epoch 9th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5836 - acc: 0.8092     \n",
      "Medel is training: epoch 9th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4635 - acc: 0.8158     \n",
      "Medel is training: epoch 9th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6358 - acc: 0.7973     \n",
      "Medel is training: epoch 9th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6334 - acc: 0.8022     \n",
      "Medel is training: epoch 9th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5162 - acc: 0.8106     \n",
      "Medel is training: epoch 9th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4956 - acc: 0.8109     \n",
      "Medel is training: epoch 9th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6974 - acc: 0.7943     \n",
      "Medel is training: epoch 9th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6025 - acc: 0.8056     \n",
      "Medel is training: epoch 9th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3567 - acc: 0.8235     \n",
      "Medel is training: epoch 9th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7097 - acc: 0.7919     \n",
      "Medel is training: epoch 9th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5973 - acc: 0.8049     \n",
      "Medel is training: epoch 9th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4062 - acc: 0.8185     \n",
      "Medel is training: epoch 9th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5108 - acc: 0.8091     \n",
      "Medel is training: epoch 9th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6894 - acc: 0.7941     \n",
      "Medel is training: epoch 9th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6169 - acc: 0.8043     \n",
      "Medel is training: epoch 9th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3213 - acc: 0.8221     \n",
      "Medel is training: epoch 9th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6550 - acc: 0.7962     \n",
      "Medel is training: epoch 9th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6271 - acc: 0.8029     \n",
      "Medel is training: epoch 9th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5492 - acc: 0.8084     \n",
      "Medel is training: epoch 9th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3310 - acc: 0.8229     \n",
      "Medel is training: epoch 9th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7241 - acc: 0.7896     \n",
      "Medel is training: epoch 9th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5721 - acc: 0.8101     \n",
      "Medel is training: epoch 9th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5954 - acc: 0.8029     \n",
      "Medel is training: epoch 9th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3310 - acc: 0.8223     \n",
      "Medel is training: epoch 9th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7110 - acc: 0.7906     \n",
      "Medel is training: epoch 9th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6121 - acc: 0.8043     \n",
      "Medel is training: epoch 9th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5321 - acc: 0.8081     \n",
      "Medel is training: epoch 9th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3383 - acc: 0.8214     \n",
      "Medel is training: epoch 9th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7039 - acc: 0.7910     \n",
      "Medel is training: epoch 9th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6625 - acc: 0.7979     \n",
      "Medel is training: epoch 9th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.6788 - acc: 0.9722\n",
      "Medel is training: epoch 10th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6985 - acc: 0.7937     \n",
      "Medel is training: epoch 10th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5149 - acc: 0.8128     \n",
      "Medel is training: epoch 10th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5721 - acc: 0.8034     \n",
      "Medel is training: epoch 10th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5827 - acc: 0.8071     \n",
      "Medel is training: epoch 10th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4755 - acc: 0.8155     \n",
      "Medel is training: epoch 10th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6633 - acc: 0.7969     \n",
      "Medel is training: epoch 10th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6008 - acc: 0.8037     \n",
      "Medel is training: epoch 10th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4645 - acc: 0.8151     \n",
      "Medel is training: epoch 10th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6705 - acc: 0.7958     \n",
      "Medel is training: epoch 10th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5076 - acc: 0.8124     \n",
      "Medel is training: epoch 10th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5898 - acc: 0.8033     \n",
      "Medel is training: epoch 10th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 6s - loss: 1.6392 - acc: 0.8009     \n",
      "Medel is training: epoch 10th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4759 - acc: 0.8148     \n",
      "Medel is training: epoch 10th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7028 - acc: 0.7904     \n",
      "Medel is training: epoch 10th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5940 - acc: 0.8058     \n",
      "Medel is training: epoch 10th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4546 - acc: 0.8156     \n",
      "Medel is training: epoch 10th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6520 - acc: 0.7969     \n",
      "Medel is training: epoch 10th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6017 - acc: 0.8058     \n",
      "Medel is training: epoch 10th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4346 - acc: 0.8179     \n",
      "Medel is training: epoch 10th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6670 - acc: 0.7940     \n",
      "Medel is training: epoch 10th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5824 - acc: 0.8092     \n",
      "Medel is training: epoch 10th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4598 - acc: 0.8160     \n",
      "Medel is training: epoch 10th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6341 - acc: 0.7976     \n",
      "Medel is training: epoch 10th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6323 - acc: 0.8022     \n",
      "Medel is training: epoch 10th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5139 - acc: 0.8108     \n",
      "Medel is training: epoch 10th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4931 - acc: 0.8111     \n",
      "Medel is training: epoch 10th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6966 - acc: 0.7943     \n",
      "Medel is training: epoch 10th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6014 - acc: 0.8056     \n",
      "Medel is training: epoch 10th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3547 - acc: 0.8232     \n",
      "Medel is training: epoch 10th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7074 - acc: 0.7919     \n",
      "Medel is training: epoch 10th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5952 - acc: 0.8050     \n",
      "Medel is training: epoch 10th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4034 - acc: 0.8184     \n",
      "Medel is training: epoch 10th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5069 - acc: 0.8096     \n",
      "Medel is training: epoch 10th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6880 - acc: 0.7941     \n",
      "Medel is training: epoch 10th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6151 - acc: 0.8043     \n",
      "Medel is training: epoch 10th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3168 - acc: 0.8220     \n",
      "Medel is training: epoch 10th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6505 - acc: 0.7966     \n",
      "Medel is training: epoch 10th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6249 - acc: 0.8029     \n",
      "Medel is training: epoch 10th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5470 - acc: 0.8084     \n",
      "Medel is training: epoch 10th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3280 - acc: 0.8231     \n",
      "Medel is training: epoch 10th 40000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.7210 - acc: 0.7898     \n",
      "Medel is training: epoch 10th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5708 - acc: 0.8101     \n",
      "Medel is training: epoch 10th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5937 - acc: 0.8029     \n",
      "Medel is training: epoch 10th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3272 - acc: 0.8223     \n",
      "Medel is training: epoch 10th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7078 - acc: 0.7917     \n",
      "Medel is training: epoch 10th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6100 - acc: 0.8044     \n",
      "Medel is training: epoch 10th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5292 - acc: 0.8082     \n",
      "Medel is training: epoch 10th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3347 - acc: 0.8216     \n",
      "Medel is training: epoch 10th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7017 - acc: 0.7914     \n",
      "Medel is training: epoch 10th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6617 - acc: 0.7979     \n",
      "Medel is training: epoch 10th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.6349 - acc: 0.9722\n",
      "Medel is training: epoch 11th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6967 - acc: 0.7937     \n",
      "Medel is training: epoch 11th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5126 - acc: 0.8128     \n",
      "Medel is training: epoch 11th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5692 - acc: 0.8037     \n",
      "Medel is training: epoch 11th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5810 - acc: 0.8070     \n",
      "Medel is training: epoch 11th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4724 - acc: 0.8156     \n",
      "Medel is training: epoch 11th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6615 - acc: 0.7969     \n",
      "Medel is training: epoch 11th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5997 - acc: 0.8038     \n",
      "Medel is training: epoch 11th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4620 - acc: 0.8148     \n",
      "Medel is training: epoch 11th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6691 - acc: 0.7958     \n",
      "Medel is training: epoch 11th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5056 - acc: 0.8124     \n",
      "Medel is training: epoch 11th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5874 - acc: 0.8033     \n",
      "Medel is training: epoch 11th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6377 - acc: 0.8008     \n",
      "Medel is training: epoch 11th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4736 - acc: 0.8147     \n",
      "Medel is training: epoch 11th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7001 - acc: 0.7904     \n",
      "Medel is training: epoch 11th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5921 - acc: 0.8058     \n",
      "Medel is training: epoch 11th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4515 - acc: 0.8156     \n",
      "Medel is training: epoch 11th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6486 - acc: 0.7971     \n",
      "Medel is training: epoch 11th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6004 - acc: 0.8058     \n",
      "Medel is training: epoch 11th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4323 - acc: 0.8179     \n",
      "Medel is training: epoch 11th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6642 - acc: 0.7942     \n",
      "Medel is training: epoch 11th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5801 - acc: 0.8093     \n",
      "Medel is training: epoch 11th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4570 - acc: 0.8161     \n",
      "Medel is training: epoch 11th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6306 - acc: 0.7978     \n",
      "Medel is training: epoch 11th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6304 - acc: 0.8023     \n",
      "Medel is training: epoch 11th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5119 - acc: 0.8107     \n",
      "Medel is training: epoch 11th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4898 - acc: 0.8114     \n",
      "Medel is training: epoch 11th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6945 - acc: 0.7942     \n",
      "Medel is training: epoch 11th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5984 - acc: 0.8056     \n",
      "Medel is training: epoch 11th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3505 - acc: 0.8234     \n",
      "Medel is training: epoch 11th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7027 - acc: 0.7921     \n",
      "Medel is training: epoch 11th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5957 - acc: 0.8049     \n",
      "Medel is training: epoch 11th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4007 - acc: 0.8185     \n",
      "Medel is training: epoch 11th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5052 - acc: 0.8097     \n",
      "Medel is training: epoch 11th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6855 - acc: 0.7942     \n",
      "Medel is training: epoch 11th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6136 - acc: 0.8043     \n",
      "Medel is training: epoch 11th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3138 - acc: 0.8218     \n",
      "Medel is training: epoch 11th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6472 - acc: 0.7973     \n",
      "Medel is training: epoch 11th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6230 - acc: 0.8029     \n",
      "Medel is training: epoch 11th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5448 - acc: 0.8084     \n",
      "Medel is training: epoch 11th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3252 - acc: 0.8229     \n",
      "Medel is training: epoch 11th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7183 - acc: 0.7904     \n",
      "Medel is training: epoch 11th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5690 - acc: 0.8101     \n",
      "Medel is training: epoch 11th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5918 - acc: 0.8029     \n",
      "Medel is training: epoch 11th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3247 - acc: 0.8223     \n",
      "Medel is training: epoch 11th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7068 - acc: 0.7917     \n",
      "Medel is training: epoch 11th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6091 - acc: 0.8044     \n",
      "Medel is training: epoch 11th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5282 - acc: 0.8082     \n",
      "Medel is training: epoch 11th 47000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.3316 - acc: 0.8217     \n",
      "Medel is training: epoch 11th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7002 - acc: 0.7915     \n",
      "Medel is training: epoch 11th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6599 - acc: 0.7979     \n",
      "Medel is training: epoch 11th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5924 - acc: 0.9722\n",
      "Medel is training: epoch 12th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6946 - acc: 0.7937     \n",
      "Medel is training: epoch 12th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5108 - acc: 0.8129     \n",
      "Medel is training: epoch 12th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5660 - acc: 0.8038     \n",
      "Medel is training: epoch 12th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5794 - acc: 0.8071     \n",
      "Medel is training: epoch 12th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4697 - acc: 0.8156     \n",
      "Medel is training: epoch 12th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6590 - acc: 0.7970     \n",
      "Medel is training: epoch 12th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5984 - acc: 0.8037     \n",
      "Medel is training: epoch 12th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4590 - acc: 0.8148     \n",
      "Medel is training: epoch 12th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6683 - acc: 0.7958     \n",
      "Medel is training: epoch 12th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5033 - acc: 0.8124     \n",
      "Medel is training: epoch 12th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5849 - acc: 0.8032     \n",
      "Medel is training: epoch 12th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6361 - acc: 0.8008     \n",
      "Medel is training: epoch 12th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4712 - acc: 0.8146     \n",
      "Medel is training: epoch 12th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6979 - acc: 0.7906     \n",
      "Medel is training: epoch 12th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5907 - acc: 0.8058     \n",
      "Medel is training: epoch 12th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4482 - acc: 0.8156     \n",
      "Medel is training: epoch 12th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6468 - acc: 0.7971     \n",
      "Medel is training: epoch 12th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5983 - acc: 0.8058     \n",
      "Medel is training: epoch 12th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4298 - acc: 0.8177     \n",
      "Medel is training: epoch 12th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6622 - acc: 0.7944     \n",
      "Medel is training: epoch 12th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5785 - acc: 0.8093     \n",
      "Medel is training: epoch 12th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4547 - acc: 0.8160     \n",
      "Medel is training: epoch 12th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6276 - acc: 0.7980     \n",
      "Medel is training: epoch 12th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6286 - acc: 0.8022     \n",
      "Medel is training: epoch 12th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5094 - acc: 0.8107     \n",
      "Medel is training: epoch 12th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4878 - acc: 0.8114     \n",
      "Medel is training: epoch 12th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6925 - acc: 0.7942     \n",
      "Medel is training: epoch 12th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5976 - acc: 0.8056     \n",
      "Medel is training: epoch 12th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3468 - acc: 0.8234     \n",
      "Medel is training: epoch 12th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7017 - acc: 0.7924     \n",
      "Medel is training: epoch 12th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5931 - acc: 0.8049     \n",
      "Medel is training: epoch 12th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3966 - acc: 0.8185     \n",
      "Medel is training: epoch 12th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5019 - acc: 0.8099     \n",
      "Medel is training: epoch 12th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6833 - acc: 0.7943     \n",
      "Medel is training: epoch 12th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6120 - acc: 0.8043     \n",
      "Medel is training: epoch 12th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3095 - acc: 0.8219     \n",
      "Medel is training: epoch 12th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6448 - acc: 0.7972     \n",
      "Medel is training: epoch 12th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6212 - acc: 0.8029     \n",
      "Medel is training: epoch 12th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5424 - acc: 0.8085     \n",
      "Medel is training: epoch 12th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3213 - acc: 0.8232     \n",
      "Medel is training: epoch 12th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7154 - acc: 0.7904     \n",
      "Medel is training: epoch 12th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5679 - acc: 0.8101     \n",
      "Medel is training: epoch 12th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5903 - acc: 0.8029     \n",
      "Medel is training: epoch 12th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3211 - acc: 0.8222     \n",
      "Medel is training: epoch 12th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7042 - acc: 0.7916     \n",
      "Medel is training: epoch 12th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6079 - acc: 0.8043     \n",
      "Medel is training: epoch 12th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5250 - acc: 0.8082     \n",
      "Medel is training: epoch 12th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3281 - acc: 0.8216     \n",
      "Medel is training: epoch 12th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6979 - acc: 0.7914     \n",
      "Medel is training: epoch 12th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6592 - acc: 0.7977     \n",
      "Medel is training: epoch 12th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5558 - acc: 0.9722\n",
      "Medel is training: epoch 13th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6930 - acc: 0.7937     \n",
      "Medel is training: epoch 13th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5091 - acc: 0.8128     \n",
      "Medel is training: epoch 13th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5637 - acc: 0.8039     \n",
      "Medel is training: epoch 13th 3000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.5779 - acc: 0.8070     \n",
      "Medel is training: epoch 13th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4673 - acc: 0.8157     \n",
      "Medel is training: epoch 13th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6576 - acc: 0.7969     \n",
      "Medel is training: epoch 13th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5972 - acc: 0.8038     \n",
      "Medel is training: epoch 13th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4565 - acc: 0.8148     \n",
      "Medel is training: epoch 13th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6663 - acc: 0.7958     \n",
      "Medel is training: epoch 13th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5012 - acc: 0.8124     \n",
      "Medel is training: epoch 13th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5828 - acc: 0.8032     \n",
      "Medel is training: epoch 13th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6345 - acc: 0.8008     \n",
      "Medel is training: epoch 13th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4689 - acc: 0.8147     \n",
      "Medel is training: epoch 13th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6971 - acc: 0.7904     \n",
      "Medel is training: epoch 13th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5891 - acc: 0.8058     \n",
      "Medel is training: epoch 13th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4461 - acc: 0.8157     \n",
      "Medel is training: epoch 13th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6454 - acc: 0.7970     \n",
      "Medel is training: epoch 13th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5981 - acc: 0.8058     \n",
      "Medel is training: epoch 13th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4267 - acc: 0.8180     \n",
      "Medel is training: epoch 13th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6623 - acc: 0.7943     \n",
      "Medel is training: epoch 13th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5778 - acc: 0.8092     \n",
      "Medel is training: epoch 13th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4527 - acc: 0.8161     \n",
      "Medel is training: epoch 13th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6266 - acc: 0.7979     \n",
      "Medel is training: epoch 13th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6268 - acc: 0.8023     \n",
      "Medel is training: epoch 13th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5067 - acc: 0.8108     \n",
      "Medel is training: epoch 13th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4849 - acc: 0.8114     \n",
      "Medel is training: epoch 13th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6909 - acc: 0.7943     \n",
      "Medel is training: epoch 13th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5959 - acc: 0.8056     \n",
      "Medel is training: epoch 13th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3442 - acc: 0.8232     \n",
      "Medel is training: epoch 13th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7004 - acc: 0.7925     \n",
      "Medel is training: epoch 13th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5918 - acc: 0.8050     \n",
      "Medel is training: epoch 13th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3910 - acc: 0.8186     \n",
      "Medel is training: epoch 13th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4999 - acc: 0.8099     \n",
      "Medel is training: epoch 13th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6817 - acc: 0.7941     \n",
      "Medel is training: epoch 13th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6112 - acc: 0.8043     \n",
      "Medel is training: epoch 13th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3052 - acc: 0.8221     \n",
      "Medel is training: epoch 13th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6453 - acc: 0.7971     \n",
      "Medel is training: epoch 13th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6197 - acc: 0.8028     \n",
      "Medel is training: epoch 13th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5406 - acc: 0.8085     \n",
      "Medel is training: epoch 13th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3155 - acc: 0.8233     \n",
      "Medel is training: epoch 13th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7140 - acc: 0.7904     \n",
      "Medel is training: epoch 13th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5666 - acc: 0.8101     \n",
      "Medel is training: epoch 13th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5887 - acc: 0.8030     \n",
      "Medel is training: epoch 13th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3156 - acc: 0.8223     \n",
      "Medel is training: epoch 13th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7017 - acc: 0.7914     \n",
      "Medel is training: epoch 13th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6081 - acc: 0.8043     \n",
      "Medel is training: epoch 13th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5225 - acc: 0.8082     \n",
      "Medel is training: epoch 13th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3217 - acc: 0.8217     \n",
      "Medel is training: epoch 13th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6939 - acc: 0.7914     \n",
      "Medel is training: epoch 13th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6577 - acc: 0.7979     \n",
      "Medel is training: epoch 13th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.5253 - acc: 0.9722\n",
      "Medel is training: epoch 14th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6912 - acc: 0.7937     \n",
      "Medel is training: epoch 14th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5070 - acc: 0.8128     \n",
      "Medel is training: epoch 14th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5608 - acc: 0.8038     \n",
      "Medel is training: epoch 14th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5765 - acc: 0.8070     \n",
      "Medel is training: epoch 14th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4637 - acc: 0.8157     \n",
      "Medel is training: epoch 14th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6561 - acc: 0.7969     \n",
      "Medel is training: epoch 14th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5959 - acc: 0.8038     \n",
      "Medel is training: epoch 14th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4536 - acc: 0.8147     \n",
      "Medel is training: epoch 14th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6644 - acc: 0.7959     \n",
      "Medel is training: epoch 14th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4995 - acc: 0.8123     \n",
      "Medel is training: epoch 14th 10000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.5801 - acc: 0.8031     \n",
      "Medel is training: epoch 14th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6333 - acc: 0.8008     \n",
      "Medel is training: epoch 14th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4649 - acc: 0.8146     \n",
      "Medel is training: epoch 14th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6931 - acc: 0.7905     \n",
      "Medel is training: epoch 14th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5883 - acc: 0.8058     \n",
      "Medel is training: epoch 14th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4404 - acc: 0.8156     \n",
      "Medel is training: epoch 14th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6427 - acc: 0.7971     \n",
      "Medel is training: epoch 14th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5959 - acc: 0.8058     \n",
      "Medel is training: epoch 14th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4219 - acc: 0.8179     \n",
      "Medel is training: epoch 14th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6586 - acc: 0.7943     \n",
      "Medel is training: epoch 14th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5781 - acc: 0.8092     \n",
      "Medel is training: epoch 14th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4461 - acc: 0.8160     \n",
      "Medel is training: epoch 14th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6242 - acc: 0.7980     \n",
      "Medel is training: epoch 14th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6254 - acc: 0.8021     \n",
      "Medel is training: epoch 14th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5017 - acc: 0.8107     \n",
      "Medel is training: epoch 14th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4793 - acc: 0.8115     \n",
      "Medel is training: epoch 14th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6887 - acc: 0.7943     \n",
      "Medel is training: epoch 14th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5947 - acc: 0.8056     \n",
      "Medel is training: epoch 14th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3298 - acc: 0.8244     \n",
      "Medel is training: epoch 14th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6985 - acc: 0.7927     \n",
      "Medel is training: epoch 14th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5912 - acc: 0.8050     \n",
      "Medel is training: epoch 14th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3796 - acc: 0.8214     \n",
      "Medel is training: epoch 14th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4934 - acc: 0.8106     \n",
      "Medel is training: epoch 14th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6772 - acc: 0.7941     \n",
      "Medel is training: epoch 14th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6089 - acc: 0.8043     \n",
      "Medel is training: epoch 14th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2846 - acc: 0.8260     \n",
      "Medel is training: epoch 14th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6398 - acc: 0.7971     \n",
      "Medel is training: epoch 14th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6173 - acc: 0.8027     \n",
      "Medel is training: epoch 14th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5322 - acc: 0.8096     \n",
      "Medel is training: epoch 14th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2970 - acc: 0.8266     \n",
      "Medel is training: epoch 14th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7109 - acc: 0.7905     \n",
      "Medel is training: epoch 14th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5627 - acc: 0.8100     \n",
      "Medel is training: epoch 14th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5823 - acc: 0.8036     \n",
      "Medel is training: epoch 14th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2921 - acc: 0.8255     \n",
      "Medel is training: epoch 14th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6975 - acc: 0.7918     \n",
      "Medel is training: epoch 14th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6035 - acc: 0.8042     \n",
      "Medel is training: epoch 14th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5127 - acc: 0.8095     \n",
      "Medel is training: epoch 14th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3003 - acc: 0.8250     \n",
      "Medel is training: epoch 14th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6910 - acc: 0.7914     \n",
      "Medel is training: epoch 14th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6524 - acc: 0.7979     \n",
      "Medel is training: epoch 14th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4980 - acc: 0.9722\n",
      "Medel is training: epoch 15th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6879 - acc: 0.7936     \n",
      "Medel is training: epoch 15th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5029 - acc: 0.8132     \n",
      "Medel is training: epoch 15th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5541 - acc: 0.8045     \n",
      "Medel is training: epoch 15th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5731 - acc: 0.8069     \n",
      "Medel is training: epoch 15th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4552 - acc: 0.8165     \n",
      "Medel is training: epoch 15th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6519 - acc: 0.7971     \n",
      "Medel is training: epoch 15th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5938 - acc: 0.8037     \n",
      "Medel is training: epoch 15th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4424 - acc: 0.8161     \n",
      "Medel is training: epoch 15th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6615 - acc: 0.7959     \n",
      "Medel is training: epoch 15th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4916 - acc: 0.8130     \n",
      "Medel is training: epoch 15th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5726 - acc: 0.8037     \n",
      "Medel is training: epoch 15th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6302 - acc: 0.8008     \n",
      "Medel is training: epoch 15th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4533 - acc: 0.8161     \n",
      "Medel is training: epoch 15th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6888 - acc: 0.7911     \n",
      "Medel is training: epoch 15th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5863 - acc: 0.8057     \n",
      "Medel is training: epoch 15th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4260 - acc: 0.8169     \n",
      "Medel is training: epoch 15th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6386 - acc: 0.7973     \n",
      "Medel is training: epoch 15th 17000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.5933 - acc: 0.8056     \n",
      "Medel is training: epoch 15th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4085 - acc: 0.8191     \n",
      "Medel is training: epoch 15th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6522 - acc: 0.7946     \n",
      "Medel is training: epoch 15th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5732 - acc: 0.8093     \n",
      "Medel is training: epoch 15th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4309 - acc: 0.8174     \n",
      "Medel is training: epoch 15th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6150 - acc: 0.7983     \n",
      "Medel is training: epoch 15th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6217 - acc: 0.8024     \n",
      "Medel is training: epoch 15th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4860 - acc: 0.8126     \n",
      "Medel is training: epoch 15th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4639 - acc: 0.8125     \n",
      "Medel is training: epoch 15th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6833 - acc: 0.7943     \n",
      "Medel is training: epoch 15th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5907 - acc: 0.8057     \n",
      "Medel is training: epoch 15th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3020 - acc: 0.8265     \n",
      "Medel is training: epoch 15th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6916 - acc: 0.7929     \n",
      "Medel is training: epoch 15th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5847 - acc: 0.8053     \n",
      "Medel is training: epoch 15th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3547 - acc: 0.8223     \n",
      "Medel is training: epoch 15th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4797 - acc: 0.8112     \n",
      "Medel is training: epoch 15th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6737 - acc: 0.7943     \n",
      "Medel is training: epoch 15th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6040 - acc: 0.8043     \n",
      "Medel is training: epoch 15th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2546 - acc: 0.8306     \n",
      "Medel is training: epoch 15th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6313 - acc: 0.7978     \n",
      "Medel is training: epoch 15th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6116 - acc: 0.8031     \n",
      "Medel is training: epoch 15th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5210 - acc: 0.8109     \n",
      "Medel is training: epoch 15th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2716 - acc: 0.8305     \n",
      "Medel is training: epoch 15th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.7031 - acc: 0.7908     \n",
      "Medel is training: epoch 15th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5563 - acc: 0.8102     \n",
      "Medel is training: epoch 15th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5743 - acc: 0.8043     \n",
      "Medel is training: epoch 15th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2649 - acc: 0.8300     \n",
      "Medel is training: epoch 15th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6903 - acc: 0.7921     \n",
      "Medel is training: epoch 15th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5952 - acc: 0.8047     \n",
      "Medel is training: epoch 15th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5013 - acc: 0.8114     \n",
      "Medel is training: epoch 15th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2730 - acc: 0.8290     \n",
      "Medel is training: epoch 15th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6835 - acc: 0.7916     \n",
      "Medel is training: epoch 15th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6429 - acc: 0.7983     \n",
      "Medel is training: epoch 15th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4704 - acc: 0.9722\n",
      "Medel is training: epoch 16th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6802 - acc: 0.7939     \n",
      "Medel is training: epoch 16th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4975 - acc: 0.8129     \n",
      "Medel is training: epoch 16th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5433 - acc: 0.8049     \n",
      "Medel is training: epoch 16th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5693 - acc: 0.8071     \n",
      "Medel is training: epoch 16th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4431 - acc: 0.8168     \n",
      "Medel is training: epoch 16th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6473 - acc: 0.7973     \n",
      "Medel is training: epoch 16th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5910 - acc: 0.8036     \n",
      "Medel is training: epoch 16th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4291 - acc: 0.8162     \n",
      "Medel is training: epoch 16th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6578 - acc: 0.7959     \n",
      "Medel is training: epoch 16th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4817 - acc: 0.8134     \n",
      "Medel is training: epoch 16th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5605 - acc: 0.8038     \n",
      "Medel is training: epoch 16th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6257 - acc: 0.8009     \n",
      "Medel is training: epoch 16th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4380 - acc: 0.8169     \n",
      "Medel is training: epoch 16th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6786 - acc: 0.7911     \n",
      "Medel is training: epoch 16th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5818 - acc: 0.8057     \n",
      "Medel is training: epoch 16th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4093 - acc: 0.8175     \n",
      "Medel is training: epoch 16th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6287 - acc: 0.7975     \n",
      "Medel is training: epoch 16th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5896 - acc: 0.8056     \n",
      "Medel is training: epoch 16th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3907 - acc: 0.8200     \n",
      "Medel is training: epoch 16th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6434 - acc: 0.7950     \n",
      "Medel is training: epoch 16th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5690 - acc: 0.8094     \n",
      "Medel is training: epoch 16th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4162 - acc: 0.8190     \n",
      "Medel is training: epoch 16th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6035 - acc: 0.7989     \n",
      "Medel is training: epoch 16th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6173 - acc: 0.8025     \n",
      "Medel is training: epoch 16th 24000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.4700 - acc: 0.8144     \n",
      "Medel is training: epoch 16th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4468 - acc: 0.8131     \n",
      "Medel is training: epoch 16th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6767 - acc: 0.7944     \n",
      "Medel is training: epoch 16th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5862 - acc: 0.8057     \n",
      "Medel is training: epoch 16th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2749 - acc: 0.8303     \n",
      "Medel is training: epoch 16th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6827 - acc: 0.7932     \n",
      "Medel is training: epoch 16th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5802 - acc: 0.8052     \n",
      "Medel is training: epoch 16th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3388 - acc: 0.8266     \n",
      "Medel is training: epoch 16th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4647 - acc: 0.8118     \n",
      "Medel is training: epoch 16th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6669 - acc: 0.7943     \n",
      "Medel is training: epoch 16th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5991 - acc: 0.8044     \n",
      "Medel is training: epoch 16th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2302 - acc: 0.8312     \n",
      "Medel is training: epoch 16th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6217 - acc: 0.7976     \n",
      "Medel is training: epoch 16th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6053 - acc: 0.8031     \n",
      "Medel is training: epoch 16th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5128 - acc: 0.8118     \n",
      "Medel is training: epoch 16th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2522 - acc: 0.8310     \n",
      "Medel is training: epoch 16th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6968 - acc: 0.7906     \n",
      "Medel is training: epoch 16th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5503 - acc: 0.8101     \n",
      "Medel is training: epoch 16th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5680 - acc: 0.8046     \n",
      "Medel is training: epoch 16th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2466 - acc: 0.8301     \n",
      "Medel is training: epoch 16th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6805 - acc: 0.7921     \n",
      "Medel is training: epoch 16th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5884 - acc: 0.8047     \n",
      "Medel is training: epoch 16th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4937 - acc: 0.8116     \n",
      "Medel is training: epoch 16th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2563 - acc: 0.8292     \n",
      "Medel is training: epoch 16th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6755 - acc: 0.7914     \n",
      "Medel is training: epoch 16th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6383 - acc: 0.7979     \n",
      "Medel is training: epoch 16th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4422 - acc: 0.9722\n",
      "Medel is training: epoch 17th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6745 - acc: 0.7939     \n",
      "Medel is training: epoch 17th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4916 - acc: 0.8131     \n",
      "Medel is training: epoch 17th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5349 - acc: 0.8048     \n",
      "Medel is training: epoch 17th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5664 - acc: 0.8069     \n",
      "Medel is training: epoch 17th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4334 - acc: 0.8165     \n",
      "Medel is training: epoch 17th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6404 - acc: 0.7973     \n",
      "Medel is training: epoch 17th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5879 - acc: 0.8037     \n",
      "Medel is training: epoch 17th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4167 - acc: 0.8161     \n",
      "Medel is training: epoch 17th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6494 - acc: 0.7960     \n",
      "Medel is training: epoch 17th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4735 - acc: 0.8136     \n",
      "Medel is training: epoch 17th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5512 - acc: 0.8039     \n",
      "Medel is training: epoch 17th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6206 - acc: 0.8010     \n",
      "Medel is training: epoch 17th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4284 - acc: 0.8170     \n",
      "Medel is training: epoch 17th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6729 - acc: 0.7912     \n",
      "Medel is training: epoch 17th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5787 - acc: 0.8057     \n",
      "Medel is training: epoch 17th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3977 - acc: 0.8172     \n",
      "Medel is training: epoch 17th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6206 - acc: 0.7975     \n",
      "Medel is training: epoch 17th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5845 - acc: 0.8059     \n",
      "Medel is training: epoch 17th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3807 - acc: 0.8201     \n",
      "Medel is training: epoch 17th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6362 - acc: 0.7949     \n",
      "Medel is training: epoch 17th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5649 - acc: 0.8094     \n",
      "Medel is training: epoch 17th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4060 - acc: 0.8193     \n",
      "Medel is training: epoch 17th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5952 - acc: 0.7990     \n",
      "Medel is training: epoch 17th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6121 - acc: 0.8025     \n",
      "Medel is training: epoch 17th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4623 - acc: 0.8147     \n",
      "Medel is training: epoch 17th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4356 - acc: 0.8131     \n",
      "Medel is training: epoch 17th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6710 - acc: 0.7942     \n",
      "Medel is training: epoch 17th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5834 - acc: 0.8056     \n",
      "Medel is training: epoch 17th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2648 - acc: 0.8304     \n",
      "Medel is training: epoch 17th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6777 - acc: 0.7931     \n",
      "Medel is training: epoch 17th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5767 - acc: 0.8052     \n",
      "Medel is training: epoch 17th 31000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.3268 - acc: 0.8271     \n",
      "Medel is training: epoch 17th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4554 - acc: 0.8119     \n",
      "Medel is training: epoch 17th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6618 - acc: 0.7941     \n",
      "Medel is training: epoch 17th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5957 - acc: 0.8043     \n",
      "Medel is training: epoch 17th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2171 - acc: 0.8321     \n",
      "Medel is training: epoch 17th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6151 - acc: 0.7976     \n",
      "Medel is training: epoch 17th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6012 - acc: 0.8031     \n",
      "Medel is training: epoch 17th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5079 - acc: 0.8118     \n",
      "Medel is training: epoch 17th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2425 - acc: 0.8313     \n",
      "Medel is training: epoch 17th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6896 - acc: 0.7904     \n",
      "Medel is training: epoch 17th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5478 - acc: 0.8099     \n",
      "Medel is training: epoch 17th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5644 - acc: 0.8047     \n",
      "Medel is training: epoch 17th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2364 - acc: 0.8306     \n",
      "Medel is training: epoch 17th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6730 - acc: 0.7919     \n",
      "Medel is training: epoch 17th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 6s - loss: 1.5851 - acc: 0.8047     \n",
      "Medel is training: epoch 17th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4879 - acc: 0.8115     \n",
      "Medel is training: epoch 17th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2464 - acc: 0.8312     \n",
      "Medel is training: epoch 17th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6672 - acc: 0.7914     \n",
      "Medel is training: epoch 17th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6343 - acc: 0.7980     \n",
      "Medel is training: epoch 17th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.4153 - acc: 0.9722\n",
      "Medel is training: epoch 18th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6710 - acc: 0.7940     \n",
      "Medel is training: epoch 18th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4865 - acc: 0.8133     \n",
      "Medel is training: epoch 18th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5275 - acc: 0.8043     \n",
      "Medel is training: epoch 18th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5632 - acc: 0.8070     \n",
      "Medel is training: epoch 18th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4257 - acc: 0.8164     \n",
      "Medel is training: epoch 18th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6361 - acc: 0.7972     \n",
      "Medel is training: epoch 18th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5851 - acc: 0.8037     \n",
      "Medel is training: epoch 18th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4074 - acc: 0.8161     \n",
      "Medel is training: epoch 18th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6459 - acc: 0.7961     \n",
      "Medel is training: epoch 18th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4681 - acc: 0.8135     \n",
      "Medel is training: epoch 18th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5450 - acc: 0.8038     \n",
      "Medel is training: epoch 18th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6174 - acc: 0.8010     \n",
      "Medel is training: epoch 18th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4225 - acc: 0.8169     \n",
      "Medel is training: epoch 18th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6692 - acc: 0.7912     \n",
      "Medel is training: epoch 18th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5761 - acc: 0.8057     \n",
      "Medel is training: epoch 18th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3906 - acc: 0.8176     \n",
      "Medel is training: epoch 18th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6162 - acc: 0.7976     \n",
      "Medel is training: epoch 18th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5822 - acc: 0.8059     \n",
      "Medel is training: epoch 18th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3746 - acc: 0.8204     \n",
      "Medel is training: epoch 18th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6326 - acc: 0.7949     \n",
      "Medel is training: epoch 18th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5619 - acc: 0.8092     \n",
      "Medel is training: epoch 18th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4005 - acc: 0.8192     \n",
      "Medel is training: epoch 18th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5889 - acc: 0.7990     \n",
      "Medel is training: epoch 18th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6097 - acc: 0.8025     \n",
      "Medel is training: epoch 18th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4590 - acc: 0.8146     \n",
      "Medel is training: epoch 18th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4289 - acc: 0.8133     \n",
      "Medel is training: epoch 18th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6676 - acc: 0.7941     \n",
      "Medel is training: epoch 18th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5805 - acc: 0.8058     \n",
      "Medel is training: epoch 18th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2559 - acc: 0.8308     \n",
      "Medel is training: epoch 18th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6721 - acc: 0.7931     \n",
      "Medel is training: epoch 18th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5760 - acc: 0.8051     \n",
      "Medel is training: epoch 18th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3194 - acc: 0.8270     \n",
      "Medel is training: epoch 18th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4497 - acc: 0.8121     \n",
      "Medel is training: epoch 18th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6584 - acc: 0.7943     \n",
      "Medel is training: epoch 18th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5941 - acc: 0.8043     \n",
      "Medel is training: epoch 18th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2100 - acc: 0.8321     \n",
      "Medel is training: epoch 18th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6092 - acc: 0.7976     \n",
      "Medel is training: epoch 18th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5977 - acc: 0.8030     \n",
      "Medel is training: epoch 18th 38000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.5055 - acc: 0.8118     \n",
      "Medel is training: epoch 18th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2351 - acc: 0.8315     \n",
      "Medel is training: epoch 18th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6860 - acc: 0.7907     \n",
      "Medel is training: epoch 18th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5445 - acc: 0.8101     \n",
      "Medel is training: epoch 18th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5612 - acc: 0.8048     \n",
      "Medel is training: epoch 18th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2280 - acc: 0.8309     \n",
      "Medel is training: epoch 18th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6688 - acc: 0.7918     \n",
      "Medel is training: epoch 18th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5818 - acc: 0.8048     \n",
      "Medel is training: epoch 18th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4846 - acc: 0.8129     \n",
      "Medel is training: epoch 18th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2404 - acc: 0.8321     \n",
      "Medel is training: epoch 18th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6634 - acc: 0.7914     \n",
      "Medel is training: epoch 18th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6309 - acc: 0.7983     \n",
      "Medel is training: epoch 18th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3920 - acc: 1.0000\n",
      "Medel is training: epoch 19th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6684 - acc: 0.7941     \n",
      "Medel is training: epoch 19th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4819 - acc: 0.8132     \n",
      "Medel is training: epoch 19th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5219 - acc: 0.8044     \n",
      "Medel is training: epoch 19th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5623 - acc: 0.8070     \n",
      "Medel is training: epoch 19th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4195 - acc: 0.8163     \n",
      "Medel is training: epoch 19th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6338 - acc: 0.7972     \n",
      "Medel is training: epoch 19th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5832 - acc: 0.8038     \n",
      "Medel is training: epoch 19th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4021 - acc: 0.8160     \n",
      "Medel is training: epoch 19th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6418 - acc: 0.7960     \n",
      "Medel is training: epoch 19th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4639 - acc: 0.8135     \n",
      "Medel is training: epoch 19th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5394 - acc: 0.8038     \n",
      "Medel is training: epoch 19th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6151 - acc: 0.8010     \n",
      "Medel is training: epoch 19th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4174 - acc: 0.8168     \n",
      "Medel is training: epoch 19th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6641 - acc: 0.7914     \n",
      "Medel is training: epoch 19th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5738 - acc: 0.8058     \n",
      "Medel is training: epoch 19th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3845 - acc: 0.8179     \n",
      "Medel is training: epoch 19th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6121 - acc: 0.7977     \n",
      "Medel is training: epoch 19th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5805 - acc: 0.8058     \n",
      "Medel is training: epoch 19th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3689 - acc: 0.8202     \n",
      "Medel is training: epoch 19th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6281 - acc: 0.7950     \n",
      "Medel is training: epoch 19th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5601 - acc: 0.8093     \n",
      "Medel is training: epoch 19th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3952 - acc: 0.8192     \n",
      "Medel is training: epoch 19th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5860 - acc: 0.7989     \n",
      "Medel is training: epoch 19th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6079 - acc: 0.8027     \n",
      "Medel is training: epoch 19th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4562 - acc: 0.8146     \n",
      "Medel is training: epoch 19th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4241 - acc: 0.8132     \n",
      "Medel is training: epoch 19th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6649 - acc: 0.7941     \n",
      "Medel is training: epoch 19th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5790 - acc: 0.8056     \n",
      "Medel is training: epoch 19th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2507 - acc: 0.8310     \n",
      "Medel is training: epoch 19th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6687 - acc: 0.7931     \n",
      "Medel is training: epoch 19th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5745 - acc: 0.8049     \n",
      "Medel is training: epoch 19th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3150 - acc: 0.8270     \n",
      "Medel is training: epoch 19th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4447 - acc: 0.8122     \n",
      "Medel is training: epoch 19th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6553 - acc: 0.7943     \n",
      "Medel is training: epoch 19th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5916 - acc: 0.8044     \n",
      "Medel is training: epoch 19th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2034 - acc: 0.8324     \n",
      "Medel is training: epoch 19th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6051 - acc: 0.7976     \n",
      "Medel is training: epoch 19th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5950 - acc: 0.8029     \n",
      "Medel is training: epoch 19th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5028 - acc: 0.8130     \n",
      "Medel is training: epoch 19th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2311 - acc: 0.8339     \n",
      "Medel is training: epoch 19th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6823 - acc: 0.7907     \n",
      "Medel is training: epoch 19th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5425 - acc: 0.8101     \n",
      "Medel is training: epoch 19th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5582 - acc: 0.8055     \n",
      "Medel is training: epoch 19th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2214 - acc: 0.8342     \n",
      "Medel is training: epoch 19th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6652 - acc: 0.7921     \n",
      "Medel is training: epoch 19th 45000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.5796 - acc: 0.8048     \n",
      "Medel is training: epoch 19th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4816 - acc: 0.8129     \n",
      "Medel is training: epoch 19th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2341 - acc: 0.8327     \n",
      "Medel is training: epoch 19th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6596 - acc: 0.7912     \n",
      "Medel is training: epoch 19th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6294 - acc: 0.7980     \n",
      "Medel is training: epoch 19th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3747 - acc: 1.0000\n",
      "Medel is training: epoch 20th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6664 - acc: 0.7940     \n",
      "Medel is training: epoch 20th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4779 - acc: 0.8129     \n",
      "Medel is training: epoch 20th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5176 - acc: 0.8044     \n",
      "Medel is training: epoch 20th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5597 - acc: 0.8071     \n",
      "Medel is training: epoch 20th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4129 - acc: 0.8163     \n",
      "Medel is training: epoch 20th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6305 - acc: 0.7973     \n",
      "Medel is training: epoch 20th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5815 - acc: 0.8038     \n",
      "Medel is training: epoch 20th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3958 - acc: 0.8162     \n",
      "Medel is training: epoch 20th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6391 - acc: 0.7960     \n",
      "Medel is training: epoch 20th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4608 - acc: 0.8136     \n",
      "Medel is training: epoch 20th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5358 - acc: 0.8041     \n",
      "Medel is training: epoch 20th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6130 - acc: 0.8010     \n",
      "Medel is training: epoch 20th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4133 - acc: 0.8172     \n",
      "Medel is training: epoch 20th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6611 - acc: 0.7914     \n",
      "Medel is training: epoch 20th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5728 - acc: 0.8058     \n",
      "Medel is training: epoch 20th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3791 - acc: 0.8180     \n",
      "Medel is training: epoch 20th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6090 - acc: 0.7980     \n",
      "Medel is training: epoch 20th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5788 - acc: 0.8058     \n",
      "Medel is training: epoch 20th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3645 - acc: 0.8203     \n",
      "Medel is training: epoch 20th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6255 - acc: 0.7955     \n",
      "Medel is training: epoch 20th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5585 - acc: 0.8092     \n",
      "Medel is training: epoch 20th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3907 - acc: 0.8191     \n",
      "Medel is training: epoch 20th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5828 - acc: 0.7990     \n",
      "Medel is training: epoch 20th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6059 - acc: 0.8027     \n",
      "Medel is training: epoch 20th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4529 - acc: 0.8144     \n",
      "Medel is training: epoch 20th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4207 - acc: 0.8135     \n",
      "Medel is training: epoch 20th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6616 - acc: 0.7944     \n",
      "Medel is training: epoch 20th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5778 - acc: 0.8058     \n",
      "Medel is training: epoch 20th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2450 - acc: 0.8312     \n",
      "Medel is training: epoch 20th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6682 - acc: 0.7930     \n",
      "Medel is training: epoch 20th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5718 - acc: 0.8051     \n",
      "Medel is training: epoch 20th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3116 - acc: 0.8297     \n",
      "Medel is training: epoch 20th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4405 - acc: 0.8124     \n",
      "Medel is training: epoch 20th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6540 - acc: 0.7943     \n",
      "Medel is training: epoch 20th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5893 - acc: 0.8045     \n",
      "Medel is training: epoch 20th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2005 - acc: 0.8354     \n",
      "Medel is training: epoch 20th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6018 - acc: 0.7975     \n",
      "Medel is training: epoch 20th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5929 - acc: 0.8029     \n",
      "Medel is training: epoch 20th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5010 - acc: 0.8128     \n",
      "Medel is training: epoch 20th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2268 - acc: 0.8339     \n",
      "Medel is training: epoch 20th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6783 - acc: 0.7909     \n",
      "Medel is training: epoch 20th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5413 - acc: 0.8100     \n",
      "Medel is training: epoch 20th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5552 - acc: 0.8057     \n",
      "Medel is training: epoch 20th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2174 - acc: 0.8341     \n",
      "Medel is training: epoch 20th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6636 - acc: 0.7921     \n",
      "Medel is training: epoch 20th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5780 - acc: 0.8047     \n",
      "Medel is training: epoch 20th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4795 - acc: 0.8128     \n",
      "Medel is training: epoch 20th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2292 - acc: 0.8329     \n",
      "Medel is training: epoch 20th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6554 - acc: 0.7915     \n",
      "Medel is training: epoch 20th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6275 - acc: 0.7979     \n",
      "Medel is training: epoch 20th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3609 - acc: 1.0000\n",
      "Medel is training: epoch 21th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6643 - acc: 0.7940     \n",
      "Medel is training: epoch 21th 1000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.4739 - acc: 0.8131     \n",
      "Medel is training: epoch 21th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5142 - acc: 0.8044     \n",
      "Medel is training: epoch 21th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5583 - acc: 0.8070     \n",
      "Medel is training: epoch 21th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4097 - acc: 0.8167     \n",
      "Medel is training: epoch 21th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6292 - acc: 0.7975     \n",
      "Medel is training: epoch 21th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5801 - acc: 0.8039     \n",
      "Medel is training: epoch 21th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3920 - acc: 0.8165     \n",
      "Medel is training: epoch 21th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6375 - acc: 0.7962     \n",
      "Medel is training: epoch 21th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4579 - acc: 0.8136     \n",
      "Medel is training: epoch 21th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5319 - acc: 0.8044     \n",
      "Medel is training: epoch 21th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6113 - acc: 0.8010     \n",
      "Medel is training: epoch 21th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4094 - acc: 0.8173     \n",
      "Medel is training: epoch 21th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6590 - acc: 0.7914     \n",
      "Medel is training: epoch 21th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5705 - acc: 0.8058     \n",
      "Medel is training: epoch 21th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3747 - acc: 0.8182     \n",
      "Medel is training: epoch 21th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6071 - acc: 0.7981     \n",
      "Medel is training: epoch 21th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5776 - acc: 0.8058     \n",
      "Medel is training: epoch 21th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3600 - acc: 0.8204     \n",
      "Medel is training: epoch 21th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6226 - acc: 0.7957     \n",
      "Medel is training: epoch 21th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5552 - acc: 0.8094     \n",
      "Medel is training: epoch 21th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3880 - acc: 0.8192     \n",
      "Medel is training: epoch 21th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5786 - acc: 0.7992     \n",
      "Medel is training: epoch 21th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6035 - acc: 0.8027     \n",
      "Medel is training: epoch 21th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4495 - acc: 0.8156     \n",
      "Medel is training: epoch 21th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4166 - acc: 0.8136     \n",
      "Medel is training: epoch 21th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6587 - acc: 0.7946     \n",
      "Medel is training: epoch 21th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5760 - acc: 0.8058     \n",
      "Medel is training: epoch 21th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2394 - acc: 0.8334     \n",
      "Medel is training: epoch 21th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6628 - acc: 0.7933     \n",
      "Medel is training: epoch 21th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5700 - acc: 0.8051     \n",
      "Medel is training: epoch 21th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3099 - acc: 0.8290     \n",
      "Medel is training: epoch 21th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4373 - acc: 0.8130     \n",
      "Medel is training: epoch 21th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6510 - acc: 0.7944     \n",
      "Medel is training: epoch 21th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5877 - acc: 0.8044     \n",
      "Medel is training: epoch 21th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1946 - acc: 0.8356     \n",
      "Medel is training: epoch 21th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5995 - acc: 0.7977     \n",
      "Medel is training: epoch 21th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5907 - acc: 0.8031     \n",
      "Medel is training: epoch 21th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4994 - acc: 0.8127     \n",
      "Medel is training: epoch 21th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2226 - acc: 0.8341     \n",
      "Medel is training: epoch 21th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6760 - acc: 0.7911     \n",
      "Medel is training: epoch 21th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5401 - acc: 0.8096     \n",
      "Medel is training: epoch 21th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5538 - acc: 0.8055     \n",
      "Medel is training: epoch 21th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2133 - acc: 0.8342     \n",
      "Medel is training: epoch 21th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6592 - acc: 0.7923     \n",
      "Medel is training: epoch 21th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5773 - acc: 0.8046     \n",
      "Medel is training: epoch 21th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4780 - acc: 0.8129     \n",
      "Medel is training: epoch 21th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2237 - acc: 0.8332     \n",
      "Medel is training: epoch 21th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6535 - acc: 0.7916     \n",
      "Medel is training: epoch 21th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6251 - acc: 0.7982     \n",
      "Medel is training: epoch 21th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3489 - acc: 1.0000\n",
      "Medel is training: epoch 22th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6626 - acc: 0.7940     \n",
      "Medel is training: epoch 22th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4718 - acc: 0.8132     \n",
      "Medel is training: epoch 22th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5105 - acc: 0.8048     \n",
      "Medel is training: epoch 22th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5570 - acc: 0.8071     \n",
      "Medel is training: epoch 22th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4052 - acc: 0.8165     \n",
      "Medel is training: epoch 22th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6264 - acc: 0.7975     \n",
      "Medel is training: epoch 22th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5782 - acc: 0.8038     \n",
      "Medel is training: epoch 22th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3882 - acc: 0.8167     \n",
      "Medel is training: epoch 22th 8000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.6347 - acc: 0.7962     \n",
      "Medel is training: epoch 22th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4542 - acc: 0.8139     \n",
      "Medel is training: epoch 22th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5289 - acc: 0.8046     \n",
      "Medel is training: epoch 22th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6099 - acc: 0.8010     \n",
      "Medel is training: epoch 22th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4065 - acc: 0.8177     \n",
      "Medel is training: epoch 22th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6565 - acc: 0.7916     \n",
      "Medel is training: epoch 22th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5690 - acc: 0.8058     \n",
      "Medel is training: epoch 22th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3708 - acc: 0.8184     \n",
      "Medel is training: epoch 22th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6037 - acc: 0.7981     \n",
      "Medel is training: epoch 22th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5759 - acc: 0.8058     \n",
      "Medel is training: epoch 22th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3562 - acc: 0.8205     \n",
      "Medel is training: epoch 22th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6201 - acc: 0.7957     \n",
      "Medel is training: epoch 22th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5542 - acc: 0.8093     \n",
      "Medel is training: epoch 22th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3835 - acc: 0.8199     \n",
      "Medel is training: epoch 22th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5763 - acc: 0.7996     \n",
      "Medel is training: epoch 22th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6021 - acc: 0.8026     \n",
      "Medel is training: epoch 22th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4468 - acc: 0.8158     \n",
      "Medel is training: epoch 22th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4132 - acc: 0.8141     \n",
      "Medel is training: epoch 22th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6570 - acc: 0.7947     \n",
      "Medel is training: epoch 22th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5748 - acc: 0.8058     \n",
      "Medel is training: epoch 22th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2342 - acc: 0.8331     \n",
      "Medel is training: epoch 22th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6608 - acc: 0.7933     \n",
      "Medel is training: epoch 22th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5678 - acc: 0.8052     \n",
      "Medel is training: epoch 22th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3033 - acc: 0.8299     \n",
      "Medel is training: epoch 22th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4341 - acc: 0.8131     \n",
      "Medel is training: epoch 22th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6484 - acc: 0.7946     \n",
      "Medel is training: epoch 22th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5871 - acc: 0.8043     \n",
      "Medel is training: epoch 22th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1904 - acc: 0.8356     \n",
      "Medel is training: epoch 22th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5976 - acc: 0.7979     \n",
      "Medel is training: epoch 22th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5899 - acc: 0.8030     \n",
      "Medel is training: epoch 22th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4976 - acc: 0.8130     \n",
      "Medel is training: epoch 22th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2172 - acc: 0.8342     \n",
      "Medel is training: epoch 22th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6739 - acc: 0.7910     \n",
      "Medel is training: epoch 22th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5378 - acc: 0.8099     \n",
      "Medel is training: epoch 22th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5512 - acc: 0.8056     \n",
      "Medel is training: epoch 22th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2080 - acc: 0.8345     \n",
      "Medel is training: epoch 22th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6576 - acc: 0.7924     \n",
      "Medel is training: epoch 22th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5749 - acc: 0.8046     \n",
      "Medel is training: epoch 22th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4747 - acc: 0.8130     \n",
      "Medel is training: epoch 22th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2202 - acc: 0.8331     \n",
      "Medel is training: epoch 22th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6503 - acc: 0.7917     \n",
      "Medel is training: epoch 22th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6222 - acc: 0.7982     \n",
      "Medel is training: epoch 22th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3376 - acc: 1.0000\n",
      "Medel is training: epoch 23th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6607 - acc: 0.7939     \n",
      "Medel is training: epoch 23th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4702 - acc: 0.8128     \n",
      "Medel is training: epoch 23th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5076 - acc: 0.8048     \n",
      "Medel is training: epoch 23th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5554 - acc: 0.8070     \n",
      "Medel is training: epoch 23th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4017 - acc: 0.8170     \n",
      "Medel is training: epoch 23th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6245 - acc: 0.7975     \n",
      "Medel is training: epoch 23th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5771 - acc: 0.8038     \n",
      "Medel is training: epoch 23th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3844 - acc: 0.8169     \n",
      "Medel is training: epoch 23th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6330 - acc: 0.7962     \n",
      "Medel is training: epoch 23th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4515 - acc: 0.8138     \n",
      "Medel is training: epoch 23th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5258 - acc: 0.8046     \n",
      "Medel is training: epoch 23th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6087 - acc: 0.8011     \n",
      "Medel is training: epoch 23th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4032 - acc: 0.8179     \n",
      "Medel is training: epoch 23th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6541 - acc: 0.7915     \n",
      "Medel is training: epoch 23th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5680 - acc: 0.8058     \n",
      "Medel is training: epoch 23th 15000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.3664 - acc: 0.8186     \n",
      "Medel is training: epoch 23th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6017 - acc: 0.7984     \n",
      "Medel is training: epoch 23th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5749 - acc: 0.8058     \n",
      "Medel is training: epoch 23th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3527 - acc: 0.8207     \n",
      "Medel is training: epoch 23th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6181 - acc: 0.7956     \n",
      "Medel is training: epoch 23th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5518 - acc: 0.8094     \n",
      "Medel is training: epoch 23th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3807 - acc: 0.8201     \n",
      "Medel is training: epoch 23th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5718 - acc: 0.7996     \n",
      "Medel is training: epoch 23th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6007 - acc: 0.8026     \n",
      "Medel is training: epoch 23th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4441 - acc: 0.8161     \n",
      "Medel is training: epoch 23th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4105 - acc: 0.8142     \n",
      "Medel is training: epoch 23th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6547 - acc: 0.7947     \n",
      "Medel is training: epoch 23th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5732 - acc: 0.8058     \n",
      "Medel is training: epoch 23th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2291 - acc: 0.8332     \n",
      "Medel is training: epoch 23th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6585 - acc: 0.7935     \n",
      "Medel is training: epoch 23th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5664 - acc: 0.8053     \n",
      "Medel is training: epoch 23th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3002 - acc: 0.8298     \n",
      "Medel is training: epoch 23th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4316 - acc: 0.8132     \n",
      "Medel is training: epoch 23th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6456 - acc: 0.7946     \n",
      "Medel is training: epoch 23th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5854 - acc: 0.8042     \n",
      "Medel is training: epoch 23th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1862 - acc: 0.8355     \n",
      "Medel is training: epoch 23th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5946 - acc: 0.7980     \n",
      "Medel is training: epoch 23th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5874 - acc: 0.8032     \n",
      "Medel is training: epoch 23th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4955 - acc: 0.8131     \n",
      "Medel is training: epoch 23th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2148 - acc: 0.8345     \n",
      "Medel is training: epoch 23th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6723 - acc: 0.7910     \n",
      "Medel is training: epoch 23th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5372 - acc: 0.8098     \n",
      "Medel is training: epoch 23th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5505 - acc: 0.8053     \n",
      "Medel is training: epoch 23th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2060 - acc: 0.8348     \n",
      "Medel is training: epoch 23th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6565 - acc: 0.7923     \n",
      "Medel is training: epoch 23th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5728 - acc: 0.8046     \n",
      "Medel is training: epoch 23th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4730 - acc: 0.8129     \n",
      "Medel is training: epoch 23th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2161 - acc: 0.8336     \n",
      "Medel is training: epoch 23th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6476 - acc: 0.7919     \n",
      "Medel is training: epoch 23th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6225 - acc: 0.7978     \n",
      "Medel is training: epoch 23th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3265 - acc: 1.0000\n",
      "Medel is training: epoch 24th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6586 - acc: 0.7939     \n",
      "Medel is training: epoch 24th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4665 - acc: 0.8131     \n",
      "Medel is training: epoch 24th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5055 - acc: 0.8051     \n",
      "Medel is training: epoch 24th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5541 - acc: 0.8071     \n",
      "Medel is training: epoch 24th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3982 - acc: 0.8172     \n",
      "Medel is training: epoch 24th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6227 - acc: 0.7975     \n",
      "Medel is training: epoch 24th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5759 - acc: 0.8038     \n",
      "Medel is training: epoch 24th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3809 - acc: 0.8170     \n",
      "Medel is training: epoch 24th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6310 - acc: 0.7961     \n",
      "Medel is training: epoch 24th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4493 - acc: 0.8139     \n",
      "Medel is training: epoch 24th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5236 - acc: 0.8048     \n",
      "Medel is training: epoch 24th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6068 - acc: 0.8011     \n",
      "Medel is training: epoch 24th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4005 - acc: 0.8179     \n",
      "Medel is training: epoch 24th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6514 - acc: 0.7917     \n",
      "Medel is training: epoch 24th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5665 - acc: 0.8059     \n",
      "Medel is training: epoch 24th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3634 - acc: 0.8189     \n",
      "Medel is training: epoch 24th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5989 - acc: 0.7982     \n",
      "Medel is training: epoch 24th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5734 - acc: 0.8058     \n",
      "Medel is training: epoch 24th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3501 - acc: 0.8204     \n",
      "Medel is training: epoch 24th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6151 - acc: 0.7956     \n",
      "Medel is training: epoch 24th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5509 - acc: 0.8094     \n",
      "Medel is training: epoch 24th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3776 - acc: 0.8203     \n",
      "Medel is training: epoch 24th 22000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.5696 - acc: 0.7998     \n",
      "Medel is training: epoch 24th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5994 - acc: 0.8026     \n",
      "Medel is training: epoch 24th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4419 - acc: 0.8159     \n",
      "Medel is training: epoch 24th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4071 - acc: 0.8144     \n",
      "Medel is training: epoch 24th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6530 - acc: 0.7947     \n",
      "Medel is training: epoch 24th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5724 - acc: 0.8057     \n",
      "Medel is training: epoch 24th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2267 - acc: 0.8332     \n",
      "Medel is training: epoch 24th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6576 - acc: 0.7935     \n",
      "Medel is training: epoch 24th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5654 - acc: 0.8053     \n",
      "Medel is training: epoch 24th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2959 - acc: 0.8303     \n",
      "Medel is training: epoch 24th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4287 - acc: 0.8133     \n",
      "Medel is training: epoch 24th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6443 - acc: 0.7947     \n",
      "Medel is training: epoch 24th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5844 - acc: 0.8040     \n",
      "Medel is training: epoch 24th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1826 - acc: 0.8358     \n",
      "Medel is training: epoch 24th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5924 - acc: 0.7980     \n",
      "Medel is training: epoch 24th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5858 - acc: 0.8033     \n",
      "Medel is training: epoch 24th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4946 - acc: 0.8127     \n",
      "Medel is training: epoch 24th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2091 - acc: 0.8346     \n",
      "Medel is training: epoch 24th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6692 - acc: 0.7912     \n",
      "Medel is training: epoch 24th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5350 - acc: 0.8099     \n",
      "Medel is training: epoch 24th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5479 - acc: 0.8054     \n",
      "Medel is training: epoch 24th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2016 - acc: 0.8344     \n",
      "Medel is training: epoch 24th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6525 - acc: 0.7926     \n",
      "Medel is training: epoch 24th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5727 - acc: 0.8044     \n",
      "Medel is training: epoch 24th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4715 - acc: 0.8129     \n",
      "Medel is training: epoch 24th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2122 - acc: 0.8335     \n",
      "Medel is training: epoch 24th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6446 - acc: 0.7917     \n",
      "Medel is training: epoch 24th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6189 - acc: 0.7981     \n",
      "Medel is training: epoch 24th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3149 - acc: 1.0000\n",
      "Medel is training: epoch 25th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6572 - acc: 0.7937     \n",
      "Medel is training: epoch 25th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4654 - acc: 0.8136     \n",
      "Medel is training: epoch 25th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5021 - acc: 0.8055     \n",
      "Medel is training: epoch 25th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5525 - acc: 0.8071     \n",
      "Medel is training: epoch 25th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3941 - acc: 0.8176     \n",
      "Medel is training: epoch 25th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6202 - acc: 0.7976     \n",
      "Medel is training: epoch 25th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5745 - acc: 0.8038     \n",
      "Medel is training: epoch 25th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3766 - acc: 0.8174     \n",
      "Medel is training: epoch 25th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6296 - acc: 0.7964     \n",
      "Medel is training: epoch 25th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4470 - acc: 0.8139     \n",
      "Medel is training: epoch 25th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5202 - acc: 0.8049     \n",
      "Medel is training: epoch 25th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6064 - acc: 0.8011     \n",
      "Medel is training: epoch 25th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3975 - acc: 0.8180     \n",
      "Medel is training: epoch 25th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6493 - acc: 0.7917     \n",
      "Medel is training: epoch 25th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5647 - acc: 0.8059     \n",
      "Medel is training: epoch 25th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3593 - acc: 0.8190     \n",
      "Medel is training: epoch 25th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5966 - acc: 0.7984     \n",
      "Medel is training: epoch 25th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5723 - acc: 0.8058     \n",
      "Medel is training: epoch 25th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3466 - acc: 0.8209     \n",
      "Medel is training: epoch 25th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6135 - acc: 0.7956     \n",
      "Medel is training: epoch 25th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5491 - acc: 0.8096     \n",
      "Medel is training: epoch 25th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3750 - acc: 0.8203     \n",
      "Medel is training: epoch 25th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5666 - acc: 0.7999     \n",
      "Medel is training: epoch 25th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5981 - acc: 0.8026     \n",
      "Medel is training: epoch 25th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4378 - acc: 0.8165     \n",
      "Medel is training: epoch 25th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4032 - acc: 0.8144     \n",
      "Medel is training: epoch 25th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6511 - acc: 0.7946     \n",
      "Medel is training: epoch 25th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5703 - acc: 0.8058     \n",
      "Medel is training: epoch 25th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2218 - acc: 0.8336     \n",
      "Medel is training: epoch 25th 29000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.6541 - acc: 0.7936     \n",
      "Medel is training: epoch 25th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5632 - acc: 0.8053     \n",
      "Medel is training: epoch 25th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2929 - acc: 0.8299     \n",
      "Medel is training: epoch 25th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4253 - acc: 0.8137     \n",
      "Medel is training: epoch 25th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6426 - acc: 0.7947     \n",
      "Medel is training: epoch 25th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5832 - acc: 0.8043     \n",
      "Medel is training: epoch 25th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1785 - acc: 0.8359     \n",
      "Medel is training: epoch 25th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5894 - acc: 0.7981     \n",
      "Medel is training: epoch 25th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5836 - acc: 0.8033     \n",
      "Medel is training: epoch 25th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4925 - acc: 0.8132     \n",
      "Medel is training: epoch 25th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2055 - acc: 0.8348     \n",
      "Medel is training: epoch 25th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6662 - acc: 0.7913     \n",
      "Medel is training: epoch 25th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5330 - acc: 0.8102     \n",
      "Medel is training: epoch 25th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5459 - acc: 0.8055     \n",
      "Medel is training: epoch 25th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1963 - acc: 0.8355     \n",
      "Medel is training: epoch 25th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6506 - acc: 0.7924     \n",
      "Medel is training: epoch 25th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5703 - acc: 0.8045     \n",
      "Medel is training: epoch 25th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4685 - acc: 0.8133     \n",
      "Medel is training: epoch 25th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2089 - acc: 0.8336     \n",
      "Medel is training: epoch 25th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6427 - acc: 0.7917     \n",
      "Medel is training: epoch 25th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6176 - acc: 0.7981     \n",
      "Medel is training: epoch 25th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.3020 - acc: 1.0000\n",
      "Medel is training: epoch 26th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6557 - acc: 0.7939     \n",
      "Medel is training: epoch 26th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4633 - acc: 0.8139     \n",
      "Medel is training: epoch 26th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4998 - acc: 0.8059     \n",
      "Medel is training: epoch 26th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5509 - acc: 0.8072     \n",
      "Medel is training: epoch 26th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3904 - acc: 0.8176     \n",
      "Medel is training: epoch 26th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6186 - acc: 0.7977     \n",
      "Medel is training: epoch 26th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5735 - acc: 0.8038     \n",
      "Medel is training: epoch 26th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3730 - acc: 0.8178     \n",
      "Medel is training: epoch 26th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6271 - acc: 0.7966     \n",
      "Medel is training: epoch 26th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4447 - acc: 0.8141     \n",
      "Medel is training: epoch 26th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5176 - acc: 0.8051     \n",
      "Medel is training: epoch 26th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6049 - acc: 0.8011     \n",
      "Medel is training: epoch 26th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3947 - acc: 0.8181     \n",
      "Medel is training: epoch 26th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6474 - acc: 0.7919     \n",
      "Medel is training: epoch 26th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5641 - acc: 0.8059     \n",
      "Medel is training: epoch 26th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3557 - acc: 0.8192     \n",
      "Medel is training: epoch 26th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5944 - acc: 0.7983     \n",
      "Medel is training: epoch 26th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5709 - acc: 0.8058     \n",
      "Medel is training: epoch 26th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3425 - acc: 0.8213     \n",
      "Medel is training: epoch 26th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6110 - acc: 0.7958     \n",
      "Medel is training: epoch 26th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5475 - acc: 0.8095     \n",
      "Medel is training: epoch 26th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3716 - acc: 0.8206     \n",
      "Medel is training: epoch 26th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5646 - acc: 0.8001     \n",
      "Medel is training: epoch 26th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5967 - acc: 0.8028     \n",
      "Medel is training: epoch 26th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4355 - acc: 0.8167     \n",
      "Medel is training: epoch 26th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3999 - acc: 0.8151     \n",
      "Medel is training: epoch 26th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6488 - acc: 0.7950     \n",
      "Medel is training: epoch 26th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5694 - acc: 0.8059     \n",
      "Medel is training: epoch 26th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2179 - acc: 0.8339     \n",
      "Medel is training: epoch 26th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6530 - acc: 0.7936     \n",
      "Medel is training: epoch 26th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5619 - acc: 0.8053     \n",
      "Medel is training: epoch 26th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2900 - acc: 0.8307     \n",
      "Medel is training: epoch 26th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4221 - acc: 0.8138     \n",
      "Medel is training: epoch 26th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6401 - acc: 0.7949     \n",
      "Medel is training: epoch 26th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5820 - acc: 0.8041     \n",
      "Medel is training: epoch 26th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1738 - acc: 0.8361     \n",
      "Medel is training: epoch 26th 36000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.5865 - acc: 0.7984     \n",
      "Medel is training: epoch 26th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5806 - acc: 0.8034     \n",
      "Medel is training: epoch 26th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4906 - acc: 0.8131     \n",
      "Medel is training: epoch 26th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1998 - acc: 0.8353     \n",
      "Medel is training: epoch 26th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6628 - acc: 0.7916     \n",
      "Medel is training: epoch 26th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5315 - acc: 0.8102     \n",
      "Medel is training: epoch 26th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5437 - acc: 0.8055     \n",
      "Medel is training: epoch 26th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1915 - acc: 0.8358     \n",
      "Medel is training: epoch 26th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6480 - acc: 0.7928     \n",
      "Medel is training: epoch 26th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5684 - acc: 0.8048     \n",
      "Medel is training: epoch 26th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4670 - acc: 0.8132     \n",
      "Medel is training: epoch 26th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2050 - acc: 0.8340     \n",
      "Medel is training: epoch 26th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6389 - acc: 0.7922     \n",
      "Medel is training: epoch 26th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6170 - acc: 0.7980     \n",
      "Medel is training: epoch 26th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2889 - acc: 1.0000\n",
      "Medel is training: epoch 27th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6535 - acc: 0.7939     \n",
      "Medel is training: epoch 27th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4605 - acc: 0.8140     \n",
      "Medel is training: epoch 27th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4970 - acc: 0.8059     \n",
      "Medel is training: epoch 27th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5495 - acc: 0.8072     \n",
      "Medel is training: epoch 27th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3874 - acc: 0.8177     \n",
      "Medel is training: epoch 27th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6169 - acc: 0.7981     \n",
      "Medel is training: epoch 27th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5725 - acc: 0.8038     \n",
      "Medel is training: epoch 27th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3691 - acc: 0.8181     \n",
      "Medel is training: epoch 27th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6254 - acc: 0.7967     \n",
      "Medel is training: epoch 27th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4422 - acc: 0.8142     \n",
      "Medel is training: epoch 27th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5150 - acc: 0.8052     \n",
      "Medel is training: epoch 27th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6035 - acc: 0.8012     \n",
      "Medel is training: epoch 27th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3912 - acc: 0.8183     \n",
      "Medel is training: epoch 27th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6459 - acc: 0.7919     \n",
      "Medel is training: epoch 27th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5621 - acc: 0.8060     \n",
      "Medel is training: epoch 27th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3518 - acc: 0.8196     \n",
      "Medel is training: epoch 27th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5923 - acc: 0.7985     \n",
      "Medel is training: epoch 27th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5691 - acc: 0.8058     \n",
      "Medel is training: epoch 27th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3386 - acc: 0.8217     \n",
      "Medel is training: epoch 27th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6084 - acc: 0.7958     \n",
      "Medel is training: epoch 27th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5464 - acc: 0.8095     \n",
      "Medel is training: epoch 27th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3682 - acc: 0.8209     \n",
      "Medel is training: epoch 27th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5618 - acc: 0.8002     \n",
      "Medel is training: epoch 27th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5955 - acc: 0.8027     \n",
      "Medel is training: epoch 27th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4326 - acc: 0.8167     \n",
      "Medel is training: epoch 27th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3965 - acc: 0.8154     \n",
      "Medel is training: epoch 27th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6469 - acc: 0.7950     \n",
      "Medel is training: epoch 27th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5687 - acc: 0.8059     \n",
      "Medel is training: epoch 27th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2139 - acc: 0.8346     \n",
      "Medel is training: epoch 27th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6502 - acc: 0.7939     \n",
      "Medel is training: epoch 27th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5603 - acc: 0.8055     \n",
      "Medel is training: epoch 27th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2856 - acc: 0.8309     \n",
      "Medel is training: epoch 27th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4189 - acc: 0.8137     \n",
      "Medel is training: epoch 27th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6378 - acc: 0.7949     \n",
      "Medel is training: epoch 27th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5800 - acc: 0.8042     \n",
      "Medel is training: epoch 27th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1691 - acc: 0.8361     \n",
      "Medel is training: epoch 27th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5834 - acc: 0.7985     \n",
      "Medel is training: epoch 27th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5795 - acc: 0.8034     \n",
      "Medel is training: epoch 27th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4885 - acc: 0.8131     \n",
      "Medel is training: epoch 27th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1972 - acc: 0.8353     \n",
      "Medel is training: epoch 27th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6607 - acc: 0.7914     \n",
      "Medel is training: epoch 27th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5316 - acc: 0.8098     \n",
      "Medel is training: epoch 27th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5416 - acc: 0.8056     \n",
      "Medel is training: epoch 27th 43000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.1895 - acc: 0.8366     \n",
      "Medel is training: epoch 27th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6470 - acc: 0.7926     \n",
      "Medel is training: epoch 27th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5671 - acc: 0.8047     \n",
      "Medel is training: epoch 27th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4654 - acc: 0.8131     \n",
      "Medel is training: epoch 27th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2005 - acc: 0.8343     \n",
      "Medel is training: epoch 27th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6376 - acc: 0.7922     \n",
      "Medel is training: epoch 27th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6148 - acc: 0.7982     \n",
      "Medel is training: epoch 27th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2743 - acc: 1.0000\n",
      "Medel is training: epoch 28th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6521 - acc: 0.7940     \n",
      "Medel is training: epoch 28th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4576 - acc: 0.8142     \n",
      "Medel is training: epoch 28th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4946 - acc: 0.8058     \n",
      "Medel is training: epoch 28th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5477 - acc: 0.8072     \n",
      "Medel is training: epoch 28th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3833 - acc: 0.8178     \n",
      "Medel is training: epoch 28th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6152 - acc: 0.7980     \n",
      "Medel is training: epoch 28th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5711 - acc: 0.8039     \n",
      "Medel is training: epoch 28th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3656 - acc: 0.8181     \n",
      "Medel is training: epoch 28th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6240 - acc: 0.7966     \n",
      "Medel is training: epoch 28th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4396 - acc: 0.8143     \n",
      "Medel is training: epoch 28th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5121 - acc: 0.8053     \n",
      "Medel is training: epoch 28th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6017 - acc: 0.8012     \n",
      "Medel is training: epoch 28th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3883 - acc: 0.8188     \n",
      "Medel is training: epoch 28th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6428 - acc: 0.7919     \n",
      "Medel is training: epoch 28th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5611 - acc: 0.8060     \n",
      "Medel is training: epoch 28th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3480 - acc: 0.8197     \n",
      "Medel is training: epoch 28th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5905 - acc: 0.7987     \n",
      "Medel is training: epoch 28th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5681 - acc: 0.8057     \n",
      "Medel is training: epoch 28th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3350 - acc: 0.8230     \n",
      "Medel is training: epoch 28th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6063 - acc: 0.7956     \n",
      "Medel is training: epoch 28th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5451 - acc: 0.8096     \n",
      "Medel is training: epoch 28th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3649 - acc: 0.8217     \n",
      "Medel is training: epoch 28th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5602 - acc: 0.8005     \n",
      "Medel is training: epoch 28th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5944 - acc: 0.8027     \n",
      "Medel is training: epoch 28th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4307 - acc: 0.8168     \n",
      "Medel is training: epoch 28th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3926 - acc: 0.8158     \n",
      "Medel is training: epoch 28th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6451 - acc: 0.7951     \n",
      "Medel is training: epoch 28th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5667 - acc: 0.8059     \n",
      "Medel is training: epoch 28th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2097 - acc: 0.8347     \n",
      "Medel is training: epoch 28th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6498 - acc: 0.7938     \n",
      "Medel is training: epoch 28th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5593 - acc: 0.8056     \n",
      "Medel is training: epoch 28th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2821 - acc: 0.8310     \n",
      "Medel is training: epoch 28th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4166 - acc: 0.8141     \n",
      "Medel is training: epoch 28th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6370 - acc: 0.7950     \n",
      "Medel is training: epoch 28th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5786 - acc: 0.8043     \n",
      "Medel is training: epoch 28th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1639 - acc: 0.8366     \n",
      "Medel is training: epoch 28th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5795 - acc: 0.7987     \n",
      "Medel is training: epoch 28th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5775 - acc: 0.8035     \n",
      "Medel is training: epoch 28th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4863 - acc: 0.8130     \n",
      "Medel is training: epoch 28th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1928 - acc: 0.8363     \n",
      "Medel is training: epoch 28th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6575 - acc: 0.7916     \n",
      "Medel is training: epoch 28th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5299 - acc: 0.8102     \n",
      "Medel is training: epoch 28th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5393 - acc: 0.8057     \n",
      "Medel is training: epoch 28th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1857 - acc: 0.8368     \n",
      "Medel is training: epoch 28th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6419 - acc: 0.7927     \n",
      "Medel is training: epoch 28th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5661 - acc: 0.8048     \n",
      "Medel is training: epoch 28th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4632 - acc: 0.8133     \n",
      "Medel is training: epoch 28th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1963 - acc: 0.8354     \n",
      "Medel is training: epoch 28th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6345 - acc: 0.7923     \n",
      "Medel is training: epoch 28th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6128 - acc: 0.7983     \n",
      "Medel is training: epoch 28th 50000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s - loss: 0.2599 - acc: 1.0000\n",
      "Medel is training: epoch 29th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6506 - acc: 0.7940     \n",
      "Medel is training: epoch 29th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4551 - acc: 0.8145     \n",
      "Medel is training: epoch 29th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4911 - acc: 0.8061     \n",
      "Medel is training: epoch 29th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5467 - acc: 0.8071     \n",
      "Medel is training: epoch 29th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3795 - acc: 0.8182     \n",
      "Medel is training: epoch 29th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6125 - acc: 0.7979     \n",
      "Medel is training: epoch 29th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5701 - acc: 0.8039     \n",
      "Medel is training: epoch 29th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3613 - acc: 0.8180     \n",
      "Medel is training: epoch 29th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6225 - acc: 0.7967     \n",
      "Medel is training: epoch 29th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4372 - acc: 0.8145     \n",
      "Medel is training: epoch 29th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5100 - acc: 0.8055     \n",
      "Medel is training: epoch 29th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6005 - acc: 0.8012     \n",
      "Medel is training: epoch 29th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3858 - acc: 0.8189     \n",
      "Medel is training: epoch 29th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6419 - acc: 0.7919     \n",
      "Medel is training: epoch 29th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5594 - acc: 0.8060     \n",
      "Medel is training: epoch 29th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3446 - acc: 0.8203     \n",
      "Medel is training: epoch 29th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5882 - acc: 0.7986     \n",
      "Medel is training: epoch 29th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5668 - acc: 0.8057     \n",
      "Medel is training: epoch 29th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3321 - acc: 0.8239     \n",
      "Medel is training: epoch 29th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6041 - acc: 0.7957     \n",
      "Medel is training: epoch 29th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5428 - acc: 0.8095     \n",
      "Medel is training: epoch 29th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3615 - acc: 0.8223     \n",
      "Medel is training: epoch 29th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5562 - acc: 0.8008     \n",
      "Medel is training: epoch 29th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5932 - acc: 0.8027     \n",
      "Medel is training: epoch 29th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4279 - acc: 0.8175     \n",
      "Medel is training: epoch 29th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3897 - acc: 0.8164     \n",
      "Medel is training: epoch 29th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6426 - acc: 0.7951     \n",
      "Medel is training: epoch 29th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5659 - acc: 0.8059     \n",
      "Medel is training: epoch 29th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2055 - acc: 0.8352     \n",
      "Medel is training: epoch 29th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6481 - acc: 0.7937     \n",
      "Medel is training: epoch 29th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5578 - acc: 0.8056     \n",
      "Medel is training: epoch 29th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2786 - acc: 0.8314     \n",
      "Medel is training: epoch 29th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4120 - acc: 0.8150     \n",
      "Medel is training: epoch 29th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6351 - acc: 0.7950     \n",
      "Medel is training: epoch 29th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5770 - acc: 0.8043     \n",
      "Medel is training: epoch 29th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1587 - acc: 0.8375     \n",
      "Medel is training: epoch 29th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5768 - acc: 0.7987     \n",
      "Medel is training: epoch 29th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5760 - acc: 0.8035     \n",
      "Medel is training: epoch 29th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4843 - acc: 0.8129     \n",
      "Medel is training: epoch 29th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1874 - acc: 0.8363     \n",
      "Medel is training: epoch 29th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6562 - acc: 0.7918     \n",
      "Medel is training: epoch 29th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5283 - acc: 0.8098     \n",
      "Medel is training: epoch 29th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5379 - acc: 0.8056     \n",
      "Medel is training: epoch 29th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1826 - acc: 0.8369     \n",
      "Medel is training: epoch 29th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6408 - acc: 0.7926     \n",
      "Medel is training: epoch 29th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5655 - acc: 0.8047     \n",
      "Medel is training: epoch 29th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4620 - acc: 0.8130     \n",
      "Medel is training: epoch 29th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1941 - acc: 0.8350     \n",
      "Medel is training: epoch 29th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6321 - acc: 0.7923     \n",
      "Medel is training: epoch 29th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6103 - acc: 0.7985     \n",
      "Medel is training: epoch 29th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2462 - acc: 1.0000\n",
      "Medel is training: epoch 30th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6493 - acc: 0.7941     \n",
      "Medel is training: epoch 30th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4532 - acc: 0.8145     \n",
      "Medel is training: epoch 30th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4888 - acc: 0.8061     \n",
      "Medel is training: epoch 30th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5451 - acc: 0.8072     \n",
      "Medel is training: epoch 30th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3758 - acc: 0.8185     \n",
      "Medel is training: epoch 30th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6115 - acc: 0.7980     \n",
      "Medel is training: epoch 30th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5685 - acc: 0.8039     \n",
      "Medel is training: epoch 30th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3585 - acc: 0.8183     \n",
      "Medel is training: epoch 30th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6213 - acc: 0.7967     \n",
      "Medel is training: epoch 30th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4338 - acc: 0.8146     \n",
      "Medel is training: epoch 30th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5062 - acc: 0.8057     \n",
      "Medel is training: epoch 30th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5991 - acc: 0.8012     \n",
      "Medel is training: epoch 30th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3823 - acc: 0.8199     \n",
      "Medel is training: epoch 30th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6397 - acc: 0.7922     \n",
      "Medel is training: epoch 30th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5586 - acc: 0.8060     \n",
      "Medel is training: epoch 30th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3404 - acc: 0.8222     \n",
      "Medel is training: epoch 30th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5868 - acc: 0.7986     \n",
      "Medel is training: epoch 30th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5653 - acc: 0.8057     \n",
      "Medel is training: epoch 30th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3279 - acc: 0.8240     \n",
      "Medel is training: epoch 30th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6015 - acc: 0.7957     \n",
      "Medel is training: epoch 30th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5418 - acc: 0.8095     \n",
      "Medel is training: epoch 30th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3580 - acc: 0.8224     \n",
      "Medel is training: epoch 30th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5544 - acc: 0.8008     \n",
      "Medel is training: epoch 30th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5915 - acc: 0.8027     \n",
      "Medel is training: epoch 30th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4250 - acc: 0.8179     \n",
      "Medel is training: epoch 30th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3860 - acc: 0.8173     \n",
      "Medel is training: epoch 30th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6408 - acc: 0.7951     \n",
      "Medel is training: epoch 30th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5642 - acc: 0.8060     \n",
      "Medel is training: epoch 30th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2000 - acc: 0.8371     \n",
      "Medel is training: epoch 30th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6442 - acc: 0.7939     \n",
      "Medel is training: epoch 30th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5571 - acc: 0.8056     \n",
      "Medel is training: epoch 30th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2745 - acc: 0.8323     \n",
      "Medel is training: epoch 30th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4101 - acc: 0.8152     \n",
      "Medel is training: epoch 30th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6327 - acc: 0.7949     \n",
      "Medel is training: epoch 30th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5768 - acc: 0.8043     \n",
      "Medel is training: epoch 30th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1542 - acc: 0.8384     \n",
      "Medel is training: epoch 30th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5752 - acc: 0.7986     \n",
      "Medel is training: epoch 30th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5747 - acc: 0.8034     \n",
      "Medel is training: epoch 30th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4827 - acc: 0.8132     \n",
      "Medel is training: epoch 30th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1825 - acc: 0.8363     \n",
      "Medel is training: epoch 30th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6551 - acc: 0.7918     \n",
      "Medel is training: epoch 30th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5262 - acc: 0.8103     \n",
      "Medel is training: epoch 30th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5360 - acc: 0.8056     \n",
      "Medel is training: epoch 30th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1776 - acc: 0.8369     \n",
      "Medel is training: epoch 30th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6379 - acc: 0.7925     \n",
      "Medel is training: epoch 30th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5642 - acc: 0.8048     \n",
      "Medel is training: epoch 30th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4585 - acc: 0.8136     \n",
      "Medel is training: epoch 30th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1891 - acc: 0.8354     \n",
      "Medel is training: epoch 30th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6303 - acc: 0.7923     \n",
      "Medel is training: epoch 30th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6097 - acc: 0.7985     \n",
      "Medel is training: epoch 30th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2338 - acc: 1.0000\n",
      "Medel is training: epoch 31th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6488 - acc: 0.7941     \n",
      "Medel is training: epoch 31th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4504 - acc: 0.8147     \n",
      "Medel is training: epoch 31th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4860 - acc: 0.8062     \n",
      "Medel is training: epoch 31th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5435 - acc: 0.8073     \n",
      "Medel is training: epoch 31th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3721 - acc: 0.8186     \n",
      "Medel is training: epoch 31th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6092 - acc: 0.7981     \n",
      "Medel is training: epoch 31th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5675 - acc: 0.8039     \n",
      "Medel is training: epoch 31th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3542 - acc: 0.8188     \n",
      "Medel is training: epoch 31th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6195 - acc: 0.7967     \n",
      "Medel is training: epoch 31th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4313 - acc: 0.8153     \n",
      "Medel is training: epoch 31th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5033 - acc: 0.8061     \n",
      "Medel is training: epoch 31th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5977 - acc: 0.8012     \n",
      "Medel is training: epoch 31th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3795 - acc: 0.8204     \n",
      "Medel is training: epoch 31th 13000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.6371 - acc: 0.7922     \n",
      "Medel is training: epoch 31th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5576 - acc: 0.8060     \n",
      "Medel is training: epoch 31th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3363 - acc: 0.8227     \n",
      "Medel is training: epoch 31th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5845 - acc: 0.7987     \n",
      "Medel is training: epoch 31th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5644 - acc: 0.8057     \n",
      "Medel is training: epoch 31th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3240 - acc: 0.8245     \n",
      "Medel is training: epoch 31th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6002 - acc: 0.7956     \n",
      "Medel is training: epoch 31th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5400 - acc: 0.8095     \n",
      "Medel is training: epoch 31th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3552 - acc: 0.8225     \n",
      "Medel is training: epoch 31th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5512 - acc: 0.8010     \n",
      "Medel is training: epoch 31th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5903 - acc: 0.8027     \n",
      "Medel is training: epoch 31th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4215 - acc: 0.8183     \n",
      "Medel is training: epoch 31th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3827 - acc: 0.8174     \n",
      "Medel is training: epoch 31th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6389 - acc: 0.7952     \n",
      "Medel is training: epoch 31th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5630 - acc: 0.8059     \n",
      "Medel is training: epoch 31th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1920 - acc: 0.8375     \n",
      "Medel is training: epoch 31th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6418 - acc: 0.7938     \n",
      "Medel is training: epoch 31th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5552 - acc: 0.8058     \n",
      "Medel is training: epoch 31th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2698 - acc: 0.8326     \n",
      "Medel is training: epoch 31th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4074 - acc: 0.8152     \n",
      "Medel is training: epoch 31th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6305 - acc: 0.7949     \n",
      "Medel is training: epoch 31th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5763 - acc: 0.8044     \n",
      "Medel is training: epoch 31th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1483 - acc: 0.8403     \n",
      "Medel is training: epoch 31th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5731 - acc: 0.7991     \n",
      "Medel is training: epoch 31th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5735 - acc: 0.8034     \n",
      "Medel is training: epoch 31th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4817 - acc: 0.8132     \n",
      "Medel is training: epoch 31th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1796 - acc: 0.8376     \n",
      "Medel is training: epoch 31th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6516 - acc: 0.7916     \n",
      "Medel is training: epoch 31th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5258 - acc: 0.8102     \n",
      "Medel is training: epoch 31th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5347 - acc: 0.8057     \n",
      "Medel is training: epoch 31th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1725 - acc: 0.8379     \n",
      "Medel is training: epoch 31th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6356 - acc: 0.7927     \n",
      "Medel is training: epoch 31th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5617 - acc: 0.8048     \n",
      "Medel is training: epoch 31th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4577 - acc: 0.8135     \n",
      "Medel is training: epoch 31th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1842 - acc: 0.8361     \n",
      "Medel is training: epoch 31th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6285 - acc: 0.7924     \n",
      "Medel is training: epoch 31th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6073 - acc: 0.7986     \n",
      "Medel is training: epoch 31th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2227 - acc: 1.0000\n",
      "Medel is training: epoch 32th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6471 - acc: 0.7941     \n",
      "Medel is training: epoch 32th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4487 - acc: 0.8147     \n",
      "Medel is training: epoch 32th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4845 - acc: 0.8062     \n",
      "Medel is training: epoch 32th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5421 - acc: 0.8073     \n",
      "Medel is training: epoch 32th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3690 - acc: 0.8195     \n",
      "Medel is training: epoch 32th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6068 - acc: 0.7979     \n",
      "Medel is training: epoch 32th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5664 - acc: 0.8039     \n",
      "Medel is training: epoch 32th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3511 - acc: 0.8192     \n",
      "Medel is training: epoch 32th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6174 - acc: 0.7967     \n",
      "Medel is training: epoch 32th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4291 - acc: 0.8155     \n",
      "Medel is training: epoch 32th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5003 - acc: 0.8063     \n",
      "Medel is training: epoch 32th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5965 - acc: 0.8012     \n",
      "Medel is training: epoch 32th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3765 - acc: 0.8206     \n",
      "Medel is training: epoch 32th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6356 - acc: 0.7923     \n",
      "Medel is training: epoch 32th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5561 - acc: 0.8060     \n",
      "Medel is training: epoch 32th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3334 - acc: 0.8227     \n",
      "Medel is training: epoch 32th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5835 - acc: 0.7986     \n",
      "Medel is training: epoch 32th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5628 - acc: 0.8058     \n",
      "Medel is training: epoch 32th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3216 - acc: 0.8248     \n",
      "Medel is training: epoch 32th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5976 - acc: 0.7956     \n",
      "Medel is training: epoch 32th 20000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.5384 - acc: 0.8094     \n",
      "Medel is training: epoch 32th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3524 - acc: 0.8228     \n",
      "Medel is training: epoch 32th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5482 - acc: 0.8014     \n",
      "Medel is training: epoch 32th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5889 - acc: 0.8028     \n",
      "Medel is training: epoch 32th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4193 - acc: 0.8186     \n",
      "Medel is training: epoch 32th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3789 - acc: 0.8174     \n",
      "Medel is training: epoch 32th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6374 - acc: 0.7952     \n",
      "Medel is training: epoch 32th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5623 - acc: 0.8060     \n",
      "Medel is training: epoch 32th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1900 - acc: 0.8380     \n",
      "Medel is training: epoch 32th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6392 - acc: 0.7939     \n",
      "Medel is training: epoch 32th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5538 - acc: 0.8057     \n",
      "Medel is training: epoch 32th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2670 - acc: 0.8326     \n",
      "Medel is training: epoch 32th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4039 - acc: 0.8158     \n",
      "Medel is training: epoch 32th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6284 - acc: 0.7949     \n",
      "Medel is training: epoch 32th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5750 - acc: 0.8044     \n",
      "Medel is training: epoch 32th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1433 - acc: 0.8404     \n",
      "Medel is training: epoch 32th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5706 - acc: 0.7991     \n",
      "Medel is training: epoch 32th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5713 - acc: 0.8035     \n",
      "Medel is training: epoch 32th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4797 - acc: 0.8133     \n",
      "Medel is training: epoch 32th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1751 - acc: 0.8381     \n",
      "Medel is training: epoch 32th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6486 - acc: 0.7917     \n",
      "Medel is training: epoch 32th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5235 - acc: 0.8104     \n",
      "Medel is training: epoch 32th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5330 - acc: 0.8059     \n",
      "Medel is training: epoch 32th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1684 - acc: 0.8384     \n",
      "Medel is training: epoch 32th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6341 - acc: 0.7927     \n",
      "Medel is training: epoch 32th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5609 - acc: 0.8048     \n",
      "Medel is training: epoch 32th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4558 - acc: 0.8136     \n",
      "Medel is training: epoch 32th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1801 - acc: 0.8365     \n",
      "Medel is training: epoch 32th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6269 - acc: 0.7924     \n",
      "Medel is training: epoch 32th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6045 - acc: 0.7988     \n",
      "Medel is training: epoch 32th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2132 - acc: 1.0000\n",
      "Medel is training: epoch 33th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6456 - acc: 0.7942     \n",
      "Medel is training: epoch 33th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4480 - acc: 0.8149     \n",
      "Medel is training: epoch 33th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4812 - acc: 0.8064     \n",
      "Medel is training: epoch 33th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5411 - acc: 0.8074     \n",
      "Medel is training: epoch 33th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3656 - acc: 0.8203     \n",
      "Medel is training: epoch 33th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6052 - acc: 0.7981     \n",
      "Medel is training: epoch 33th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5646 - acc: 0.8040     \n",
      "Medel is training: epoch 33th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3472 - acc: 0.8200     \n",
      "Medel is training: epoch 33th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6163 - acc: 0.7967     \n",
      "Medel is training: epoch 33th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4272 - acc: 0.8155     \n",
      "Medel is training: epoch 33th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4973 - acc: 0.8067     \n",
      "Medel is training: epoch 33th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5950 - acc: 0.8012     \n",
      "Medel is training: epoch 33th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3736 - acc: 0.8208     \n",
      "Medel is training: epoch 33th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6331 - acc: 0.7924     \n",
      "Medel is training: epoch 33th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5544 - acc: 0.8060     \n",
      "Medel is training: epoch 33th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3295 - acc: 0.8232     \n",
      "Medel is training: epoch 33th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5811 - acc: 0.7989     \n",
      "Medel is training: epoch 33th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5617 - acc: 0.8058     \n",
      "Medel is training: epoch 33th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3174 - acc: 0.8252     \n",
      "Medel is training: epoch 33th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5954 - acc: 0.7957     \n",
      "Medel is training: epoch 33th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5367 - acc: 0.8094     \n",
      "Medel is training: epoch 33th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3491 - acc: 0.8229     \n",
      "Medel is training: epoch 33th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5456 - acc: 0.8016     \n",
      "Medel is training: epoch 33th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5870 - acc: 0.8029     \n",
      "Medel is training: epoch 33th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4165 - acc: 0.8186     \n",
      "Medel is training: epoch 33th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3756 - acc: 0.8181     \n",
      "Medel is training: epoch 33th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6358 - acc: 0.7951     \n",
      "Medel is training: epoch 33th 27000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.5606 - acc: 0.8060     \n",
      "Medel is training: epoch 33th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1851 - acc: 0.8383     \n",
      "Medel is training: epoch 33th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6383 - acc: 0.7938     \n",
      "Medel is training: epoch 33th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5534 - acc: 0.8056     \n",
      "Medel is training: epoch 33th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2654 - acc: 0.8325     \n",
      "Medel is training: epoch 33th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4014 - acc: 0.8159     \n",
      "Medel is training: epoch 33th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6272 - acc: 0.7949     \n",
      "Medel is training: epoch 33th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5729 - acc: 0.8044     \n",
      "Medel is training: epoch 33th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1392 - acc: 0.8405     \n",
      "Medel is training: epoch 33th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5680 - acc: 0.7991     \n",
      "Medel is training: epoch 33th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5693 - acc: 0.8036     \n",
      "Medel is training: epoch 33th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4776 - acc: 0.8132     \n",
      "Medel is training: epoch 33th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1696 - acc: 0.8379     \n",
      "Medel is training: epoch 33th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6468 - acc: 0.7918     \n",
      "Medel is training: epoch 33th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5218 - acc: 0.8103     \n",
      "Medel is training: epoch 33th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5310 - acc: 0.8059     \n",
      "Medel is training: epoch 33th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1647 - acc: 0.8379     \n",
      "Medel is training: epoch 33th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6319 - acc: 0.7927     \n",
      "Medel is training: epoch 33th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5588 - acc: 0.8048     \n",
      "Medel is training: epoch 33th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4544 - acc: 0.8136     \n",
      "Medel is training: epoch 33th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1772 - acc: 0.8363     \n",
      "Medel is training: epoch 33th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6248 - acc: 0.7924     \n",
      "Medel is training: epoch 33th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6028 - acc: 0.7989     \n",
      "Medel is training: epoch 33th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2059 - acc: 1.0000\n",
      "Medel is training: epoch 34th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6445 - acc: 0.7941     \n",
      "Medel is training: epoch 34th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4444 - acc: 0.8151     \n",
      "Medel is training: epoch 34th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4797 - acc: 0.8064     \n",
      "Medel is training: epoch 34th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5394 - acc: 0.8073     \n",
      "Medel is training: epoch 34th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3621 - acc: 0.8205     \n",
      "Medel is training: epoch 34th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6036 - acc: 0.7980     \n",
      "Medel is training: epoch 34th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5633 - acc: 0.8039     \n",
      "Medel is training: epoch 34th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3449 - acc: 0.8202     \n",
      "Medel is training: epoch 34th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6144 - acc: 0.7969     \n",
      "Medel is training: epoch 34th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4244 - acc: 0.8161     \n",
      "Medel is training: epoch 34th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4947 - acc: 0.8071     \n",
      "Medel is training: epoch 34th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5935 - acc: 0.8012     \n",
      "Medel is training: epoch 34th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3710 - acc: 0.8206     \n",
      "Medel is training: epoch 34th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6309 - acc: 0.7925     \n",
      "Medel is training: epoch 34th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5538 - acc: 0.8059     \n",
      "Medel is training: epoch 34th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3263 - acc: 0.8236     \n",
      "Medel is training: epoch 34th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5792 - acc: 0.7989     \n",
      "Medel is training: epoch 34th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5602 - acc: 0.8058     \n",
      "Medel is training: epoch 34th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3140 - acc: 0.8257     \n",
      "Medel is training: epoch 34th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5932 - acc: 0.7958     \n",
      "Medel is training: epoch 34th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5355 - acc: 0.8095     \n",
      "Medel is training: epoch 34th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3465 - acc: 0.8233     \n",
      "Medel is training: epoch 34th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5431 - acc: 0.8018     \n",
      "Medel is training: epoch 34th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5856 - acc: 0.8028     \n",
      "Medel is training: epoch 34th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4141 - acc: 0.8187     \n",
      "Medel is training: epoch 34th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3727 - acc: 0.8184     \n",
      "Medel is training: epoch 34th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6334 - acc: 0.7952     \n",
      "Medel is training: epoch 34th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5600 - acc: 0.8060     \n",
      "Medel is training: epoch 34th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1837 - acc: 0.8382     \n",
      "Medel is training: epoch 34th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6368 - acc: 0.7940     \n",
      "Medel is training: epoch 34th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5513 - acc: 0.8057     \n",
      "Medel is training: epoch 34th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2613 - acc: 0.8332     \n",
      "Medel is training: epoch 34th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3979 - acc: 0.8161     \n",
      "Medel is training: epoch 34th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6251 - acc: 0.7951     \n",
      "Medel is training: epoch 34th 34000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.5727 - acc: 0.8044     \n",
      "Medel is training: epoch 34th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1346 - acc: 0.8409     \n",
      "Medel is training: epoch 34th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5652 - acc: 0.7990     \n",
      "Medel is training: epoch 34th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5677 - acc: 0.8036     \n",
      "Medel is training: epoch 34th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4757 - acc: 0.8134     \n",
      "Medel is training: epoch 34th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1654 - acc: 0.8382     \n",
      "Medel is training: epoch 34th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6451 - acc: 0.7917     \n",
      "Medel is training: epoch 34th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5194 - acc: 0.8103     \n",
      "Medel is training: epoch 34th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5293 - acc: 0.8062     \n",
      "Medel is training: epoch 34th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1612 - acc: 0.8385     \n",
      "Medel is training: epoch 34th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6293 - acc: 0.7928     \n",
      "Medel is training: epoch 34th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5574 - acc: 0.8048     \n",
      "Medel is training: epoch 34th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4527 - acc: 0.8135     \n",
      "Medel is training: epoch 34th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1740 - acc: 0.8366     \n",
      "Medel is training: epoch 34th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6224 - acc: 0.7922     \n",
      "Medel is training: epoch 34th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6014 - acc: 0.7988     \n",
      "Medel is training: epoch 34th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.2002 - acc: 1.0000\n",
      "Medel is training: epoch 35th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6438 - acc: 0.7942     \n",
      "Medel is training: epoch 35th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4422 - acc: 0.8150     \n",
      "Medel is training: epoch 35th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4767 - acc: 0.8067     \n",
      "Medel is training: epoch 35th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5381 - acc: 0.8074     \n",
      "Medel is training: epoch 35th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3590 - acc: 0.8206     \n",
      "Medel is training: epoch 35th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6016 - acc: 0.7980     \n",
      "Medel is training: epoch 35th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5623 - acc: 0.8039     \n",
      "Medel is training: epoch 35th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3410 - acc: 0.8203     \n",
      "Medel is training: epoch 35th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6131 - acc: 0.7969     \n",
      "Medel is training: epoch 35th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4221 - acc: 0.8161     \n",
      "Medel is training: epoch 35th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4920 - acc: 0.8072     \n",
      "Medel is training: epoch 35th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5920 - acc: 0.8013     \n",
      "Medel is training: epoch 35th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3683 - acc: 0.8209     \n",
      "Medel is training: epoch 35th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6294 - acc: 0.7925     \n",
      "Medel is training: epoch 35th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5519 - acc: 0.8060     \n",
      "Medel is training: epoch 35th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3230 - acc: 0.8240     \n",
      "Medel is training: epoch 35th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5766 - acc: 0.7989     \n",
      "Medel is training: epoch 35th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5588 - acc: 0.8058     \n",
      "Medel is training: epoch 35th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3109 - acc: 0.8259     \n",
      "Medel is training: epoch 35th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5910 - acc: 0.7958     \n",
      "Medel is training: epoch 35th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5339 - acc: 0.8095     \n",
      "Medel is training: epoch 35th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3435 - acc: 0.8237     \n",
      "Medel is training: epoch 35th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5402 - acc: 0.8018     \n",
      "Medel is training: epoch 35th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5840 - acc: 0.8029     \n",
      "Medel is training: epoch 35th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4118 - acc: 0.8189     \n",
      "Medel is training: epoch 35th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3689 - acc: 0.8183     \n",
      "Medel is training: epoch 35th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6321 - acc: 0.7953     \n",
      "Medel is training: epoch 35th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 6s - loss: 1.5585 - acc: 0.8060     \n",
      "Medel is training: epoch 35th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1779 - acc: 0.8387     \n",
      "Medel is training: epoch 35th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6340 - acc: 0.7941     \n",
      "Medel is training: epoch 35th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5507 - acc: 0.8056     \n",
      "Medel is training: epoch 35th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2593 - acc: 0.8335     \n",
      "Medel is training: epoch 35th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3951 - acc: 0.8160     \n",
      "Medel is training: epoch 35th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6235 - acc: 0.7950     \n",
      "Medel is training: epoch 35th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5704 - acc: 0.8044     \n",
      "Medel is training: epoch 35th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1311 - acc: 0.8410     \n",
      "Medel is training: epoch 35th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5627 - acc: 0.7990     \n",
      "Medel is training: epoch 35th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5665 - acc: 0.8036     \n",
      "Medel is training: epoch 35th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4742 - acc: 0.8136     \n",
      "Medel is training: epoch 35th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1620 - acc: 0.8383     \n",
      "Medel is training: epoch 35th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6428 - acc: 0.7917     \n",
      "Medel is training: epoch 35th 41000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.5186 - acc: 0.8104     \n",
      "Medel is training: epoch 35th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5281 - acc: 0.8059     \n",
      "Medel is training: epoch 35th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1580 - acc: 0.8383     \n",
      "Medel is training: epoch 35th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6275 - acc: 0.7928     \n",
      "Medel is training: epoch 35th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5557 - acc: 0.8049     \n",
      "Medel is training: epoch 35th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4507 - acc: 0.8136     \n",
      "Medel is training: epoch 35th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1697 - acc: 0.8365     \n",
      "Medel is training: epoch 35th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6206 - acc: 0.7922     \n",
      "Medel is training: epoch 35th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5997 - acc: 0.7987     \n",
      "Medel is training: epoch 35th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1961 - acc: 1.0000\n",
      "Medel is training: epoch 36th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6409 - acc: 0.7942     \n",
      "Medel is training: epoch 36th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4404 - acc: 0.8150     \n",
      "Medel is training: epoch 36th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4745 - acc: 0.8067     \n",
      "Medel is training: epoch 36th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5374 - acc: 0.8074     \n",
      "Medel is training: epoch 36th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3559 - acc: 0.8213     \n",
      "Medel is training: epoch 36th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5992 - acc: 0.7980     \n",
      "Medel is training: epoch 36th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5609 - acc: 0.8039     \n",
      "Medel is training: epoch 36th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3384 - acc: 0.8206     \n",
      "Medel is training: epoch 36th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6111 - acc: 0.7969     \n",
      "Medel is training: epoch 36th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4203 - acc: 0.8163     \n",
      "Medel is training: epoch 36th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4898 - acc: 0.8074     \n",
      "Medel is training: epoch 36th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5906 - acc: 0.8014     \n",
      "Medel is training: epoch 36th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3664 - acc: 0.8210     \n",
      "Medel is training: epoch 36th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6276 - acc: 0.7927     \n",
      "Medel is training: epoch 36th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5506 - acc: 0.8059     \n",
      "Medel is training: epoch 36th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3201 - acc: 0.8246     \n",
      "Medel is training: epoch 36th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5753 - acc: 0.7991     \n",
      "Medel is training: epoch 36th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5576 - acc: 0.8058     \n",
      "Medel is training: epoch 36th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3084 - acc: 0.8260     \n",
      "Medel is training: epoch 36th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5887 - acc: 0.7959     \n",
      "Medel is training: epoch 36th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5322 - acc: 0.8095     \n",
      "Medel is training: epoch 36th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3408 - acc: 0.8239     \n",
      "Medel is training: epoch 36th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5374 - acc: 0.8020     \n",
      "Medel is training: epoch 36th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5827 - acc: 0.8028     \n",
      "Medel is training: epoch 36th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4093 - acc: 0.8190     \n",
      "Medel is training: epoch 36th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3663 - acc: 0.8186     \n",
      "Medel is training: epoch 36th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6301 - acc: 0.7951     \n",
      "Medel is training: epoch 36th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5573 - acc: 0.8060     \n",
      "Medel is training: epoch 36th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1747 - acc: 0.8386     \n",
      "Medel is training: epoch 36th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6322 - acc: 0.7942     \n",
      "Medel is training: epoch 36th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5488 - acc: 0.8057     \n",
      "Medel is training: epoch 36th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2557 - acc: 0.8336     \n",
      "Medel is training: epoch 36th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3928 - acc: 0.8160     \n",
      "Medel is training: epoch 36th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6204 - acc: 0.7952     \n",
      "Medel is training: epoch 36th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5693 - acc: 0.8043     \n",
      "Medel is training: epoch 36th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1272 - acc: 0.8412     \n",
      "Medel is training: epoch 36th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5608 - acc: 0.7988     \n",
      "Medel is training: epoch 36th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5651 - acc: 0.8036     \n",
      "Medel is training: epoch 36th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4726 - acc: 0.8135     \n",
      "Medel is training: epoch 36th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1576 - acc: 0.8390     \n",
      "Medel is training: epoch 36th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6411 - acc: 0.7917     \n",
      "Medel is training: epoch 36th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5169 - acc: 0.8104     \n",
      "Medel is training: epoch 36th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5258 - acc: 0.8060     \n",
      "Medel is training: epoch 36th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1531 - acc: 0.8388     \n",
      "Medel is training: epoch 36th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6251 - acc: 0.7929     \n",
      "Medel is training: epoch 36th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5546 - acc: 0.8049     \n",
      "Medel is training: epoch 36th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4485 - acc: 0.8138     \n",
      "Medel is training: epoch 36th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1669 - acc: 0.8373     \n",
      "Medel is training: epoch 36th 48000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.6183 - acc: 0.7925     \n",
      "Medel is training: epoch 36th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5982 - acc: 0.7991     \n",
      "Medel is training: epoch 36th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1925 - acc: 1.0000\n",
      "Medel is training: epoch 37th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6400 - acc: 0.7944     \n",
      "Medel is training: epoch 37th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4379 - acc: 0.8152     \n",
      "Medel is training: epoch 37th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4715 - acc: 0.8068     \n",
      "Medel is training: epoch 37th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5353 - acc: 0.8074     \n",
      "Medel is training: epoch 37th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3531 - acc: 0.8213     \n",
      "Medel is training: epoch 37th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5979 - acc: 0.7981     \n",
      "Medel is training: epoch 37th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5592 - acc: 0.8039     \n",
      "Medel is training: epoch 37th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3356 - acc: 0.8206     \n",
      "Medel is training: epoch 37th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6094 - acc: 0.7970     \n",
      "Medel is training: epoch 37th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4185 - acc: 0.8162     \n",
      "Medel is training: epoch 37th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4871 - acc: 0.8074     \n",
      "Medel is training: epoch 37th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5890 - acc: 0.8013     \n",
      "Medel is training: epoch 37th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3636 - acc: 0.8209     \n",
      "Medel is training: epoch 37th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6260 - acc: 0.7927     \n",
      "Medel is training: epoch 37th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5498 - acc: 0.8059     \n",
      "Medel is training: epoch 37th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3175 - acc: 0.8247     \n",
      "Medel is training: epoch 37th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5734 - acc: 0.7991     \n",
      "Medel is training: epoch 37th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5561 - acc: 0.8058     \n",
      "Medel is training: epoch 37th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3053 - acc: 0.8261     \n",
      "Medel is training: epoch 37th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5877 - acc: 0.7959     \n",
      "Medel is training: epoch 37th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5306 - acc: 0.8097     \n",
      "Medel is training: epoch 37th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3381 - acc: 0.8241     \n",
      "Medel is training: epoch 37th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5341 - acc: 0.8020     \n",
      "Medel is training: epoch 37th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5817 - acc: 0.8026     \n",
      "Medel is training: epoch 37th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4079 - acc: 0.8191     \n",
      "Medel is training: epoch 37th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3631 - acc: 0.8190     \n",
      "Medel is training: epoch 37th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6284 - acc: 0.7954     \n",
      "Medel is training: epoch 37th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 6s - loss: 1.5561 - acc: 0.8060     \n",
      "Medel is training: epoch 37th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1698 - acc: 0.8396     \n",
      "Medel is training: epoch 37th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6296 - acc: 0.7945     \n",
      "Medel is training: epoch 37th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5478 - acc: 0.8056     \n",
      "Medel is training: epoch 37th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2541 - acc: 0.8336     \n",
      "Medel is training: epoch 37th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3896 - acc: 0.8160     \n",
      "Medel is training: epoch 37th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6188 - acc: 0.7952     \n",
      "Medel is training: epoch 37th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5682 - acc: 0.8044     \n",
      "Medel is training: epoch 37th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1224 - acc: 0.8416     \n",
      "Medel is training: epoch 37th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5573 - acc: 0.7992     \n",
      "Medel is training: epoch 37th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5632 - acc: 0.8035     \n",
      "Medel is training: epoch 37th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4709 - acc: 0.8137     \n",
      "Medel is training: epoch 37th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1544 - acc: 0.8388     \n",
      "Medel is training: epoch 37th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6379 - acc: 0.7919     \n",
      "Medel is training: epoch 37th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5164 - acc: 0.8104     \n",
      "Medel is training: epoch 37th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5245 - acc: 0.8061     \n",
      "Medel is training: epoch 37th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1499 - acc: 0.8391     \n",
      "Medel is training: epoch 37th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6230 - acc: 0.7931     \n",
      "Medel is training: epoch 37th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5523 - acc: 0.8049     \n",
      "Medel is training: epoch 37th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4475 - acc: 0.8138     \n",
      "Medel is training: epoch 37th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1638 - acc: 0.8374     \n",
      "Medel is training: epoch 37th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6161 - acc: 0.7926     \n",
      "Medel is training: epoch 37th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5959 - acc: 0.7992     \n",
      "Medel is training: epoch 37th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1898 - acc: 1.0000\n",
      "Medel is training: epoch 38th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6390 - acc: 0.7942     \n",
      "Medel is training: epoch 38th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4363 - acc: 0.8155     \n",
      "Medel is training: epoch 38th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4695 - acc: 0.8070     \n",
      "Medel is training: epoch 38th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5346 - acc: 0.8073     \n",
      "Medel is training: epoch 38th 4000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.3504 - acc: 0.8216     \n",
      "Medel is training: epoch 38th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5964 - acc: 0.7983     \n",
      "Medel is training: epoch 38th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5581 - acc: 0.8038     \n",
      "Medel is training: epoch 38th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3330 - acc: 0.8209     \n",
      "Medel is training: epoch 38th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6082 - acc: 0.7969     \n",
      "Medel is training: epoch 38th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4163 - acc: 0.8163     \n",
      "Medel is training: epoch 38th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4842 - acc: 0.8075     \n",
      "Medel is training: epoch 38th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5878 - acc: 0.8012     \n",
      "Medel is training: epoch 38th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3615 - acc: 0.8212     \n",
      "Medel is training: epoch 38th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6238 - acc: 0.7930     \n",
      "Medel is training: epoch 38th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5487 - acc: 0.8057     \n",
      "Medel is training: epoch 38th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3147 - acc: 0.8254     \n",
      "Medel is training: epoch 38th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5709 - acc: 0.7993     \n",
      "Medel is training: epoch 38th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5550 - acc: 0.8058     \n",
      "Medel is training: epoch 38th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3030 - acc: 0.8263     \n",
      "Medel is training: epoch 38th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5859 - acc: 0.7964     \n",
      "Medel is training: epoch 38th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5290 - acc: 0.8098     \n",
      "Medel is training: epoch 38th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3362 - acc: 0.8243     \n",
      "Medel is training: epoch 38th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5312 - acc: 0.8021     \n",
      "Medel is training: epoch 38th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5798 - acc: 0.8025     \n",
      "Medel is training: epoch 38th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4056 - acc: 0.8193     \n",
      "Medel is training: epoch 38th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3611 - acc: 0.8192     \n",
      "Medel is training: epoch 38th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6265 - acc: 0.7954     \n",
      "Medel is training: epoch 38th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5551 - acc: 0.8060     \n",
      "Medel is training: epoch 38th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1666 - acc: 0.8399     \n",
      "Medel is training: epoch 38th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6256 - acc: 0.7943     \n",
      "Medel is training: epoch 38th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5472 - acc: 0.8055     \n",
      "Medel is training: epoch 38th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2502 - acc: 0.8341     \n",
      "Medel is training: epoch 38th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3872 - acc: 0.8161     \n",
      "Medel is training: epoch 38th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6165 - acc: 0.7952     \n",
      "Medel is training: epoch 38th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5671 - acc: 0.8043     \n",
      "Medel is training: epoch 38th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1196 - acc: 0.8419     \n",
      "Medel is training: epoch 38th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5552 - acc: 0.7992     \n",
      "Medel is training: epoch 38th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5614 - acc: 0.8036     \n",
      "Medel is training: epoch 38th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4701 - acc: 0.8134     \n",
      "Medel is training: epoch 38th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1512 - acc: 0.8386     \n",
      "Medel is training: epoch 38th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6367 - acc: 0.7917     \n",
      "Medel is training: epoch 38th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5137 - acc: 0.8106     \n",
      "Medel is training: epoch 38th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5227 - acc: 0.8062     \n",
      "Medel is training: epoch 38th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1484 - acc: 0.8387     \n",
      "Medel is training: epoch 38th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6209 - acc: 0.7931     \n",
      "Medel is training: epoch 38th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5506 - acc: 0.8047     \n",
      "Medel is training: epoch 38th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4456 - acc: 0.8139     \n",
      "Medel is training: epoch 38th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1605 - acc: 0.8374     \n",
      "Medel is training: epoch 38th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6135 - acc: 0.7926     \n",
      "Medel is training: epoch 38th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5949 - acc: 0.7993     \n",
      "Medel is training: epoch 38th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1874 - acc: 1.0000\n",
      "Medel is training: epoch 39th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6367 - acc: 0.7943     \n",
      "Medel is training: epoch 39th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4337 - acc: 0.8157     \n",
      "Medel is training: epoch 39th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4668 - acc: 0.8072     \n",
      "Medel is training: epoch 39th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5332 - acc: 0.8075     \n",
      "Medel is training: epoch 39th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3475 - acc: 0.8220     \n",
      "Medel is training: epoch 39th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5944 - acc: 0.7982     \n",
      "Medel is training: epoch 39th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5570 - acc: 0.8036     \n",
      "Medel is training: epoch 39th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3302 - acc: 0.8212     \n",
      "Medel is training: epoch 39th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6072 - acc: 0.7972     \n",
      "Medel is training: epoch 39th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4146 - acc: 0.8166     \n",
      "Medel is training: epoch 39th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4818 - acc: 0.8078     \n",
      "Medel is training: epoch 39th 11000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.5866 - acc: 0.8013     \n",
      "Medel is training: epoch 39th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3590 - acc: 0.8214     \n",
      "Medel is training: epoch 39th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6213 - acc: 0.7928     \n",
      "Medel is training: epoch 39th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5471 - acc: 0.8059     \n",
      "Medel is training: epoch 39th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3119 - acc: 0.8255     \n",
      "Medel is training: epoch 39th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5687 - acc: 0.7994     \n",
      "Medel is training: epoch 39th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5541 - acc: 0.8058     \n",
      "Medel is training: epoch 39th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3000 - acc: 0.8269     \n",
      "Medel is training: epoch 39th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5829 - acc: 0.7965     \n",
      "Medel is training: epoch 39th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5276 - acc: 0.8098     \n",
      "Medel is training: epoch 39th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3331 - acc: 0.8244     \n",
      "Medel is training: epoch 39th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5289 - acc: 0.8020     \n",
      "Medel is training: epoch 39th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5780 - acc: 0.8026     \n",
      "Medel is training: epoch 39th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4037 - acc: 0.8193     \n",
      "Medel is training: epoch 39th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 6s - loss: 1.3579 - acc: 0.8192     \n",
      "Medel is training: epoch 39th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6249 - acc: 0.7956     \n",
      "Medel is training: epoch 39th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5538 - acc: 0.8060     \n",
      "Medel is training: epoch 39th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1638 - acc: 0.8401     \n",
      "Medel is training: epoch 39th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6240 - acc: 0.7946     \n",
      "Medel is training: epoch 39th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5450 - acc: 0.8054     \n",
      "Medel is training: epoch 39th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2489 - acc: 0.8340     \n",
      "Medel is training: epoch 39th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3851 - acc: 0.8159     \n",
      "Medel is training: epoch 39th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6146 - acc: 0.7953     \n",
      "Medel is training: epoch 39th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5668 - acc: 0.8043     \n",
      "Medel is training: epoch 39th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1163 - acc: 0.8423     \n",
      "Medel is training: epoch 39th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5539 - acc: 0.7992     \n",
      "Medel is training: epoch 39th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5607 - acc: 0.8036     \n",
      "Medel is training: epoch 39th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4691 - acc: 0.8133     \n",
      "Medel is training: epoch 39th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1483 - acc: 0.8389     \n",
      "Medel is training: epoch 39th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6339 - acc: 0.7918     \n",
      "Medel is training: epoch 39th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5124 - acc: 0.8107     \n",
      "Medel is training: epoch 39th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5222 - acc: 0.8062     \n",
      "Medel is training: epoch 39th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1447 - acc: 0.8392     \n",
      "Medel is training: epoch 39th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6173 - acc: 0.7930     \n",
      "Medel is training: epoch 39th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5489 - acc: 0.8045     \n",
      "Medel is training: epoch 39th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4439 - acc: 0.8139     \n",
      "Medel is training: epoch 39th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1559 - acc: 0.8383     \n",
      "Medel is training: epoch 39th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6107 - acc: 0.7927     \n",
      "Medel is training: epoch 39th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5920 - acc: 0.7994     \n",
      "Medel is training: epoch 39th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1855 - acc: 1.0000\n",
      "Medel is training: epoch 40th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6360 - acc: 0.7943     \n",
      "Medel is training: epoch 40th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4325 - acc: 0.8156     \n",
      "Medel is training: epoch 40th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4646 - acc: 0.8074     \n",
      "Medel is training: epoch 40th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5320 - acc: 0.8074     \n",
      "Medel is training: epoch 40th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3456 - acc: 0.8222     \n",
      "Medel is training: epoch 40th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5928 - acc: 0.7984     \n",
      "Medel is training: epoch 40th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5554 - acc: 0.8037     \n",
      "Medel is training: epoch 40th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3275 - acc: 0.8215     \n",
      "Medel is training: epoch 40th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6044 - acc: 0.7971     \n",
      "Medel is training: epoch 40th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4136 - acc: 0.8165     \n",
      "Medel is training: epoch 40th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4794 - acc: 0.8081     \n",
      "Medel is training: epoch 40th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5850 - acc: 0.8013     \n",
      "Medel is training: epoch 40th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3574 - acc: 0.8214     \n",
      "Medel is training: epoch 40th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6186 - acc: 0.7929     \n",
      "Medel is training: epoch 40th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5462 - acc: 0.8059     \n",
      "Medel is training: epoch 40th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3096 - acc: 0.8257     \n",
      "Medel is training: epoch 40th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5666 - acc: 0.7995     \n",
      "Medel is training: epoch 40th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5530 - acc: 0.8058     \n",
      "Medel is training: epoch 40th 18000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.2967 - acc: 0.8273     \n",
      "Medel is training: epoch 40th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5810 - acc: 0.7967     \n",
      "Medel is training: epoch 40th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5262 - acc: 0.8095     \n",
      "Medel is training: epoch 40th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3309 - acc: 0.8246     \n",
      "Medel is training: epoch 40th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5258 - acc: 0.8021     \n",
      "Medel is training: epoch 40th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 6s - loss: 1.5764 - acc: 0.8026     \n",
      "Medel is training: epoch 40th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4015 - acc: 0.8194     \n",
      "Medel is training: epoch 40th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3557 - acc: 0.8193     \n",
      "Medel is training: epoch 40th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6236 - acc: 0.7957     \n",
      "Medel is training: epoch 40th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5532 - acc: 0.8059     \n",
      "Medel is training: epoch 40th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1601 - acc: 0.8406     \n",
      "Medel is training: epoch 40th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6218 - acc: 0.7949     \n",
      "Medel is training: epoch 40th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5444 - acc: 0.8056     \n",
      "Medel is training: epoch 40th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2467 - acc: 0.8344     \n",
      "Medel is training: epoch 40th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3821 - acc: 0.8162     \n",
      "Medel is training: epoch 40th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6125 - acc: 0.7953     \n",
      "Medel is training: epoch 40th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5658 - acc: 0.8042     \n",
      "Medel is training: epoch 40th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1129 - acc: 0.8426     \n",
      "Medel is training: epoch 40th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5528 - acc: 0.7993     \n",
      "Medel is training: epoch 40th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5584 - acc: 0.8036     \n",
      "Medel is training: epoch 40th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4681 - acc: 0.8135     \n",
      "Medel is training: epoch 40th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1450 - acc: 0.8392     \n",
      "Medel is training: epoch 40th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6319 - acc: 0.7916     \n",
      "Medel is training: epoch 40th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5107 - acc: 0.8110     \n",
      "Medel is training: epoch 40th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 6s - loss: 1.5206 - acc: 0.8063     \n",
      "Medel is training: epoch 40th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1433 - acc: 0.8398     \n",
      "Medel is training: epoch 40th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6150 - acc: 0.7929     \n",
      "Medel is training: epoch 40th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5484 - acc: 0.8047     \n",
      "Medel is training: epoch 40th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4426 - acc: 0.8141     \n",
      "Medel is training: epoch 40th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1545 - acc: 0.8384     \n",
      "Medel is training: epoch 40th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6097 - acc: 0.7927     \n",
      "Medel is training: epoch 40th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5908 - acc: 0.7992     \n",
      "Medel is training: epoch 40th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1835 - acc: 1.0000\n",
      "Medel is training: epoch 41th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6335 - acc: 0.7944     \n",
      "Medel is training: epoch 41th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 6s - loss: 1.4307 - acc: 0.8156     \n",
      "Medel is training: epoch 41th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4614 - acc: 0.8078     \n",
      "Medel is training: epoch 41th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5310 - acc: 0.8076     \n",
      "Medel is training: epoch 41th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3434 - acc: 0.8224     \n",
      "Medel is training: epoch 41th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5916 - acc: 0.7986     \n",
      "Medel is training: epoch 41th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5541 - acc: 0.8036     \n",
      "Medel is training: epoch 41th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 6s - loss: 1.3253 - acc: 0.8215     \n",
      "Medel is training: epoch 41th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6030 - acc: 0.7974     \n",
      "Medel is training: epoch 41th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4115 - acc: 0.8166     \n",
      "Medel is training: epoch 41th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4768 - acc: 0.8083     \n",
      "Medel is training: epoch 41th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5835 - acc: 0.8013     \n",
      "Medel is training: epoch 41th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3548 - acc: 0.8216     \n",
      "Medel is training: epoch 41th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6170 - acc: 0.7932     \n",
      "Medel is training: epoch 41th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5457 - acc: 0.8059     \n",
      "Medel is training: epoch 41th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3067 - acc: 0.8256     \n",
      "Medel is training: epoch 41th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5656 - acc: 0.7995     \n",
      "Medel is training: epoch 41th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 6s - loss: 1.5512 - acc: 0.8057     \n",
      "Medel is training: epoch 41th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2945 - acc: 0.8273     \n",
      "Medel is training: epoch 41th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5791 - acc: 0.7966     \n",
      "Medel is training: epoch 41th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5252 - acc: 0.8096     \n",
      "Medel is training: epoch 41th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3288 - acc: 0.8246     \n",
      "Medel is training: epoch 41th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5235 - acc: 0.8021     \n",
      "Medel is training: epoch 41th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5750 - acc: 0.8025     \n",
      "Medel is training: epoch 41th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4000 - acc: 0.8192     \n",
      "Medel is training: epoch 41th 25000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.3540 - acc: 0.8194     \n",
      "Medel is training: epoch 41th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6223 - acc: 0.7954     \n",
      "Medel is training: epoch 41th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5519 - acc: 0.8057     \n",
      "Medel is training: epoch 41th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1574 - acc: 0.8404     \n",
      "Medel is training: epoch 41th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6204 - acc: 0.7947     \n",
      "Medel is training: epoch 41th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5433 - acc: 0.8056     \n",
      "Medel is training: epoch 41th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2444 - acc: 0.8346     \n",
      "Medel is training: epoch 41th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3803 - acc: 0.8160     \n",
      "Medel is training: epoch 41th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6108 - acc: 0.7956     \n",
      "Medel is training: epoch 41th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5643 - acc: 0.8043     \n",
      "Medel is training: epoch 41th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1102 - acc: 0.8433     \n",
      "Medel is training: epoch 41th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5496 - acc: 0.7997     \n",
      "Medel is training: epoch 41th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5573 - acc: 0.8036     \n",
      "Medel is training: epoch 41th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4662 - acc: 0.8132     \n",
      "Medel is training: epoch 41th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1424 - acc: 0.8393     \n",
      "Medel is training: epoch 41th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6294 - acc: 0.7917     \n",
      "Medel is training: epoch 41th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5088 - acc: 0.8109     \n",
      "Medel is training: epoch 41th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5196 - acc: 0.8065     \n",
      "Medel is training: epoch 41th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1395 - acc: 0.8397     \n",
      "Medel is training: epoch 41th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6137 - acc: 0.7931     \n",
      "Medel is training: epoch 41th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5463 - acc: 0.8046     \n",
      "Medel is training: epoch 41th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4408 - acc: 0.8141     \n",
      "Medel is training: epoch 41th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1525 - acc: 0.8384     \n",
      "Medel is training: epoch 41th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6062 - acc: 0.7926     \n",
      "Medel is training: epoch 41th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5893 - acc: 0.7992     \n",
      "Medel is training: epoch 41th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1816 - acc: 1.0000\n",
      "Medel is training: epoch 42th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6322 - acc: 0.7945     \n",
      "Medel is training: epoch 42th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4289 - acc: 0.8158     \n",
      "Medel is training: epoch 42th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4598 - acc: 0.8077     \n",
      "Medel is training: epoch 42th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5296 - acc: 0.8076     \n",
      "Medel is training: epoch 42th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3413 - acc: 0.8224     \n",
      "Medel is training: epoch 42th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5895 - acc: 0.7987     \n",
      "Medel is training: epoch 42th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5532 - acc: 0.8037     \n",
      "Medel is training: epoch 42th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3225 - acc: 0.8217     \n",
      "Medel is training: epoch 42th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6011 - acc: 0.7974     \n",
      "Medel is training: epoch 42th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4101 - acc: 0.8165     \n",
      "Medel is training: epoch 42th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4746 - acc: 0.8083     \n",
      "Medel is training: epoch 42th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5821 - acc: 0.8014     \n",
      "Medel is training: epoch 42th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3529 - acc: 0.8217     \n",
      "Medel is training: epoch 42th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6158 - acc: 0.7931     \n",
      "Medel is training: epoch 42th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5446 - acc: 0.8057     \n",
      "Medel is training: epoch 42th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3049 - acc: 0.8259     \n",
      "Medel is training: epoch 42th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5631 - acc: 0.7997     \n",
      "Medel is training: epoch 42th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5504 - acc: 0.8057     \n",
      "Medel is training: epoch 42th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2920 - acc: 0.8273     \n",
      "Medel is training: epoch 42th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5767 - acc: 0.7968     \n",
      "Medel is training: epoch 42th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5249 - acc: 0.8096     \n",
      "Medel is training: epoch 42th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3267 - acc: 0.8248     \n",
      "Medel is training: epoch 42th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5220 - acc: 0.8021     \n",
      "Medel is training: epoch 42th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5733 - acc: 0.8026     \n",
      "Medel is training: epoch 42th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3984 - acc: 0.8195     \n",
      "Medel is training: epoch 42th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3511 - acc: 0.8195     \n",
      "Medel is training: epoch 42th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6201 - acc: 0.7956     \n",
      "Medel is training: epoch 42th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5507 - acc: 0.8058     \n",
      "Medel is training: epoch 42th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1541 - acc: 0.8409     \n",
      "Medel is training: epoch 42th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6171 - acc: 0.7950     \n",
      "Medel is training: epoch 42th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5415 - acc: 0.8054     \n",
      "Medel is training: epoch 42th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2420 - acc: 0.8347     \n",
      "Medel is training: epoch 42th 32000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.3774 - acc: 0.8162     \n",
      "Medel is training: epoch 42th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6086 - acc: 0.7957     \n",
      "Medel is training: epoch 42th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5649 - acc: 0.8043     \n",
      "Medel is training: epoch 42th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1068 - acc: 0.8433     \n",
      "Medel is training: epoch 42th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5475 - acc: 0.7997     \n",
      "Medel is training: epoch 42th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5559 - acc: 0.8034     \n",
      "Medel is training: epoch 42th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4653 - acc: 0.8136     \n",
      "Medel is training: epoch 42th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1393 - acc: 0.8396     \n",
      "Medel is training: epoch 42th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6279 - acc: 0.7920     \n",
      "Medel is training: epoch 42th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5069 - acc: 0.8109     \n",
      "Medel is training: epoch 42th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5180 - acc: 0.8066     \n",
      "Medel is training: epoch 42th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1368 - acc: 0.8400     \n",
      "Medel is training: epoch 42th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6096 - acc: 0.7932     \n",
      "Medel is training: epoch 42th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5444 - acc: 0.8048     \n",
      "Medel is training: epoch 42th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4397 - acc: 0.8142     \n",
      "Medel is training: epoch 42th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1468 - acc: 0.8389     \n",
      "Medel is training: epoch 42th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6042 - acc: 0.7926     \n",
      "Medel is training: epoch 42th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5876 - acc: 0.7994     \n",
      "Medel is training: epoch 42th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1797 - acc: 1.0000\n",
      "Medel is training: epoch 43th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6303 - acc: 0.7946     \n",
      "Medel is training: epoch 43th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4274 - acc: 0.8157     \n",
      "Medel is training: epoch 43th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4587 - acc: 0.8079     \n",
      "Medel is training: epoch 43th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5287 - acc: 0.8076     \n",
      "Medel is training: epoch 43th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3392 - acc: 0.8228     \n",
      "Medel is training: epoch 43th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5879 - acc: 0.7988     \n",
      "Medel is training: epoch 43th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5517 - acc: 0.8036     \n",
      "Medel is training: epoch 43th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3204 - acc: 0.8221     \n",
      "Medel is training: epoch 43th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5997 - acc: 0.7977     \n",
      "Medel is training: epoch 43th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4083 - acc: 0.8165     \n",
      "Medel is training: epoch 43th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4723 - acc: 0.8086     \n",
      "Medel is training: epoch 43th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5810 - acc: 0.8015     \n",
      "Medel is training: epoch 43th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3511 - acc: 0.8219     \n",
      "Medel is training: epoch 43th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6135 - acc: 0.7934     \n",
      "Medel is training: epoch 43th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5429 - acc: 0.8057     \n",
      "Medel is training: epoch 43th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3026 - acc: 0.8262     \n",
      "Medel is training: epoch 43th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5606 - acc: 0.7996     \n",
      "Medel is training: epoch 43th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5491 - acc: 0.8057     \n",
      "Medel is training: epoch 43th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2898 - acc: 0.8275     \n",
      "Medel is training: epoch 43th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5748 - acc: 0.7970     \n",
      "Medel is training: epoch 43th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5222 - acc: 0.8097     \n",
      "Medel is training: epoch 43th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3245 - acc: 0.8248     \n",
      "Medel is training: epoch 43th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5182 - acc: 0.8022     \n",
      "Medel is training: epoch 43th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5718 - acc: 0.8027     \n",
      "Medel is training: epoch 43th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3966 - acc: 0.8196     \n",
      "Medel is training: epoch 43th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3490 - acc: 0.8199     \n",
      "Medel is training: epoch 43th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6185 - acc: 0.7956     \n",
      "Medel is training: epoch 43th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5509 - acc: 0.8056     \n",
      "Medel is training: epoch 43th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1507 - acc: 0.8407     \n",
      "Medel is training: epoch 43th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6163 - acc: 0.7952     \n",
      "Medel is training: epoch 43th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5405 - acc: 0.8056     \n",
      "Medel is training: epoch 43th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2412 - acc: 0.8342     \n",
      "Medel is training: epoch 43th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3749 - acc: 0.8169     \n",
      "Medel is training: epoch 43th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6066 - acc: 0.7959     \n",
      "Medel is training: epoch 43th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5629 - acc: 0.8044     \n",
      "Medel is training: epoch 43th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1028 - acc: 0.8435     \n",
      "Medel is training: epoch 43th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5450 - acc: 0.8000     \n",
      "Medel is training: epoch 43th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5539 - acc: 0.8037     \n",
      "Medel is training: epoch 43th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4639 - acc: 0.8135     \n",
      "Medel is training: epoch 43th 39000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.1366 - acc: 0.8400     \n",
      "Medel is training: epoch 43th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6256 - acc: 0.7922     \n",
      "Medel is training: epoch 43th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5048 - acc: 0.8111     \n",
      "Medel is training: epoch 43th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5165 - acc: 0.8064     \n",
      "Medel is training: epoch 43th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1330 - acc: 0.8401     \n",
      "Medel is training: epoch 43th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6069 - acc: 0.7934     \n",
      "Medel is training: epoch 43th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5419 - acc: 0.8051     \n",
      "Medel is training: epoch 43th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4381 - acc: 0.8141     \n",
      "Medel is training: epoch 43th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1449 - acc: 0.8393     \n",
      "Medel is training: epoch 43th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6014 - acc: 0.7930     \n",
      "Medel is training: epoch 43th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5844 - acc: 0.7994     \n",
      "Medel is training: epoch 43th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1776 - acc: 1.0000\n",
      "Medel is training: epoch 44th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6289 - acc: 0.7944     \n",
      "Medel is training: epoch 44th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4262 - acc: 0.8159     \n",
      "Medel is training: epoch 44th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4554 - acc: 0.8085     \n",
      "Medel is training: epoch 44th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5275 - acc: 0.8076     \n",
      "Medel is training: epoch 44th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3368 - acc: 0.8229     \n",
      "Medel is training: epoch 44th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5861 - acc: 0.7990     \n",
      "Medel is training: epoch 44th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5508 - acc: 0.8037     \n",
      "Medel is training: epoch 44th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3176 - acc: 0.8223     \n",
      "Medel is training: epoch 44th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5977 - acc: 0.7974     \n",
      "Medel is training: epoch 44th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4067 - acc: 0.8166     \n",
      "Medel is training: epoch 44th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4699 - acc: 0.8086     \n",
      "Medel is training: epoch 44th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5799 - acc: 0.8015     \n",
      "Medel is training: epoch 44th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3491 - acc: 0.8217     \n",
      "Medel is training: epoch 44th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6113 - acc: 0.7933     \n",
      "Medel is training: epoch 44th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5416 - acc: 0.8057     \n",
      "Medel is training: epoch 44th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2999 - acc: 0.8264     \n",
      "Medel is training: epoch 44th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5582 - acc: 0.7997     \n",
      "Medel is training: epoch 44th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5479 - acc: 0.8057     \n",
      "Medel is training: epoch 44th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2872 - acc: 0.8274     \n",
      "Medel is training: epoch 44th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5725 - acc: 0.7972     \n",
      "Medel is training: epoch 44th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5207 - acc: 0.8097     \n",
      "Medel is training: epoch 44th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3225 - acc: 0.8250     \n",
      "Medel is training: epoch 44th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5156 - acc: 0.8021     \n",
      "Medel is training: epoch 44th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5704 - acc: 0.8026     \n",
      "Medel is training: epoch 44th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3949 - acc: 0.8198     \n",
      "Medel is training: epoch 44th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3465 - acc: 0.8199     \n",
      "Medel is training: epoch 44th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6176 - acc: 0.7957     \n",
      "Medel is training: epoch 44th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5487 - acc: 0.8056     \n",
      "Medel is training: epoch 44th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1505 - acc: 0.8406     \n",
      "Medel is training: epoch 44th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6143 - acc: 0.7957     \n",
      "Medel is training: epoch 44th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5397 - acc: 0.8055     \n",
      "Medel is training: epoch 44th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2379 - acc: 0.8348     \n",
      "Medel is training: epoch 44th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3731 - acc: 0.8169     \n",
      "Medel is training: epoch 44th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6058 - acc: 0.7960     \n",
      "Medel is training: epoch 44th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5613 - acc: 0.8043     \n",
      "Medel is training: epoch 44th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1003 - acc: 0.8434     \n",
      "Medel is training: epoch 44th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5419 - acc: 0.8002     \n",
      "Medel is training: epoch 44th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5521 - acc: 0.8039     \n",
      "Medel is training: epoch 44th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4629 - acc: 0.8135     \n",
      "Medel is training: epoch 44th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1333 - acc: 0.8402     \n",
      "Medel is training: epoch 44th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6228 - acc: 0.7923     \n",
      "Medel is training: epoch 44th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5043 - acc: 0.8111     \n",
      "Medel is training: epoch 44th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5158 - acc: 0.8064     \n",
      "Medel is training: epoch 44th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1305 - acc: 0.8401     \n",
      "Medel is training: epoch 44th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6059 - acc: 0.7938     \n",
      "Medel is training: epoch 44th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5406 - acc: 0.8051     \n",
      "Medel is training: epoch 44th 46000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.4369 - acc: 0.8139     \n",
      "Medel is training: epoch 44th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1418 - acc: 0.8393     \n",
      "Medel is training: epoch 44th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5995 - acc: 0.7933     \n",
      "Medel is training: epoch 44th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5831 - acc: 0.7994     \n",
      "Medel is training: epoch 44th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1758 - acc: 1.0000\n",
      "Medel is training: epoch 45th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6273 - acc: 0.7947     \n",
      "Medel is training: epoch 45th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4240 - acc: 0.8158     \n",
      "Medel is training: epoch 45th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4537 - acc: 0.8086     \n",
      "Medel is training: epoch 45th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5264 - acc: 0.8077     \n",
      "Medel is training: epoch 45th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3344 - acc: 0.8230     \n",
      "Medel is training: epoch 45th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5843 - acc: 0.7992     \n",
      "Medel is training: epoch 45th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5500 - acc: 0.8036     \n",
      "Medel is training: epoch 45th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3157 - acc: 0.8224     \n",
      "Medel is training: epoch 45th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5957 - acc: 0.7976     \n",
      "Medel is training: epoch 45th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4052 - acc: 0.8165     \n",
      "Medel is training: epoch 45th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4676 - acc: 0.8088     \n",
      "Medel is training: epoch 45th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5788 - acc: 0.8015     \n",
      "Medel is training: epoch 45th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3473 - acc: 0.8219     \n",
      "Medel is training: epoch 45th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6094 - acc: 0.7933     \n",
      "Medel is training: epoch 45th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5408 - acc: 0.8057     \n",
      "Medel is training: epoch 45th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2978 - acc: 0.8264     \n",
      "Medel is training: epoch 45th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5567 - acc: 0.7998     \n",
      "Medel is training: epoch 45th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5470 - acc: 0.8057     \n",
      "Medel is training: epoch 45th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2861 - acc: 0.8274     \n",
      "Medel is training: epoch 45th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5697 - acc: 0.7973     \n",
      "Medel is training: epoch 45th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5198 - acc: 0.8097     \n",
      "Medel is training: epoch 45th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3205 - acc: 0.8250     \n",
      "Medel is training: epoch 45th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5135 - acc: 0.8022     \n",
      "Medel is training: epoch 45th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5687 - acc: 0.8026     \n",
      "Medel is training: epoch 45th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3937 - acc: 0.8197     \n",
      "Medel is training: epoch 45th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3449 - acc: 0.8200     \n",
      "Medel is training: epoch 45th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6162 - acc: 0.7959     \n",
      "Medel is training: epoch 45th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5487 - acc: 0.8056     \n",
      "Medel is training: epoch 45th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1462 - acc: 0.8411     \n",
      "Medel is training: epoch 45th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6123 - acc: 0.7956     \n",
      "Medel is training: epoch 45th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5382 - acc: 0.8057     \n",
      "Medel is training: epoch 45th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2351 - acc: 0.8349     \n",
      "Medel is training: epoch 45th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3695 - acc: 0.8171     \n",
      "Medel is training: epoch 45th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6029 - acc: 0.7959     \n",
      "Medel is training: epoch 45th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5605 - acc: 0.8042     \n",
      "Medel is training: epoch 45th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0987 - acc: 0.8438     \n",
      "Medel is training: epoch 45th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5404 - acc: 0.8002     \n",
      "Medel is training: epoch 45th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5507 - acc: 0.8037     \n",
      "Medel is training: epoch 45th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4621 - acc: 0.8137     \n",
      "Medel is training: epoch 45th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1320 - acc: 0.8403     \n",
      "Medel is training: epoch 45th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6206 - acc: 0.7925     \n",
      "Medel is training: epoch 45th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5016 - acc: 0.8111     \n",
      "Medel is training: epoch 45th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5142 - acc: 0.8063     \n",
      "Medel is training: epoch 45th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1283 - acc: 0.8402     \n",
      "Medel is training: epoch 45th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6037 - acc: 0.7941     \n",
      "Medel is training: epoch 45th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5395 - acc: 0.8052     \n",
      "Medel is training: epoch 45th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4351 - acc: 0.8140     \n",
      "Medel is training: epoch 45th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1397 - acc: 0.8391     \n",
      "Medel is training: epoch 45th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5970 - acc: 0.7937     \n",
      "Medel is training: epoch 45th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5815 - acc: 0.7994     \n",
      "Medel is training: epoch 45th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1740 - acc: 1.0000\n",
      "Medel is training: epoch 46th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6255 - acc: 0.7951     \n",
      "Medel is training: epoch 46th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4228 - acc: 0.8159     \n",
      "Medel is training: epoch 46th 2000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.4515 - acc: 0.8091     \n",
      "Medel is training: epoch 46th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5257 - acc: 0.8077     \n",
      "Medel is training: epoch 46th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3328 - acc: 0.8231     \n",
      "Medel is training: epoch 46th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5827 - acc: 0.7994     \n",
      "Medel is training: epoch 46th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5485 - acc: 0.8036     \n",
      "Medel is training: epoch 46th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3123 - acc: 0.8226     \n",
      "Medel is training: epoch 46th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5944 - acc: 0.7976     \n",
      "Medel is training: epoch 46th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4038 - acc: 0.8167     \n",
      "Medel is training: epoch 46th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4657 - acc: 0.8088     \n",
      "Medel is training: epoch 46th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5771 - acc: 0.8016     \n",
      "Medel is training: epoch 46th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3452 - acc: 0.8222     \n",
      "Medel is training: epoch 46th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6069 - acc: 0.7936     \n",
      "Medel is training: epoch 46th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5397 - acc: 0.8058     \n",
      "Medel is training: epoch 46th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2962 - acc: 0.8266     \n",
      "Medel is training: epoch 46th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5542 - acc: 0.7998     \n",
      "Medel is training: epoch 46th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5460 - acc: 0.8057     \n",
      "Medel is training: epoch 46th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2825 - acc: 0.8279     \n",
      "Medel is training: epoch 46th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5684 - acc: 0.7971     \n",
      "Medel is training: epoch 46th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5175 - acc: 0.8098     \n",
      "Medel is training: epoch 46th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3188 - acc: 0.8252     \n",
      "Medel is training: epoch 46th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5100 - acc: 0.8022     \n",
      "Medel is training: epoch 46th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5672 - acc: 0.8029     \n",
      "Medel is training: epoch 46th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3923 - acc: 0.8198     \n",
      "Medel is training: epoch 46th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3418 - acc: 0.8202     \n",
      "Medel is training: epoch 46th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6142 - acc: 0.7958     \n",
      "Medel is training: epoch 46th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5466 - acc: 0.8056     \n",
      "Medel is training: epoch 46th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1443 - acc: 0.8417     \n",
      "Medel is training: epoch 46th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6093 - acc: 0.7958     \n",
      "Medel is training: epoch 46th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5367 - acc: 0.8056     \n",
      "Medel is training: epoch 46th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2340 - acc: 0.8351     \n",
      "Medel is training: epoch 46th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3677 - acc: 0.8173     \n",
      "Medel is training: epoch 46th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6007 - acc: 0.7959     \n",
      "Medel is training: epoch 46th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5592 - acc: 0.8043     \n",
      "Medel is training: epoch 46th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0935 - acc: 0.8441     \n",
      "Medel is training: epoch 46th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5377 - acc: 0.8002     \n",
      "Medel is training: epoch 46th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5491 - acc: 0.8037     \n",
      "Medel is training: epoch 46th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4609 - acc: 0.8136     \n",
      "Medel is training: epoch 46th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1285 - acc: 0.8408     \n",
      "Medel is training: epoch 46th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6179 - acc: 0.7925     \n",
      "Medel is training: epoch 46th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5001 - acc: 0.8111     \n",
      "Medel is training: epoch 46th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5139 - acc: 0.8063     \n",
      "Medel is training: epoch 46th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1251 - acc: 0.8402     \n",
      "Medel is training: epoch 46th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6008 - acc: 0.7941     \n",
      "Medel is training: epoch 46th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5371 - acc: 0.8053     \n",
      "Medel is training: epoch 46th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4341 - acc: 0.8142     \n",
      "Medel is training: epoch 46th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1369 - acc: 0.8389     \n",
      "Medel is training: epoch 46th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5952 - acc: 0.7936     \n",
      "Medel is training: epoch 46th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5799 - acc: 0.7997     \n",
      "Medel is training: epoch 46th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1721 - acc: 1.0000\n",
      "Medel is training: epoch 47th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6239 - acc: 0.7951     \n",
      "Medel is training: epoch 47th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4210 - acc: 0.8158     \n",
      "Medel is training: epoch 47th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4487 - acc: 0.8088     \n",
      "Medel is training: epoch 47th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5248 - acc: 0.8077     \n",
      "Medel is training: epoch 47th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3305 - acc: 0.8234     \n",
      "Medel is training: epoch 47th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5813 - acc: 0.7992     \n",
      "Medel is training: epoch 47th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5476 - acc: 0.8036     \n",
      "Medel is training: epoch 47th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3095 - acc: 0.8228     \n",
      "Medel is training: epoch 47th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5925 - acc: 0.7975     \n",
      "Medel is training: epoch 47th 9000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.4025 - acc: 0.8167     \n",
      "Medel is training: epoch 47th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4635 - acc: 0.8091     \n",
      "Medel is training: epoch 47th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5761 - acc: 0.8015     \n",
      "Medel is training: epoch 47th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3439 - acc: 0.8225     \n",
      "Medel is training: epoch 47th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6044 - acc: 0.7935     \n",
      "Medel is training: epoch 47th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5384 - acc: 0.8059     \n",
      "Medel is training: epoch 47th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2939 - acc: 0.8269     \n",
      "Medel is training: epoch 47th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5525 - acc: 0.7998     \n",
      "Medel is training: epoch 47th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5444 - acc: 0.8059     \n",
      "Medel is training: epoch 47th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2808 - acc: 0.8277     \n",
      "Medel is training: epoch 47th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5659 - acc: 0.7976     \n",
      "Medel is training: epoch 47th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5163 - acc: 0.8098     \n",
      "Medel is training: epoch 47th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3164 - acc: 0.8251     \n",
      "Medel is training: epoch 47th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5075 - acc: 0.8023     \n",
      "Medel is training: epoch 47th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5659 - acc: 0.8029     \n",
      "Medel is training: epoch 47th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3898 - acc: 0.8201     \n",
      "Medel is training: epoch 47th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3399 - acc: 0.8204     \n",
      "Medel is training: epoch 47th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6122 - acc: 0.7959     \n",
      "Medel is training: epoch 47th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5464 - acc: 0.8055     \n",
      "Medel is training: epoch 47th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1426 - acc: 0.8414     \n",
      "Medel is training: epoch 47th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6068 - acc: 0.7960     \n",
      "Medel is training: epoch 47th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5349 - acc: 0.8058     \n",
      "Medel is training: epoch 47th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2311 - acc: 0.8351     \n",
      "Medel is training: epoch 47th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3651 - acc: 0.8174     \n",
      "Medel is training: epoch 47th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5979 - acc: 0.7961     \n",
      "Medel is training: epoch 47th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5584 - acc: 0.8043     \n",
      "Medel is training: epoch 47th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0913 - acc: 0.8437     \n",
      "Medel is training: epoch 47th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5363 - acc: 0.8004     \n",
      "Medel is training: epoch 47th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5476 - acc: 0.8037     \n",
      "Medel is training: epoch 47th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4602 - acc: 0.8137     \n",
      "Medel is training: epoch 47th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1249 - acc: 0.8407     \n",
      "Medel is training: epoch 47th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6164 - acc: 0.7927     \n",
      "Medel is training: epoch 47th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4982 - acc: 0.8112     \n",
      "Medel is training: epoch 47th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5116 - acc: 0.8063     \n",
      "Medel is training: epoch 47th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1221 - acc: 0.8405     \n",
      "Medel is training: epoch 47th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5991 - acc: 0.7940     \n",
      "Medel is training: epoch 47th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5357 - acc: 0.8054     \n",
      "Medel is training: epoch 47th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4324 - acc: 0.8142     \n",
      "Medel is training: epoch 47th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1349 - acc: 0.8390     \n",
      "Medel is training: epoch 47th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5922 - acc: 0.7937     \n",
      "Medel is training: epoch 47th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5780 - acc: 0.7997     \n",
      "Medel is training: epoch 47th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1703 - acc: 1.0000\n",
      "Medel is training: epoch 48th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6223 - acc: 0.7951     \n",
      "Medel is training: epoch 48th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4193 - acc: 0.8158     \n",
      "Medel is training: epoch 48th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4469 - acc: 0.8090     \n",
      "Medel is training: epoch 48th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5239 - acc: 0.8077     \n",
      "Medel is training: epoch 48th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3292 - acc: 0.8234     \n",
      "Medel is training: epoch 48th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5797 - acc: 0.7993     \n",
      "Medel is training: epoch 48th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5465 - acc: 0.8036     \n",
      "Medel is training: epoch 48th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3068 - acc: 0.8234     \n",
      "Medel is training: epoch 48th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5907 - acc: 0.7976     \n",
      "Medel is training: epoch 48th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4010 - acc: 0.8170     \n",
      "Medel is training: epoch 48th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4606 - acc: 0.8091     \n",
      "Medel is training: epoch 48th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5750 - acc: 0.8017     \n",
      "Medel is training: epoch 48th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3417 - acc: 0.8226     \n",
      "Medel is training: epoch 48th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6027 - acc: 0.7936     \n",
      "Medel is training: epoch 48th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5369 - acc: 0.8061     \n",
      "Medel is training: epoch 48th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2916 - acc: 0.8269     \n",
      "Medel is training: epoch 48th 16000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.5504 - acc: 0.7999     \n",
      "Medel is training: epoch 48th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5435 - acc: 0.8058     \n",
      "Medel is training: epoch 48th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2793 - acc: 0.8280     \n",
      "Medel is training: epoch 48th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5639 - acc: 0.7979     \n",
      "Medel is training: epoch 48th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5148 - acc: 0.8099     \n",
      "Medel is training: epoch 48th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3147 - acc: 0.8254     \n",
      "Medel is training: epoch 48th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5047 - acc: 0.8023     \n",
      "Medel is training: epoch 48th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5640 - acc: 0.8029     \n",
      "Medel is training: epoch 48th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3887 - acc: 0.8201     \n",
      "Medel is training: epoch 48th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3375 - acc: 0.8203     \n",
      "Medel is training: epoch 48th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6102 - acc: 0.7959     \n",
      "Medel is training: epoch 48th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5453 - acc: 0.8055     \n",
      "Medel is training: epoch 48th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1378 - acc: 0.8423     \n",
      "Medel is training: epoch 48th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6045 - acc: 0.7958     \n",
      "Medel is training: epoch 48th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5353 - acc: 0.8057     \n",
      "Medel is training: epoch 48th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2304 - acc: 0.8351     \n",
      "Medel is training: epoch 48th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3625 - acc: 0.8174     \n",
      "Medel is training: epoch 48th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5971 - acc: 0.7958     \n",
      "Medel is training: epoch 48th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5571 - acc: 0.8042     \n",
      "Medel is training: epoch 48th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0881 - acc: 0.8444     \n",
      "Medel is training: epoch 48th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5339 - acc: 0.8004     \n",
      "Medel is training: epoch 48th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5452 - acc: 0.8039     \n",
      "Medel is training: epoch 48th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4589 - acc: 0.8137     \n",
      "Medel is training: epoch 48th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1220 - acc: 0.8406     \n",
      "Medel is training: epoch 48th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6137 - acc: 0.7931     \n",
      "Medel is training: epoch 48th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4964 - acc: 0.8112     \n",
      "Medel is training: epoch 48th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5107 - acc: 0.8062     \n",
      "Medel is training: epoch 48th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1196 - acc: 0.8406     \n",
      "Medel is training: epoch 48th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5968 - acc: 0.7941     \n",
      "Medel is training: epoch 48th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5338 - acc: 0.8054     \n",
      "Medel is training: epoch 48th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4316 - acc: 0.8144     \n",
      "Medel is training: epoch 48th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1313 - acc: 0.8396     \n",
      "Medel is training: epoch 48th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5912 - acc: 0.7939     \n",
      "Medel is training: epoch 48th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5749 - acc: 0.7995     \n",
      "Medel is training: epoch 48th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1680 - acc: 1.0000\n",
      "Medel is training: epoch 49th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6205 - acc: 0.7952     \n",
      "Medel is training: epoch 49th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4191 - acc: 0.8159     \n",
      "Medel is training: epoch 49th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4440 - acc: 0.8088     \n",
      "Medel is training: epoch 49th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5227 - acc: 0.8077     \n",
      "Medel is training: epoch 49th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3267 - acc: 0.8234     \n",
      "Medel is training: epoch 49th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5779 - acc: 0.7991     \n",
      "Medel is training: epoch 49th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5459 - acc: 0.8037     \n",
      "Medel is training: epoch 49th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3042 - acc: 0.8234     \n",
      "Medel is training: epoch 49th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5894 - acc: 0.7976     \n",
      "Medel is training: epoch 49th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3991 - acc: 0.8169     \n",
      "Medel is training: epoch 49th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4585 - acc: 0.8090     \n",
      "Medel is training: epoch 49th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5736 - acc: 0.8016     \n",
      "Medel is training: epoch 49th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3402 - acc: 0.8227     \n",
      "Medel is training: epoch 49th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6010 - acc: 0.7937     \n",
      "Medel is training: epoch 49th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5354 - acc: 0.8062     \n",
      "Medel is training: epoch 49th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2896 - acc: 0.8269     \n",
      "Medel is training: epoch 49th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5479 - acc: 0.8001     \n",
      "Medel is training: epoch 49th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5427 - acc: 0.8059     \n",
      "Medel is training: epoch 49th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2768 - acc: 0.8282     \n",
      "Medel is training: epoch 49th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5620 - acc: 0.7977     \n",
      "Medel is training: epoch 49th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5139 - acc: 0.8100     \n",
      "Medel is training: epoch 49th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3126 - acc: 0.8255     \n",
      "Medel is training: epoch 49th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5022 - acc: 0.8025     \n",
      "Medel is training: epoch 49th 23000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.5628 - acc: 0.8029     \n",
      "Medel is training: epoch 49th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3870 - acc: 0.8203     \n",
      "Medel is training: epoch 49th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3352 - acc: 0.8204     \n",
      "Medel is training: epoch 49th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6078 - acc: 0.7958     \n",
      "Medel is training: epoch 49th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5440 - acc: 0.8055     \n",
      "Medel is training: epoch 49th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1371 - acc: 0.8422     \n",
      "Medel is training: epoch 49th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6025 - acc: 0.7962     \n",
      "Medel is training: epoch 49th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5331 - acc: 0.8057     \n",
      "Medel is training: epoch 49th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2275 - acc: 0.8356     \n",
      "Medel is training: epoch 49th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3590 - acc: 0.8178     \n",
      "Medel is training: epoch 49th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5945 - acc: 0.7962     \n",
      "Medel is training: epoch 49th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5552 - acc: 0.8044     \n",
      "Medel is training: epoch 49th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0855 - acc: 0.8447     \n",
      "Medel is training: epoch 49th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5312 - acc: 0.8004     \n",
      "Medel is training: epoch 49th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5443 - acc: 0.8041     \n",
      "Medel is training: epoch 49th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4575 - acc: 0.8136     \n",
      "Medel is training: epoch 49th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1211 - acc: 0.8412     \n",
      "Medel is training: epoch 49th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6122 - acc: 0.7928     \n",
      "Medel is training: epoch 49th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4942 - acc: 0.8113     \n",
      "Medel is training: epoch 49th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5094 - acc: 0.8062     \n",
      "Medel is training: epoch 49th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1166 - acc: 0.8407     \n",
      "Medel is training: epoch 49th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5942 - acc: 0.7942     \n",
      "Medel is training: epoch 49th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5315 - acc: 0.8055     \n",
      "Medel is training: epoch 49th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4300 - acc: 0.8141     \n",
      "Medel is training: epoch 49th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1295 - acc: 0.8394     \n",
      "Medel is training: epoch 49th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5873 - acc: 0.7938     \n",
      "Medel is training: epoch 49th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5727 - acc: 0.7995     \n",
      "Medel is training: epoch 49th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1661 - acc: 1.0000\n",
      "Medel is training: epoch 50th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6194 - acc: 0.7953     \n",
      "Medel is training: epoch 50th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4166 - acc: 0.8160     \n",
      "Medel is training: epoch 50th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4426 - acc: 0.8089     \n",
      "Medel is training: epoch 50th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5218 - acc: 0.8077     \n",
      "Medel is training: epoch 50th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3248 - acc: 0.8234     \n",
      "Medel is training: epoch 50th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5760 - acc: 0.7992     \n",
      "Medel is training: epoch 50th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5447 - acc: 0.8038     \n",
      "Medel is training: epoch 50th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3019 - acc: 0.8235     \n",
      "Medel is training: epoch 50th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5884 - acc: 0.7976     \n",
      "Medel is training: epoch 50th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3982 - acc: 0.8170     \n",
      "Medel is training: epoch 50th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4561 - acc: 0.8094     \n",
      "Medel is training: epoch 50th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5723 - acc: 0.8017     \n",
      "Medel is training: epoch 50th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3385 - acc: 0.8227     \n",
      "Medel is training: epoch 50th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5988 - acc: 0.7937     \n",
      "Medel is training: epoch 50th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5350 - acc: 0.8062     \n",
      "Medel is training: epoch 50th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2874 - acc: 0.8267     \n",
      "Medel is training: epoch 50th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5461 - acc: 0.8003     \n",
      "Medel is training: epoch 50th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5416 - acc: 0.8060     \n",
      "Medel is training: epoch 50th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2749 - acc: 0.8284     \n",
      "Medel is training: epoch 50th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5600 - acc: 0.7978     \n",
      "Medel is training: epoch 50th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5118 - acc: 0.8101     \n",
      "Medel is training: epoch 50th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3109 - acc: 0.8258     \n",
      "Medel is training: epoch 50th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5000 - acc: 0.8026     \n",
      "Medel is training: epoch 50th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5611 - acc: 0.8029     \n",
      "Medel is training: epoch 50th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3855 - acc: 0.8203     \n",
      "Medel is training: epoch 50th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3332 - acc: 0.8207     \n",
      "Medel is training: epoch 50th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 6s - loss: 1.6058 - acc: 0.7959     \n",
      "Medel is training: epoch 50th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 6s - loss: 1.5428 - acc: 0.8056     \n",
      "Medel is training: epoch 50th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1345 - acc: 0.8424     \n",
      "Medel is training: epoch 50th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6012 - acc: 0.7960     \n",
      "Medel is training: epoch 50th 30000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.5321 - acc: 0.8056     \n",
      "Medel is training: epoch 50th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2256 - acc: 0.8355     \n",
      "Medel is training: epoch 50th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3575 - acc: 0.8179     \n",
      "Medel is training: epoch 50th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5925 - acc: 0.7961     \n",
      "Medel is training: epoch 50th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 6s - loss: 1.5547 - acc: 0.8043     \n",
      "Medel is training: epoch 50th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0829 - acc: 0.8445     \n",
      "Medel is training: epoch 50th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5288 - acc: 0.8007     \n",
      "Medel is training: epoch 50th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5420 - acc: 0.8038     \n",
      "Medel is training: epoch 50th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4562 - acc: 0.8138     \n",
      "Medel is training: epoch 50th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1165 - acc: 0.8413     \n",
      "Medel is training: epoch 50th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6094 - acc: 0.7931     \n",
      "Medel is training: epoch 50th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4930 - acc: 0.8112     \n",
      "Medel is training: epoch 50th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5082 - acc: 0.8062     \n",
      "Medel is training: epoch 50th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1140 - acc: 0.8409     \n",
      "Medel is training: epoch 50th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5918 - acc: 0.7944     \n",
      "Medel is training: epoch 50th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5316 - acc: 0.8052     \n",
      "Medel is training: epoch 50th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4288 - acc: 0.8141     \n",
      "Medel is training: epoch 50th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1268 - acc: 0.8401     \n",
      "Medel is training: epoch 50th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5858 - acc: 0.7941     \n",
      "Medel is training: epoch 50th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5709 - acc: 0.7995     \n",
      "Medel is training: epoch 50th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1644 - acc: 1.0000\n",
      "Medel is training: epoch 51th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6168 - acc: 0.7953     \n",
      "Medel is training: epoch 51th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4154 - acc: 0.8162     \n",
      "Medel is training: epoch 51th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4407 - acc: 0.8092     \n",
      "Medel is training: epoch 51th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 6s - loss: 1.5204 - acc: 0.8076     \n",
      "Medel is training: epoch 51th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3225 - acc: 0.8236     \n",
      "Medel is training: epoch 51th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5744 - acc: 0.7992     \n",
      "Medel is training: epoch 51th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5444 - acc: 0.8037     \n",
      "Medel is training: epoch 51th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 6s - loss: 1.2994 - acc: 0.8239     \n",
      "Medel is training: epoch 51th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5865 - acc: 0.7975     \n",
      "Medel is training: epoch 51th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3965 - acc: 0.8171     \n",
      "Medel is training: epoch 51th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4537 - acc: 0.8093     \n",
      "Medel is training: epoch 51th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5707 - acc: 0.8017     \n",
      "Medel is training: epoch 51th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3372 - acc: 0.8228     \n",
      "Medel is training: epoch 51th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5971 - acc: 0.7937     \n",
      "Medel is training: epoch 51th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5334 - acc: 0.8063     \n",
      "Medel is training: epoch 51th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2858 - acc: 0.8269     \n",
      "Medel is training: epoch 51th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5440 - acc: 0.8005     \n",
      "Medel is training: epoch 51th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5400 - acc: 0.8059     \n",
      "Medel is training: epoch 51th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2734 - acc: 0.8284     \n",
      "Medel is training: epoch 51th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5573 - acc: 0.7979     \n",
      "Medel is training: epoch 51th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5111 - acc: 0.8101     \n",
      "Medel is training: epoch 51th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3093 - acc: 0.8262     \n",
      "Medel is training: epoch 51th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4977 - acc: 0.8025     \n",
      "Medel is training: epoch 51th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5600 - acc: 0.8030     \n",
      "Medel is training: epoch 51th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3845 - acc: 0.8205     \n",
      "Medel is training: epoch 51th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3309 - acc: 0.8208     \n",
      "Medel is training: epoch 51th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6044 - acc: 0.7961     \n",
      "Medel is training: epoch 51th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5420 - acc: 0.8055     \n",
      "Medel is training: epoch 51th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1332 - acc: 0.8426     \n",
      "Medel is training: epoch 51th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5985 - acc: 0.7961     \n",
      "Medel is training: epoch 51th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5311 - acc: 0.8057     \n",
      "Medel is training: epoch 51th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 6s - loss: 1.2244 - acc: 0.8354     \n",
      "Medel is training: epoch 51th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3552 - acc: 0.8179     \n",
      "Medel is training: epoch 51th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5906 - acc: 0.7963     \n",
      "Medel is training: epoch 51th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5537 - acc: 0.8044     \n",
      "Medel is training: epoch 51th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0800 - acc: 0.8449     \n",
      "Medel is training: epoch 51th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5263 - acc: 0.8006     \n",
      "Medel is training: epoch 51th 37000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.5414 - acc: 0.8039     \n",
      "Medel is training: epoch 51th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4553 - acc: 0.8138     \n",
      "Medel is training: epoch 51th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 6s - loss: 1.1136 - acc: 0.8414     \n",
      "Medel is training: epoch 51th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6074 - acc: 0.7932     \n",
      "Medel is training: epoch 51th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4910 - acc: 0.8114     \n",
      "Medel is training: epoch 51th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5070 - acc: 0.8062     \n",
      "Medel is training: epoch 51th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 6s - loss: 1.1116 - acc: 0.8411     \n",
      "Medel is training: epoch 51th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5886 - acc: 0.7943     \n",
      "Medel is training: epoch 51th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5297 - acc: 0.8055     \n",
      "Medel is training: epoch 51th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4269 - acc: 0.8143     \n",
      "Medel is training: epoch 51th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1235 - acc: 0.8402     \n",
      "Medel is training: epoch 51th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5843 - acc: 0.7941     \n",
      "Medel is training: epoch 51th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5692 - acc: 0.7998     \n",
      "Medel is training: epoch 51th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1624 - acc: 1.0000\n",
      "Medel is training: epoch 52th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6160 - acc: 0.7950     \n",
      "Medel is training: epoch 52th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4135 - acc: 0.8160     \n",
      "Medel is training: epoch 52th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4387 - acc: 0.8091     \n",
      "Medel is training: epoch 52th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5198 - acc: 0.8076     \n",
      "Medel is training: epoch 52th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3211 - acc: 0.8234     \n",
      "Medel is training: epoch 52th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5728 - acc: 0.7991     \n",
      "Medel is training: epoch 52th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5427 - acc: 0.8039     \n",
      "Medel is training: epoch 52th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2970 - acc: 0.8239     \n",
      "Medel is training: epoch 52th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5850 - acc: 0.7976     \n",
      "Medel is training: epoch 52th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3955 - acc: 0.8172     \n",
      "Medel is training: epoch 52th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4518 - acc: 0.8093     \n",
      "Medel is training: epoch 52th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5690 - acc: 0.8015     \n",
      "Medel is training: epoch 52th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3355 - acc: 0.8231     \n",
      "Medel is training: epoch 52th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5952 - acc: 0.7938     \n",
      "Medel is training: epoch 52th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5330 - acc: 0.8063     \n",
      "Medel is training: epoch 52th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2845 - acc: 0.8271     \n",
      "Medel is training: epoch 52th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5428 - acc: 0.8004     \n",
      "Medel is training: epoch 52th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5383 - acc: 0.8062     \n",
      "Medel is training: epoch 52th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2721 - acc: 0.8287     \n",
      "Medel is training: epoch 52th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5549 - acc: 0.7982     \n",
      "Medel is training: epoch 52th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5098 - acc: 0.8099     \n",
      "Medel is training: epoch 52th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3077 - acc: 0.8259     \n",
      "Medel is training: epoch 52th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4952 - acc: 0.8027     \n",
      "Medel is training: epoch 52th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5583 - acc: 0.8030     \n",
      "Medel is training: epoch 52th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3831 - acc: 0.8202     \n",
      "Medel is training: epoch 52th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3287 - acc: 0.8210     \n",
      "Medel is training: epoch 52th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6026 - acc: 0.7959     \n",
      "Medel is training: epoch 52th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5419 - acc: 0.8054     \n",
      "Medel is training: epoch 52th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1305 - acc: 0.8428     \n",
      "Medel is training: epoch 52th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5972 - acc: 0.7959     \n",
      "Medel is training: epoch 52th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5311 - acc: 0.8057     \n",
      "Medel is training: epoch 52th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2221 - acc: 0.8357     \n",
      "Medel is training: epoch 52th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3538 - acc: 0.8181     \n",
      "Medel is training: epoch 52th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5895 - acc: 0.7962     \n",
      "Medel is training: epoch 52th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5521 - acc: 0.8044     \n",
      "Medel is training: epoch 52th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0783 - acc: 0.8450     \n",
      "Medel is training: epoch 52th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 6s - loss: 1.5232 - acc: 0.8008     \n",
      "Medel is training: epoch 52th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5390 - acc: 0.8041     \n",
      "Medel is training: epoch 52th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4544 - acc: 0.8137     \n",
      "Medel is training: epoch 52th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1109 - acc: 0.8416     \n",
      "Medel is training: epoch 52th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6043 - acc: 0.7935     \n",
      "Medel is training: epoch 52th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4901 - acc: 0.8115     \n",
      "Medel is training: epoch 52th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5059 - acc: 0.8061     \n",
      "Medel is training: epoch 52th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1085 - acc: 0.8413     \n",
      "Medel is training: epoch 52th 44000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.5867 - acc: 0.7945     \n",
      "Medel is training: epoch 52th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5276 - acc: 0.8056     \n",
      "Medel is training: epoch 52th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4260 - acc: 0.8145     \n",
      "Medel is training: epoch 52th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1205 - acc: 0.8407     \n",
      "Medel is training: epoch 52th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5813 - acc: 0.7942     \n",
      "Medel is training: epoch 52th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5673 - acc: 0.7997     \n",
      "Medel is training: epoch 52th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1605 - acc: 1.0000\n",
      "Medel is training: epoch 53th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6157 - acc: 0.7951     \n",
      "Medel is training: epoch 53th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4127 - acc: 0.8161     \n",
      "Medel is training: epoch 53th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4362 - acc: 0.8094     \n",
      "Medel is training: epoch 53th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5187 - acc: 0.8076     \n",
      "Medel is training: epoch 53th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3189 - acc: 0.8237     \n",
      "Medel is training: epoch 53th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5709 - acc: 0.7990     \n",
      "Medel is training: epoch 53th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5419 - acc: 0.8038     \n",
      "Medel is training: epoch 53th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2943 - acc: 0.8244     \n",
      "Medel is training: epoch 53th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5836 - acc: 0.7977     \n",
      "Medel is training: epoch 53th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3937 - acc: 0.8175     \n",
      "Medel is training: epoch 53th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4501 - acc: 0.8094     \n",
      "Medel is training: epoch 53th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5677 - acc: 0.8016     \n",
      "Medel is training: epoch 53th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3340 - acc: 0.8228     \n",
      "Medel is training: epoch 53th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5929 - acc: 0.7939     \n",
      "Medel is training: epoch 53th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5316 - acc: 0.8062     \n",
      "Medel is training: epoch 53th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2824 - acc: 0.8270     \n",
      "Medel is training: epoch 53th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5411 - acc: 0.8005     \n",
      "Medel is training: epoch 53th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5373 - acc: 0.8060     \n",
      "Medel is training: epoch 53th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2701 - acc: 0.8286     \n",
      "Medel is training: epoch 53th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5526 - acc: 0.7981     \n",
      "Medel is training: epoch 53th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5082 - acc: 0.8098     \n",
      "Medel is training: epoch 53th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3061 - acc: 0.8261     \n",
      "Medel is training: epoch 53th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4925 - acc: 0.8028     \n",
      "Medel is training: epoch 53th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5570 - acc: 0.8030     \n",
      "Medel is training: epoch 53th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3812 - acc: 0.8204     \n",
      "Medel is training: epoch 53th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3269 - acc: 0.8211     \n",
      "Medel is training: epoch 53th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6005 - acc: 0.7961     \n",
      "Medel is training: epoch 53th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5404 - acc: 0.8054     \n",
      "Medel is training: epoch 53th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1273 - acc: 0.8431     \n",
      "Medel is training: epoch 53th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 6s - loss: 1.5933 - acc: 0.7959     \n",
      "Medel is training: epoch 53th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5295 - acc: 0.8056     \n",
      "Medel is training: epoch 53th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2203 - acc: 0.8362     \n",
      "Medel is training: epoch 53th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3513 - acc: 0.8183     \n",
      "Medel is training: epoch 53th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5870 - acc: 0.7964     \n",
      "Medel is training: epoch 53th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5509 - acc: 0.8044     \n",
      "Medel is training: epoch 53th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0746 - acc: 0.8448     \n",
      "Medel is training: epoch 53th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5215 - acc: 0.8008     \n",
      "Medel is training: epoch 53th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5373 - acc: 0.8041     \n",
      "Medel is training: epoch 53th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4528 - acc: 0.8139     \n",
      "Medel is training: epoch 53th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1082 - acc: 0.8417     \n",
      "Medel is training: epoch 53th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6013 - acc: 0.7934     \n",
      "Medel is training: epoch 53th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4891 - acc: 0.8115     \n",
      "Medel is training: epoch 53th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5049 - acc: 0.8065     \n",
      "Medel is training: epoch 53th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1064 - acc: 0.8417     \n",
      "Medel is training: epoch 53th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5855 - acc: 0.7949     \n",
      "Medel is training: epoch 53th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5272 - acc: 0.8053     \n",
      "Medel is training: epoch 53th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4250 - acc: 0.8144     \n",
      "Medel is training: epoch 53th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1198 - acc: 0.8407     \n",
      "Medel is training: epoch 53th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5799 - acc: 0.7944     \n",
      "Medel is training: epoch 53th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5666 - acc: 0.7996     \n",
      "Medel is training: epoch 53th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1588 - acc: 1.0000\n",
      "Medel is training: epoch 54th 0/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.6125 - acc: 0.7952     \n",
      "Medel is training: epoch 54th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4104 - acc: 0.8163     \n",
      "Medel is training: epoch 54th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4344 - acc: 0.8093     \n",
      "Medel is training: epoch 54th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5176 - acc: 0.8077     \n",
      "Medel is training: epoch 54th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3173 - acc: 0.8238     \n",
      "Medel is training: epoch 54th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5697 - acc: 0.7990     \n",
      "Medel is training: epoch 54th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5408 - acc: 0.8038     \n",
      "Medel is training: epoch 54th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2916 - acc: 0.8246     \n",
      "Medel is training: epoch 54th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5819 - acc: 0.7979     \n",
      "Medel is training: epoch 54th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3926 - acc: 0.8174     \n",
      "Medel is training: epoch 54th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4484 - acc: 0.8095     \n",
      "Medel is training: epoch 54th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5665 - acc: 0.8017     \n",
      "Medel is training: epoch 54th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3326 - acc: 0.8230     \n",
      "Medel is training: epoch 54th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5910 - acc: 0.7939     \n",
      "Medel is training: epoch 54th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5299 - acc: 0.8062     \n",
      "Medel is training: epoch 54th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2807 - acc: 0.8272     \n",
      "Medel is training: epoch 54th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5381 - acc: 0.8009     \n",
      "Medel is training: epoch 54th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5361 - acc: 0.8062     \n",
      "Medel is training: epoch 54th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2689 - acc: 0.8284     \n",
      "Medel is training: epoch 54th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5510 - acc: 0.7984     \n",
      "Medel is training: epoch 54th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5074 - acc: 0.8099     \n",
      "Medel is training: epoch 54th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3048 - acc: 0.8260     \n",
      "Medel is training: epoch 54th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4905 - acc: 0.8029     \n",
      "Medel is training: epoch 54th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5559 - acc: 0.8028     \n",
      "Medel is training: epoch 54th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3800 - acc: 0.8206     \n",
      "Medel is training: epoch 54th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3236 - acc: 0.8211     \n",
      "Medel is training: epoch 54th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5993 - acc: 0.7960     \n",
      "Medel is training: epoch 54th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5389 - acc: 0.8055     \n",
      "Medel is training: epoch 54th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1244 - acc: 0.8429     \n",
      "Medel is training: epoch 54th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5904 - acc: 0.7959     \n",
      "Medel is training: epoch 54th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5274 - acc: 0.8057     \n",
      "Medel is training: epoch 54th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2191 - acc: 0.8362     \n",
      "Medel is training: epoch 54th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3484 - acc: 0.8183     \n",
      "Medel is training: epoch 54th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5844 - acc: 0.7965     \n",
      "Medel is training: epoch 54th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5502 - acc: 0.8044     \n",
      "Medel is training: epoch 54th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0727 - acc: 0.8449     \n",
      "Medel is training: epoch 54th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5197 - acc: 0.8006     \n",
      "Medel is training: epoch 54th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5357 - acc: 0.8040     \n",
      "Medel is training: epoch 54th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4518 - acc: 0.8138     \n",
      "Medel is training: epoch 54th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1078 - acc: 0.8424     \n",
      "Medel is training: epoch 54th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6005 - acc: 0.7931     \n",
      "Medel is training: epoch 54th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4885 - acc: 0.8113     \n",
      "Medel is training: epoch 54th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5039 - acc: 0.8063     \n",
      "Medel is training: epoch 54th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1040 - acc: 0.8416     \n",
      "Medel is training: epoch 54th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5831 - acc: 0.7947     \n",
      "Medel is training: epoch 54th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5248 - acc: 0.8057     \n",
      "Medel is training: epoch 54th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4238 - acc: 0.8142     \n",
      "Medel is training: epoch 54th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1156 - acc: 0.8409     \n",
      "Medel is training: epoch 54th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5766 - acc: 0.7943     \n",
      "Medel is training: epoch 54th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5638 - acc: 0.7998     \n",
      "Medel is training: epoch 54th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1566 - acc: 1.0000\n",
      "Medel is training: epoch 55th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6115 - acc: 0.7953     \n",
      "Medel is training: epoch 55th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4090 - acc: 0.8163     \n",
      "Medel is training: epoch 55th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4329 - acc: 0.8093     \n",
      "Medel is training: epoch 55th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5164 - acc: 0.8077     \n",
      "Medel is training: epoch 55th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3157 - acc: 0.8238     \n",
      "Medel is training: epoch 55th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5677 - acc: 0.7991     \n",
      "Medel is training: epoch 55th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5401 - acc: 0.8038     \n",
      "Medel is training: epoch 55th 7000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.2896 - acc: 0.8246     \n",
      "Medel is training: epoch 55th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5806 - acc: 0.7977     \n",
      "Medel is training: epoch 55th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3913 - acc: 0.8177     \n",
      "Medel is training: epoch 55th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4467 - acc: 0.8096     \n",
      "Medel is training: epoch 55th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5651 - acc: 0.8016     \n",
      "Medel is training: epoch 55th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3311 - acc: 0.8233     \n",
      "Medel is training: epoch 55th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5885 - acc: 0.7939     \n",
      "Medel is training: epoch 55th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5296 - acc: 0.8062     \n",
      "Medel is training: epoch 55th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2784 - acc: 0.8274     \n",
      "Medel is training: epoch 55th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5368 - acc: 0.8008     \n",
      "Medel is training: epoch 55th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5351 - acc: 0.8060     \n",
      "Medel is training: epoch 55th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2667 - acc: 0.8288     \n",
      "Medel is training: epoch 55th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5492 - acc: 0.7985     \n",
      "Medel is training: epoch 55th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5064 - acc: 0.8098     \n",
      "Medel is training: epoch 55th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3031 - acc: 0.8264     \n",
      "Medel is training: epoch 55th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4875 - acc: 0.8030     \n",
      "Medel is training: epoch 55th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5541 - acc: 0.8031     \n",
      "Medel is training: epoch 55th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3783 - acc: 0.8206     \n",
      "Medel is training: epoch 55th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3215 - acc: 0.8213     \n",
      "Medel is training: epoch 55th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5968 - acc: 0.7962     \n",
      "Medel is training: epoch 55th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5379 - acc: 0.8057     \n",
      "Medel is training: epoch 55th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1209 - acc: 0.8436     \n",
      "Medel is training: epoch 55th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5889 - acc: 0.7956     \n",
      "Medel is training: epoch 55th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5259 - acc: 0.8059     \n",
      "Medel is training: epoch 55th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2172 - acc: 0.8359     \n",
      "Medel is training: epoch 55th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3461 - acc: 0.8187     \n",
      "Medel is training: epoch 55th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5831 - acc: 0.7964     \n",
      "Medel is training: epoch 55th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5487 - acc: 0.8044     \n",
      "Medel is training: epoch 55th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0697 - acc: 0.8457     \n",
      "Medel is training: epoch 55th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5172 - acc: 0.8008     \n",
      "Medel is training: epoch 55th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5344 - acc: 0.8042     \n",
      "Medel is training: epoch 55th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4508 - acc: 0.8139     \n",
      "Medel is training: epoch 55th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1046 - acc: 0.8426     \n",
      "Medel is training: epoch 55th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5974 - acc: 0.7935     \n",
      "Medel is training: epoch 55th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4867 - acc: 0.8114     \n",
      "Medel is training: epoch 55th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5024 - acc: 0.8063     \n",
      "Medel is training: epoch 55th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0998 - acc: 0.8420     \n",
      "Medel is training: epoch 55th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5815 - acc: 0.7947     \n",
      "Medel is training: epoch 55th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5237 - acc: 0.8054     \n",
      "Medel is training: epoch 55th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4223 - acc: 0.8143     \n",
      "Medel is training: epoch 55th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1121 - acc: 0.8412     \n",
      "Medel is training: epoch 55th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5746 - acc: 0.7946     \n",
      "Medel is training: epoch 55th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5621 - acc: 0.8000     \n",
      "Medel is training: epoch 55th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1542 - acc: 1.0000\n",
      "Medel is training: epoch 56th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6101 - acc: 0.7952     \n",
      "Medel is training: epoch 56th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4095 - acc: 0.8161     \n",
      "Medel is training: epoch 56th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4316 - acc: 0.8092     \n",
      "Medel is training: epoch 56th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5159 - acc: 0.8077     \n",
      "Medel is training: epoch 56th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3136 - acc: 0.8241     \n",
      "Medel is training: epoch 56th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 6s - loss: 1.5660 - acc: 0.7990     \n",
      "Medel is training: epoch 56th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5391 - acc: 0.8038     \n",
      "Medel is training: epoch 56th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2865 - acc: 0.8247     \n",
      "Medel is training: epoch 56th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5783 - acc: 0.7979     \n",
      "Medel is training: epoch 56th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3896 - acc: 0.8177     \n",
      "Medel is training: epoch 56th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4442 - acc: 0.8097     \n",
      "Medel is training: epoch 56th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5642 - acc: 0.8016     \n",
      "Medel is training: epoch 56th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3296 - acc: 0.8234     \n",
      "Medel is training: epoch 56th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5872 - acc: 0.7940     \n",
      "Medel is training: epoch 56th 14000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.5286 - acc: 0.8062     \n",
      "Medel is training: epoch 56th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2765 - acc: 0.8276     \n",
      "Medel is training: epoch 56th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5349 - acc: 0.8008     \n",
      "Medel is training: epoch 56th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5337 - acc: 0.8060     \n",
      "Medel is training: epoch 56th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2642 - acc: 0.8287     \n",
      "Medel is training: epoch 56th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5471 - acc: 0.7985     \n",
      "Medel is training: epoch 56th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5047 - acc: 0.8098     \n",
      "Medel is training: epoch 56th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3013 - acc: 0.8264     \n",
      "Medel is training: epoch 56th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4852 - acc: 0.8032     \n",
      "Medel is training: epoch 56th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5523 - acc: 0.8031     \n",
      "Medel is training: epoch 56th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3771 - acc: 0.8208     \n",
      "Medel is training: epoch 56th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3191 - acc: 0.8213     \n",
      "Medel is training: epoch 56th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 6s - loss: 1.5955 - acc: 0.7961     \n",
      "Medel is training: epoch 56th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5367 - acc: 0.8057     \n",
      "Medel is training: epoch 56th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1203 - acc: 0.8439     \n",
      "Medel is training: epoch 56th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5867 - acc: 0.7958     \n",
      "Medel is training: epoch 56th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5254 - acc: 0.8059     \n",
      "Medel is training: epoch 56th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2154 - acc: 0.8361     \n",
      "Medel is training: epoch 56th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3443 - acc: 0.8184     \n",
      "Medel is training: epoch 56th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 6s - loss: 1.5809 - acc: 0.7965     \n",
      "Medel is training: epoch 56th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5476 - acc: 0.8046     \n",
      "Medel is training: epoch 56th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0665 - acc: 0.8457     \n",
      "Medel is training: epoch 56th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5140 - acc: 0.8009     \n",
      "Medel is training: epoch 56th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 6s - loss: 1.5331 - acc: 0.8042     \n",
      "Medel is training: epoch 56th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 6s - loss: 1.4498 - acc: 0.8138     \n",
      "Medel is training: epoch 56th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1013 - acc: 0.8427     \n",
      "Medel is training: epoch 56th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5953 - acc: 0.7934     \n",
      "Medel is training: epoch 56th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4852 - acc: 0.8114     \n",
      "Medel is training: epoch 56th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5008 - acc: 0.8063     \n",
      "Medel is training: epoch 56th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0973 - acc: 0.8425     \n",
      "Medel is training: epoch 56th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5793 - acc: 0.7948     \n",
      "Medel is training: epoch 56th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5225 - acc: 0.8056     \n",
      "Medel is training: epoch 56th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4209 - acc: 0.8144     \n",
      "Medel is training: epoch 56th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1100 - acc: 0.8414     \n",
      "Medel is training: epoch 56th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5733 - acc: 0.7943     \n",
      "Medel is training: epoch 56th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5607 - acc: 0.7997     \n",
      "Medel is training: epoch 56th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1525 - acc: 1.0000\n",
      "Medel is training: epoch 57th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6087 - acc: 0.7954     \n",
      "Medel is training: epoch 57th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4073 - acc: 0.8162     \n",
      "Medel is training: epoch 57th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4296 - acc: 0.8093     \n",
      "Medel is training: epoch 57th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5147 - acc: 0.8077     \n",
      "Medel is training: epoch 57th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3119 - acc: 0.8242     \n",
      "Medel is training: epoch 57th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5647 - acc: 0.7991     \n",
      "Medel is training: epoch 57th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5384 - acc: 0.8038     \n",
      "Medel is training: epoch 57th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2845 - acc: 0.8249     \n",
      "Medel is training: epoch 57th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5776 - acc: 0.7980     \n",
      "Medel is training: epoch 57th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3888 - acc: 0.8177     \n",
      "Medel is training: epoch 57th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4421 - acc: 0.8096     \n",
      "Medel is training: epoch 57th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5631 - acc: 0.8016     \n",
      "Medel is training: epoch 57th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3283 - acc: 0.8235     \n",
      "Medel is training: epoch 57th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5848 - acc: 0.7938     \n",
      "Medel is training: epoch 57th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5271 - acc: 0.8062     \n",
      "Medel is training: epoch 57th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2747 - acc: 0.8276     \n",
      "Medel is training: epoch 57th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5330 - acc: 0.8008     \n",
      "Medel is training: epoch 57th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5329 - acc: 0.8060     \n",
      "Medel is training: epoch 57th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2629 - acc: 0.8290     \n",
      "Medel is training: epoch 57th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5447 - acc: 0.7985     \n",
      "Medel is training: epoch 57th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5033 - acc: 0.8099     \n",
      "Medel is training: epoch 57th 21000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.2999 - acc: 0.8264     \n",
      "Medel is training: epoch 57th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4828 - acc: 0.8033     \n",
      "Medel is training: epoch 57th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5520 - acc: 0.8031     \n",
      "Medel is training: epoch 57th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3763 - acc: 0.8208     \n",
      "Medel is training: epoch 57th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3178 - acc: 0.8215     \n",
      "Medel is training: epoch 57th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5940 - acc: 0.7964     \n",
      "Medel is training: epoch 57th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5366 - acc: 0.8057     \n",
      "Medel is training: epoch 57th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1177 - acc: 0.8438     \n",
      "Medel is training: epoch 57th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5862 - acc: 0.7960     \n",
      "Medel is training: epoch 57th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5239 - acc: 0.8058     \n",
      "Medel is training: epoch 57th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2146 - acc: 0.8364     \n",
      "Medel is training: epoch 57th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3421 - acc: 0.8188     \n",
      "Medel is training: epoch 57th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5804 - acc: 0.7966     \n",
      "Medel is training: epoch 57th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 6s - loss: 1.5465 - acc: 0.8045     \n",
      "Medel is training: epoch 57th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0650 - acc: 0.8462     \n",
      "Medel is training: epoch 57th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5130 - acc: 0.8010     \n",
      "Medel is training: epoch 57th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5321 - acc: 0.8043     \n",
      "Medel is training: epoch 57th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4488 - acc: 0.8142     \n",
      "Medel is training: epoch 57th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0997 - acc: 0.8436     \n",
      "Medel is training: epoch 57th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5937 - acc: 0.7934     \n",
      "Medel is training: epoch 57th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4838 - acc: 0.8114     \n",
      "Medel is training: epoch 57th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5002 - acc: 0.8063     \n",
      "Medel is training: epoch 57th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0950 - acc: 0.8427     \n",
      "Medel is training: epoch 57th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5762 - acc: 0.7948     \n",
      "Medel is training: epoch 57th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5207 - acc: 0.8056     \n",
      "Medel is training: epoch 57th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4206 - acc: 0.8144     \n",
      "Medel is training: epoch 57th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1072 - acc: 0.8416     \n",
      "Medel is training: epoch 57th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5704 - acc: 0.7944     \n",
      "Medel is training: epoch 57th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5600 - acc: 0.7998     \n",
      "Medel is training: epoch 57th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1505 - acc: 1.0000\n",
      "Medel is training: epoch 58th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6066 - acc: 0.7954     \n",
      "Medel is training: epoch 58th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4057 - acc: 0.8163     \n",
      "Medel is training: epoch 58th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4271 - acc: 0.8094     \n",
      "Medel is training: epoch 58th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5140 - acc: 0.8077     \n",
      "Medel is training: epoch 58th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3101 - acc: 0.8244     \n",
      "Medel is training: epoch 58th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5630 - acc: 0.7991     \n",
      "Medel is training: epoch 58th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5370 - acc: 0.8039     \n",
      "Medel is training: epoch 58th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2826 - acc: 0.8250     \n",
      "Medel is training: epoch 58th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5760 - acc: 0.7981     \n",
      "Medel is training: epoch 58th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3871 - acc: 0.8180     \n",
      "Medel is training: epoch 58th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4406 - acc: 0.8098     \n",
      "Medel is training: epoch 58th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5615 - acc: 0.8017     \n",
      "Medel is training: epoch 58th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3268 - acc: 0.8235     \n",
      "Medel is training: epoch 58th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5830 - acc: 0.7941     \n",
      "Medel is training: epoch 58th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5264 - acc: 0.8062     \n",
      "Medel is training: epoch 58th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2735 - acc: 0.8280     \n",
      "Medel is training: epoch 58th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5317 - acc: 0.8008     \n",
      "Medel is training: epoch 58th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5319 - acc: 0.8060     \n",
      "Medel is training: epoch 58th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2615 - acc: 0.8292     \n",
      "Medel is training: epoch 58th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5426 - acc: 0.7987     \n",
      "Medel is training: epoch 58th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5022 - acc: 0.8101     \n",
      "Medel is training: epoch 58th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2985 - acc: 0.8264     \n",
      "Medel is training: epoch 58th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4801 - acc: 0.8034     \n",
      "Medel is training: epoch 58th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5508 - acc: 0.8032     \n",
      "Medel is training: epoch 58th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3741 - acc: 0.8208     \n",
      "Medel is training: epoch 58th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3147 - acc: 0.8216     \n",
      "Medel is training: epoch 58th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5918 - acc: 0.7962     \n",
      "Medel is training: epoch 58th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5350 - acc: 0.8056     \n",
      "Medel is training: epoch 58th 28000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.1156 - acc: 0.8438     \n",
      "Medel is training: epoch 58th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5832 - acc: 0.7957     \n",
      "Medel is training: epoch 58th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5231 - acc: 0.8059     \n",
      "Medel is training: epoch 58th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2122 - acc: 0.8366     \n",
      "Medel is training: epoch 58th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3401 - acc: 0.8192     \n",
      "Medel is training: epoch 58th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5776 - acc: 0.7967     \n",
      "Medel is training: epoch 58th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5453 - acc: 0.8044     \n",
      "Medel is training: epoch 58th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0618 - acc: 0.8468     \n",
      "Medel is training: epoch 58th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5113 - acc: 0.8007     \n",
      "Medel is training: epoch 58th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5308 - acc: 0.8042     \n",
      "Medel is training: epoch 58th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4479 - acc: 0.8138     \n",
      "Medel is training: epoch 58th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0974 - acc: 0.8439     \n",
      "Medel is training: epoch 58th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5924 - acc: 0.7936     \n",
      "Medel is training: epoch 58th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4825 - acc: 0.8117     \n",
      "Medel is training: epoch 58th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4992 - acc: 0.8066     \n",
      "Medel is training: epoch 58th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0925 - acc: 0.8434     \n",
      "Medel is training: epoch 58th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5751 - acc: 0.7949     \n",
      "Medel is training: epoch 58th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5197 - acc: 0.8053     \n",
      "Medel is training: epoch 58th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4194 - acc: 0.8144     \n",
      "Medel is training: epoch 58th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1048 - acc: 0.8422     \n",
      "Medel is training: epoch 58th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5685 - acc: 0.7944     \n",
      "Medel is training: epoch 58th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5582 - acc: 0.7999     \n",
      "Medel is training: epoch 58th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1486 - acc: 1.0000\n",
      "Medel is training: epoch 59th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6060 - acc: 0.7954     \n",
      "Medel is training: epoch 59th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4046 - acc: 0.8162     \n",
      "Medel is training: epoch 59th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4266 - acc: 0.8092     \n",
      "Medel is training: epoch 59th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5128 - acc: 0.8077     \n",
      "Medel is training: epoch 59th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3084 - acc: 0.8246     \n",
      "Medel is training: epoch 59th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5616 - acc: 0.7992     \n",
      "Medel is training: epoch 59th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5372 - acc: 0.8039     \n",
      "Medel is training: epoch 59th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2803 - acc: 0.8252     \n",
      "Medel is training: epoch 59th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5752 - acc: 0.7981     \n",
      "Medel is training: epoch 59th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3864 - acc: 0.8179     \n",
      "Medel is training: epoch 59th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4386 - acc: 0.8102     \n",
      "Medel is training: epoch 59th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5607 - acc: 0.8017     \n",
      "Medel is training: epoch 59th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3254 - acc: 0.8234     \n",
      "Medel is training: epoch 59th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5809 - acc: 0.7941     \n",
      "Medel is training: epoch 59th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5255 - acc: 0.8060     \n",
      "Medel is training: epoch 59th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2714 - acc: 0.8280     \n",
      "Medel is training: epoch 59th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5300 - acc: 0.8009     \n",
      "Medel is training: epoch 59th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5310 - acc: 0.8059     \n",
      "Medel is training: epoch 59th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2601 - acc: 0.8296     \n",
      "Medel is training: epoch 59th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5405 - acc: 0.7989     \n",
      "Medel is training: epoch 59th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5016 - acc: 0.8099     \n",
      "Medel is training: epoch 59th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2973 - acc: 0.8266     \n",
      "Medel is training: epoch 59th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4789 - acc: 0.8037     \n",
      "Medel is training: epoch 59th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5495 - acc: 0.8032     \n",
      "Medel is training: epoch 59th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3730 - acc: 0.8211     \n",
      "Medel is training: epoch 59th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3124 - acc: 0.8220     \n",
      "Medel is training: epoch 59th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5900 - acc: 0.7961     \n",
      "Medel is training: epoch 59th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5349 - acc: 0.8057     \n",
      "Medel is training: epoch 59th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1127 - acc: 0.8439     \n",
      "Medel is training: epoch 59th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5815 - acc: 0.7962     \n",
      "Medel is training: epoch 59th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5224 - acc: 0.8058     \n",
      "Medel is training: epoch 59th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2111 - acc: 0.8368     \n",
      "Medel is training: epoch 59th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3378 - acc: 0.8196     \n",
      "Medel is training: epoch 59th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5765 - acc: 0.7966     \n",
      "Medel is training: epoch 59th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5450 - acc: 0.8045     \n",
      "Medel is training: epoch 59th 35000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.0599 - acc: 0.8474     \n",
      "Medel is training: epoch 59th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5091 - acc: 0.8010     \n",
      "Medel is training: epoch 59th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5288 - acc: 0.8043     \n",
      "Medel is training: epoch 59th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4471 - acc: 0.8140     \n",
      "Medel is training: epoch 59th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0953 - acc: 0.8435     \n",
      "Medel is training: epoch 59th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5889 - acc: 0.7938     \n",
      "Medel is training: epoch 59th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4809 - acc: 0.8116     \n",
      "Medel is training: epoch 59th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4988 - acc: 0.8067     \n",
      "Medel is training: epoch 59th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0902 - acc: 0.8432     \n",
      "Medel is training: epoch 59th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5736 - acc: 0.7950     \n",
      "Medel is training: epoch 59th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5184 - acc: 0.8056     \n",
      "Medel is training: epoch 59th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4180 - acc: 0.8144     \n",
      "Medel is training: epoch 59th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1040 - acc: 0.8428     \n",
      "Medel is training: epoch 59th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5676 - acc: 0.7947     \n",
      "Medel is training: epoch 59th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5564 - acc: 0.8000     \n",
      "Medel is training: epoch 59th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1467 - acc: 1.0000\n",
      "Medel is training: epoch 60th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6042 - acc: 0.7954     \n",
      "Medel is training: epoch 60th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4036 - acc: 0.8165     \n",
      "Medel is training: epoch 60th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4242 - acc: 0.8101     \n",
      "Medel is training: epoch 60th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5118 - acc: 0.8077     \n",
      "Medel is training: epoch 60th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3071 - acc: 0.8247     \n",
      "Medel is training: epoch 60th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5607 - acc: 0.7993     \n",
      "Medel is training: epoch 60th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5359 - acc: 0.8040     \n",
      "Medel is training: epoch 60th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2780 - acc: 0.8253     \n",
      "Medel is training: epoch 60th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5737 - acc: 0.7981     \n",
      "Medel is training: epoch 60th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3854 - acc: 0.8182     \n",
      "Medel is training: epoch 60th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4369 - acc: 0.8104     \n",
      "Medel is training: epoch 60th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5596 - acc: 0.8017     \n",
      "Medel is training: epoch 60th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3243 - acc: 0.8236     \n",
      "Medel is training: epoch 60th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5791 - acc: 0.7943     \n",
      "Medel is training: epoch 60th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5241 - acc: 0.8062     \n",
      "Medel is training: epoch 60th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2702 - acc: 0.8283     \n",
      "Medel is training: epoch 60th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5278 - acc: 0.8011     \n",
      "Medel is training: epoch 60th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5298 - acc: 0.8058     \n",
      "Medel is training: epoch 60th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2587 - acc: 0.8296     \n",
      "Medel is training: epoch 60th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5389 - acc: 0.7989     \n",
      "Medel is training: epoch 60th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5003 - acc: 0.8100     \n",
      "Medel is training: epoch 60th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2962 - acc: 0.8270     \n",
      "Medel is training: epoch 60th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4763 - acc: 0.8038     \n",
      "Medel is training: epoch 60th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5483 - acc: 0.8032     \n",
      "Medel is training: epoch 60th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3720 - acc: 0.8211     \n",
      "Medel is training: epoch 60th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3102 - acc: 0.8223     \n",
      "Medel is training: epoch 60th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5891 - acc: 0.7964     \n",
      "Medel is training: epoch 60th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5340 - acc: 0.8058     \n",
      "Medel is training: epoch 60th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1110 - acc: 0.8441     \n",
      "Medel is training: epoch 60th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5796 - acc: 0.7959     \n",
      "Medel is training: epoch 60th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5213 - acc: 0.8059     \n",
      "Medel is training: epoch 60th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2101 - acc: 0.8364     \n",
      "Medel is training: epoch 60th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3359 - acc: 0.8197     \n",
      "Medel is training: epoch 60th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5748 - acc: 0.7966     \n",
      "Medel is training: epoch 60th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5438 - acc: 0.8044     \n",
      "Medel is training: epoch 60th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0582 - acc: 0.8479     \n",
      "Medel is training: epoch 60th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5070 - acc: 0.8012     \n",
      "Medel is training: epoch 60th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5273 - acc: 0.8041     \n",
      "Medel is training: epoch 60th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4462 - acc: 0.8142     \n",
      "Medel is training: epoch 60th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0926 - acc: 0.8440     \n",
      "Medel is training: epoch 60th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5882 - acc: 0.7937     \n",
      "Medel is training: epoch 60th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4795 - acc: 0.8116     \n",
      "Medel is training: epoch 60th 42000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.4977 - acc: 0.8064     \n",
      "Medel is training: epoch 60th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0879 - acc: 0.8432     \n",
      "Medel is training: epoch 60th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5713 - acc: 0.7949     \n",
      "Medel is training: epoch 60th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5170 - acc: 0.8057     \n",
      "Medel is training: epoch 60th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4164 - acc: 0.8148     \n",
      "Medel is training: epoch 60th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1002 - acc: 0.8426     \n",
      "Medel is training: epoch 60th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5660 - acc: 0.7945     \n",
      "Medel is training: epoch 60th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5547 - acc: 0.8000     \n",
      "Medel is training: epoch 60th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1449 - acc: 1.0000\n",
      "Medel is training: epoch 61th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6021 - acc: 0.7954     \n",
      "Medel is training: epoch 61th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4026 - acc: 0.8164     \n",
      "Medel is training: epoch 61th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4229 - acc: 0.8102     \n",
      "Medel is training: epoch 61th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5113 - acc: 0.8078     \n",
      "Medel is training: epoch 61th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3055 - acc: 0.8249     \n",
      "Medel is training: epoch 61th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5589 - acc: 0.7992     \n",
      "Medel is training: epoch 61th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5350 - acc: 0.8041     \n",
      "Medel is training: epoch 61th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2762 - acc: 0.8250     \n",
      "Medel is training: epoch 61th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5723 - acc: 0.7982     \n",
      "Medel is training: epoch 61th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3843 - acc: 0.8183     \n",
      "Medel is training: epoch 61th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4351 - acc: 0.8101     \n",
      "Medel is training: epoch 61th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5583 - acc: 0.8016     \n",
      "Medel is training: epoch 61th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3227 - acc: 0.8238     \n",
      "Medel is training: epoch 61th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5773 - acc: 0.7944     \n",
      "Medel is training: epoch 61th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5228 - acc: 0.8063     \n",
      "Medel is training: epoch 61th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2684 - acc: 0.8283     \n",
      "Medel is training: epoch 61th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5258 - acc: 0.8010     \n",
      "Medel is training: epoch 61th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5292 - acc: 0.8058     \n",
      "Medel is training: epoch 61th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2564 - acc: 0.8298     \n",
      "Medel is training: epoch 61th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5376 - acc: 0.7988     \n",
      "Medel is training: epoch 61th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4994 - acc: 0.8100     \n",
      "Medel is training: epoch 61th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2947 - acc: 0.8267     \n",
      "Medel is training: epoch 61th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4745 - acc: 0.8039     \n",
      "Medel is training: epoch 61th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5475 - acc: 0.8032     \n",
      "Medel is training: epoch 61th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3711 - acc: 0.8213     \n",
      "Medel is training: epoch 61th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3082 - acc: 0.8225     \n",
      "Medel is training: epoch 61th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5876 - acc: 0.7964     \n",
      "Medel is training: epoch 61th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5332 - acc: 0.8058     \n",
      "Medel is training: epoch 61th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1094 - acc: 0.8446     \n",
      "Medel is training: epoch 61th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5772 - acc: 0.7959     \n",
      "Medel is training: epoch 61th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5200 - acc: 0.8060     \n",
      "Medel is training: epoch 61th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2076 - acc: 0.8368     \n",
      "Medel is training: epoch 61th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3334 - acc: 0.8200     \n",
      "Medel is training: epoch 61th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5733 - acc: 0.7966     \n",
      "Medel is training: epoch 61th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5434 - acc: 0.8044     \n",
      "Medel is training: epoch 61th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0559 - acc: 0.8479     \n",
      "Medel is training: epoch 61th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5059 - acc: 0.8011     \n",
      "Medel is training: epoch 61th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5258 - acc: 0.8041     \n",
      "Medel is training: epoch 61th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4461 - acc: 0.8142     \n",
      "Medel is training: epoch 61th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0896 - acc: 0.8444     \n",
      "Medel is training: epoch 61th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5872 - acc: 0.7936     \n",
      "Medel is training: epoch 61th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4783 - acc: 0.8116     \n",
      "Medel is training: epoch 61th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4957 - acc: 0.8065     \n",
      "Medel is training: epoch 61th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0849 - acc: 0.8436     \n",
      "Medel is training: epoch 61th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5684 - acc: 0.7952     \n",
      "Medel is training: epoch 61th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5159 - acc: 0.8057     \n",
      "Medel is training: epoch 61th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4152 - acc: 0.8147     \n",
      "Medel is training: epoch 61th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0981 - acc: 0.8427     \n",
      "Medel is training: epoch 61th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5632 - acc: 0.7945     \n",
      "Medel is training: epoch 61th 49000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.5532 - acc: 0.7999     \n",
      "Medel is training: epoch 61th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1432 - acc: 1.0000\n",
      "Medel is training: epoch 62th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.6014 - acc: 0.7955     \n",
      "Medel is training: epoch 62th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4018 - acc: 0.8166     \n",
      "Medel is training: epoch 62th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4211 - acc: 0.8104     \n",
      "Medel is training: epoch 62th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5102 - acc: 0.8077     \n",
      "Medel is training: epoch 62th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3033 - acc: 0.8250     \n",
      "Medel is training: epoch 62th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5578 - acc: 0.7993     \n",
      "Medel is training: epoch 62th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5341 - acc: 0.8041     \n",
      "Medel is training: epoch 62th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2750 - acc: 0.8252     \n",
      "Medel is training: epoch 62th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5711 - acc: 0.7982     \n",
      "Medel is training: epoch 62th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3833 - acc: 0.8185     \n",
      "Medel is training: epoch 62th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4332 - acc: 0.8103     \n",
      "Medel is training: epoch 62th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5573 - acc: 0.8017     \n",
      "Medel is training: epoch 62th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3216 - acc: 0.8237     \n",
      "Medel is training: epoch 62th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5758 - acc: 0.7945     \n",
      "Medel is training: epoch 62th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5218 - acc: 0.8062     \n",
      "Medel is training: epoch 62th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2670 - acc: 0.8286     \n",
      "Medel is training: epoch 62th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5243 - acc: 0.8012     \n",
      "Medel is training: epoch 62th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5284 - acc: 0.8060     \n",
      "Medel is training: epoch 62th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2558 - acc: 0.8298     \n",
      "Medel is training: epoch 62th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5362 - acc: 0.7991     \n",
      "Medel is training: epoch 62th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4983 - acc: 0.8101     \n",
      "Medel is training: epoch 62th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2935 - acc: 0.8269     \n",
      "Medel is training: epoch 62th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4728 - acc: 0.8040     \n",
      "Medel is training: epoch 62th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5460 - acc: 0.8034     \n",
      "Medel is training: epoch 62th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3693 - acc: 0.8211     \n",
      "Medel is training: epoch 62th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3064 - acc: 0.8227     \n",
      "Medel is training: epoch 62th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5861 - acc: 0.7964     \n",
      "Medel is training: epoch 62th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5322 - acc: 0.8056     \n",
      "Medel is training: epoch 62th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1069 - acc: 0.8449     \n",
      "Medel is training: epoch 62th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5750 - acc: 0.7958     \n",
      "Medel is training: epoch 62th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5182 - acc: 0.8059     \n",
      "Medel is training: epoch 62th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2069 - acc: 0.8368     \n",
      "Medel is training: epoch 62th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3319 - acc: 0.8198     \n",
      "Medel is training: epoch 62th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5714 - acc: 0.7964     \n",
      "Medel is training: epoch 62th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5418 - acc: 0.8044     \n",
      "Medel is training: epoch 62th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0542 - acc: 0.8478     \n",
      "Medel is training: epoch 62th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5038 - acc: 0.8014     \n",
      "Medel is training: epoch 62th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5248 - acc: 0.8042     \n",
      "Medel is training: epoch 62th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4456 - acc: 0.8142     \n",
      "Medel is training: epoch 62th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0883 - acc: 0.8442     \n",
      "Medel is training: epoch 62th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5841 - acc: 0.7937     \n",
      "Medel is training: epoch 62th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4765 - acc: 0.8116     \n",
      "Medel is training: epoch 62th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4953 - acc: 0.8067     \n",
      "Medel is training: epoch 62th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0826 - acc: 0.8437     \n",
      "Medel is training: epoch 62th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5668 - acc: 0.7951     \n",
      "Medel is training: epoch 62th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5151 - acc: 0.8057     \n",
      "Medel is training: epoch 62th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4144 - acc: 0.8144     \n",
      "Medel is training: epoch 62th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0958 - acc: 0.8432     \n",
      "Medel is training: epoch 62th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5622 - acc: 0.7946     \n",
      "Medel is training: epoch 62th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5525 - acc: 0.7999     \n",
      "Medel is training: epoch 62th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1414 - acc: 1.0000\n",
      "Medel is training: epoch 63th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5996 - acc: 0.7955     \n",
      "Medel is training: epoch 63th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3999 - acc: 0.8170     \n",
      "Medel is training: epoch 63th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4192 - acc: 0.8103     \n",
      "Medel is training: epoch 63th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5096 - acc: 0.8077     \n",
      "Medel is training: epoch 63th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3016 - acc: 0.8251     \n",
      "Medel is training: epoch 63th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5562 - acc: 0.7994     \n",
      "Medel is training: epoch 63th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5336 - acc: 0.8040     \n",
      "Medel is training: epoch 63th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2728 - acc: 0.8256     \n",
      "Medel is training: epoch 63th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5698 - acc: 0.7983     \n",
      "Medel is training: epoch 63th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3822 - acc: 0.8187     \n",
      "Medel is training: epoch 63th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4311 - acc: 0.8104     \n",
      "Medel is training: epoch 63th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5560 - acc: 0.8018     \n",
      "Medel is training: epoch 63th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3201 - acc: 0.8240     \n",
      "Medel is training: epoch 63th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5737 - acc: 0.7945     \n",
      "Medel is training: epoch 63th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5211 - acc: 0.8063     \n",
      "Medel is training: epoch 63th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2653 - acc: 0.8288     \n",
      "Medel is training: epoch 63th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5230 - acc: 0.8013     \n",
      "Medel is training: epoch 63th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5272 - acc: 0.8060     \n",
      "Medel is training: epoch 63th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2540 - acc: 0.8297     \n",
      "Medel is training: epoch 63th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5338 - acc: 0.7992     \n",
      "Medel is training: epoch 63th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4968 - acc: 0.8100     \n",
      "Medel is training: epoch 63th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2925 - acc: 0.8272     \n",
      "Medel is training: epoch 63th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4705 - acc: 0.8042     \n",
      "Medel is training: epoch 63th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5452 - acc: 0.8033     \n",
      "Medel is training: epoch 63th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3682 - acc: 0.8211     \n",
      "Medel is training: epoch 63th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3044 - acc: 0.8228     \n",
      "Medel is training: epoch 63th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5849 - acc: 0.7963     \n",
      "Medel is training: epoch 63th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5321 - acc: 0.8059     \n",
      "Medel is training: epoch 63th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1048 - acc: 0.8446     \n",
      "Medel is training: epoch 63th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5737 - acc: 0.7959     \n",
      "Medel is training: epoch 63th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5175 - acc: 0.8058     \n",
      "Medel is training: epoch 63th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2047 - acc: 0.8370     \n",
      "Medel is training: epoch 63th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3295 - acc: 0.8198     \n",
      "Medel is training: epoch 63th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5697 - acc: 0.7967     \n",
      "Medel is training: epoch 63th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5414 - acc: 0.8044     \n",
      "Medel is training: epoch 63th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0515 - acc: 0.8485     \n",
      "Medel is training: epoch 63th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5020 - acc: 0.8012     \n",
      "Medel is training: epoch 63th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5234 - acc: 0.8043     \n",
      "Medel is training: epoch 63th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4431 - acc: 0.8143     \n",
      "Medel is training: epoch 63th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0861 - acc: 0.8442     \n",
      "Medel is training: epoch 63th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5817 - acc: 0.7937     \n",
      "Medel is training: epoch 63th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4762 - acc: 0.8118     \n",
      "Medel is training: epoch 63th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4942 - acc: 0.8067     \n",
      "Medel is training: epoch 63th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0809 - acc: 0.8437     \n",
      "Medel is training: epoch 63th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5654 - acc: 0.7949     \n",
      "Medel is training: epoch 63th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5139 - acc: 0.8057     \n",
      "Medel is training: epoch 63th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4133 - acc: 0.8144     \n",
      "Medel is training: epoch 63th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0935 - acc: 0.8430     \n",
      "Medel is training: epoch 63th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5607 - acc: 0.7945     \n",
      "Medel is training: epoch 63th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5509 - acc: 0.7997     \n",
      "Medel is training: epoch 63th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1397 - acc: 1.0000\n",
      "Medel is training: epoch 64th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5986 - acc: 0.7958     \n",
      "Medel is training: epoch 64th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3990 - acc: 0.8168     \n",
      "Medel is training: epoch 64th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4186 - acc: 0.8106     \n",
      "Medel is training: epoch 64th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5087 - acc: 0.8077     \n",
      "Medel is training: epoch 64th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3005 - acc: 0.8251     \n",
      "Medel is training: epoch 64th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5544 - acc: 0.7994     \n",
      "Medel is training: epoch 64th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5330 - acc: 0.8040     \n",
      "Medel is training: epoch 64th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2713 - acc: 0.8259     \n",
      "Medel is training: epoch 64th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5682 - acc: 0.7984     \n",
      "Medel is training: epoch 64th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3814 - acc: 0.8185     \n",
      "Medel is training: epoch 64th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4294 - acc: 0.8108     \n",
      "Medel is training: epoch 64th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5554 - acc: 0.8015     \n",
      "Medel is training: epoch 64th 12000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.3193 - acc: 0.8241     \n",
      "Medel is training: epoch 64th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5726 - acc: 0.7946     \n",
      "Medel is training: epoch 64th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5198 - acc: 0.8063     \n",
      "Medel is training: epoch 64th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2640 - acc: 0.8287     \n",
      "Medel is training: epoch 64th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5208 - acc: 0.8013     \n",
      "Medel is training: epoch 64th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5257 - acc: 0.8059     \n",
      "Medel is training: epoch 64th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2525 - acc: 0.8301     \n",
      "Medel is training: epoch 64th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5322 - acc: 0.7991     \n",
      "Medel is training: epoch 64th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4960 - acc: 0.8102     \n",
      "Medel is training: epoch 64th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2908 - acc: 0.8274     \n",
      "Medel is training: epoch 64th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4693 - acc: 0.8043     \n",
      "Medel is training: epoch 64th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5443 - acc: 0.8033     \n",
      "Medel is training: epoch 64th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3674 - acc: 0.8212     \n",
      "Medel is training: epoch 64th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3022 - acc: 0.8230     \n",
      "Medel is training: epoch 64th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5832 - acc: 0.7962     \n",
      "Medel is training: epoch 64th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5312 - acc: 0.8059     \n",
      "Medel is training: epoch 64th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1024 - acc: 0.8452     \n",
      "Medel is training: epoch 64th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5708 - acc: 0.7961     \n",
      "Medel is training: epoch 64th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5171 - acc: 0.8058     \n",
      "Medel is training: epoch 64th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2034 - acc: 0.8373     \n",
      "Medel is training: epoch 64th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3285 - acc: 0.8204     \n",
      "Medel is training: epoch 64th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5682 - acc: 0.7967     \n",
      "Medel is training: epoch 64th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5409 - acc: 0.8044     \n",
      "Medel is training: epoch 64th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0497 - acc: 0.8488     \n",
      "Medel is training: epoch 64th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5010 - acc: 0.8012     \n",
      "Medel is training: epoch 64th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5217 - acc: 0.8043     \n",
      "Medel is training: epoch 64th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4429 - acc: 0.8142     \n",
      "Medel is training: epoch 64th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0830 - acc: 0.8444     \n",
      "Medel is training: epoch 64th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5815 - acc: 0.7938     \n",
      "Medel is training: epoch 64th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4739 - acc: 0.8119     \n",
      "Medel is training: epoch 64th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4929 - acc: 0.8067     \n",
      "Medel is training: epoch 64th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0786 - acc: 0.8441     \n",
      "Medel is training: epoch 64th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5642 - acc: 0.7951     \n",
      "Medel is training: epoch 64th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5126 - acc: 0.8057     \n",
      "Medel is training: epoch 64th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4125 - acc: 0.8149     \n",
      "Medel is training: epoch 64th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0913 - acc: 0.8433     \n",
      "Medel is training: epoch 64th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5576 - acc: 0.7945     \n",
      "Medel is training: epoch 64th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5498 - acc: 0.8001     \n",
      "Medel is training: epoch 64th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1378 - acc: 1.0000\n",
      "Medel is training: epoch 65th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5966 - acc: 0.7957     \n",
      "Medel is training: epoch 65th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3976 - acc: 0.8170     \n",
      "Medel is training: epoch 65th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4167 - acc: 0.8106     \n",
      "Medel is training: epoch 65th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5078 - acc: 0.8078     \n",
      "Medel is training: epoch 65th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2991 - acc: 0.8250     \n",
      "Medel is training: epoch 65th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5534 - acc: 0.7996     \n",
      "Medel is training: epoch 65th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5316 - acc: 0.8042     \n",
      "Medel is training: epoch 65th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2706 - acc: 0.8257     \n",
      "Medel is training: epoch 65th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5675 - acc: 0.7983     \n",
      "Medel is training: epoch 65th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3807 - acc: 0.8189     \n",
      "Medel is training: epoch 65th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4275 - acc: 0.8111     \n",
      "Medel is training: epoch 65th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5538 - acc: 0.8017     \n",
      "Medel is training: epoch 65th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3182 - acc: 0.8243     \n",
      "Medel is training: epoch 65th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5705 - acc: 0.7946     \n",
      "Medel is training: epoch 65th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5187 - acc: 0.8065     \n",
      "Medel is training: epoch 65th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2623 - acc: 0.8289     \n",
      "Medel is training: epoch 65th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5190 - acc: 0.8014     \n",
      "Medel is training: epoch 65th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5254 - acc: 0.8062     \n",
      "Medel is training: epoch 65th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2512 - acc: 0.8300     \n",
      "Medel is training: epoch 65th 19000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.5303 - acc: 0.7993     \n",
      "Medel is training: epoch 65th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4953 - acc: 0.8101     \n",
      "Medel is training: epoch 65th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2899 - acc: 0.8271     \n",
      "Medel is training: epoch 65th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4670 - acc: 0.8044     \n",
      "Medel is training: epoch 65th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5425 - acc: 0.8034     \n",
      "Medel is training: epoch 65th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3660 - acc: 0.8212     \n",
      "Medel is training: epoch 65th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3000 - acc: 0.8231     \n",
      "Medel is training: epoch 65th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5819 - acc: 0.7964     \n",
      "Medel is training: epoch 65th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5307 - acc: 0.8057     \n",
      "Medel is training: epoch 65th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1020 - acc: 0.8451     \n",
      "Medel is training: epoch 65th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5684 - acc: 0.7964     \n",
      "Medel is training: epoch 65th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5153 - acc: 0.8059     \n",
      "Medel is training: epoch 65th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2021 - acc: 0.8373     \n",
      "Medel is training: epoch 65th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3261 - acc: 0.8202     \n",
      "Medel is training: epoch 65th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5670 - acc: 0.7969     \n",
      "Medel is training: epoch 65th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5403 - acc: 0.8044     \n",
      "Medel is training: epoch 65th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0485 - acc: 0.8485     \n",
      "Medel is training: epoch 65th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4992 - acc: 0.8014     \n",
      "Medel is training: epoch 65th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5205 - acc: 0.8044     \n",
      "Medel is training: epoch 65th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4425 - acc: 0.8141     \n",
      "Medel is training: epoch 65th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0826 - acc: 0.8442     \n",
      "Medel is training: epoch 65th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5788 - acc: 0.7937     \n",
      "Medel is training: epoch 65th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4731 - acc: 0.8117     \n",
      "Medel is training: epoch 65th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4921 - acc: 0.8067     \n",
      "Medel is training: epoch 65th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0761 - acc: 0.8444     \n",
      "Medel is training: epoch 65th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5620 - acc: 0.7951     \n",
      "Medel is training: epoch 65th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5110 - acc: 0.8059     \n",
      "Medel is training: epoch 65th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4106 - acc: 0.8147     \n",
      "Medel is training: epoch 65th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0897 - acc: 0.8432     \n",
      "Medel is training: epoch 65th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5559 - acc: 0.7947     \n",
      "Medel is training: epoch 65th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5485 - acc: 0.8000     \n",
      "Medel is training: epoch 65th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1361 - acc: 1.0000\n",
      "Medel is training: epoch 66th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5949 - acc: 0.7956     \n",
      "Medel is training: epoch 66th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3972 - acc: 0.8170     \n",
      "Medel is training: epoch 66th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4146 - acc: 0.8108     \n",
      "Medel is training: epoch 66th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5068 - acc: 0.8079     \n",
      "Medel is training: epoch 66th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2971 - acc: 0.8249     \n",
      "Medel is training: epoch 66th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5521 - acc: 0.7997     \n",
      "Medel is training: epoch 66th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5311 - acc: 0.8041     \n",
      "Medel is training: epoch 66th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2669 - acc: 0.8259     \n",
      "Medel is training: epoch 66th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5667 - acc: 0.7983     \n",
      "Medel is training: epoch 66th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3787 - acc: 0.8191     \n",
      "Medel is training: epoch 66th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4257 - acc: 0.8111     \n",
      "Medel is training: epoch 66th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5529 - acc: 0.8018     \n",
      "Medel is training: epoch 66th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3167 - acc: 0.8243     \n",
      "Medel is training: epoch 66th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5694 - acc: 0.7947     \n",
      "Medel is training: epoch 66th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5185 - acc: 0.8065     \n",
      "Medel is training: epoch 66th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2612 - acc: 0.8291     \n",
      "Medel is training: epoch 66th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5179 - acc: 0.8018     \n",
      "Medel is training: epoch 66th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5245 - acc: 0.8061     \n",
      "Medel is training: epoch 66th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2500 - acc: 0.8302     \n",
      "Medel is training: epoch 66th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5286 - acc: 0.7994     \n",
      "Medel is training: epoch 66th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4942 - acc: 0.8101     \n",
      "Medel is training: epoch 66th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2887 - acc: 0.8273     \n",
      "Medel is training: epoch 66th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4659 - acc: 0.8049     \n",
      "Medel is training: epoch 66th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5422 - acc: 0.8034     \n",
      "Medel is training: epoch 66th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3655 - acc: 0.8214     \n",
      "Medel is training: epoch 66th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2986 - acc: 0.8230     \n",
      "Medel is training: epoch 66th 26000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.5807 - acc: 0.7965     \n",
      "Medel is training: epoch 66th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5299 - acc: 0.8058     \n",
      "Medel is training: epoch 66th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0995 - acc: 0.8448     \n",
      "Medel is training: epoch 66th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5685 - acc: 0.7962     \n",
      "Medel is training: epoch 66th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5147 - acc: 0.8059     \n",
      "Medel is training: epoch 66th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2005 - acc: 0.8375     \n",
      "Medel is training: epoch 66th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3240 - acc: 0.8207     \n",
      "Medel is training: epoch 66th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5652 - acc: 0.7967     \n",
      "Medel is training: epoch 66th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5386 - acc: 0.8044     \n",
      "Medel is training: epoch 66th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0459 - acc: 0.8488     \n",
      "Medel is training: epoch 66th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4968 - acc: 0.8014     \n",
      "Medel is training: epoch 66th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5201 - acc: 0.8044     \n",
      "Medel is training: epoch 66th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4406 - acc: 0.8143     \n",
      "Medel is training: epoch 66th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0798 - acc: 0.8444     \n",
      "Medel is training: epoch 66th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5787 - acc: 0.7940     \n",
      "Medel is training: epoch 66th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4730 - acc: 0.8118     \n",
      "Medel is training: epoch 66th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4912 - acc: 0.8069     \n",
      "Medel is training: epoch 66th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0740 - acc: 0.8445     \n",
      "Medel is training: epoch 66th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5603 - acc: 0.7954     \n",
      "Medel is training: epoch 66th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5106 - acc: 0.8060     \n",
      "Medel is training: epoch 66th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4100 - acc: 0.8149     \n",
      "Medel is training: epoch 66th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0880 - acc: 0.8436     \n",
      "Medel is training: epoch 66th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5548 - acc: 0.7945     \n",
      "Medel is training: epoch 66th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5477 - acc: 0.8000     \n",
      "Medel is training: epoch 66th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1344 - acc: 1.0000\n",
      "Medel is training: epoch 67th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5942 - acc: 0.7957     \n",
      "Medel is training: epoch 67th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3953 - acc: 0.8168     \n",
      "Medel is training: epoch 67th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4136 - acc: 0.8106     \n",
      "Medel is training: epoch 67th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5060 - acc: 0.8079     \n",
      "Medel is training: epoch 67th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2960 - acc: 0.8250     \n",
      "Medel is training: epoch 67th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5511 - acc: 0.7998     \n",
      "Medel is training: epoch 67th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5300 - acc: 0.8044     \n",
      "Medel is training: epoch 67th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2648 - acc: 0.8265     \n",
      "Medel is training: epoch 67th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5645 - acc: 0.7984     \n",
      "Medel is training: epoch 67th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3779 - acc: 0.8192     \n",
      "Medel is training: epoch 67th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4241 - acc: 0.8111     \n",
      "Medel is training: epoch 67th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5523 - acc: 0.8016     \n",
      "Medel is training: epoch 67th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3155 - acc: 0.8247     \n",
      "Medel is training: epoch 67th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5677 - acc: 0.7946     \n",
      "Medel is training: epoch 67th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5173 - acc: 0.8065     \n",
      "Medel is training: epoch 67th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2601 - acc: 0.8288     \n",
      "Medel is training: epoch 67th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5163 - acc: 0.8015     \n",
      "Medel is training: epoch 67th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5239 - acc: 0.8060     \n",
      "Medel is training: epoch 67th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2484 - acc: 0.8301     \n",
      "Medel is training: epoch 67th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5274 - acc: 0.7993     \n",
      "Medel is training: epoch 67th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4934 - acc: 0.8101     \n",
      "Medel is training: epoch 67th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2880 - acc: 0.8275     \n",
      "Medel is training: epoch 67th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4643 - acc: 0.8045     \n",
      "Medel is training: epoch 67th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5412 - acc: 0.8034     \n",
      "Medel is training: epoch 67th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3644 - acc: 0.8216     \n",
      "Medel is training: epoch 67th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2970 - acc: 0.8233     \n",
      "Medel is training: epoch 67th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5793 - acc: 0.7964     \n",
      "Medel is training: epoch 67th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5287 - acc: 0.8059     \n",
      "Medel is training: epoch 67th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0976 - acc: 0.8450     \n",
      "Medel is training: epoch 67th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5655 - acc: 0.7963     \n",
      "Medel is training: epoch 67th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5142 - acc: 0.8060     \n",
      "Medel is training: epoch 67th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1990 - acc: 0.8376     \n",
      "Medel is training: epoch 67th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3220 - acc: 0.8207     \n",
      "Medel is training: epoch 67th 33000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.5639 - acc: 0.7969     \n",
      "Medel is training: epoch 67th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5381 - acc: 0.8045     \n",
      "Medel is training: epoch 67th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0437 - acc: 0.8491     \n",
      "Medel is training: epoch 67th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4937 - acc: 0.8019     \n",
      "Medel is training: epoch 67th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5189 - acc: 0.8044     \n",
      "Medel is training: epoch 67th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4397 - acc: 0.8143     \n",
      "Medel is training: epoch 67th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0796 - acc: 0.8444     \n",
      "Medel is training: epoch 67th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5753 - acc: 0.7939     \n",
      "Medel is training: epoch 67th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4716 - acc: 0.8119     \n",
      "Medel is training: epoch 67th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4898 - acc: 0.8068     \n",
      "Medel is training: epoch 67th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0720 - acc: 0.8449     \n",
      "Medel is training: epoch 67th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5582 - acc: 0.7954     \n",
      "Medel is training: epoch 67th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5085 - acc: 0.8060     \n",
      "Medel is training: epoch 67th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4084 - acc: 0.8149     \n",
      "Medel is training: epoch 67th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0861 - acc: 0.8439     \n",
      "Medel is training: epoch 67th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5526 - acc: 0.7949     \n",
      "Medel is training: epoch 67th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5462 - acc: 0.8001     \n",
      "Medel is training: epoch 67th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1326 - acc: 1.0000\n",
      "Medel is training: epoch 68th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5927 - acc: 0.7959     \n",
      "Medel is training: epoch 68th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3945 - acc: 0.8174     \n",
      "Medel is training: epoch 68th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4125 - acc: 0.8109     \n",
      "Medel is training: epoch 68th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5046 - acc: 0.8079     \n",
      "Medel is training: epoch 68th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2946 - acc: 0.8253     \n",
      "Medel is training: epoch 68th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5501 - acc: 0.7997     \n",
      "Medel is training: epoch 68th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5293 - acc: 0.8043     \n",
      "Medel is training: epoch 68th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2643 - acc: 0.8263     \n",
      "Medel is training: epoch 68th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5631 - acc: 0.7984     \n",
      "Medel is training: epoch 68th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3778 - acc: 0.8192     \n",
      "Medel is training: epoch 68th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4225 - acc: 0.8110     \n",
      "Medel is training: epoch 68th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5509 - acc: 0.8015     \n",
      "Medel is training: epoch 68th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3144 - acc: 0.8246     \n",
      "Medel is training: epoch 68th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5658 - acc: 0.7948     \n",
      "Medel is training: epoch 68th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5168 - acc: 0.8065     \n",
      "Medel is training: epoch 68th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2586 - acc: 0.8290     \n",
      "Medel is training: epoch 68th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5150 - acc: 0.8015     \n",
      "Medel is training: epoch 68th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5228 - acc: 0.8062     \n",
      "Medel is training: epoch 68th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2470 - acc: 0.8303     \n",
      "Medel is training: epoch 68th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5255 - acc: 0.7994     \n",
      "Medel is training: epoch 68th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4923 - acc: 0.8101     \n",
      "Medel is training: epoch 68th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2866 - acc: 0.8274     \n",
      "Medel is training: epoch 68th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4620 - acc: 0.8048     \n",
      "Medel is training: epoch 68th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5398 - acc: 0.8034     \n",
      "Medel is training: epoch 68th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3634 - acc: 0.8216     \n",
      "Medel is training: epoch 68th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2956 - acc: 0.8232     \n",
      "Medel is training: epoch 68th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5774 - acc: 0.7965     \n",
      "Medel is training: epoch 68th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5287 - acc: 0.8057     \n",
      "Medel is training: epoch 68th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0965 - acc: 0.8453     \n",
      "Medel is training: epoch 68th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5646 - acc: 0.7966     \n",
      "Medel is training: epoch 68th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5122 - acc: 0.8060     \n",
      "Medel is training: epoch 68th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1983 - acc: 0.8378     \n",
      "Medel is training: epoch 68th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3208 - acc: 0.8203     \n",
      "Medel is training: epoch 68th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5626 - acc: 0.7968     \n",
      "Medel is training: epoch 68th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5371 - acc: 0.8044     \n",
      "Medel is training: epoch 68th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0425 - acc: 0.8490     \n",
      "Medel is training: epoch 68th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4932 - acc: 0.8017     \n",
      "Medel is training: epoch 68th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5174 - acc: 0.8042     \n",
      "Medel is training: epoch 68th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4396 - acc: 0.8144     \n",
      "Medel is training: epoch 68th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0757 - acc: 0.8452     \n",
      "Medel is training: epoch 68th 40000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.5735 - acc: 0.7941     \n",
      "Medel is training: epoch 68th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4710 - acc: 0.8117     \n",
      "Medel is training: epoch 68th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4891 - acc: 0.8069     \n",
      "Medel is training: epoch 68th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0704 - acc: 0.8453     \n",
      "Medel is training: epoch 68th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5573 - acc: 0.7953     \n",
      "Medel is training: epoch 68th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5069 - acc: 0.8060     \n",
      "Medel is training: epoch 68th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4075 - acc: 0.8150     \n",
      "Medel is training: epoch 68th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0832 - acc: 0.8439     \n",
      "Medel is training: epoch 68th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5516 - acc: 0.7946     \n",
      "Medel is training: epoch 68th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5437 - acc: 0.8000     \n",
      "Medel is training: epoch 68th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1309 - acc: 1.0000\n",
      "Medel is training: epoch 69th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5911 - acc: 0.7958     \n",
      "Medel is training: epoch 69th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3931 - acc: 0.8173     \n",
      "Medel is training: epoch 69th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4109 - acc: 0.8109     \n",
      "Medel is training: epoch 69th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5042 - acc: 0.8078     \n",
      "Medel is training: epoch 69th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2932 - acc: 0.8252     \n",
      "Medel is training: epoch 69th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5490 - acc: 0.7998     \n",
      "Medel is training: epoch 69th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5283 - acc: 0.8043     \n",
      "Medel is training: epoch 69th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2616 - acc: 0.8267     \n",
      "Medel is training: epoch 69th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5612 - acc: 0.7983     \n",
      "Medel is training: epoch 69th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3758 - acc: 0.8191     \n",
      "Medel is training: epoch 69th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4208 - acc: 0.8111     \n",
      "Medel is training: epoch 69th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5500 - acc: 0.8017     \n",
      "Medel is training: epoch 69th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3130 - acc: 0.8249     \n",
      "Medel is training: epoch 69th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5641 - acc: 0.7946     \n",
      "Medel is training: epoch 69th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5159 - acc: 0.8066     \n",
      "Medel is training: epoch 69th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2571 - acc: 0.8294     \n",
      "Medel is training: epoch 69th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5136 - acc: 0.8013     \n",
      "Medel is training: epoch 69th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5218 - acc: 0.8062     \n",
      "Medel is training: epoch 69th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2460 - acc: 0.8304     \n",
      "Medel is training: epoch 69th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5237 - acc: 0.7995     \n",
      "Medel is training: epoch 69th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4913 - acc: 0.8103     \n",
      "Medel is training: epoch 69th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2854 - acc: 0.8274     \n",
      "Medel is training: epoch 69th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4601 - acc: 0.8049     \n",
      "Medel is training: epoch 69th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5388 - acc: 0.8035     \n",
      "Medel is training: epoch 69th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3627 - acc: 0.8213     \n",
      "Medel is training: epoch 69th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2928 - acc: 0.8233     \n",
      "Medel is training: epoch 69th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5766 - acc: 0.7965     \n",
      "Medel is training: epoch 69th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5281 - acc: 0.8059     \n",
      "Medel is training: epoch 69th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0935 - acc: 0.8451     \n",
      "Medel is training: epoch 69th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5616 - acc: 0.7964     \n",
      "Medel is training: epoch 69th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5122 - acc: 0.8059     \n",
      "Medel is training: epoch 69th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1961 - acc: 0.8379     \n",
      "Medel is training: epoch 69th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3188 - acc: 0.8208     \n",
      "Medel is training: epoch 69th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5609 - acc: 0.7971     \n",
      "Medel is training: epoch 69th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5367 - acc: 0.8044     \n",
      "Medel is training: epoch 69th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0403 - acc: 0.8493     \n",
      "Medel is training: epoch 69th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4911 - acc: 0.8018     \n",
      "Medel is training: epoch 69th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5169 - acc: 0.8045     \n",
      "Medel is training: epoch 69th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4381 - acc: 0.8145     \n",
      "Medel is training: epoch 69th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0755 - acc: 0.8447     \n",
      "Medel is training: epoch 69th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5722 - acc: 0.7939     \n",
      "Medel is training: epoch 69th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4686 - acc: 0.8119     \n",
      "Medel is training: epoch 69th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4884 - acc: 0.8068     \n",
      "Medel is training: epoch 69th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0687 - acc: 0.8447     \n",
      "Medel is training: epoch 69th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5556 - acc: 0.7955     \n",
      "Medel is training: epoch 69th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5070 - acc: 0.8059     \n",
      "Medel is training: epoch 69th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4070 - acc: 0.8152     \n",
      "Medel is training: epoch 69th 47000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.0828 - acc: 0.8440     \n",
      "Medel is training: epoch 69th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5497 - acc: 0.7950     \n",
      "Medel is training: epoch 69th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5448 - acc: 0.8002     \n",
      "Medel is training: epoch 69th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1293 - acc: 1.0000\n",
      "Medel is training: epoch 70th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5896 - acc: 0.7958     \n",
      "Medel is training: epoch 70th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3932 - acc: 0.8173     \n",
      "Medel is training: epoch 70th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4093 - acc: 0.8110     \n",
      "Medel is training: epoch 70th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5038 - acc: 0.8080     \n",
      "Medel is training: epoch 70th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2924 - acc: 0.8250     \n",
      "Medel is training: epoch 70th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5478 - acc: 0.7997     \n",
      "Medel is training: epoch 70th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5280 - acc: 0.8043     \n",
      "Medel is training: epoch 70th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2606 - acc: 0.8264     \n",
      "Medel is training: epoch 70th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5612 - acc: 0.7984     \n",
      "Medel is training: epoch 70th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3753 - acc: 0.8192     \n",
      "Medel is training: epoch 70th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4192 - acc: 0.8112     \n",
      "Medel is training: epoch 70th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5487 - acc: 0.8017     \n",
      "Medel is training: epoch 70th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3117 - acc: 0.8247     \n",
      "Medel is training: epoch 70th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5625 - acc: 0.7947     \n",
      "Medel is training: epoch 70th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5162 - acc: 0.8065     \n",
      "Medel is training: epoch 70th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2563 - acc: 0.8292     \n",
      "Medel is training: epoch 70th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5120 - acc: 0.8014     \n",
      "Medel is training: epoch 70th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5209 - acc: 0.8061     \n",
      "Medel is training: epoch 70th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2448 - acc: 0.8305     \n",
      "Medel is training: epoch 70th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5219 - acc: 0.7995     \n",
      "Medel is training: epoch 70th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4911 - acc: 0.8103     \n",
      "Medel is training: epoch 70th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2843 - acc: 0.8274     \n",
      "Medel is training: epoch 70th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4590 - acc: 0.8051     \n",
      "Medel is training: epoch 70th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5379 - acc: 0.8034     \n",
      "Medel is training: epoch 70th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3611 - acc: 0.8216     \n",
      "Medel is training: epoch 70th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2911 - acc: 0.8231     \n",
      "Medel is training: epoch 70th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5751 - acc: 0.7966     \n",
      "Medel is training: epoch 70th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5272 - acc: 0.8058     \n",
      "Medel is training: epoch 70th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0910 - acc: 0.8457     \n",
      "Medel is training: epoch 70th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5606 - acc: 0.7961     \n",
      "Medel is training: epoch 70th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5101 - acc: 0.8060     \n",
      "Medel is training: epoch 70th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1950 - acc: 0.8380     \n",
      "Medel is training: epoch 70th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3170 - acc: 0.8209     \n",
      "Medel is training: epoch 70th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5595 - acc: 0.7970     \n",
      "Medel is training: epoch 70th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5354 - acc: 0.8046     \n",
      "Medel is training: epoch 70th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0380 - acc: 0.8493     \n",
      "Medel is training: epoch 70th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4898 - acc: 0.8018     \n",
      "Medel is training: epoch 70th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5152 - acc: 0.8044     \n",
      "Medel is training: epoch 70th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4372 - acc: 0.8144     \n",
      "Medel is training: epoch 70th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0726 - acc: 0.8451     \n",
      "Medel is training: epoch 70th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5694 - acc: 0.7941     \n",
      "Medel is training: epoch 70th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4677 - acc: 0.8119     \n",
      "Medel is training: epoch 70th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4877 - acc: 0.8070     \n",
      "Medel is training: epoch 70th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0668 - acc: 0.8448     \n",
      "Medel is training: epoch 70th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5533 - acc: 0.7958     \n",
      "Medel is training: epoch 70th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5055 - acc: 0.8060     \n",
      "Medel is training: epoch 70th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4063 - acc: 0.8151     \n",
      "Medel is training: epoch 70th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0805 - acc: 0.8441     \n",
      "Medel is training: epoch 70th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5485 - acc: 0.7947     \n",
      "Medel is training: epoch 70th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5427 - acc: 0.8000     \n",
      "Medel is training: epoch 70th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1275 - acc: 1.0000\n",
      "Medel is training: epoch 71th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5887 - acc: 0.7961     \n",
      "Medel is training: epoch 71th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3916 - acc: 0.8175     \n",
      "Medel is training: epoch 71th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4068 - acc: 0.8111     \n",
      "Medel is training: epoch 71th 3000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.5030 - acc: 0.8080     \n",
      "Medel is training: epoch 71th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2904 - acc: 0.8258     \n",
      "Medel is training: epoch 71th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5465 - acc: 0.7998     \n",
      "Medel is training: epoch 71th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5270 - acc: 0.8042     \n",
      "Medel is training: epoch 71th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2589 - acc: 0.8267     \n",
      "Medel is training: epoch 71th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5596 - acc: 0.7985     \n",
      "Medel is training: epoch 71th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3744 - acc: 0.8191     \n",
      "Medel is training: epoch 71th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4182 - acc: 0.8112     \n",
      "Medel is training: epoch 71th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5478 - acc: 0.8019     \n",
      "Medel is training: epoch 71th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3104 - acc: 0.8247     \n",
      "Medel is training: epoch 71th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5613 - acc: 0.7947     \n",
      "Medel is training: epoch 71th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5146 - acc: 0.8066     \n",
      "Medel is training: epoch 71th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2549 - acc: 0.8295     \n",
      "Medel is training: epoch 71th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5096 - acc: 0.8018     \n",
      "Medel is training: epoch 71th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5204 - acc: 0.8062     \n",
      "Medel is training: epoch 71th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2433 - acc: 0.8308     \n",
      "Medel is training: epoch 71th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5207 - acc: 0.7996     \n",
      "Medel is training: epoch 71th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4898 - acc: 0.8102     \n",
      "Medel is training: epoch 71th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2827 - acc: 0.8273     \n",
      "Medel is training: epoch 71th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4576 - acc: 0.8052     \n",
      "Medel is training: epoch 71th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5370 - acc: 0.8036     \n",
      "Medel is training: epoch 71th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3602 - acc: 0.8216     \n",
      "Medel is training: epoch 71th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2894 - acc: 0.8235     \n",
      "Medel is training: epoch 71th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5746 - acc: 0.7966     \n",
      "Medel is training: epoch 71th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5265 - acc: 0.8058     \n",
      "Medel is training: epoch 71th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0891 - acc: 0.8457     \n",
      "Medel is training: epoch 71th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5585 - acc: 0.7965     \n",
      "Medel is training: epoch 71th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5095 - acc: 0.8061     \n",
      "Medel is training: epoch 71th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1938 - acc: 0.8380     \n",
      "Medel is training: epoch 71th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3154 - acc: 0.8210     \n",
      "Medel is training: epoch 71th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5581 - acc: 0.7968     \n",
      "Medel is training: epoch 71th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5344 - acc: 0.8045     \n",
      "Medel is training: epoch 71th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0370 - acc: 0.8497     \n",
      "Medel is training: epoch 71th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4876 - acc: 0.8019     \n",
      "Medel is training: epoch 71th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5145 - acc: 0.8046     \n",
      "Medel is training: epoch 71th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4368 - acc: 0.8145     \n",
      "Medel is training: epoch 71th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0705 - acc: 0.8451     \n",
      "Medel is training: epoch 71th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5692 - acc: 0.7940     \n",
      "Medel is training: epoch 71th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4675 - acc: 0.8118     \n",
      "Medel is training: epoch 71th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4868 - acc: 0.8069     \n",
      "Medel is training: epoch 71th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0646 - acc: 0.8452     \n",
      "Medel is training: epoch 71th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5508 - acc: 0.7954     \n",
      "Medel is training: epoch 71th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5048 - acc: 0.8060     \n",
      "Medel is training: epoch 71th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4056 - acc: 0.8150     \n",
      "Medel is training: epoch 71th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0792 - acc: 0.8439     \n",
      "Medel is training: epoch 71th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5458 - acc: 0.7947     \n",
      "Medel is training: epoch 71th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5412 - acc: 0.8002     \n",
      "Medel is training: epoch 71th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1258 - acc: 1.0000\n",
      "Medel is training: epoch 72th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5875 - acc: 0.7960     \n",
      "Medel is training: epoch 72th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3909 - acc: 0.8174     \n",
      "Medel is training: epoch 72th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4063 - acc: 0.8111     \n",
      "Medel is training: epoch 72th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5023 - acc: 0.8081     \n",
      "Medel is training: epoch 72th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2891 - acc: 0.8256     \n",
      "Medel is training: epoch 72th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5455 - acc: 0.7998     \n",
      "Medel is training: epoch 72th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5264 - acc: 0.8043     \n",
      "Medel is training: epoch 72th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2570 - acc: 0.8267     \n",
      "Medel is training: epoch 72th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5577 - acc: 0.7986     \n",
      "Medel is training: epoch 72th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3734 - acc: 0.8191     \n",
      "Medel is training: epoch 72th 10000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.4165 - acc: 0.8115     \n",
      "Medel is training: epoch 72th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5474 - acc: 0.8017     \n",
      "Medel is training: epoch 72th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3096 - acc: 0.8248     \n",
      "Medel is training: epoch 72th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5606 - acc: 0.7948     \n",
      "Medel is training: epoch 72th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5134 - acc: 0.8066     \n",
      "Medel is training: epoch 72th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2537 - acc: 0.8295     \n",
      "Medel is training: epoch 72th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5083 - acc: 0.8015     \n",
      "Medel is training: epoch 72th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5194 - acc: 0.8061     \n",
      "Medel is training: epoch 72th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2420 - acc: 0.8306     \n",
      "Medel is training: epoch 72th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5192 - acc: 0.7998     \n",
      "Medel is training: epoch 72th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4887 - acc: 0.8101     \n",
      "Medel is training: epoch 72th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2816 - acc: 0.8275     \n",
      "Medel is training: epoch 72th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4562 - acc: 0.8051     \n",
      "Medel is training: epoch 72th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5359 - acc: 0.8035     \n",
      "Medel is training: epoch 72th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3596 - acc: 0.8219     \n",
      "Medel is training: epoch 72th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2887 - acc: 0.8236     \n",
      "Medel is training: epoch 72th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5725 - acc: 0.7966     \n",
      "Medel is training: epoch 72th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5258 - acc: 0.8059     \n",
      "Medel is training: epoch 72th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0889 - acc: 0.8452     \n",
      "Medel is training: epoch 72th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5575 - acc: 0.7963     \n",
      "Medel is training: epoch 72th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5088 - acc: 0.8061     \n",
      "Medel is training: epoch 72th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1930 - acc: 0.8382     \n",
      "Medel is training: epoch 72th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3137 - acc: 0.8210     \n",
      "Medel is training: epoch 72th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5580 - acc: 0.7970     \n",
      "Medel is training: epoch 72th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5333 - acc: 0.8045     \n",
      "Medel is training: epoch 72th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0346 - acc: 0.8496     \n",
      "Medel is training: epoch 72th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4857 - acc: 0.8017     \n",
      "Medel is training: epoch 72th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5130 - acc: 0.8048     \n",
      "Medel is training: epoch 72th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4355 - acc: 0.8143     \n",
      "Medel is training: epoch 72th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0696 - acc: 0.8449     \n",
      "Medel is training: epoch 72th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5670 - acc: 0.7939     \n",
      "Medel is training: epoch 72th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4661 - acc: 0.8119     \n",
      "Medel is training: epoch 72th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4855 - acc: 0.8069     \n",
      "Medel is training: epoch 72th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0631 - acc: 0.8454     \n",
      "Medel is training: epoch 72th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5500 - acc: 0.7955     \n",
      "Medel is training: epoch 72th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5036 - acc: 0.8060     \n",
      "Medel is training: epoch 72th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4042 - acc: 0.8152     \n",
      "Medel is training: epoch 72th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0775 - acc: 0.8446     \n",
      "Medel is training: epoch 72th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5450 - acc: 0.7946     \n",
      "Medel is training: epoch 72th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5397 - acc: 0.8002     \n",
      "Medel is training: epoch 72th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1240 - acc: 1.0000\n",
      "Medel is training: epoch 73th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5875 - acc: 0.7959     \n",
      "Medel is training: epoch 73th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3905 - acc: 0.8174     \n",
      "Medel is training: epoch 73th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4046 - acc: 0.8111     \n",
      "Medel is training: epoch 73th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5014 - acc: 0.8082     \n",
      "Medel is training: epoch 73th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2879 - acc: 0.8255     \n",
      "Medel is training: epoch 73th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5443 - acc: 0.7998     \n",
      "Medel is training: epoch 73th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5249 - acc: 0.8043     \n",
      "Medel is training: epoch 73th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2556 - acc: 0.8269     \n",
      "Medel is training: epoch 73th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5566 - acc: 0.7985     \n",
      "Medel is training: epoch 73th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3722 - acc: 0.8194     \n",
      "Medel is training: epoch 73th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4153 - acc: 0.8116     \n",
      "Medel is training: epoch 73th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5459 - acc: 0.8018     \n",
      "Medel is training: epoch 73th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3083 - acc: 0.8250     \n",
      "Medel is training: epoch 73th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5585 - acc: 0.7947     \n",
      "Medel is training: epoch 73th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5128 - acc: 0.8065     \n",
      "Medel is training: epoch 73th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2527 - acc: 0.8294     \n",
      "Medel is training: epoch 73th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5072 - acc: 0.8016     \n",
      "Medel is training: epoch 73th 17000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.5184 - acc: 0.8063     \n",
      "Medel is training: epoch 73th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2407 - acc: 0.8307     \n",
      "Medel is training: epoch 73th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5175 - acc: 0.7997     \n",
      "Medel is training: epoch 73th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4881 - acc: 0.8103     \n",
      "Medel is training: epoch 73th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2805 - acc: 0.8274     \n",
      "Medel is training: epoch 73th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4540 - acc: 0.8052     \n",
      "Medel is training: epoch 73th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5350 - acc: 0.8036     \n",
      "Medel is training: epoch 73th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3581 - acc: 0.8218     \n",
      "Medel is training: epoch 73th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2860 - acc: 0.8236     \n",
      "Medel is training: epoch 73th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5715 - acc: 0.7966     \n",
      "Medel is training: epoch 73th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5258 - acc: 0.8058     \n",
      "Medel is training: epoch 73th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0854 - acc: 0.8462     \n",
      "Medel is training: epoch 73th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5555 - acc: 0.7965     \n",
      "Medel is training: epoch 73th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5077 - acc: 0.8062     \n",
      "Medel is training: epoch 73th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1911 - acc: 0.8381     \n",
      "Medel is training: epoch 73th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3128 - acc: 0.8213     \n",
      "Medel is training: epoch 73th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5555 - acc: 0.7970     \n",
      "Medel is training: epoch 73th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5328 - acc: 0.8044     \n",
      "Medel is training: epoch 73th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0341 - acc: 0.8498     \n",
      "Medel is training: epoch 73th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4850 - acc: 0.8018     \n",
      "Medel is training: epoch 73th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5118 - acc: 0.8049     \n",
      "Medel is training: epoch 73th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4352 - acc: 0.8143     \n",
      "Medel is training: epoch 73th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0678 - acc: 0.8453     \n",
      "Medel is training: epoch 73th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5652 - acc: 0.7941     \n",
      "Medel is training: epoch 73th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4653 - acc: 0.8120     \n",
      "Medel is training: epoch 73th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4849 - acc: 0.8069     \n",
      "Medel is training: epoch 73th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0609 - acc: 0.8456     \n",
      "Medel is training: epoch 73th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5490 - acc: 0.7954     \n",
      "Medel is training: epoch 73th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5018 - acc: 0.8061     \n",
      "Medel is training: epoch 73th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4038 - acc: 0.8153     \n",
      "Medel is training: epoch 73th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0761 - acc: 0.8445     \n",
      "Medel is training: epoch 73th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5437 - acc: 0.7950     \n",
      "Medel is training: epoch 73th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5379 - acc: 0.8002     \n",
      "Medel is training: epoch 73th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1225 - acc: 1.0000\n",
      "Medel is training: epoch 74th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5844 - acc: 0.7959     \n",
      "Medel is training: epoch 74th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3892 - acc: 0.8175     \n",
      "Medel is training: epoch 74th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4033 - acc: 0.8112     \n",
      "Medel is training: epoch 74th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5011 - acc: 0.8081     \n",
      "Medel is training: epoch 74th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2867 - acc: 0.8258     \n",
      "Medel is training: epoch 74th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5431 - acc: 0.7998     \n",
      "Medel is training: epoch 74th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5245 - acc: 0.8043     \n",
      "Medel is training: epoch 74th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2541 - acc: 0.8269     \n",
      "Medel is training: epoch 74th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5554 - acc: 0.7985     \n",
      "Medel is training: epoch 74th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3713 - acc: 0.8192     \n",
      "Medel is training: epoch 74th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4141 - acc: 0.8117     \n",
      "Medel is training: epoch 74th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5454 - acc: 0.8018     \n",
      "Medel is training: epoch 74th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3076 - acc: 0.8251     \n",
      "Medel is training: epoch 74th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5578 - acc: 0.7949     \n",
      "Medel is training: epoch 74th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5120 - acc: 0.8065     \n",
      "Medel is training: epoch 74th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2511 - acc: 0.8295     \n",
      "Medel is training: epoch 74th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5057 - acc: 0.8016     \n",
      "Medel is training: epoch 74th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5174 - acc: 0.8062     \n",
      "Medel is training: epoch 74th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2394 - acc: 0.8306     \n",
      "Medel is training: epoch 74th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5165 - acc: 0.7996     \n",
      "Medel is training: epoch 74th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4874 - acc: 0.8102     \n",
      "Medel is training: epoch 74th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2798 - acc: 0.8275     \n",
      "Medel is training: epoch 74th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4526 - acc: 0.8052     \n",
      "Medel is training: epoch 74th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5339 - acc: 0.8036     \n",
      "Medel is training: epoch 74th 24000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.3571 - acc: 0.8217     \n",
      "Medel is training: epoch 74th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2850 - acc: 0.8236     \n",
      "Medel is training: epoch 74th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5703 - acc: 0.7967     \n",
      "Medel is training: epoch 74th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5248 - acc: 0.8059     \n",
      "Medel is training: epoch 74th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0844 - acc: 0.8457     \n",
      "Medel is training: epoch 74th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5532 - acc: 0.7965     \n",
      "Medel is training: epoch 74th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5075 - acc: 0.8061     \n",
      "Medel is training: epoch 74th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1902 - acc: 0.8382     \n",
      "Medel is training: epoch 74th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3104 - acc: 0.8213     \n",
      "Medel is training: epoch 74th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5550 - acc: 0.7972     \n",
      "Medel is training: epoch 74th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5321 - acc: 0.8044     \n",
      "Medel is training: epoch 74th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0315 - acc: 0.8494     \n",
      "Medel is training: epoch 74th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4837 - acc: 0.8019     \n",
      "Medel is training: epoch 74th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5107 - acc: 0.8049     \n",
      "Medel is training: epoch 74th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4337 - acc: 0.8146     \n",
      "Medel is training: epoch 74th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0657 - acc: 0.8455     \n",
      "Medel is training: epoch 74th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5645 - acc: 0.7939     \n",
      "Medel is training: epoch 74th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4633 - acc: 0.8121     \n",
      "Medel is training: epoch 74th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4847 - acc: 0.8068     \n",
      "Medel is training: epoch 74th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0596 - acc: 0.8450     \n",
      "Medel is training: epoch 74th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5465 - acc: 0.7955     \n",
      "Medel is training: epoch 74th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5014 - acc: 0.8060     \n",
      "Medel is training: epoch 74th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4022 - acc: 0.8153     \n",
      "Medel is training: epoch 74th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0736 - acc: 0.8449     \n",
      "Medel is training: epoch 74th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5416 - acc: 0.7951     \n",
      "Medel is training: epoch 74th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5376 - acc: 0.8000     \n",
      "Medel is training: epoch 74th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1209 - acc: 1.0000\n",
      "Medel is training: epoch 75th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5842 - acc: 0.7960     \n",
      "Medel is training: epoch 75th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3880 - acc: 0.8176     \n",
      "Medel is training: epoch 75th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4026 - acc: 0.8114     \n",
      "Medel is training: epoch 75th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5005 - acc: 0.8082     \n",
      "Medel is training: epoch 75th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2853 - acc: 0.8257     \n",
      "Medel is training: epoch 75th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5416 - acc: 0.7999     \n",
      "Medel is training: epoch 75th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5238 - acc: 0.8043     \n",
      "Medel is training: epoch 75th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2524 - acc: 0.8271     \n",
      "Medel is training: epoch 75th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5544 - acc: 0.7986     \n",
      "Medel is training: epoch 75th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3709 - acc: 0.8191     \n",
      "Medel is training: epoch 75th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4124 - acc: 0.8115     \n",
      "Medel is training: epoch 75th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5441 - acc: 0.8017     \n",
      "Medel is training: epoch 75th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3065 - acc: 0.8251     \n",
      "Medel is training: epoch 75th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5559 - acc: 0.7950     \n",
      "Medel is training: epoch 75th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5113 - acc: 0.8066     \n",
      "Medel is training: epoch 75th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2500 - acc: 0.8294     \n",
      "Medel is training: epoch 75th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5047 - acc: 0.8017     \n",
      "Medel is training: epoch 75th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5167 - acc: 0.8063     \n",
      "Medel is training: epoch 75th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2386 - acc: 0.8307     \n",
      "Medel is training: epoch 75th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5145 - acc: 0.7998     \n",
      "Medel is training: epoch 75th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4864 - acc: 0.8102     \n",
      "Medel is training: epoch 75th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2784 - acc: 0.8275     \n",
      "Medel is training: epoch 75th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4510 - acc: 0.8051     \n",
      "Medel is training: epoch 75th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5328 - acc: 0.8035     \n",
      "Medel is training: epoch 75th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3560 - acc: 0.8217     \n",
      "Medel is training: epoch 75th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2835 - acc: 0.8237     \n",
      "Medel is training: epoch 75th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5692 - acc: 0.7968     \n",
      "Medel is training: epoch 75th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5241 - acc: 0.8059     \n",
      "Medel is training: epoch 75th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0823 - acc: 0.8458     \n",
      "Medel is training: epoch 75th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5528 - acc: 0.7966     \n",
      "Medel is training: epoch 75th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5062 - acc: 0.8063     \n",
      "Medel is training: epoch 75th 31000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.1885 - acc: 0.8383     \n",
      "Medel is training: epoch 75th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3091 - acc: 0.8212     \n",
      "Medel is training: epoch 75th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5536 - acc: 0.7971     \n",
      "Medel is training: epoch 75th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5312 - acc: 0.8046     \n",
      "Medel is training: epoch 75th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0298 - acc: 0.8501     \n",
      "Medel is training: epoch 75th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4816 - acc: 0.8019     \n",
      "Medel is training: epoch 75th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5097 - acc: 0.8047     \n",
      "Medel is training: epoch 75th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4328 - acc: 0.8145     \n",
      "Medel is training: epoch 75th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0633 - acc: 0.8456     \n",
      "Medel is training: epoch 75th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5634 - acc: 0.7943     \n",
      "Medel is training: epoch 75th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4632 - acc: 0.8121     \n",
      "Medel is training: epoch 75th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4831 - acc: 0.8070     \n",
      "Medel is training: epoch 75th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0570 - acc: 0.8456     \n",
      "Medel is training: epoch 75th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5446 - acc: 0.7956     \n",
      "Medel is training: epoch 75th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4996 - acc: 0.8062     \n",
      "Medel is training: epoch 75th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4026 - acc: 0.8151     \n",
      "Medel is training: epoch 75th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0725 - acc: 0.8449     \n",
      "Medel is training: epoch 75th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5401 - acc: 0.7949     \n",
      "Medel is training: epoch 75th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5359 - acc: 0.8005     \n",
      "Medel is training: epoch 75th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1191 - acc: 1.0000\n",
      "Medel is training: epoch 76th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5836 - acc: 0.7962     \n",
      "Medel is training: epoch 76th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3871 - acc: 0.8177     \n",
      "Medel is training: epoch 76th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4007 - acc: 0.8112     \n",
      "Medel is training: epoch 76th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5000 - acc: 0.8083     \n",
      "Medel is training: epoch 76th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2841 - acc: 0.8258     \n",
      "Medel is training: epoch 76th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5407 - acc: 0.8001     \n",
      "Medel is training: epoch 76th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5232 - acc: 0.8044     \n",
      "Medel is training: epoch 76th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2507 - acc: 0.8272     \n",
      "Medel is training: epoch 76th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5535 - acc: 0.7986     \n",
      "Medel is training: epoch 76th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3700 - acc: 0.8193     \n",
      "Medel is training: epoch 76th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4106 - acc: 0.8114     \n",
      "Medel is training: epoch 76th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5434 - acc: 0.8019     \n",
      "Medel is training: epoch 76th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3051 - acc: 0.8251     \n",
      "Medel is training: epoch 76th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5548 - acc: 0.7951     \n",
      "Medel is training: epoch 76th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5106 - acc: 0.8065     \n",
      "Medel is training: epoch 76th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2490 - acc: 0.8295     \n",
      "Medel is training: epoch 76th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5032 - acc: 0.8018     \n",
      "Medel is training: epoch 76th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5158 - acc: 0.8063     \n",
      "Medel is training: epoch 76th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2370 - acc: 0.8308     \n",
      "Medel is training: epoch 76th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5132 - acc: 0.7997     \n",
      "Medel is training: epoch 76th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4859 - acc: 0.8102     \n",
      "Medel is training: epoch 76th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2770 - acc: 0.8279     \n",
      "Medel is training: epoch 76th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4501 - acc: 0.8052     \n",
      "Medel is training: epoch 76th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5322 - acc: 0.8036     \n",
      "Medel is training: epoch 76th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3561 - acc: 0.8216     \n",
      "Medel is training: epoch 76th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2826 - acc: 0.8238     \n",
      "Medel is training: epoch 76th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5679 - acc: 0.7968     \n",
      "Medel is training: epoch 76th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5234 - acc: 0.8059     \n",
      "Medel is training: epoch 76th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0798 - acc: 0.8459     \n",
      "Medel is training: epoch 76th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5510 - acc: 0.7965     \n",
      "Medel is training: epoch 76th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5054 - acc: 0.8061     \n",
      "Medel is training: epoch 76th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1873 - acc: 0.8383     \n",
      "Medel is training: epoch 76th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3074 - acc: 0.8214     \n",
      "Medel is training: epoch 76th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5528 - acc: 0.7972     \n",
      "Medel is training: epoch 76th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5303 - acc: 0.8045     \n",
      "Medel is training: epoch 76th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0295 - acc: 0.8494     \n",
      "Medel is training: epoch 76th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4808 - acc: 0.8017     \n",
      "Medel is training: epoch 76th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5090 - acc: 0.8049     \n",
      "Medel is training: epoch 76th 38000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.4318 - acc: 0.8144     \n",
      "Medel is training: epoch 76th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0629 - acc: 0.8455     \n",
      "Medel is training: epoch 76th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5604 - acc: 0.7942     \n",
      "Medel is training: epoch 76th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4620 - acc: 0.8119     \n",
      "Medel is training: epoch 76th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4828 - acc: 0.8071     \n",
      "Medel is training: epoch 76th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0553 - acc: 0.8460     \n",
      "Medel is training: epoch 76th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5449 - acc: 0.7957     \n",
      "Medel is training: epoch 76th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4988 - acc: 0.8062     \n",
      "Medel is training: epoch 76th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4021 - acc: 0.8154     \n",
      "Medel is training: epoch 76th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0709 - acc: 0.8448     \n",
      "Medel is training: epoch 76th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5383 - acc: 0.7951     \n",
      "Medel is training: epoch 76th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5350 - acc: 0.8006     \n",
      "Medel is training: epoch 76th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1174 - acc: 1.0000\n",
      "Medel is training: epoch 77th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5820 - acc: 0.7963     \n",
      "Medel is training: epoch 77th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3868 - acc: 0.8176     \n",
      "Medel is training: epoch 77th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3993 - acc: 0.8112     \n",
      "Medel is training: epoch 77th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4990 - acc: 0.8083     \n",
      "Medel is training: epoch 77th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2830 - acc: 0.8259     \n",
      "Medel is training: epoch 77th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5400 - acc: 0.7999     \n",
      "Medel is training: epoch 77th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5222 - acc: 0.8044     \n",
      "Medel is training: epoch 77th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2491 - acc: 0.8271     \n",
      "Medel is training: epoch 77th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5518 - acc: 0.7986     \n",
      "Medel is training: epoch 77th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3685 - acc: 0.8192     \n",
      "Medel is training: epoch 77th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4093 - acc: 0.8117     \n",
      "Medel is training: epoch 77th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5421 - acc: 0.8019     \n",
      "Medel is training: epoch 77th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3038 - acc: 0.8252     \n",
      "Medel is training: epoch 77th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5533 - acc: 0.7950     \n",
      "Medel is training: epoch 77th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5098 - acc: 0.8065     \n",
      "Medel is training: epoch 77th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2472 - acc: 0.8296     \n",
      "Medel is training: epoch 77th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5014 - acc: 0.8017     \n",
      "Medel is training: epoch 77th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5151 - acc: 0.8063     \n",
      "Medel is training: epoch 77th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2361 - acc: 0.8310     \n",
      "Medel is training: epoch 77th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5117 - acc: 0.7998     \n",
      "Medel is training: epoch 77th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4847 - acc: 0.8102     \n",
      "Medel is training: epoch 77th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2765 - acc: 0.8277     \n",
      "Medel is training: epoch 77th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4481 - acc: 0.8053     \n",
      "Medel is training: epoch 77th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5313 - acc: 0.8037     \n",
      "Medel is training: epoch 77th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3545 - acc: 0.8219     \n",
      "Medel is training: epoch 77th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2805 - acc: 0.8237     \n",
      "Medel is training: epoch 77th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5670 - acc: 0.7968     \n",
      "Medel is training: epoch 77th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5226 - acc: 0.8059     \n",
      "Medel is training: epoch 77th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0785 - acc: 0.8462     \n",
      "Medel is training: epoch 77th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5494 - acc: 0.7965     \n",
      "Medel is training: epoch 77th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5042 - acc: 0.8061     \n",
      "Medel is training: epoch 77th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1865 - acc: 0.8384     \n",
      "Medel is training: epoch 77th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3057 - acc: 0.8212     \n",
      "Medel is training: epoch 77th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5509 - acc: 0.7970     \n",
      "Medel is training: epoch 77th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5300 - acc: 0.8045     \n",
      "Medel is training: epoch 77th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0274 - acc: 0.8499     \n",
      "Medel is training: epoch 77th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4787 - acc: 0.8024     \n",
      "Medel is training: epoch 77th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5078 - acc: 0.8047     \n",
      "Medel is training: epoch 77th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4316 - acc: 0.8144     \n",
      "Medel is training: epoch 77th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0615 - acc: 0.8457     \n",
      "Medel is training: epoch 77th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5600 - acc: 0.7941     \n",
      "Medel is training: epoch 77th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4613 - acc: 0.8121     \n",
      "Medel is training: epoch 77th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4824 - acc: 0.8071     \n",
      "Medel is training: epoch 77th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0538 - acc: 0.8459     \n",
      "Medel is training: epoch 77th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5425 - acc: 0.7957     \n",
      "Medel is training: epoch 77th 45000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.4975 - acc: 0.8060     \n",
      "Medel is training: epoch 77th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3999 - acc: 0.8151     \n",
      "Medel is training: epoch 77th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0681 - acc: 0.8448     \n",
      "Medel is training: epoch 77th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5379 - acc: 0.7950     \n",
      "Medel is training: epoch 77th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5344 - acc: 0.8004     \n",
      "Medel is training: epoch 77th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1159 - acc: 1.0000\n",
      "Medel is training: epoch 78th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5803 - acc: 0.7962     \n",
      "Medel is training: epoch 78th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3842 - acc: 0.8176     \n",
      "Medel is training: epoch 78th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3982 - acc: 0.8112     \n",
      "Medel is training: epoch 78th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4983 - acc: 0.8083     \n",
      "Medel is training: epoch 78th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2819 - acc: 0.8259     \n",
      "Medel is training: epoch 78th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5385 - acc: 0.8001     \n",
      "Medel is training: epoch 78th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5218 - acc: 0.8044     \n",
      "Medel is training: epoch 78th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2477 - acc: 0.8273     \n",
      "Medel is training: epoch 78th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5510 - acc: 0.7986     \n",
      "Medel is training: epoch 78th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3681 - acc: 0.8192     \n",
      "Medel is training: epoch 78th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4082 - acc: 0.8117     \n",
      "Medel is training: epoch 78th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5418 - acc: 0.8018     \n",
      "Medel is training: epoch 78th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3031 - acc: 0.8252     \n",
      "Medel is training: epoch 78th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5528 - acc: 0.7950     \n",
      "Medel is training: epoch 78th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5094 - acc: 0.8066     \n",
      "Medel is training: epoch 78th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2469 - acc: 0.8296     \n",
      "Medel is training: epoch 78th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5003 - acc: 0.8016     \n",
      "Medel is training: epoch 78th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5142 - acc: 0.8063     \n",
      "Medel is training: epoch 78th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2347 - acc: 0.8311     \n",
      "Medel is training: epoch 78th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5103 - acc: 0.7997     \n",
      "Medel is training: epoch 78th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4839 - acc: 0.8103     \n",
      "Medel is training: epoch 78th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2750 - acc: 0.8279     \n",
      "Medel is training: epoch 78th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4469 - acc: 0.8054     \n",
      "Medel is training: epoch 78th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5303 - acc: 0.8036     \n",
      "Medel is training: epoch 78th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3537 - acc: 0.8218     \n",
      "Medel is training: epoch 78th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2789 - acc: 0.8238     \n",
      "Medel is training: epoch 78th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5654 - acc: 0.7969     \n",
      "Medel is training: epoch 78th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5222 - acc: 0.8060     \n",
      "Medel is training: epoch 78th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0766 - acc: 0.8468     \n",
      "Medel is training: epoch 78th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5479 - acc: 0.7967     \n",
      "Medel is training: epoch 78th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5039 - acc: 0.8061     \n",
      "Medel is training: epoch 78th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1851 - acc: 0.8385     \n",
      "Medel is training: epoch 78th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3045 - acc: 0.8214     \n",
      "Medel is training: epoch 78th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5498 - acc: 0.7973     \n",
      "Medel is training: epoch 78th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5286 - acc: 0.8045     \n",
      "Medel is training: epoch 78th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0263 - acc: 0.8503     \n",
      "Medel is training: epoch 78th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4766 - acc: 0.8022     \n",
      "Medel is training: epoch 78th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5070 - acc: 0.8050     \n",
      "Medel is training: epoch 78th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4302 - acc: 0.8147     \n",
      "Medel is training: epoch 78th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0593 - acc: 0.8462     \n",
      "Medel is training: epoch 78th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5580 - acc: 0.7939     \n",
      "Medel is training: epoch 78th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4596 - acc: 0.8121     \n",
      "Medel is training: epoch 78th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4815 - acc: 0.8071     \n",
      "Medel is training: epoch 78th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0517 - acc: 0.8456     \n",
      "Medel is training: epoch 78th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5411 - acc: 0.7960     \n",
      "Medel is training: epoch 78th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4970 - acc: 0.8063     \n",
      "Medel is training: epoch 78th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3989 - acc: 0.8153     \n",
      "Medel is training: epoch 78th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0669 - acc: 0.8457     \n",
      "Medel is training: epoch 78th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5352 - acc: 0.7953     \n",
      "Medel is training: epoch 78th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5336 - acc: 0.8004     \n",
      "Medel is training: epoch 78th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1141 - acc: 1.0000\n",
      "Medel is training: epoch 79th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5795 - acc: 0.7961     \n",
      "Medel is training: epoch 79th 1000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.3845 - acc: 0.8178     \n",
      "Medel is training: epoch 79th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3968 - acc: 0.8116     \n",
      "Medel is training: epoch 79th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4977 - acc: 0.8083     \n",
      "Medel is training: epoch 79th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2809 - acc: 0.8263     \n",
      "Medel is training: epoch 79th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5375 - acc: 0.8000     \n",
      "Medel is training: epoch 79th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5210 - acc: 0.8044     \n",
      "Medel is training: epoch 79th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2465 - acc: 0.8274     \n",
      "Medel is training: epoch 79th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5497 - acc: 0.7985     \n",
      "Medel is training: epoch 79th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3672 - acc: 0.8192     \n",
      "Medel is training: epoch 79th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4064 - acc: 0.8116     \n",
      "Medel is training: epoch 79th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5408 - acc: 0.8019     \n",
      "Medel is training: epoch 79th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3018 - acc: 0.8252     \n",
      "Medel is training: epoch 79th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5516 - acc: 0.7950     \n",
      "Medel is training: epoch 79th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5089 - acc: 0.8065     \n",
      "Medel is training: epoch 79th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2451 - acc: 0.8298     \n",
      "Medel is training: epoch 79th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4984 - acc: 0.8018     \n",
      "Medel is training: epoch 79th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5132 - acc: 0.8064     \n",
      "Medel is training: epoch 79th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2338 - acc: 0.8311     \n",
      "Medel is training: epoch 79th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5089 - acc: 0.7998     \n",
      "Medel is training: epoch 79th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4832 - acc: 0.8104     \n",
      "Medel is training: epoch 79th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2740 - acc: 0.8280     \n",
      "Medel is training: epoch 79th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4450 - acc: 0.8052     \n",
      "Medel is training: epoch 79th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5297 - acc: 0.8035     \n",
      "Medel is training: epoch 79th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3524 - acc: 0.8219     \n",
      "Medel is training: epoch 79th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2774 - acc: 0.8239     \n",
      "Medel is training: epoch 79th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5638 - acc: 0.7970     \n",
      "Medel is training: epoch 79th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5216 - acc: 0.8060     \n",
      "Medel is training: epoch 79th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0749 - acc: 0.8465     \n",
      "Medel is training: epoch 79th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5475 - acc: 0.7966     \n",
      "Medel is training: epoch 79th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5029 - acc: 0.8061     \n",
      "Medel is training: epoch 79th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1846 - acc: 0.8384     \n",
      "Medel is training: epoch 79th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3025 - acc: 0.8215     \n",
      "Medel is training: epoch 79th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5485 - acc: 0.7971     \n",
      "Medel is training: epoch 79th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5274 - acc: 0.8045     \n",
      "Medel is training: epoch 79th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0248 - acc: 0.8501     \n",
      "Medel is training: epoch 79th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4757 - acc: 0.8021     \n",
      "Medel is training: epoch 79th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5058 - acc: 0.8048     \n",
      "Medel is training: epoch 79th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4297 - acc: 0.8146     \n",
      "Medel is training: epoch 79th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0584 - acc: 0.8455     \n",
      "Medel is training: epoch 79th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5566 - acc: 0.7941     \n",
      "Medel is training: epoch 79th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4596 - acc: 0.8122     \n",
      "Medel is training: epoch 79th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4806 - acc: 0.8071     \n",
      "Medel is training: epoch 79th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0506 - acc: 0.8461     \n",
      "Medel is training: epoch 79th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5388 - acc: 0.7959     \n",
      "Medel is training: epoch 79th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4961 - acc: 0.8062     \n",
      "Medel is training: epoch 79th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3983 - acc: 0.8153     \n",
      "Medel is training: epoch 79th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0650 - acc: 0.8456     \n",
      "Medel is training: epoch 79th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5333 - acc: 0.7951     \n",
      "Medel is training: epoch 79th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5312 - acc: 0.8003     \n",
      "Medel is training: epoch 79th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1127 - acc: 1.0000\n",
      "Medel is training: epoch 80th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5771 - acc: 0.7961     \n",
      "Medel is training: epoch 80th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3838 - acc: 0.8177     \n",
      "Medel is training: epoch 80th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3946 - acc: 0.8116     \n",
      "Medel is training: epoch 80th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4971 - acc: 0.8083     \n",
      "Medel is training: epoch 80th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2808 - acc: 0.8262     \n",
      "Medel is training: epoch 80th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5365 - acc: 0.8000     \n",
      "Medel is training: epoch 80th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5207 - acc: 0.8043     \n",
      "Medel is training: epoch 80th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2446 - acc: 0.8274     \n",
      "Medel is training: epoch 80th 8000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.5490 - acc: 0.7985     \n",
      "Medel is training: epoch 80th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3661 - acc: 0.8193     \n",
      "Medel is training: epoch 80th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4054 - acc: 0.8116     \n",
      "Medel is training: epoch 80th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5400 - acc: 0.8019     \n",
      "Medel is training: epoch 80th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3011 - acc: 0.8253     \n",
      "Medel is training: epoch 80th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5500 - acc: 0.7951     \n",
      "Medel is training: epoch 80th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5079 - acc: 0.8066     \n",
      "Medel is training: epoch 80th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2444 - acc: 0.8297     \n",
      "Medel is training: epoch 80th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4978 - acc: 0.8018     \n",
      "Medel is training: epoch 80th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5127 - acc: 0.8063     \n",
      "Medel is training: epoch 80th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2325 - acc: 0.8311     \n",
      "Medel is training: epoch 80th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5071 - acc: 0.7996     \n",
      "Medel is training: epoch 80th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4821 - acc: 0.8104     \n",
      "Medel is training: epoch 80th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2731 - acc: 0.8278     \n",
      "Medel is training: epoch 80th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4436 - acc: 0.8054     \n",
      "Medel is training: epoch 80th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5284 - acc: 0.8036     \n",
      "Medel is training: epoch 80th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3518 - acc: 0.8218     \n",
      "Medel is training: epoch 80th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2762 - acc: 0.8237     \n",
      "Medel is training: epoch 80th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5626 - acc: 0.7972     \n",
      "Medel is training: epoch 80th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5208 - acc: 0.8060     \n",
      "Medel is training: epoch 80th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0738 - acc: 0.8468     \n",
      "Medel is training: epoch 80th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5449 - acc: 0.7966     \n",
      "Medel is training: epoch 80th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5028 - acc: 0.8061     \n",
      "Medel is training: epoch 80th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1830 - acc: 0.8386     \n",
      "Medel is training: epoch 80th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3027 - acc: 0.8213     \n",
      "Medel is training: epoch 80th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5473 - acc: 0.7972     \n",
      "Medel is training: epoch 80th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5273 - acc: 0.8046     \n",
      "Medel is training: epoch 80th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0228 - acc: 0.8504     \n",
      "Medel is training: epoch 80th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4742 - acc: 0.8022     \n",
      "Medel is training: epoch 80th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5046 - acc: 0.8047     \n",
      "Medel is training: epoch 80th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4298 - acc: 0.8144     \n",
      "Medel is training: epoch 80th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0561 - acc: 0.8459     \n",
      "Medel is training: epoch 80th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5548 - acc: 0.7942     \n",
      "Medel is training: epoch 80th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4581 - acc: 0.8123     \n",
      "Medel is training: epoch 80th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4802 - acc: 0.8072     \n",
      "Medel is training: epoch 80th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0499 - acc: 0.8463     \n",
      "Medel is training: epoch 80th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5375 - acc: 0.7961     \n",
      "Medel is training: epoch 80th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4944 - acc: 0.8063     \n",
      "Medel is training: epoch 80th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3986 - acc: 0.8154     \n",
      "Medel is training: epoch 80th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0629 - acc: 0.8460     \n",
      "Medel is training: epoch 80th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5313 - acc: 0.7949     \n",
      "Medel is training: epoch 80th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5301 - acc: 0.8004     \n",
      "Medel is training: epoch 80th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1111 - acc: 1.0000\n",
      "Medel is training: epoch 81th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5761 - acc: 0.7961     \n",
      "Medel is training: epoch 81th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3814 - acc: 0.8177     \n",
      "Medel is training: epoch 81th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3941 - acc: 0.8115     \n",
      "Medel is training: epoch 81th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4965 - acc: 0.8083     \n",
      "Medel is training: epoch 81th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2787 - acc: 0.8264     \n",
      "Medel is training: epoch 81th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5353 - acc: 0.7999     \n",
      "Medel is training: epoch 81th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5198 - acc: 0.8043     \n",
      "Medel is training: epoch 81th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2431 - acc: 0.8272     \n",
      "Medel is training: epoch 81th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5477 - acc: 0.7986     \n",
      "Medel is training: epoch 81th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3653 - acc: 0.8192     \n",
      "Medel is training: epoch 81th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4042 - acc: 0.8118     \n",
      "Medel is training: epoch 81th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5393 - acc: 0.8019     \n",
      "Medel is training: epoch 81th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3002 - acc: 0.8253     \n",
      "Medel is training: epoch 81th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5488 - acc: 0.7950     \n",
      "Medel is training: epoch 81th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5072 - acc: 0.8066     \n",
      "Medel is training: epoch 81th 15000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.2430 - acc: 0.8299     \n",
      "Medel is training: epoch 81th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4959 - acc: 0.8020     \n",
      "Medel is training: epoch 81th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5121 - acc: 0.8064     \n",
      "Medel is training: epoch 81th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2312 - acc: 0.8312     \n",
      "Medel is training: epoch 81th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5063 - acc: 0.7996     \n",
      "Medel is training: epoch 81th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4815 - acc: 0.8103     \n",
      "Medel is training: epoch 81th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2715 - acc: 0.8281     \n",
      "Medel is training: epoch 81th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4426 - acc: 0.8053     \n",
      "Medel is training: epoch 81th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5281 - acc: 0.8036     \n",
      "Medel is training: epoch 81th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3508 - acc: 0.8219     \n",
      "Medel is training: epoch 81th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2747 - acc: 0.8239     \n",
      "Medel is training: epoch 81th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5624 - acc: 0.7971     \n",
      "Medel is training: epoch 81th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5210 - acc: 0.8061     \n",
      "Medel is training: epoch 81th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0729 - acc: 0.8466     \n",
      "Medel is training: epoch 81th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5441 - acc: 0.7969     \n",
      "Medel is training: epoch 81th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5016 - acc: 0.8062     \n",
      "Medel is training: epoch 81th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1818 - acc: 0.8386     \n",
      "Medel is training: epoch 81th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3001 - acc: 0.8215     \n",
      "Medel is training: epoch 81th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5458 - acc: 0.7973     \n",
      "Medel is training: epoch 81th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5268 - acc: 0.8045     \n",
      "Medel is training: epoch 81th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0217 - acc: 0.8506     \n",
      "Medel is training: epoch 81th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4737 - acc: 0.8021     \n",
      "Medel is training: epoch 81th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5038 - acc: 0.8048     \n",
      "Medel is training: epoch 81th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4280 - acc: 0.8146     \n",
      "Medel is training: epoch 81th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0540 - acc: 0.8468     \n",
      "Medel is training: epoch 81th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5539 - acc: 0.7942     \n",
      "Medel is training: epoch 81th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4568 - acc: 0.8121     \n",
      "Medel is training: epoch 81th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4799 - acc: 0.8072     \n",
      "Medel is training: epoch 81th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0468 - acc: 0.8466     \n",
      "Medel is training: epoch 81th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5362 - acc: 0.7961     \n",
      "Medel is training: epoch 81th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4930 - acc: 0.8063     \n",
      "Medel is training: epoch 81th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3967 - acc: 0.8154     \n",
      "Medel is training: epoch 81th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0610 - acc: 0.8459     \n",
      "Medel is training: epoch 81th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5305 - acc: 0.7949     \n",
      "Medel is training: epoch 81th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5294 - acc: 0.8004     \n",
      "Medel is training: epoch 81th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1094 - acc: 1.0000\n",
      "Medel is training: epoch 82th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5747 - acc: 0.7961     \n",
      "Medel is training: epoch 82th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3823 - acc: 0.8178     \n",
      "Medel is training: epoch 82th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3930 - acc: 0.8117     \n",
      "Medel is training: epoch 82th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4959 - acc: 0.8082     \n",
      "Medel is training: epoch 82th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2778 - acc: 0.8265     \n",
      "Medel is training: epoch 82th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5340 - acc: 0.8000     \n",
      "Medel is training: epoch 82th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5193 - acc: 0.8043     \n",
      "Medel is training: epoch 82th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2421 - acc: 0.8275     \n",
      "Medel is training: epoch 82th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5466 - acc: 0.7987     \n",
      "Medel is training: epoch 82th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3644 - acc: 0.8193     \n",
      "Medel is training: epoch 82th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4028 - acc: 0.8117     \n",
      "Medel is training: epoch 82th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5385 - acc: 0.8020     \n",
      "Medel is training: epoch 82th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2989 - acc: 0.8253     \n",
      "Medel is training: epoch 82th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5471 - acc: 0.7950     \n",
      "Medel is training: epoch 82th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5068 - acc: 0.8066     \n",
      "Medel is training: epoch 82th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2421 - acc: 0.8299     \n",
      "Medel is training: epoch 82th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4952 - acc: 0.8019     \n",
      "Medel is training: epoch 82th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5110 - acc: 0.8062     \n",
      "Medel is training: epoch 82th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2305 - acc: 0.8311     \n",
      "Medel is training: epoch 82th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5050 - acc: 0.7998     \n",
      "Medel is training: epoch 82th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4806 - acc: 0.8103     \n",
      "Medel is training: epoch 82th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2711 - acc: 0.8283     \n",
      "Medel is training: epoch 82th 22000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.4415 - acc: 0.8055     \n",
      "Medel is training: epoch 82th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5266 - acc: 0.8036     \n",
      "Medel is training: epoch 82th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3503 - acc: 0.8219     \n",
      "Medel is training: epoch 82th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2737 - acc: 0.8238     \n",
      "Medel is training: epoch 82th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5605 - acc: 0.7971     \n",
      "Medel is training: epoch 82th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5198 - acc: 0.8060     \n",
      "Medel is training: epoch 82th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0723 - acc: 0.8467     \n",
      "Medel is training: epoch 82th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5419 - acc: 0.7970     \n",
      "Medel is training: epoch 82th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5010 - acc: 0.8061     \n",
      "Medel is training: epoch 82th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1811 - acc: 0.8388     \n",
      "Medel is training: epoch 82th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2985 - acc: 0.8215     \n",
      "Medel is training: epoch 82th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5454 - acc: 0.7972     \n",
      "Medel is training: epoch 82th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5267 - acc: 0.8043     \n",
      "Medel is training: epoch 82th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0203 - acc: 0.8512     \n",
      "Medel is training: epoch 82th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4721 - acc: 0.8021     \n",
      "Medel is training: epoch 82th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5024 - acc: 0.8048     \n",
      "Medel is training: epoch 82th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4271 - acc: 0.8146     \n",
      "Medel is training: epoch 82th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0527 - acc: 0.8467     \n",
      "Medel is training: epoch 82th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5514 - acc: 0.7941     \n",
      "Medel is training: epoch 82th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4555 - acc: 0.8123     \n",
      "Medel is training: epoch 82th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4785 - acc: 0.8071     \n",
      "Medel is training: epoch 82th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0455 - acc: 0.8466     \n",
      "Medel is training: epoch 82th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5347 - acc: 0.7959     \n",
      "Medel is training: epoch 82th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4929 - acc: 0.8063     \n",
      "Medel is training: epoch 82th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3964 - acc: 0.8154     \n",
      "Medel is training: epoch 82th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0596 - acc: 0.8457     \n",
      "Medel is training: epoch 82th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5283 - acc: 0.7950     \n",
      "Medel is training: epoch 82th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5283 - acc: 0.8007     \n",
      "Medel is training: epoch 82th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1079 - acc: 1.0000\n",
      "Medel is training: epoch 83th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5736 - acc: 0.7960     \n",
      "Medel is training: epoch 83th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3804 - acc: 0.8181     \n",
      "Medel is training: epoch 83th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3912 - acc: 0.8117     \n",
      "Medel is training: epoch 83th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4948 - acc: 0.8083     \n",
      "Medel is training: epoch 83th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2772 - acc: 0.8267     \n",
      "Medel is training: epoch 83th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5330 - acc: 0.8001     \n",
      "Medel is training: epoch 83th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5187 - acc: 0.8043     \n",
      "Medel is training: epoch 83th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2409 - acc: 0.8273     \n",
      "Medel is training: epoch 83th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5456 - acc: 0.7987     \n",
      "Medel is training: epoch 83th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3638 - acc: 0.8193     \n",
      "Medel is training: epoch 83th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4018 - acc: 0.8118     \n",
      "Medel is training: epoch 83th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5373 - acc: 0.8019     \n",
      "Medel is training: epoch 83th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2979 - acc: 0.8253     \n",
      "Medel is training: epoch 83th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5463 - acc: 0.7951     \n",
      "Medel is training: epoch 83th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5059 - acc: 0.8066     \n",
      "Medel is training: epoch 83th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2411 - acc: 0.8300     \n",
      "Medel is training: epoch 83th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4925 - acc: 0.8020     \n",
      "Medel is training: epoch 83th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5101 - acc: 0.8062     \n",
      "Medel is training: epoch 83th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2290 - acc: 0.8312     \n",
      "Medel is training: epoch 83th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5038 - acc: 0.7994     \n",
      "Medel is training: epoch 83th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4794 - acc: 0.8104     \n",
      "Medel is training: epoch 83th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2695 - acc: 0.8283     \n",
      "Medel is training: epoch 83th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4393 - acc: 0.8054     \n",
      "Medel is training: epoch 83th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5256 - acc: 0.8035     \n",
      "Medel is training: epoch 83th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3490 - acc: 0.8218     \n",
      "Medel is training: epoch 83th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2718 - acc: 0.8242     \n",
      "Medel is training: epoch 83th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5599 - acc: 0.7970     \n",
      "Medel is training: epoch 83th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5194 - acc: 0.8062     \n",
      "Medel is training: epoch 83th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0704 - acc: 0.8474     \n",
      "Medel is training: epoch 83th 29000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.5406 - acc: 0.7970     \n",
      "Medel is training: epoch 83th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5002 - acc: 0.8061     \n",
      "Medel is training: epoch 83th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1800 - acc: 0.8387     \n",
      "Medel is training: epoch 83th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2976 - acc: 0.8218     \n",
      "Medel is training: epoch 83th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5441 - acc: 0.7970     \n",
      "Medel is training: epoch 83th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5258 - acc: 0.8046     \n",
      "Medel is training: epoch 83th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0183 - acc: 0.8504     \n",
      "Medel is training: epoch 83th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4701 - acc: 0.8023     \n",
      "Medel is training: epoch 83th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5017 - acc: 0.8048     \n",
      "Medel is training: epoch 83th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4264 - acc: 0.8147     \n",
      "Medel is training: epoch 83th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0513 - acc: 0.8469     \n",
      "Medel is training: epoch 83th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5501 - acc: 0.7942     \n",
      "Medel is training: epoch 83th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4554 - acc: 0.8123     \n",
      "Medel is training: epoch 83th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4782 - acc: 0.8072     \n",
      "Medel is training: epoch 83th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0440 - acc: 0.8467     \n",
      "Medel is training: epoch 83th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5332 - acc: 0.7963     \n",
      "Medel is training: epoch 83th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4913 - acc: 0.8064     \n",
      "Medel is training: epoch 83th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3959 - acc: 0.8154     \n",
      "Medel is training: epoch 83th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0587 - acc: 0.8456     \n",
      "Medel is training: epoch 83th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5283 - acc: 0.7951     \n",
      "Medel is training: epoch 83th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5271 - acc: 0.8006     \n",
      "Medel is training: epoch 83th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1062 - acc: 1.0000\n",
      "Medel is training: epoch 84th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5724 - acc: 0.7962     \n",
      "Medel is training: epoch 84th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3812 - acc: 0.8177     \n",
      "Medel is training: epoch 84th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3894 - acc: 0.8117     \n",
      "Medel is training: epoch 84th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4945 - acc: 0.8083     \n",
      "Medel is training: epoch 84th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2757 - acc: 0.8264     \n",
      "Medel is training: epoch 84th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5318 - acc: 0.7999     \n",
      "Medel is training: epoch 84th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5180 - acc: 0.8044     \n",
      "Medel is training: epoch 84th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2392 - acc: 0.8275     \n",
      "Medel is training: epoch 84th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5449 - acc: 0.7987     \n",
      "Medel is training: epoch 84th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3625 - acc: 0.8195     \n",
      "Medel is training: epoch 84th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4000 - acc: 0.8119     \n",
      "Medel is training: epoch 84th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5370 - acc: 0.8020     \n",
      "Medel is training: epoch 84th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2966 - acc: 0.8256     \n",
      "Medel is training: epoch 84th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5448 - acc: 0.7952     \n",
      "Medel is training: epoch 84th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5054 - acc: 0.8066     \n",
      "Medel is training: epoch 84th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2396 - acc: 0.8301     \n",
      "Medel is training: epoch 84th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4916 - acc: 0.8022     \n",
      "Medel is training: epoch 84th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5095 - acc: 0.8062     \n",
      "Medel is training: epoch 84th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2284 - acc: 0.8310     \n",
      "Medel is training: epoch 84th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5023 - acc: 0.7997     \n",
      "Medel is training: epoch 84th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4788 - acc: 0.8103     \n",
      "Medel is training: epoch 84th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2689 - acc: 0.8283     \n",
      "Medel is training: epoch 84th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4386 - acc: 0.8054     \n",
      "Medel is training: epoch 84th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5255 - acc: 0.8035     \n",
      "Medel is training: epoch 84th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3477 - acc: 0.8221     \n",
      "Medel is training: epoch 84th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2707 - acc: 0.8242     \n",
      "Medel is training: epoch 84th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5585 - acc: 0.7970     \n",
      "Medel is training: epoch 84th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5185 - acc: 0.8060     \n",
      "Medel is training: epoch 84th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0674 - acc: 0.8471     \n",
      "Medel is training: epoch 84th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5395 - acc: 0.7965     \n",
      "Medel is training: epoch 84th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4989 - acc: 0.8061     \n",
      "Medel is training: epoch 84th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1789 - acc: 0.8385     \n",
      "Medel is training: epoch 84th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2959 - acc: 0.8219     \n",
      "Medel is training: epoch 84th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5429 - acc: 0.7973     \n",
      "Medel is training: epoch 84th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5245 - acc: 0.8046     \n",
      "Medel is training: epoch 84th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0177 - acc: 0.8504     \n",
      "Medel is training: epoch 84th 36000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.4687 - acc: 0.8024     \n",
      "Medel is training: epoch 84th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5002 - acc: 0.8046     \n",
      "Medel is training: epoch 84th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4253 - acc: 0.8150     \n",
      "Medel is training: epoch 84th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0496 - acc: 0.8469     \n",
      "Medel is training: epoch 84th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5484 - acc: 0.7942     \n",
      "Medel is training: epoch 84th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4539 - acc: 0.8124     \n",
      "Medel is training: epoch 84th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4771 - acc: 0.8072     \n",
      "Medel is training: epoch 84th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0415 - acc: 0.8468     \n",
      "Medel is training: epoch 84th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5321 - acc: 0.7962     \n",
      "Medel is training: epoch 84th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4901 - acc: 0.8063     \n",
      "Medel is training: epoch 84th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3953 - acc: 0.8156     \n",
      "Medel is training: epoch 84th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0552 - acc: 0.8458     \n",
      "Medel is training: epoch 84th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5253 - acc: 0.7947     \n",
      "Medel is training: epoch 84th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5262 - acc: 0.8006     \n",
      "Medel is training: epoch 84th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1049 - acc: 1.0000\n",
      "Medel is training: epoch 85th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5718 - acc: 0.7963     \n",
      "Medel is training: epoch 85th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3796 - acc: 0.8179     \n",
      "Medel is training: epoch 85th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3881 - acc: 0.8116     \n",
      "Medel is training: epoch 85th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4938 - acc: 0.8084     \n",
      "Medel is training: epoch 85th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2744 - acc: 0.8264     \n",
      "Medel is training: epoch 85th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5307 - acc: 0.8000     \n",
      "Medel is training: epoch 85th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5171 - acc: 0.8043     \n",
      "Medel is training: epoch 85th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2378 - acc: 0.8276     \n",
      "Medel is training: epoch 85th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5435 - acc: 0.7987     \n",
      "Medel is training: epoch 85th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3619 - acc: 0.8194     \n",
      "Medel is training: epoch 85th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3989 - acc: 0.8121     \n",
      "Medel is training: epoch 85th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5360 - acc: 0.8019     \n",
      "Medel is training: epoch 85th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2958 - acc: 0.8254     \n",
      "Medel is training: epoch 85th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5440 - acc: 0.7950     \n",
      "Medel is training: epoch 85th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5046 - acc: 0.8066     \n",
      "Medel is training: epoch 85th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2384 - acc: 0.8299     \n",
      "Medel is training: epoch 85th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4903 - acc: 0.8021     \n",
      "Medel is training: epoch 85th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5087 - acc: 0.8063     \n",
      "Medel is training: epoch 85th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2272 - acc: 0.8312     \n",
      "Medel is training: epoch 85th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5007 - acc: 0.7998     \n",
      "Medel is training: epoch 85th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4778 - acc: 0.8106     \n",
      "Medel is training: epoch 85th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2677 - acc: 0.8283     \n",
      "Medel is training: epoch 85th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4366 - acc: 0.8055     \n",
      "Medel is training: epoch 85th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5247 - acc: 0.8034     \n",
      "Medel is training: epoch 85th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3475 - acc: 0.8222     \n",
      "Medel is training: epoch 85th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2696 - acc: 0.8236     \n",
      "Medel is training: epoch 85th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5578 - acc: 0.7969     \n",
      "Medel is training: epoch 85th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5174 - acc: 0.8061     \n",
      "Medel is training: epoch 85th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0666 - acc: 0.8476     \n",
      "Medel is training: epoch 85th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5376 - acc: 0.7968     \n",
      "Medel is training: epoch 85th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4987 - acc: 0.8063     \n",
      "Medel is training: epoch 85th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1781 - acc: 0.8389     \n",
      "Medel is training: epoch 85th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2947 - acc: 0.8223     \n",
      "Medel is training: epoch 85th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5417 - acc: 0.7972     \n",
      "Medel is training: epoch 85th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5240 - acc: 0.8046     \n",
      "Medel is training: epoch 85th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0162 - acc: 0.8511     \n",
      "Medel is training: epoch 85th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4671 - acc: 0.8023     \n",
      "Medel is training: epoch 85th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5001 - acc: 0.8049     \n",
      "Medel is training: epoch 85th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4248 - acc: 0.8147     \n",
      "Medel is training: epoch 85th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0478 - acc: 0.8469     \n",
      "Medel is training: epoch 85th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5473 - acc: 0.7942     \n",
      "Medel is training: epoch 85th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4532 - acc: 0.8123     \n",
      "Medel is training: epoch 85th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4768 - acc: 0.8073     \n",
      "Medel is training: epoch 85th 43000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.0404 - acc: 0.8471     \n",
      "Medel is training: epoch 85th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5317 - acc: 0.7963     \n",
      "Medel is training: epoch 85th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4896 - acc: 0.8062     \n",
      "Medel is training: epoch 85th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3946 - acc: 0.8156     \n",
      "Medel is training: epoch 85th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0546 - acc: 0.8462     \n",
      "Medel is training: epoch 85th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5241 - acc: 0.7949     \n",
      "Medel is training: epoch 85th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5246 - acc: 0.8005     \n",
      "Medel is training: epoch 85th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1031 - acc: 1.0000\n",
      "Medel is training: epoch 86th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5716 - acc: 0.7961     \n",
      "Medel is training: epoch 86th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3790 - acc: 0.8179     \n",
      "Medel is training: epoch 86th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3884 - acc: 0.8116     \n",
      "Medel is training: epoch 86th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4932 - acc: 0.8084     \n",
      "Medel is training: epoch 86th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2738 - acc: 0.8265     \n",
      "Medel is training: epoch 86th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5297 - acc: 0.8001     \n",
      "Medel is training: epoch 86th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5166 - acc: 0.8042     \n",
      "Medel is training: epoch 86th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2373 - acc: 0.8274     \n",
      "Medel is training: epoch 86th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5423 - acc: 0.7987     \n",
      "Medel is training: epoch 86th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3618 - acc: 0.8194     \n",
      "Medel is training: epoch 86th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3976 - acc: 0.8119     \n",
      "Medel is training: epoch 86th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5351 - acc: 0.8021     \n",
      "Medel is training: epoch 86th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2954 - acc: 0.8257     \n",
      "Medel is training: epoch 86th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5422 - acc: 0.7951     \n",
      "Medel is training: epoch 86th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5033 - acc: 0.8066     \n",
      "Medel is training: epoch 86th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2376 - acc: 0.8299     \n",
      "Medel is training: epoch 86th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4884 - acc: 0.8023     \n",
      "Medel is training: epoch 86th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5079 - acc: 0.8063     \n",
      "Medel is training: epoch 86th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2262 - acc: 0.8310     \n",
      "Medel is training: epoch 86th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4995 - acc: 0.7998     \n",
      "Medel is training: epoch 86th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4773 - acc: 0.8104     \n",
      "Medel is training: epoch 86th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2669 - acc: 0.8284     \n",
      "Medel is training: epoch 86th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4356 - acc: 0.8056     \n",
      "Medel is training: epoch 86th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5232 - acc: 0.8036     \n",
      "Medel is training: epoch 86th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3469 - acc: 0.8221     \n",
      "Medel is training: epoch 86th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2678 - acc: 0.8237     \n",
      "Medel is training: epoch 86th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5557 - acc: 0.7970     \n",
      "Medel is training: epoch 86th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5172 - acc: 0.8063     \n",
      "Medel is training: epoch 86th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0637 - acc: 0.8476     \n",
      "Medel is training: epoch 86th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5357 - acc: 0.7968     \n",
      "Medel is training: epoch 86th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4974 - acc: 0.8063     \n",
      "Medel is training: epoch 86th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1771 - acc: 0.8388     \n",
      "Medel is training: epoch 86th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2930 - acc: 0.8218     \n",
      "Medel is training: epoch 86th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5409 - acc: 0.7971     \n",
      "Medel is training: epoch 86th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5230 - acc: 0.8047     \n",
      "Medel is training: epoch 86th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0145 - acc: 0.8509     \n",
      "Medel is training: epoch 86th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4662 - acc: 0.8022     \n",
      "Medel is training: epoch 86th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4987 - acc: 0.8047     \n",
      "Medel is training: epoch 86th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4239 - acc: 0.8147     \n",
      "Medel is training: epoch 86th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0469 - acc: 0.8466     \n",
      "Medel is training: epoch 86th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5469 - acc: 0.7943     \n",
      "Medel is training: epoch 86th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4513 - acc: 0.8122     \n",
      "Medel is training: epoch 86th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4756 - acc: 0.8072     \n",
      "Medel is training: epoch 86th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0400 - acc: 0.8471     \n",
      "Medel is training: epoch 86th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5293 - acc: 0.7962     \n",
      "Medel is training: epoch 86th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4885 - acc: 0.8065     \n",
      "Medel is training: epoch 86th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3929 - acc: 0.8158     \n",
      "Medel is training: epoch 86th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0533 - acc: 0.8462     \n",
      "Medel is training: epoch 86th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5226 - acc: 0.7950     \n",
      "Medel is training: epoch 86th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5233 - acc: 0.8007     \n",
      "Medel is training: epoch 86th 50000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s - loss: 0.1016 - acc: 1.0000\n",
      "Medel is training: epoch 87th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5693 - acc: 0.7962     \n",
      "Medel is training: epoch 87th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3789 - acc: 0.8180     \n",
      "Medel is training: epoch 87th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3852 - acc: 0.8119     \n",
      "Medel is training: epoch 87th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4916 - acc: 0.8085     \n",
      "Medel is training: epoch 87th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2728 - acc: 0.8266     \n",
      "Medel is training: epoch 87th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5291 - acc: 0.8001     \n",
      "Medel is training: epoch 87th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5163 - acc: 0.8042     \n",
      "Medel is training: epoch 87th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2349 - acc: 0.8277     \n",
      "Medel is training: epoch 87th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5415 - acc: 0.7985     \n",
      "Medel is training: epoch 87th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3605 - acc: 0.8194     \n",
      "Medel is training: epoch 87th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3964 - acc: 0.8119     \n",
      "Medel is training: epoch 87th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5345 - acc: 0.8021     \n",
      "Medel is training: epoch 87th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2943 - acc: 0.8256     \n",
      "Medel is training: epoch 87th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5411 - acc: 0.7953     \n",
      "Medel is training: epoch 87th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5029 - acc: 0.8066     \n",
      "Medel is training: epoch 87th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2368 - acc: 0.8302     \n",
      "Medel is training: epoch 87th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4871 - acc: 0.8020     \n",
      "Medel is training: epoch 87th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5072 - acc: 0.8063     \n",
      "Medel is training: epoch 87th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2253 - acc: 0.8311     \n",
      "Medel is training: epoch 87th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4987 - acc: 0.7999     \n",
      "Medel is training: epoch 87th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4764 - acc: 0.8104     \n",
      "Medel is training: epoch 87th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2659 - acc: 0.8285     \n",
      "Medel is training: epoch 87th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4343 - acc: 0.8058     \n",
      "Medel is training: epoch 87th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5227 - acc: 0.8035     \n",
      "Medel is training: epoch 87th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3459 - acc: 0.8221     \n",
      "Medel is training: epoch 87th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2664 - acc: 0.8239     \n",
      "Medel is training: epoch 87th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5549 - acc: 0.7969     \n",
      "Medel is training: epoch 87th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5166 - acc: 0.8062     \n",
      "Medel is training: epoch 87th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0630 - acc: 0.8477     \n",
      "Medel is training: epoch 87th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5343 - acc: 0.7968     \n",
      "Medel is training: epoch 87th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4970 - acc: 0.8061     \n",
      "Medel is training: epoch 87th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1755 - acc: 0.8391     \n",
      "Medel is training: epoch 87th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2910 - acc: 0.8219     \n",
      "Medel is training: epoch 87th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5395 - acc: 0.7972     \n",
      "Medel is training: epoch 87th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5223 - acc: 0.8046     \n",
      "Medel is training: epoch 87th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0139 - acc: 0.8513     \n",
      "Medel is training: epoch 87th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4648 - acc: 0.8023     \n",
      "Medel is training: epoch 87th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4972 - acc: 0.8050     \n",
      "Medel is training: epoch 87th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4227 - acc: 0.8147     \n",
      "Medel is training: epoch 87th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0441 - acc: 0.8471     \n",
      "Medel is training: epoch 87th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5454 - acc: 0.7941     \n",
      "Medel is training: epoch 87th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4510 - acc: 0.8122     \n",
      "Medel is training: epoch 87th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4750 - acc: 0.8073     \n",
      "Medel is training: epoch 87th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0382 - acc: 0.8474     \n",
      "Medel is training: epoch 87th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5283 - acc: 0.7965     \n",
      "Medel is training: epoch 87th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4876 - acc: 0.8064     \n",
      "Medel is training: epoch 87th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3921 - acc: 0.8156     \n",
      "Medel is training: epoch 87th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0504 - acc: 0.8467     \n",
      "Medel is training: epoch 87th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5210 - acc: 0.7949     \n",
      "Medel is training: epoch 87th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5224 - acc: 0.8006     \n",
      "Medel is training: epoch 87th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.1001 - acc: 1.0000\n",
      "Medel is training: epoch 88th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5678 - acc: 0.7962     \n",
      "Medel is training: epoch 88th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3773 - acc: 0.8179     \n",
      "Medel is training: epoch 88th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3851 - acc: 0.8119     \n",
      "Medel is training: epoch 88th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4915 - acc: 0.8084     \n",
      "Medel is training: epoch 88th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2711 - acc: 0.8268     \n",
      "Medel is training: epoch 88th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5273 - acc: 0.8003     \n",
      "Medel is training: epoch 88th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5151 - acc: 0.8043     \n",
      "Medel is training: epoch 88th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2338 - acc: 0.8277     \n",
      "Medel is training: epoch 88th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5404 - acc: 0.7987     \n",
      "Medel is training: epoch 88th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3594 - acc: 0.8194     \n",
      "Medel is training: epoch 88th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3950 - acc: 0.8122     \n",
      "Medel is training: epoch 88th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5337 - acc: 0.8021     \n",
      "Medel is training: epoch 88th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2931 - acc: 0.8259     \n",
      "Medel is training: epoch 88th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5405 - acc: 0.7950     \n",
      "Medel is training: epoch 88th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5025 - acc: 0.8067     \n",
      "Medel is training: epoch 88th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2356 - acc: 0.8301     \n",
      "Medel is training: epoch 88th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4856 - acc: 0.8022     \n",
      "Medel is training: epoch 88th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5061 - acc: 0.8065     \n",
      "Medel is training: epoch 88th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2241 - acc: 0.8314     \n",
      "Medel is training: epoch 88th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4966 - acc: 0.7998     \n",
      "Medel is training: epoch 88th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4754 - acc: 0.8104     \n",
      "Medel is training: epoch 88th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2648 - acc: 0.8284     \n",
      "Medel is training: epoch 88th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4330 - acc: 0.8058     \n",
      "Medel is training: epoch 88th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5216 - acc: 0.8035     \n",
      "Medel is training: epoch 88th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3449 - acc: 0.8223     \n",
      "Medel is training: epoch 88th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2647 - acc: 0.8241     \n",
      "Medel is training: epoch 88th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5535 - acc: 0.7969     \n",
      "Medel is training: epoch 88th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5155 - acc: 0.8062     \n",
      "Medel is training: epoch 88th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0607 - acc: 0.8478     \n",
      "Medel is training: epoch 88th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5334 - acc: 0.7971     \n",
      "Medel is training: epoch 88th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4956 - acc: 0.8062     \n",
      "Medel is training: epoch 88th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1747 - acc: 0.8389     \n",
      "Medel is training: epoch 88th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2894 - acc: 0.8219     \n",
      "Medel is training: epoch 88th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5383 - acc: 0.7971     \n",
      "Medel is training: epoch 88th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5216 - acc: 0.8045     \n",
      "Medel is training: epoch 88th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0114 - acc: 0.8514     \n",
      "Medel is training: epoch 88th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4628 - acc: 0.8022     \n",
      "Medel is training: epoch 88th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4960 - acc: 0.8049     \n",
      "Medel is training: epoch 88th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4220 - acc: 0.8144     \n",
      "Medel is training: epoch 88th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0426 - acc: 0.8470     \n",
      "Medel is training: epoch 88th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5422 - acc: 0.7942     \n",
      "Medel is training: epoch 88th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4500 - acc: 0.8121     \n",
      "Medel is training: epoch 88th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4743 - acc: 0.8076     \n",
      "Medel is training: epoch 88th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0351 - acc: 0.8475     \n",
      "Medel is training: epoch 88th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5260 - acc: 0.7961     \n",
      "Medel is training: epoch 88th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4861 - acc: 0.8065     \n",
      "Medel is training: epoch 88th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3922 - acc: 0.8157     \n",
      "Medel is training: epoch 88th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0500 - acc: 0.8466     \n",
      "Medel is training: epoch 88th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5208 - acc: 0.7950     \n",
      "Medel is training: epoch 88th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5221 - acc: 0.8003     \n",
      "Medel is training: epoch 88th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0986 - acc: 1.0000\n",
      "Medel is training: epoch 89th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5670 - acc: 0.7960     \n",
      "Medel is training: epoch 89th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3757 - acc: 0.8178     \n",
      "Medel is training: epoch 89th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3841 - acc: 0.8118     \n",
      "Medel is training: epoch 89th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4901 - acc: 0.8084     \n",
      "Medel is training: epoch 89th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2704 - acc: 0.8268     \n",
      "Medel is training: epoch 89th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5264 - acc: 0.8002     \n",
      "Medel is training: epoch 89th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5146 - acc: 0.8044     \n",
      "Medel is training: epoch 89th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2325 - acc: 0.8276     \n",
      "Medel is training: epoch 89th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5392 - acc: 0.7987     \n",
      "Medel is training: epoch 89th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3587 - acc: 0.8194     \n",
      "Medel is training: epoch 89th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3935 - acc: 0.8122     \n",
      "Medel is training: epoch 89th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5323 - acc: 0.8021     \n",
      "Medel is training: epoch 89th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2922 - acc: 0.8258     \n",
      "Medel is training: epoch 89th 13000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.5382 - acc: 0.7953     \n",
      "Medel is training: epoch 89th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5020 - acc: 0.8065     \n",
      "Medel is training: epoch 89th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2345 - acc: 0.8303     \n",
      "Medel is training: epoch 89th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4849 - acc: 0.8021     \n",
      "Medel is training: epoch 89th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5053 - acc: 0.8063     \n",
      "Medel is training: epoch 89th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2228 - acc: 0.8312     \n",
      "Medel is training: epoch 89th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4953 - acc: 0.7999     \n",
      "Medel is training: epoch 89th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4748 - acc: 0.8106     \n",
      "Medel is training: epoch 89th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2640 - acc: 0.8286     \n",
      "Medel is training: epoch 89th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4314 - acc: 0.8055     \n",
      "Medel is training: epoch 89th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5205 - acc: 0.8034     \n",
      "Medel is training: epoch 89th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3438 - acc: 0.8222     \n",
      "Medel is training: epoch 89th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2632 - acc: 0.8239     \n",
      "Medel is training: epoch 89th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5524 - acc: 0.7971     \n",
      "Medel is training: epoch 89th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5151 - acc: 0.8061     \n",
      "Medel is training: epoch 89th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0608 - acc: 0.8476     \n",
      "Medel is training: epoch 89th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5320 - acc: 0.7967     \n",
      "Medel is training: epoch 89th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4954 - acc: 0.8061     \n",
      "Medel is training: epoch 89th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1742 - acc: 0.8389     \n",
      "Medel is training: epoch 89th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2888 - acc: 0.8221     \n",
      "Medel is training: epoch 89th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5376 - acc: 0.7969     \n",
      "Medel is training: epoch 89th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5212 - acc: 0.8046     \n",
      "Medel is training: epoch 89th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0108 - acc: 0.8512     \n",
      "Medel is training: epoch 89th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4615 - acc: 0.8025     \n",
      "Medel is training: epoch 89th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4948 - acc: 0.8049     \n",
      "Medel is training: epoch 89th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4212 - acc: 0.8146     \n",
      "Medel is training: epoch 89th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0427 - acc: 0.8471     \n",
      "Medel is training: epoch 89th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5420 - acc: 0.7943     \n",
      "Medel is training: epoch 89th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4498 - acc: 0.8122     \n",
      "Medel is training: epoch 89th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4737 - acc: 0.8075     \n",
      "Medel is training: epoch 89th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0363 - acc: 0.8469     \n",
      "Medel is training: epoch 89th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5259 - acc: 0.7963     \n",
      "Medel is training: epoch 89th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4866 - acc: 0.8064     \n",
      "Medel is training: epoch 89th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3913 - acc: 0.8157     \n",
      "Medel is training: epoch 89th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0496 - acc: 0.8464     \n",
      "Medel is training: epoch 89th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5190 - acc: 0.7950     \n",
      "Medel is training: epoch 89th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5205 - acc: 0.8006     \n",
      "Medel is training: epoch 89th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0970 - acc: 1.0000\n",
      "Medel is training: epoch 90th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5662 - acc: 0.7960     \n",
      "Medel is training: epoch 90th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3741 - acc: 0.8179     \n",
      "Medel is training: epoch 90th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3827 - acc: 0.8116     \n",
      "Medel is training: epoch 90th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4893 - acc: 0.8085     \n",
      "Medel is training: epoch 90th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2693 - acc: 0.8269     \n",
      "Medel is training: epoch 90th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5251 - acc: 0.8004     \n",
      "Medel is training: epoch 90th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5138 - acc: 0.8044     \n",
      "Medel is training: epoch 90th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2311 - acc: 0.8272     \n",
      "Medel is training: epoch 90th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5390 - acc: 0.7988     \n",
      "Medel is training: epoch 90th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3578 - acc: 0.8193     \n",
      "Medel is training: epoch 90th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3923 - acc: 0.8122     \n",
      "Medel is training: epoch 90th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5315 - acc: 0.8021     \n",
      "Medel is training: epoch 90th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2915 - acc: 0.8261     \n",
      "Medel is training: epoch 90th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5369 - acc: 0.7954     \n",
      "Medel is training: epoch 90th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5010 - acc: 0.8066     \n",
      "Medel is training: epoch 90th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2335 - acc: 0.8302     \n",
      "Medel is training: epoch 90th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4832 - acc: 0.8021     \n",
      "Medel is training: epoch 90th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5044 - acc: 0.8064     \n",
      "Medel is training: epoch 90th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2216 - acc: 0.8315     \n",
      "Medel is training: epoch 90th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4939 - acc: 0.8000     \n",
      "Medel is training: epoch 90th 20000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.4737 - acc: 0.8105     \n",
      "Medel is training: epoch 90th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2633 - acc: 0.8287     \n",
      "Medel is training: epoch 90th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4297 - acc: 0.8056     \n",
      "Medel is training: epoch 90th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5199 - acc: 0.8034     \n",
      "Medel is training: epoch 90th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3437 - acc: 0.8221     \n",
      "Medel is training: epoch 90th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2620 - acc: 0.8243     \n",
      "Medel is training: epoch 90th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5511 - acc: 0.7970     \n",
      "Medel is training: epoch 90th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5139 - acc: 0.8064     \n",
      "Medel is training: epoch 90th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0585 - acc: 0.8478     \n",
      "Medel is training: epoch 90th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5304 - acc: 0.7968     \n",
      "Medel is training: epoch 90th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4945 - acc: 0.8062     \n",
      "Medel is training: epoch 90th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1728 - acc: 0.8391     \n",
      "Medel is training: epoch 90th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2868 - acc: 0.8223     \n",
      "Medel is training: epoch 90th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5362 - acc: 0.7972     \n",
      "Medel is training: epoch 90th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5203 - acc: 0.8046     \n",
      "Medel is training: epoch 90th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0082 - acc: 0.8513     \n",
      "Medel is training: epoch 90th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4602 - acc: 0.8023     \n",
      "Medel is training: epoch 90th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4936 - acc: 0.8050     \n",
      "Medel is training: epoch 90th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4201 - acc: 0.8148     \n",
      "Medel is training: epoch 90th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0403 - acc: 0.8472     \n",
      "Medel is training: epoch 90th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5403 - acc: 0.7944     \n",
      "Medel is training: epoch 90th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4479 - acc: 0.8121     \n",
      "Medel is training: epoch 90th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4728 - acc: 0.8077     \n",
      "Medel is training: epoch 90th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0325 - acc: 0.8472     \n",
      "Medel is training: epoch 90th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5241 - acc: 0.7961     \n",
      "Medel is training: epoch 90th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4850 - acc: 0.8065     \n",
      "Medel is training: epoch 90th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3906 - acc: 0.8158     \n",
      "Medel is training: epoch 90th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0473 - acc: 0.8465     \n",
      "Medel is training: epoch 90th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5174 - acc: 0.7951     \n",
      "Medel is training: epoch 90th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5188 - acc: 0.8006     \n",
      "Medel is training: epoch 90th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0953 - acc: 1.0000\n",
      "Medel is training: epoch 91th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5657 - acc: 0.7960     \n",
      "Medel is training: epoch 91th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3729 - acc: 0.8179     \n",
      "Medel is training: epoch 91th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3808 - acc: 0.8119     \n",
      "Medel is training: epoch 91th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4880 - acc: 0.8086     \n",
      "Medel is training: epoch 91th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2684 - acc: 0.8268     \n",
      "Medel is training: epoch 91th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5247 - acc: 0.8004     \n",
      "Medel is training: epoch 91th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5138 - acc: 0.8046     \n",
      "Medel is training: epoch 91th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2292 - acc: 0.8276     \n",
      "Medel is training: epoch 91th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5375 - acc: 0.7990     \n",
      "Medel is training: epoch 91th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3571 - acc: 0.8194     \n",
      "Medel is training: epoch 91th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3911 - acc: 0.8121     \n",
      "Medel is training: epoch 91th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5305 - acc: 0.8023     \n",
      "Medel is training: epoch 91th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2905 - acc: 0.8259     \n",
      "Medel is training: epoch 91th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5356 - acc: 0.7953     \n",
      "Medel is training: epoch 91th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5000 - acc: 0.8064     \n",
      "Medel is training: epoch 91th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2326 - acc: 0.8303     \n",
      "Medel is training: epoch 91th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4821 - acc: 0.8023     \n",
      "Medel is training: epoch 91th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5036 - acc: 0.8064     \n",
      "Medel is training: epoch 91th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2209 - acc: 0.8312     \n",
      "Medel is training: epoch 91th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4924 - acc: 0.8002     \n",
      "Medel is training: epoch 91th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4731 - acc: 0.8104     \n",
      "Medel is training: epoch 91th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2617 - acc: 0.8288     \n",
      "Medel is training: epoch 91th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4287 - acc: 0.8055     \n",
      "Medel is training: epoch 91th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5193 - acc: 0.8036     \n",
      "Medel is training: epoch 91th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3424 - acc: 0.8222     \n",
      "Medel is training: epoch 91th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2608 - acc: 0.8239     \n",
      "Medel is training: epoch 91th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5506 - acc: 0.7970     \n",
      "Medel is training: epoch 91th 27000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.5134 - acc: 0.8063     \n",
      "Medel is training: epoch 91th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0573 - acc: 0.8481     \n",
      "Medel is training: epoch 91th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5301 - acc: 0.7971     \n",
      "Medel is training: epoch 91th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4941 - acc: 0.8061     \n",
      "Medel is training: epoch 91th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1721 - acc: 0.8390     \n",
      "Medel is training: epoch 91th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2863 - acc: 0.8226     \n",
      "Medel is training: epoch 91th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5350 - acc: 0.7971     \n",
      "Medel is training: epoch 91th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5200 - acc: 0.8045     \n",
      "Medel is training: epoch 91th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0078 - acc: 0.8517     \n",
      "Medel is training: epoch 91th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4590 - acc: 0.8022     \n",
      "Medel is training: epoch 91th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4929 - acc: 0.8049     \n",
      "Medel is training: epoch 91th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4194 - acc: 0.8145     \n",
      "Medel is training: epoch 91th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0390 - acc: 0.8473     \n",
      "Medel is training: epoch 91th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5386 - acc: 0.7942     \n",
      "Medel is training: epoch 91th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4476 - acc: 0.8121     \n",
      "Medel is training: epoch 91th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4724 - acc: 0.8075     \n",
      "Medel is training: epoch 91th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0322 - acc: 0.8476     \n",
      "Medel is training: epoch 91th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5242 - acc: 0.7963     \n",
      "Medel is training: epoch 91th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4838 - acc: 0.8064     \n",
      "Medel is training: epoch 91th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3895 - acc: 0.8159     \n",
      "Medel is training: epoch 91th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0454 - acc: 0.8467     \n",
      "Medel is training: epoch 91th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5149 - acc: 0.7951     \n",
      "Medel is training: epoch 91th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5174 - acc: 0.8006     \n",
      "Medel is training: epoch 91th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0939 - acc: 1.0000\n",
      "Medel is training: epoch 92th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5638 - acc: 0.7961     \n",
      "Medel is training: epoch 92th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3731 - acc: 0.8179     \n",
      "Medel is training: epoch 92th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3793 - acc: 0.8119     \n",
      "Medel is training: epoch 92th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4870 - acc: 0.8086     \n",
      "Medel is training: epoch 92th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2673 - acc: 0.8271     \n",
      "Medel is training: epoch 92th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5231 - acc: 0.8003     \n",
      "Medel is training: epoch 92th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5125 - acc: 0.8044     \n",
      "Medel is training: epoch 92th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2281 - acc: 0.8276     \n",
      "Medel is training: epoch 92th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5362 - acc: 0.7990     \n",
      "Medel is training: epoch 92th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3563 - acc: 0.8193     \n",
      "Medel is training: epoch 92th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3900 - acc: 0.8124     \n",
      "Medel is training: epoch 92th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5296 - acc: 0.8022     \n",
      "Medel is training: epoch 92th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2898 - acc: 0.8261     \n",
      "Medel is training: epoch 92th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5342 - acc: 0.7954     \n",
      "Medel is training: epoch 92th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4990 - acc: 0.8066     \n",
      "Medel is training: epoch 92th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2318 - acc: 0.8304     \n",
      "Medel is training: epoch 92th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4805 - acc: 0.8023     \n",
      "Medel is training: epoch 92th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5028 - acc: 0.8064     \n",
      "Medel is training: epoch 92th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2201 - acc: 0.8314     \n",
      "Medel is training: epoch 92th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4919 - acc: 0.8001     \n",
      "Medel is training: epoch 92th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4723 - acc: 0.8105     \n",
      "Medel is training: epoch 92th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2612 - acc: 0.8288     \n",
      "Medel is training: epoch 92th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4270 - acc: 0.8056     \n",
      "Medel is training: epoch 92th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5188 - acc: 0.8034     \n",
      "Medel is training: epoch 92th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3419 - acc: 0.8223     \n",
      "Medel is training: epoch 92th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2593 - acc: 0.8242     \n",
      "Medel is training: epoch 92th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5488 - acc: 0.7969     \n",
      "Medel is training: epoch 92th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5133 - acc: 0.8062     \n",
      "Medel is training: epoch 92th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0560 - acc: 0.8480     \n",
      "Medel is training: epoch 92th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5282 - acc: 0.7971     \n",
      "Medel is training: epoch 92th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4929 - acc: 0.8062     \n",
      "Medel is training: epoch 92th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1708 - acc: 0.8391     \n",
      "Medel is training: epoch 92th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2851 - acc: 0.8224     \n",
      "Medel is training: epoch 92th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5342 - acc: 0.7971     \n",
      "Medel is training: epoch 92th 34000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.5193 - acc: 0.8046     \n",
      "Medel is training: epoch 92th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0062 - acc: 0.8517     \n",
      "Medel is training: epoch 92th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4586 - acc: 0.8024     \n",
      "Medel is training: epoch 92th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4918 - acc: 0.8050     \n",
      "Medel is training: epoch 92th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4187 - acc: 0.8147     \n",
      "Medel is training: epoch 92th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0386 - acc: 0.8468     \n",
      "Medel is training: epoch 92th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5380 - acc: 0.7943     \n",
      "Medel is training: epoch 92th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4460 - acc: 0.8122     \n",
      "Medel is training: epoch 92th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4716 - acc: 0.8077     \n",
      "Medel is training: epoch 92th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0300 - acc: 0.8475     \n",
      "Medel is training: epoch 92th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5215 - acc: 0.7964     \n",
      "Medel is training: epoch 92th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4827 - acc: 0.8064     \n",
      "Medel is training: epoch 92th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3886 - acc: 0.8159     \n",
      "Medel is training: epoch 92th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0436 - acc: 0.8469     \n",
      "Medel is training: epoch 92th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5139 - acc: 0.7951     \n",
      "Medel is training: epoch 92th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5170 - acc: 0.8006     \n",
      "Medel is training: epoch 92th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0924 - acc: 1.0000\n",
      "Medel is training: epoch 93th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5617 - acc: 0.7963     \n",
      "Medel is training: epoch 93th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3713 - acc: 0.8182     \n",
      "Medel is training: epoch 93th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3789 - acc: 0.8121     \n",
      "Medel is training: epoch 93th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4860 - acc: 0.8087     \n",
      "Medel is training: epoch 93th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2665 - acc: 0.8269     \n",
      "Medel is training: epoch 93th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5220 - acc: 0.8004     \n",
      "Medel is training: epoch 93th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5121 - acc: 0.8046     \n",
      "Medel is training: epoch 93th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2276 - acc: 0.8276     \n",
      "Medel is training: epoch 93th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5357 - acc: 0.7989     \n",
      "Medel is training: epoch 93th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3561 - acc: 0.8193     \n",
      "Medel is training: epoch 93th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3886 - acc: 0.8123     \n",
      "Medel is training: epoch 93th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5293 - acc: 0.8022     \n",
      "Medel is training: epoch 93th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2887 - acc: 0.8259     \n",
      "Medel is training: epoch 93th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5327 - acc: 0.7954     \n",
      "Medel is training: epoch 93th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4985 - acc: 0.8065     \n",
      "Medel is training: epoch 93th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2307 - acc: 0.8307     \n",
      "Medel is training: epoch 93th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4791 - acc: 0.8023     \n",
      "Medel is training: epoch 93th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5022 - acc: 0.8064     \n",
      "Medel is training: epoch 93th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2187 - acc: 0.8316     \n",
      "Medel is training: epoch 93th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4904 - acc: 0.8003     \n",
      "Medel is training: epoch 93th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4716 - acc: 0.8106     \n",
      "Medel is training: epoch 93th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2605 - acc: 0.8286     \n",
      "Medel is training: epoch 93th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4257 - acc: 0.8058     \n",
      "Medel is training: epoch 93th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5170 - acc: 0.8034     \n",
      "Medel is training: epoch 93th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3412 - acc: 0.8222     \n",
      "Medel is training: epoch 93th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2583 - acc: 0.8240     \n",
      "Medel is training: epoch 93th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5474 - acc: 0.7971     \n",
      "Medel is training: epoch 93th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5121 - acc: 0.8064     \n",
      "Medel is training: epoch 93th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0540 - acc: 0.8480     \n",
      "Medel is training: epoch 93th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5265 - acc: 0.7970     \n",
      "Medel is training: epoch 93th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4920 - acc: 0.8063     \n",
      "Medel is training: epoch 93th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1701 - acc: 0.8395     \n",
      "Medel is training: epoch 93th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2829 - acc: 0.8224     \n",
      "Medel is training: epoch 93th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5321 - acc: 0.7974     \n",
      "Medel is training: epoch 93th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5189 - acc: 0.8045     \n",
      "Medel is training: epoch 93th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0056 - acc: 0.8514     \n",
      "Medel is training: epoch 93th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4575 - acc: 0.8022     \n",
      "Medel is training: epoch 93th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4912 - acc: 0.8048     \n",
      "Medel is training: epoch 93th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4175 - acc: 0.8146     \n",
      "Medel is training: epoch 93th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0354 - acc: 0.8474     \n",
      "Medel is training: epoch 93th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5365 - acc: 0.7941     \n",
      "Medel is training: epoch 93th 41000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.4446 - acc: 0.8121     \n",
      "Medel is training: epoch 93th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4712 - acc: 0.8076     \n",
      "Medel is training: epoch 93th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0285 - acc: 0.8477     \n",
      "Medel is training: epoch 93th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5213 - acc: 0.7961     \n",
      "Medel is training: epoch 93th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4825 - acc: 0.8061     \n",
      "Medel is training: epoch 93th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3884 - acc: 0.8158     \n",
      "Medel is training: epoch 93th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0422 - acc: 0.8473     \n",
      "Medel is training: epoch 93th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5128 - acc: 0.7951     \n",
      "Medel is training: epoch 93th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5163 - acc: 0.8006     \n",
      "Medel is training: epoch 93th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0907 - acc: 1.0000\n",
      "Medel is training: epoch 94th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5613 - acc: 0.7961     \n",
      "Medel is training: epoch 94th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3708 - acc: 0.8183     \n",
      "Medel is training: epoch 94th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3780 - acc: 0.8122     \n",
      "Medel is training: epoch 94th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4861 - acc: 0.8086     \n",
      "Medel is training: epoch 94th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2650 - acc: 0.8271     \n",
      "Medel is training: epoch 94th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5206 - acc: 0.8003     \n",
      "Medel is training: epoch 94th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5115 - acc: 0.8046     \n",
      "Medel is training: epoch 94th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2254 - acc: 0.8278     \n",
      "Medel is training: epoch 94th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5346 - acc: 0.7990     \n",
      "Medel is training: epoch 94th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3545 - acc: 0.8195     \n",
      "Medel is training: epoch 94th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3873 - acc: 0.8121     \n",
      "Medel is training: epoch 94th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5284 - acc: 0.8023     \n",
      "Medel is training: epoch 94th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2879 - acc: 0.8259     \n",
      "Medel is training: epoch 94th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5320 - acc: 0.7953     \n",
      "Medel is training: epoch 94th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4977 - acc: 0.8065     \n",
      "Medel is training: epoch 94th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2299 - acc: 0.8305     \n",
      "Medel is training: epoch 94th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4778 - acc: 0.8025     \n",
      "Medel is training: epoch 94th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5015 - acc: 0.8065     \n",
      "Medel is training: epoch 94th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2183 - acc: 0.8313     \n",
      "Medel is training: epoch 94th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4891 - acc: 0.8004     \n",
      "Medel is training: epoch 94th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4709 - acc: 0.8105     \n",
      "Medel is training: epoch 94th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2588 - acc: 0.8290     \n",
      "Medel is training: epoch 94th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4248 - acc: 0.8061     \n",
      "Medel is training: epoch 94th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5169 - acc: 0.8035     \n",
      "Medel is training: epoch 94th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3401 - acc: 0.8223     \n",
      "Medel is training: epoch 94th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2570 - acc: 0.8242     \n",
      "Medel is training: epoch 94th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5471 - acc: 0.7972     \n",
      "Medel is training: epoch 94th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5118 - acc: 0.8063     \n",
      "Medel is training: epoch 94th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0536 - acc: 0.8482     \n",
      "Medel is training: epoch 94th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5257 - acc: 0.7972     \n",
      "Medel is training: epoch 94th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4919 - acc: 0.8062     \n",
      "Medel is training: epoch 94th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1688 - acc: 0.8393     \n",
      "Medel is training: epoch 94th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2818 - acc: 0.8226     \n",
      "Medel is training: epoch 94th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5327 - acc: 0.7972     \n",
      "Medel is training: epoch 94th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5183 - acc: 0.8045     \n",
      "Medel is training: epoch 94th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0041 - acc: 0.8518     \n",
      "Medel is training: epoch 94th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4556 - acc: 0.8024     \n",
      "Medel is training: epoch 94th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4902 - acc: 0.8049     \n",
      "Medel is training: epoch 94th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4171 - acc: 0.8149     \n",
      "Medel is training: epoch 94th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0348 - acc: 0.8474     \n",
      "Medel is training: epoch 94th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5348 - acc: 0.7943     \n",
      "Medel is training: epoch 94th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4444 - acc: 0.8121     \n",
      "Medel is training: epoch 94th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4708 - acc: 0.8077     \n",
      "Medel is training: epoch 94th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0287 - acc: 0.8474     \n",
      "Medel is training: epoch 94th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5188 - acc: 0.7962     \n",
      "Medel is training: epoch 94th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4809 - acc: 0.8065     \n",
      "Medel is training: epoch 94th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3872 - acc: 0.8160     \n",
      "Medel is training: epoch 94th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0413 - acc: 0.8467     \n",
      "Medel is training: epoch 94th 48000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.5116 - acc: 0.7951     \n",
      "Medel is training: epoch 94th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5147 - acc: 0.8004     \n",
      "Medel is training: epoch 94th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0893 - acc: 1.0000\n",
      "Medel is training: epoch 95th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5602 - acc: 0.7961     \n",
      "Medel is training: epoch 95th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3700 - acc: 0.8183     \n",
      "Medel is training: epoch 95th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3760 - acc: 0.8124     \n",
      "Medel is training: epoch 95th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4845 - acc: 0.8088     \n",
      "Medel is training: epoch 95th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2644 - acc: 0.8271     \n",
      "Medel is training: epoch 95th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5199 - acc: 0.8003     \n",
      "Medel is training: epoch 95th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5105 - acc: 0.8045     \n",
      "Medel is training: epoch 95th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2244 - acc: 0.8278     \n",
      "Medel is training: epoch 95th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5333 - acc: 0.7989     \n",
      "Medel is training: epoch 95th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3539 - acc: 0.8193     \n",
      "Medel is training: epoch 95th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3864 - acc: 0.8123     \n",
      "Medel is training: epoch 95th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5275 - acc: 0.8023     \n",
      "Medel is training: epoch 95th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2875 - acc: 0.8261     \n",
      "Medel is training: epoch 95th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5310 - acc: 0.7954     \n",
      "Medel is training: epoch 95th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4971 - acc: 0.8065     \n",
      "Medel is training: epoch 95th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2292 - acc: 0.8307     \n",
      "Medel is training: epoch 95th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4772 - acc: 0.8024     \n",
      "Medel is training: epoch 95th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5006 - acc: 0.8065     \n",
      "Medel is training: epoch 95th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2166 - acc: 0.8316     \n",
      "Medel is training: epoch 95th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4876 - acc: 0.8003     \n",
      "Medel is training: epoch 95th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4701 - acc: 0.8105     \n",
      "Medel is training: epoch 95th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2589 - acc: 0.8287     \n",
      "Medel is training: epoch 95th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4229 - acc: 0.8060     \n",
      "Medel is training: epoch 95th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5157 - acc: 0.8035     \n",
      "Medel is training: epoch 95th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3394 - acc: 0.8222     \n",
      "Medel is training: epoch 95th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2559 - acc: 0.8242     \n",
      "Medel is training: epoch 95th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5455 - acc: 0.7971     \n",
      "Medel is training: epoch 95th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5114 - acc: 0.8063     \n",
      "Medel is training: epoch 95th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0519 - acc: 0.8480     \n",
      "Medel is training: epoch 95th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5238 - acc: 0.7972     \n",
      "Medel is training: epoch 95th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4907 - acc: 0.8063     \n",
      "Medel is training: epoch 95th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1680 - acc: 0.8396     \n",
      "Medel is training: epoch 95th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2803 - acc: 0.8222     \n",
      "Medel is training: epoch 95th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5305 - acc: 0.7973     \n",
      "Medel is training: epoch 95th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5175 - acc: 0.8045     \n",
      "Medel is training: epoch 95th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0016 - acc: 0.8521     \n",
      "Medel is training: epoch 95th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4538 - acc: 0.8024     \n",
      "Medel is training: epoch 95th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4885 - acc: 0.8049     \n",
      "Medel is training: epoch 95th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4161 - acc: 0.8149     \n",
      "Medel is training: epoch 95th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0329 - acc: 0.8478     \n",
      "Medel is training: epoch 95th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5337 - acc: 0.7944     \n",
      "Medel is training: epoch 95th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4436 - acc: 0.8122     \n",
      "Medel is training: epoch 95th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4697 - acc: 0.8078     \n",
      "Medel is training: epoch 95th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0260 - acc: 0.8473     \n",
      "Medel is training: epoch 95th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5183 - acc: 0.7962     \n",
      "Medel is training: epoch 95th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4809 - acc: 0.8063     \n",
      "Medel is training: epoch 95th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3864 - acc: 0.8158     \n",
      "Medel is training: epoch 95th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0400 - acc: 0.8466     \n",
      "Medel is training: epoch 95th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5110 - acc: 0.7953     \n",
      "Medel is training: epoch 95th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5142 - acc: 0.8007     \n",
      "Medel is training: epoch 95th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0875 - acc: 1.0000\n",
      "Medel is training: epoch 96th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5597 - acc: 0.7961     \n",
      "Medel is training: epoch 96th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3683 - acc: 0.8182     \n",
      "Medel is training: epoch 96th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3745 - acc: 0.8124     \n",
      "Medel is training: epoch 96th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4836 - acc: 0.8089     \n",
      "Medel is training: epoch 96th 4000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.2628 - acc: 0.8272     \n",
      "Medel is training: epoch 96th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5188 - acc: 0.8002     \n",
      "Medel is training: epoch 96th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5104 - acc: 0.8046     \n",
      "Medel is training: epoch 96th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2234 - acc: 0.8278     \n",
      "Medel is training: epoch 96th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5323 - acc: 0.7991     \n",
      "Medel is training: epoch 96th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3528 - acc: 0.8196     \n",
      "Medel is training: epoch 96th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3851 - acc: 0.8126     \n",
      "Medel is training: epoch 96th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5266 - acc: 0.8022     \n",
      "Medel is training: epoch 96th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2868 - acc: 0.8260     \n",
      "Medel is training: epoch 96th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5294 - acc: 0.7954     \n",
      "Medel is training: epoch 96th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4970 - acc: 0.8066     \n",
      "Medel is training: epoch 96th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2287 - acc: 0.8307     \n",
      "Medel is training: epoch 96th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4755 - acc: 0.8024     \n",
      "Medel is training: epoch 96th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4993 - acc: 0.8064     \n",
      "Medel is training: epoch 96th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2156 - acc: 0.8313     \n",
      "Medel is training: epoch 96th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4863 - acc: 0.8004     \n",
      "Medel is training: epoch 96th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4691 - acc: 0.8105     \n",
      "Medel is training: epoch 96th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2574 - acc: 0.8288     \n",
      "Medel is training: epoch 96th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4216 - acc: 0.8061     \n",
      "Medel is training: epoch 96th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5145 - acc: 0.8036     \n",
      "Medel is training: epoch 96th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3389 - acc: 0.8226     \n",
      "Medel is training: epoch 96th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2549 - acc: 0.8242     \n",
      "Medel is training: epoch 96th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5447 - acc: 0.7971     \n",
      "Medel is training: epoch 96th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5104 - acc: 0.8063     \n",
      "Medel is training: epoch 96th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0510 - acc: 0.8481     \n",
      "Medel is training: epoch 96th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5232 - acc: 0.7970     \n",
      "Medel is training: epoch 96th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4898 - acc: 0.8063     \n",
      "Medel is training: epoch 96th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1678 - acc: 0.8396     \n",
      "Medel is training: epoch 96th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2785 - acc: 0.8226     \n",
      "Medel is training: epoch 96th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5297 - acc: 0.7972     \n",
      "Medel is training: epoch 96th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5168 - acc: 0.8046     \n",
      "Medel is training: epoch 96th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0001 - acc: 0.8521     \n",
      "Medel is training: epoch 96th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4532 - acc: 0.8023     \n",
      "Medel is training: epoch 96th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4882 - acc: 0.8049     \n",
      "Medel is training: epoch 96th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4152 - acc: 0.8148     \n",
      "Medel is training: epoch 96th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0310 - acc: 0.8477     \n",
      "Medel is training: epoch 96th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5320 - acc: 0.7945     \n",
      "Medel is training: epoch 96th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4429 - acc: 0.8120     \n",
      "Medel is training: epoch 96th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4687 - acc: 0.8079     \n",
      "Medel is training: epoch 96th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0244 - acc: 0.8479     \n",
      "Medel is training: epoch 96th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5172 - acc: 0.7960     \n",
      "Medel is training: epoch 96th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4799 - acc: 0.8065     \n",
      "Medel is training: epoch 96th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3859 - acc: 0.8158     \n",
      "Medel is training: epoch 96th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0383 - acc: 0.8474     \n",
      "Medel is training: epoch 96th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5088 - acc: 0.7951     \n",
      "Medel is training: epoch 96th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5135 - acc: 0.8005     \n",
      "Medel is training: epoch 96th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0862 - acc: 1.0000\n",
      "Medel is training: epoch 97th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5587 - acc: 0.7963     \n",
      "Medel is training: epoch 97th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3670 - acc: 0.8185     \n",
      "Medel is training: epoch 97th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3736 - acc: 0.8125     \n",
      "Medel is training: epoch 97th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4825 - acc: 0.8090     \n",
      "Medel is training: epoch 97th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2621 - acc: 0.8273     \n",
      "Medel is training: epoch 97th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5177 - acc: 0.8004     \n",
      "Medel is training: epoch 97th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5094 - acc: 0.8046     \n",
      "Medel is training: epoch 97th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2218 - acc: 0.8279     \n",
      "Medel is training: epoch 97th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5312 - acc: 0.7991     \n",
      "Medel is training: epoch 97th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3523 - acc: 0.8196     \n",
      "Medel is training: epoch 97th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3841 - acc: 0.8124     \n",
      "Medel is training: epoch 97th 11000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.5256 - acc: 0.8023     \n",
      "Medel is training: epoch 97th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2852 - acc: 0.8260     \n",
      "Medel is training: epoch 97th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5285 - acc: 0.7956     \n",
      "Medel is training: epoch 97th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4963 - acc: 0.8065     \n",
      "Medel is training: epoch 97th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2275 - acc: 0.8307     \n",
      "Medel is training: epoch 97th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4740 - acc: 0.8023     \n",
      "Medel is training: epoch 97th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4989 - acc: 0.8064     \n",
      "Medel is training: epoch 97th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2144 - acc: 0.8317     \n",
      "Medel is training: epoch 97th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4849 - acc: 0.8006     \n",
      "Medel is training: epoch 97th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4682 - acc: 0.8106     \n",
      "Medel is training: epoch 97th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2562 - acc: 0.8290     \n",
      "Medel is training: epoch 97th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4206 - acc: 0.8061     \n",
      "Medel is training: epoch 97th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5134 - acc: 0.8036     \n",
      "Medel is training: epoch 97th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3386 - acc: 0.8221     \n",
      "Medel is training: epoch 97th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2530 - acc: 0.8241     \n",
      "Medel is training: epoch 97th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5434 - acc: 0.7972     \n",
      "Medel is training: epoch 97th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5100 - acc: 0.8063     \n",
      "Medel is training: epoch 97th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0492 - acc: 0.8479     \n",
      "Medel is training: epoch 97th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5219 - acc: 0.7974     \n",
      "Medel is training: epoch 97th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4883 - acc: 0.8063     \n",
      "Medel is training: epoch 97th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1672 - acc: 0.8393     \n",
      "Medel is training: epoch 97th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2771 - acc: 0.8228     \n",
      "Medel is training: epoch 97th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5281 - acc: 0.7975     \n",
      "Medel is training: epoch 97th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5156 - acc: 0.8045     \n",
      "Medel is training: epoch 97th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 0.9996 - acc: 0.8521     \n",
      "Medel is training: epoch 97th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4522 - acc: 0.8024     \n",
      "Medel is training: epoch 97th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4871 - acc: 0.8048     \n",
      "Medel is training: epoch 97th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4145 - acc: 0.8148     \n",
      "Medel is training: epoch 97th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0306 - acc: 0.8478     \n",
      "Medel is training: epoch 97th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5308 - acc: 0.7944     \n",
      "Medel is training: epoch 97th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4407 - acc: 0.8121     \n",
      "Medel is training: epoch 97th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4683 - acc: 0.8078     \n",
      "Medel is training: epoch 97th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0232 - acc: 0.8477     \n",
      "Medel is training: epoch 97th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5154 - acc: 0.7962     \n",
      "Medel is training: epoch 97th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4788 - acc: 0.8066     \n",
      "Medel is training: epoch 97th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3849 - acc: 0.8158     \n",
      "Medel is training: epoch 97th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0369 - acc: 0.8475     \n",
      "Medel is training: epoch 97th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5081 - acc: 0.7956     \n",
      "Medel is training: epoch 97th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5114 - acc: 0.8006     \n",
      "Medel is training: epoch 97th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0850 - acc: 1.0000\n",
      "Medel is training: epoch 98th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5570 - acc: 0.7965     \n",
      "Medel is training: epoch 98th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3663 - acc: 0.8184     \n",
      "Medel is training: epoch 98th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3725 - acc: 0.8124     \n",
      "Medel is training: epoch 98th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4817 - acc: 0.8090     \n",
      "Medel is training: epoch 98th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2609 - acc: 0.8272     \n",
      "Medel is training: epoch 98th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5164 - acc: 0.8004     \n",
      "Medel is training: epoch 98th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5088 - acc: 0.8046     \n",
      "Medel is training: epoch 98th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2204 - acc: 0.8278     \n",
      "Medel is training: epoch 98th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5300 - acc: 0.7992     \n",
      "Medel is training: epoch 98th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3515 - acc: 0.8194     \n",
      "Medel is training: epoch 98th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3827 - acc: 0.8126     \n",
      "Medel is training: epoch 98th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5247 - acc: 0.8023     \n",
      "Medel is training: epoch 98th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2844 - acc: 0.8262     \n",
      "Medel is training: epoch 98th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5273 - acc: 0.7955     \n",
      "Medel is training: epoch 98th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4955 - acc: 0.8066     \n",
      "Medel is training: epoch 98th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2268 - acc: 0.8308     \n",
      "Medel is training: epoch 98th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4730 - acc: 0.8024     \n",
      "Medel is training: epoch 98th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4984 - acc: 0.8065     \n",
      "Medel is training: epoch 98th 18000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.2135 - acc: 0.8316     \n",
      "Medel is training: epoch 98th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4841 - acc: 0.8006     \n",
      "Medel is training: epoch 98th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4680 - acc: 0.8105     \n",
      "Medel is training: epoch 98th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2559 - acc: 0.8289     \n",
      "Medel is training: epoch 98th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4189 - acc: 0.8062     \n",
      "Medel is training: epoch 98th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5132 - acc: 0.8034     \n",
      "Medel is training: epoch 98th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3372 - acc: 0.8226     \n",
      "Medel is training: epoch 98th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2524 - acc: 0.8245     \n",
      "Medel is training: epoch 98th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5426 - acc: 0.7970     \n",
      "Medel is training: epoch 98th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5092 - acc: 0.8064     \n",
      "Medel is training: epoch 98th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0489 - acc: 0.8482     \n",
      "Medel is training: epoch 98th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5208 - acc: 0.7971     \n",
      "Medel is training: epoch 98th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4887 - acc: 0.8063     \n",
      "Medel is training: epoch 98th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1657 - acc: 0.8397     \n",
      "Medel is training: epoch 98th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2772 - acc: 0.8227     \n",
      "Medel is training: epoch 98th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5272 - acc: 0.7974     \n",
      "Medel is training: epoch 98th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5156 - acc: 0.8047     \n",
      "Medel is training: epoch 98th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 0.9987 - acc: 0.8523     \n",
      "Medel is training: epoch 98th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4514 - acc: 0.8025     \n",
      "Medel is training: epoch 98th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4862 - acc: 0.8050     \n",
      "Medel is training: epoch 98th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4139 - acc: 0.8148     \n",
      "Medel is training: epoch 98th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0291 - acc: 0.8478     \n",
      "Medel is training: epoch 98th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5297 - acc: 0.7943     \n",
      "Medel is training: epoch 98th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4401 - acc: 0.8122     \n",
      "Medel is training: epoch 98th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4685 - acc: 0.8078     \n",
      "Medel is training: epoch 98th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0221 - acc: 0.8476     \n",
      "Medel is training: epoch 98th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5151 - acc: 0.7963     \n",
      "Medel is training: epoch 98th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4776 - acc: 0.8066     \n",
      "Medel is training: epoch 98th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3846 - acc: 0.8159     \n",
      "Medel is training: epoch 98th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0365 - acc: 0.8469     \n",
      "Medel is training: epoch 98th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5060 - acc: 0.7951     \n",
      "Medel is training: epoch 98th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5108 - acc: 0.8004     \n",
      "Medel is training: epoch 98th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0834 - acc: 1.0000\n",
      "Medel is training: epoch 99th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5558 - acc: 0.7964     \n",
      "Medel is training: epoch 99th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3661 - acc: 0.8186     \n",
      "Medel is training: epoch 99th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3710 - acc: 0.8124     \n",
      "Medel is training: epoch 99th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4807 - acc: 0.8089     \n",
      "Medel is training: epoch 99th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2603 - acc: 0.8273     \n",
      "Medel is training: epoch 99th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5157 - acc: 0.8002     \n",
      "Medel is training: epoch 99th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5085 - acc: 0.8046     \n",
      "Medel is training: epoch 99th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2196 - acc: 0.8278     \n",
      "Medel is training: epoch 99th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5297 - acc: 0.7991     \n",
      "Medel is training: epoch 99th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3510 - acc: 0.8194     \n",
      "Medel is training: epoch 99th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3816 - acc: 0.8124     \n",
      "Medel is training: epoch 99th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5241 - acc: 0.8024     \n",
      "Medel is training: epoch 99th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2835 - acc: 0.8262     \n",
      "Medel is training: epoch 99th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5257 - acc: 0.7956     \n",
      "Medel is training: epoch 99th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4950 - acc: 0.8064     \n",
      "Medel is training: epoch 99th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2263 - acc: 0.8306     \n",
      "Medel is training: epoch 99th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4718 - acc: 0.8026     \n",
      "Medel is training: epoch 99th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4979 - acc: 0.8064     \n",
      "Medel is training: epoch 99th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2127 - acc: 0.8315     \n",
      "Medel is training: epoch 99th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4831 - acc: 0.8007     \n",
      "Medel is training: epoch 99th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4666 - acc: 0.8106     \n",
      "Medel is training: epoch 99th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2550 - acc: 0.8289     \n",
      "Medel is training: epoch 99th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4174 - acc: 0.8063     \n",
      "Medel is training: epoch 99th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5121 - acc: 0.8036     \n",
      "Medel is training: epoch 99th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3364 - acc: 0.8223     \n",
      "Medel is training: epoch 99th 25000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.2509 - acc: 0.8244     \n",
      "Medel is training: epoch 99th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5414 - acc: 0.7971     \n",
      "Medel is training: epoch 99th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5086 - acc: 0.8062     \n",
      "Medel is training: epoch 99th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0473 - acc: 0.8489     \n",
      "Medel is training: epoch 99th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5204 - acc: 0.7972     \n",
      "Medel is training: epoch 99th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4870 - acc: 0.8063     \n",
      "Medel is training: epoch 99th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1655 - acc: 0.8397     \n",
      "Medel is training: epoch 99th 32000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2752 - acc: 0.8228     \n",
      "Medel is training: epoch 99th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5264 - acc: 0.7973     \n",
      "Medel is training: epoch 99th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5145 - acc: 0.8045     \n",
      "Medel is training: epoch 99th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 0.9982 - acc: 0.8526     \n",
      "Medel is training: epoch 99th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4492 - acc: 0.8023     \n",
      "Medel is training: epoch 99th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4851 - acc: 0.8050     \n",
      "Medel is training: epoch 99th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4130 - acc: 0.8147     \n",
      "Medel is training: epoch 99th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0287 - acc: 0.8478     \n",
      "Medel is training: epoch 99th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5284 - acc: 0.7945     \n",
      "Medel is training: epoch 99th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4408 - acc: 0.8122     \n",
      "Medel is training: epoch 99th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4668 - acc: 0.8078     \n",
      "Medel is training: epoch 99th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0211 - acc: 0.8477     \n",
      "Medel is training: epoch 99th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5137 - acc: 0.7961     \n",
      "Medel is training: epoch 99th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4772 - acc: 0.8065     \n",
      "Medel is training: epoch 99th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3833 - acc: 0.8158     \n",
      "Medel is training: epoch 99th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0344 - acc: 0.8475     \n",
      "Medel is training: epoch 99th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5052 - acc: 0.7951     \n",
      "Medel is training: epoch 99th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5099 - acc: 0.8003     \n",
      "Medel is training: epoch 99th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0819 - acc: 1.0000\n",
      "Medel is training: epoch 100th 0/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5551 - acc: 0.7964     \n",
      "Medel is training: epoch 100th 1000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3647 - acc: 0.8187     \n",
      "Medel is training: epoch 100th 2000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3698 - acc: 0.8125     \n",
      "Medel is training: epoch 100th 3000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4796 - acc: 0.8091     \n",
      "Medel is training: epoch 100th 4000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2592 - acc: 0.8273     \n",
      "Medel is training: epoch 100th 5000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5147 - acc: 0.8004     \n",
      "Medel is training: epoch 100th 6000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5075 - acc: 0.8046     \n",
      "Medel is training: epoch 100th 7000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2184 - acc: 0.8280     \n",
      "Medel is training: epoch 100th 8000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5279 - acc: 0.7992     \n",
      "Medel is training: epoch 100th 9000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3501 - acc: 0.8194     \n",
      "Medel is training: epoch 100th 10000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3804 - acc: 0.8125     \n",
      "Medel is training: epoch 100th 11000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5235 - acc: 0.8023     \n",
      "Medel is training: epoch 100th 12000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2828 - acc: 0.8264     \n",
      "Medel is training: epoch 100th 13000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5247 - acc: 0.7956     \n",
      "Medel is training: epoch 100th 14000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4939 - acc: 0.8066     \n",
      "Medel is training: epoch 100th 15000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2250 - acc: 0.8307     \n",
      "Medel is training: epoch 100th 16000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4705 - acc: 0.8025     \n",
      "Medel is training: epoch 100th 17000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4968 - acc: 0.8063     \n",
      "Medel is training: epoch 100th 18000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2117 - acc: 0.8317     \n",
      "Medel is training: epoch 100th 19000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4814 - acc: 0.8007     \n",
      "Medel is training: epoch 100th 20000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4657 - acc: 0.8107     \n",
      "Medel is training: epoch 100th 21000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2540 - acc: 0.8290     \n",
      "Medel is training: epoch 100th 22000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4166 - acc: 0.8063     \n",
      "Medel is training: epoch 100th 23000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5115 - acc: 0.8037     \n",
      "Medel is training: epoch 100th 24000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3367 - acc: 0.8224     \n",
      "Medel is training: epoch 100th 25000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.2497 - acc: 0.8246     \n",
      "Medel is training: epoch 100th 26000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5401 - acc: 0.7971     \n",
      "Medel is training: epoch 100th 27000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5072 - acc: 0.8063     \n",
      "Medel is training: epoch 100th 28000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0458 - acc: 0.8481     \n",
      "Medel is training: epoch 100th 29000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5179 - acc: 0.7972     \n",
      "Medel is training: epoch 100th 30000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4872 - acc: 0.8064     \n",
      "Medel is training: epoch 100th 31000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.1646 - acc: 0.8398     \n",
      "Medel is training: epoch 100th 32000/50001 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 1.2736 - acc: 0.8226     \n",
      "Medel is training: epoch 100th 33000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5255 - acc: 0.7974     \n",
      "Medel is training: epoch 100th 34000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5141 - acc: 0.8046     \n",
      "Medel is training: epoch 100th 35000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 0.9966 - acc: 0.8524     \n",
      "Medel is training: epoch 100th 36000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4485 - acc: 0.8025     \n",
      "Medel is training: epoch 100th 37000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4846 - acc: 0.8050     \n",
      "Medel is training: epoch 100th 38000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4125 - acc: 0.8151     \n",
      "Medel is training: epoch 100th 39000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0278 - acc: 0.8478     \n",
      "Medel is training: epoch 100th 40000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5287 - acc: 0.7942     \n",
      "Medel is training: epoch 100th 41000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4403 - acc: 0.8122     \n",
      "Medel is training: epoch 100th 42000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4670 - acc: 0.8077     \n",
      "Medel is training: epoch 100th 43000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0200 - acc: 0.8475     \n",
      "Medel is training: epoch 100th 44000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5124 - acc: 0.7964     \n",
      "Medel is training: epoch 100th 45000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.4769 - acc: 0.8064     \n",
      "Medel is training: epoch 100th 46000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.3829 - acc: 0.8161     \n",
      "Medel is training: epoch 100th 47000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.0330 - acc: 0.8475     \n",
      "Medel is training: epoch 100th 48000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5035 - acc: 0.7953     \n",
      "Medel is training: epoch 100th 49000/50001 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 5s - loss: 1.5087 - acc: 0.8003     \n",
      "Medel is training: epoch 100th 50000/50001 samples\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s - loss: 0.0804 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "len_of_transformed_article_data_train = len(transformed_article_data_train)\n",
    "for p in range(1,EPOCHS+1):\n",
    "    for item in range(0, len_of_transformed_article_data_train, 1000):\n",
    "        if item + 1000 >= len_of_transformed_article_data_train:\n",
    "            last_item = len_of_transformed_article_data_train\n",
    "        else:\n",
    "            last_item = item + 1000\n",
    "        \n",
    "        summary=transformed_summary_data_train[item:last_item]\n",
    "        \n",
    "        summary_one_hot = (np.arange(transformed_summary_data_train.max()+1) == summary[...,None]).astype(int)# One Hot \n",
    "        \n",
    "        print('Medel is training: epoch {}th {}/{} samples'.format(p, item, len_of_transformed_article_data_train))\n",
    "        model.fit(transformed_article_data_train[item:last_item], summary_one_hot, batch_size=BATCH_SIZE, nb_epoch=1,verbose=1,shuffle = True)\n",
    "    model.save_weights('./without_attention_weights/checkpoint_epoch_{}.hdf5'.format(p))   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation using Rouge score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have trained the model, load the test data i.e. test_article.txt and corresponding reference titles test_title.txt. Process test_article.txt in the same way as you did your train_article.txt. Then use your model to predict the titles.\n",
    "When you have your model predicted titles, and the reference titles (test_title.txt) calculate the Rouge score corresponding to your predictions. <br>\n",
    "You should install rouge by executing \"pip3 install rouge\". Refer https://pypi.python.org/pypi/rouge/0.2.1 for documentation on how to use the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1516"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import test data\n",
    "# TO-DO \n",
    "article_text_test =  open('data/test_article.txt', 'r')\n",
    "summary_text_test =  open('data/test_title.txt', 'r')\n",
    "\n",
    "\n",
    "articleTest_data=article_text_test.read().splitlines()\n",
    "summaryTest_data=summary_text_test.read().splitlines()\n",
    "\n",
    "\n",
    "# function to find the words that are in list 1 but not in list 2\n",
    "def words_in_doc1_not_doc2(doc1,doc2):\n",
    "    import numpy as np\n",
    "    tokenizer1 = Tokenizer()\n",
    "    tokenizer1.fit_on_texts(doc1)\n",
    "    counts1=dict(tokenizer1.word_counts)\n",
    "\n",
    "    tokenizer2 = Tokenizer()\n",
    "    tokenizer2.fit_on_texts(doc2)\n",
    "    counts2=dict(tokenizer2.word_counts)\n",
    "    \n",
    "    count1_list = list(counts1)\n",
    "    count2_lsit = list(counts2)\n",
    "    \n",
    "    main_list = np.setdiff1d(count1_list,count2_lsit)\n",
    "    \n",
    "    return list(main_list)\n",
    "\n",
    "\n",
    "target_word_to_unk = words_in_doc1_not_doc2(articleTest_data,articleTrain_data)\n",
    "target_word_to_unk = target_word_to_unk + ['<unk>']\n",
    "\n",
    "len(target_word_to_unk)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# replace words not in training dataset as 'unk'\n",
    "\n",
    "def replace_with_unk(replaced_word_list, doc):\n",
    "    new_list = []\n",
    "    for i in range(0,len(doc)):\n",
    "        for j in range(0,len(replaced_word_list)):\n",
    "            doc[i] = doc[i].replace(replaced_word_list[j],'unk')\n",
    "        new_list.append(doc[i])\n",
    "    return new_list\n",
    "\n",
    "\n",
    "\n",
    "new_articleTest_data = replace_with_unk(target_word_to_unk, articleTest_data)\n",
    "\n",
    "\n",
    "# replace '<unk>' with 'unk'\n",
    "def standard_unk(doc):\n",
    "    new_list = []\n",
    "    for i in range(0,len(doc)):\n",
    "        doc[i] = doc[i].replace('<unk>','unk')\n",
    "        new_list.append(doc[i])\n",
    "    return new_list\n",
    "\n",
    "\n",
    "\n",
    "new_summaryTest_data = standard_unk(summaryTest_data)\n",
    "\n",
    "\n",
    "testing_article_data = load_data(new_articleTest_data,new_summaryTest_data,MAX_LEN,VOCAB_SIZE)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing_article_data = load_data(articleTest_data,summaryTest_data,MAX_LEN,VOCAB_SIZE)\n",
    "transformed_article_data_test = testing_article_data[0]\n",
    "Vocab_size_of_article_test = testing_article_data[1]\n",
    "word2idx_article_test = testing_article_data[2]\n",
    "dx2word_articl_test = testing_article_data[3]\n",
    "transformed_summary_data_test = testing_article_data[4]\n",
    "Vocab_size_of_summary_test = testing_article_data[5]\n",
    "word2idx_summary_test = testing_article_data[6]\n",
    "idx2word_summary_test = testing_article_data[7]\n",
    "                                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "                                             \n",
    "# model.load_weights(\"./without_attention_weights_folder2/checkpoint_epoch_69.hdf5\")\n",
    "# print(\"Loaded model from disk\")\n",
    "\n",
    "model.load_weights(\"./without_attention_weights/checkpoint_epoch_97.hdf5\")\n",
    "print(\"Loaded model from disk\")\n",
    "y_hat = model.predict(transformed_article_data_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# function to inverse a dictionary\n",
    "def inverse_dictionary(dic):\n",
    "    new_dic = {v: k for k, v in dic.items()}\n",
    "    return new_dic\n",
    "\n",
    "# decode a one hot encoded string\n",
    "def one_hot_decode(encoded_seq):\n",
    "    return [argmax(vector) for vector in encoded_seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary_test_word_id = inverse_dictionary(word2idx_summary_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'f': 0.038552357955697579,\n",
       "  'p': 0.074542857142857133,\n",
       "  'r': 0.026746165919441019},\n",
       " 'rouge-2': {'f': 2.8571427857142878e-05,\n",
       "  'p': 2.8571428571428574e-05,\n",
       "  'r': 2.8571428571428574e-05},\n",
       " 'rouge-l': {'f': 0.0062912841542721561,\n",
       "  'p': 0.0060198412698412697,\n",
       "  'r': 0.026679903082567832}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to convert one hot to words\n",
    "def one_hot_to_words(one_hot, MAX_LEN, dic):\n",
    "    list1 = []\n",
    "    for i in range(0,len(one_hot)):\n",
    "        value = one_hot_decode(one_hot[i])\n",
    "        list1.append(value)\n",
    "        \n",
    "    list2 = []\n",
    "    for i in range(0,len(one_hot)):\n",
    "        list3 = []\n",
    "        for j in range(0,MAX_LEN):\n",
    "            content = dic[list1[i][j]]\n",
    "            list3.append(content)\n",
    "        list2.append(list3)\n",
    "    return list2\n",
    "\n",
    "\n",
    "predicted_summary_list = one_hot_to_words(y_hat, MAX_LEN, summary_test_word_id)\n",
    "\n",
    "\n",
    "\n",
    "# TO-DO\n",
    "def import_Test_data(sum_T):\n",
    "\n",
    "    summary_pad_data=[]   \n",
    "    for i in range(len(sum_T)):\n",
    "        ha=text_to_word_sequence(sum_T[i],filters='',lower=True,split=\" \") \n",
    "        summary_pad_data.append(ha)  \n",
    "    \n",
    "    return summary_pad_data\n",
    "\n",
    "\n",
    "# import test data \n",
    "real_summary_raw=import_Test_data(new_summaryTest_data)\n",
    "\n",
    "len(real_summary_raw)\n",
    "\n",
    "\n",
    "# function to modify to fitted format for rouge\n",
    "def prepare_inputs_for_rouge(prediction_raw, real_raw):\n",
    "    prediction = [[' '.join(k)] for k in prediction_raw]\n",
    "    real = [[' '.join(k)] for k in real_raw]\n",
    "    \n",
    "    hypothesis = []\n",
    "    for i in range(0,len(prediction)):\n",
    "        value = prediction[i][0]\n",
    "        hypothesis.append(value)\n",
    "        \n",
    "    reference = []\n",
    "    for i in range(0,len(real)):\n",
    "        value = real[i][0]\n",
    "        reference.append(value)\n",
    "        \n",
    "    return hypothesis, reference\n",
    "\n",
    "\n",
    "\n",
    "hypothesis, reference =  prepare_inputs_for_rouge(predicted_summary_list, real_summary_raw)\n",
    "\n",
    "\n",
    "rouge = Rouge()\n",
    "Rouge_Score = rouge.get_scores(hypothesis, reference,avg=True)\n",
    "Rouge_Score\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard Visualization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recommended training the data in batches because of our tensor constraints. This also presents us with a challenge of visualizing loss function and accuracy change with each epoch. Keras has an inbuilt function called fit_generator which takes in a generator function and gives the required batch for training. Use this Function to load data in batches of 100 for 200 steps_per_epoch. Run the training for 10 epochs. Use Keras callbacks to send data to tensorboad (you can look this up online). \n",
    "\n",
    "Once your training is done. Go to command line and run tensorboard. By default Tensorboard opens on 6006 port. Do remember to allow traffic on the same for gcloud (like you did for previous assignment). You can see various metrics depending on what you want to track like loss, accuracy, validation loss and validation accuracy over epochs. Attach the plots of loss and accuracy from the tensorboard display in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TO-DO\n",
    "\n",
    "def generator(feature, mark, batch):\n",
    "    while True:\n",
    "        for i in range(0,len(feature),batch):\n",
    "            if i + batch >= len(feature):\n",
    "                j=len(feature)\n",
    "            else:\n",
    "                j=i+batch\n",
    "            y=mark[i:j]\n",
    "            one_hot= (np.arange(mark.max()+1) == y[...,None]).astype(int)# One Hot\n",
    "            print(feature[i:j])\n",
    "            yield (feature[i:j], one_hot)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "tbCallBack =  TensorBoard(log_dir='./graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "[[1892 7168    4 ...,    0    0    0]\n",
      " [3006 2446   14 ...,    0    0    0]\n",
      " [1170 2169 2080 ...,    0    0    0]\n",
      " ..., \n",
      " [ 726    7  191 ...,    0    0    0]\n",
      " [1231   70   68 ...,    0    0    0]\n",
      " [   2  293 1244 ...,    0    0    0]]\n",
      "[[   13 10823     7 ...,     0     0     0]\n",
      " [   13   435  7769 ...,     0     0     0]\n",
      " [   13    13     9 ...,     0     0     0]\n",
      " ..., \n",
      " [    2  1745  3196 ...,     0     0     0]\n",
      " [ 8017  1395     9 ...,     0     0     0]\n",
      " [    2    13   796 ...,     0     0     0]]\n",
      "[[   19   352     8 ...,     0     0     0]\n",
      " [  187     5  4712 ...,     0     0     0]\n",
      " [ 3222  7637    13 ...,     0     0     0]\n",
      " ..., \n",
      " [  500     7 10824 ...,     0     0     0]\n",
      " [   69   297    13 ...,     0     0     0]\n",
      " [ 1152  4028   252 ...,     0     0     0]]\n",
      "  1/200 [..............................] - ETA: 139s - loss: 1.5985 - acc: 0.8061[[8602    9 2859 ...,    0    0    0]\n",
      " [   2 6397    3 ...,    0    0    0]\n",
      " [3252   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 325 1063 1998 ...,    0    0    0]\n",
      " [   1  126 2437 ...,    0    0    0]\n",
      " [  13   13   14 ...,    0    0    0]]\n",
      "[[   1   99 4711 ...,    0    0    0]\n",
      " [ 154   66    6 ...,    0    0    0]\n",
      " [ 154   66    6 ...,    0    0    0]\n",
      " ..., \n",
      " [2288   13  105 ...,    0    0    0]\n",
      " [  15  748   90 ...,    0    0    0]\n",
      " [ 356  767  811 ...,    0    0    0]]\n",
      "[[    2   222 10613 ...,     0     0     0]\n",
      " [   10    63    13 ...,     0     0     0]\n",
      " [    1    13    32 ...,     0     0     0]\n",
      " ..., \n",
      " [   13    13   298 ...,     0     0     0]\n",
      " [   19   120   438 ...,     0     0     0]\n",
      " [   34    61  6449 ...,     0     0     0]]\n",
      "  2/200 [..............................] - ETA: 118s - loss: 1.6409 - acc: 0.8010[[  304  3255   103 ...,     0     0     0]\n",
      " [ 2379  7422     8 ...,     0     0     0]\n",
      " [10485 10333   100 ...,     0     0     0]\n",
      " ..., \n",
      " [    4    13   816 ...,     0     0     0]\n",
      " [   13     9    48 ...,     0     0     0]\n",
      " [  890  2211   114 ...,     0     0     0]]\n",
      "[[5267 2367   14 ...,    0    0    0]\n",
      " [ 108  104 2357 ...,    0    0    0]\n",
      " [   4    1  894 ...,    0    0    0]\n",
      " ..., \n",
      " [ 155  301  338 ...,    0    0    0]\n",
      " [ 377 4559   13 ...,    0    0    0]\n",
      " [   4  432   68 ...,    0    0    0]]\n",
      "[[  18    1 1558 ...,    0    0    0]\n",
      " [ 986 5031  703 ...,    0    0    0]\n",
      " [3001 6530 5388 ...,    0    0    0]\n",
      " ..., \n",
      " [1289   13    2 ...,    0    0    0]\n",
      " [ 406   13 8740 ...,    0    0    0]\n",
      " [   1  387 3348 ...,    0    0    0]]\n",
      "  3/200 [..............................] - ETA: 110s - loss: 1.6873 - acc: 0.7930[[ 3470    13   626 ...,     0     0     0]\n",
      " [ 7322     9  1842 ...,     0     0     0]\n",
      " [  483  4428    10 ...,     0     0     0]\n",
      " ..., \n",
      " [   13   391     5 ...,     0     0     0]\n",
      " [ 7029  2222    81 ...,     0     0     0]\n",
      " [10683  9535    11 ...,     0     0     0]]\n",
      "[[3822 3881    3 ...,    0    0    0]\n",
      " [ 103  280   13 ...,    0    0    0]\n",
      " [ 280 4960   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 670  559  114 ...,    0    0    0]\n",
      " [  47 1401 3981 ...,    0    0    0]\n",
      " [  34   74   13 ...,    0    0    0]]\n",
      "  4/200 [..............................] - ETA: 105s - loss: 1.7161 - acc: 0.7912[[   22  2086   255 ...,     0     0     0]\n",
      " [ 1360   585    13 ...,     0     0     0]\n",
      " [  514  2246    11 ...,     0     0     0]\n",
      " ..., \n",
      " [10878    13   219 ...,     0     0     0]\n",
      " [   12   366    13 ...,     0     0     0]\n",
      " [  535    15     7 ...,     0     0     0]]\n",
      "[[5707   13  141 ...,    0    0    0]\n",
      " [  70 1807   13 ...,    0    0    0]\n",
      " [  13   13  114 ...,    0    0    0]\n",
      " ..., \n",
      " [1577   13   11 ...,    0    0    0]\n",
      " [1562   13 1191 ...,    0    0    0]\n",
      " [6551   11   81 ...,    0    0    0]]\n",
      "[[   4   13 2514 ...,    0    0    0]\n",
      " [  34   61   13 ...,    0    0    0]\n",
      " [  69  263    9 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 1033   67 ...,    0    0    0]\n",
      " [  32  348    1 ...,    0    0    0]\n",
      " [  68  128   39 ...,    0    0    0]]\n",
      "  5/200 [..............................] - ETA: 102s - loss: 1.7454 - acc: 0.7869[[ 558    5 2055 ...,    0    0    0]\n",
      " [  10   13    8 ...,    0    0    0]\n",
      " [  15  448   29 ...,    0    0    0]\n",
      " ..., \n",
      " [6422   13  192 ...,    0    0    0]\n",
      " [2495    5   13 ...,    0    0    0]\n",
      " [   1 2407    5 ...,    0    0    0]]\n",
      "[[ 297   13  263 ...,    0    0    0]\n",
      " [  13  104   14 ...,    0    0    0]\n",
      " [  13  448    3 ...,    0    0    0]\n",
      " ..., \n",
      " [  15    7   48 ...,    0    0    0]\n",
      " [  89   23  177 ...,    0    0    0]\n",
      " [   2 1099   13 ...,    0    0    0]]\n",
      "  6/200 [..............................] - ETA: 99s - loss: 1.7300 - acc: 0.7888 [[ 347  110 7274 ...,    0    0    0]\n",
      " [ 432   13   13 ...,    0    0    0]\n",
      " [  80 2742 2468 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  679  527 ...,    0    0    0]\n",
      " [  15    7  282 ...,    0    0    0]\n",
      " [  13   26  106 ...,    0    0    0]]\n",
      "  7/200 [>.............................] - ETA: 97s - loss: 1.7355 - acc: 0.7888[[1563   13 1393 ...,    0    0    0]\n",
      " [ 104  898   99 ...,    0    0    0]\n",
      " [3432  605   13 ...,    0    0    0]\n",
      " ..., \n",
      " [6448   13   14 ...,    0    0    0]\n",
      " [   1 6322    5 ...,    0    0    0]\n",
      " [ 341   13  245 ...,    0    0    0]]\n",
      "  8/200 [>.............................] - ETA: 96s - loss: 1.7189 - acc: 0.7909[[ 380    7 4121 ...,    0    0    0]\n",
      " [ 140  609   26 ...,    0    0    0]\n",
      " [ 127  179  851 ...,    0    0    0]\n",
      " ..., \n",
      " [ 140  609   26 ...,    0    0    0]\n",
      " [ 355 4849   11 ...,    0    0    0]\n",
      " [7486   13    5 ...,    0    0    0]]\n",
      "  9/200 [>.............................] - ETA: 95s - loss: 1.6990 - acc: 0.7933[[   2 1261 2099 ...,    0    0    0]\n",
      " [   2  121 1421 ...,    0    0    0]\n",
      " [ 726  217  255 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [ 176   66 2512 ...,    0    0    0]\n",
      " [   1  468 2949 ...,    0    0    0]]\n",
      " 10/200 [>.............................] - ETA: 93s - loss: 1.6952 - acc: 0.7936[[ 38 481 176 ...,   0   0   0]\n",
      " [ 13  26 441 ...,   0   0   0]\n",
      " [187  66   6 ...,   0   0   0]\n",
      " ..., \n",
      " [284   7  26 ...,   0   0   0]\n",
      " [  1  13  91 ...,   0   0   0]\n",
      " [  1  13  91 ...,   0   0   0]]\n",
      " 11/200 [>.............................] - ETA: 92s - loss: 1.6917 - acc: 0.7942[[   1   13   91 ...,    0    0    0]\n",
      " [ 140  609   26 ...,    0    0    0]\n",
      " [   1  220   73 ...,    0    0    0]\n",
      " ..., \n",
      " [ 154   66 1215 ...,    0    0    0]\n",
      " [   2  179  680 ...,    0    0    0]\n",
      " [ 390   13   11 ...,    0    0    0]]\n",
      " 12/200 [>.............................] - ETA: 91s - loss: 1.6774 - acc: 0.7959[[  456  1542   662 ...,     0     0     0]\n",
      " [  131   547  1438 ...,     0     0     0]\n",
      " [ 2351    10     1 ...,     0     0     0]\n",
      " ..., \n",
      " [    1    13  3217 ...,     0     0     0]\n",
      " [   15    14 11683 ...,     0     0     0]\n",
      " [    1  1356     5 ...,     0     0     0]]\n",
      " 13/200 [>.............................] - ETA: 90s - loss: 1.6683 - acc: 0.7966[[  13   13   13 ...,    0    0    0]\n",
      " [ 751  103 4071 ...,    0    0    0]\n",
      " [  10 2939 3751 ...,    0    0    0]\n",
      " ..., \n",
      " [ 488    7  324 ...,    0    0    0]\n",
      " [  64   82   13 ...,    0    0    0]\n",
      " [   1  412 1011 ...,    0    0    0]]\n",
      " 14/200 [=>............................] - ETA: 89s - loss: 1.6608 - acc: 0.7977[[   1 1660 2134 ...,    0    0    0]\n",
      " [  13  956 4275 ...,    0    0    0]\n",
      " [ 111    4    1 ...,    0    0    0]\n",
      " ..., \n",
      " [3289   30   24 ...,    0    0    0]\n",
      " [2095  745 2520 ...,    0    0    0]\n",
      " [5171   66  115 ...,    0    0    0]]\n",
      " 15/200 [=>............................] - ETA: 88s - loss: 1.6544 - acc: 0.7986[[    1   736  1616 ...,     0     0     0]\n",
      " [ 4701 10213     9 ...,     0     0     0]\n",
      " [    2   866  3775 ...,     0     0     0]\n",
      " ..., \n",
      " [   55     6    57 ...,     0     0     0]\n",
      " [    2  1649  1715 ...,     0     0     0]\n",
      " [   19   120    13 ...,     0     0     0]]\n",
      " 16/200 [=>............................] - ETA: 87s - loss: 1.6529 - acc: 0.7989[[ 585 9701 6296 ...,    0    0    0]\n",
      " [3626 2067   13 ...,    0    0    0]\n",
      " [   1   91  106 ...,    0    0    0]\n",
      " ..., \n",
      " [  66    6    1 ...,    0    0    0]\n",
      " [5527 5689    9 ...,    0    0    0]\n",
      " [   1   47   49 ...,    0    0    0]]\n",
      " 17/200 [=>............................] - ETA: 87s - loss: 1.6466 - acc: 0.7996[[ 1635 11261     8 ...,     0     0     0]\n",
      " [    1  3005  1719 ...,     0     0     0]\n",
      " [  109    26   115 ...,     0     0     0]\n",
      " ..., \n",
      " [  109    26   113 ...,     0     0     0]\n",
      " [   90   194  1044 ...,     0     0     0]\n",
      " [ 1287    13    81 ...,     0     0     0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 18/200 [=>............................] - ETA: 86s - loss: 1.6415 - acc: 0.8000[[2425    8   55 ...,    0    0    0]\n",
      " [2309 3927   11 ...,    0    0    0]\n",
      " [ 173 4190   10 ...,    0    0    0]\n",
      " ..., \n",
      " [1822   13    9 ...,    0    0    0]\n",
      " [3061   13   13 ...,    0    0    0]\n",
      " [   1  261   13 ...,    0    0    0]]\n",
      " 19/200 [=>............................] - ETA: 86s - loss: 1.6215 - acc: 0.8017[[   2  904  405 ...,    0    0    0]\n",
      " [3062  196 9581 ...,    0    0    0]\n",
      " [  13   13   27 ...,    0    0    0]\n",
      " ..., \n",
      " [ 681  187  399 ...,    0    0    0]\n",
      " [   1  126  198 ...,    0    0    0]\n",
      " [ 131  456 1127 ...,    0    0    0]]\n",
      " 20/200 [==>...........................] - ETA: 85s - loss: 1.6030 - acc: 0.8032[[ 276  178   13 ...,    0    0    0]\n",
      " [ 154   66   67 ...,    0    0    0]\n",
      " [  13    1 3430 ...,    0    0    0]\n",
      " ..., \n",
      " [6341 5974    7 ...,    0    0    0]\n",
      " [   1  263 1691 ...,    0    0    0]\n",
      " [   2   37  144 ...,    0    0    0]]\n",
      " 21/200 [==>...........................] - ETA: 84s - loss: 1.5839 - acc: 0.8047[[  15    7  166 ...,    0    0    0]\n",
      " [1811  217  514 ...,    0    0    0]\n",
      " [ 267  157   92 ...,    0    0    0]\n",
      " ..., \n",
      " [3718   29  337 ...,    0    0    0]\n",
      " [   4    2  188 ...,    0    0    0]\n",
      " [  54    2   94 ...,    0    0    0]]\n",
      " 22/200 [==>...........................] - ETA: 84s - loss: 1.5720 - acc: 0.8055[[   2 8865  819 ...,    0    0    0]\n",
      " [  18   15 3368 ...,    0    0    0]\n",
      " [ 302   11  319 ...,    0    0    0]\n",
      " ..., \n",
      " [   4    2   13 ...,    0    0    0]\n",
      " [  13 9772   13 ...,    0    0    0]\n",
      " [ 592 8142    1 ...,    0    0    0]]\n",
      " 23/200 [==>...........................] - ETA: 83s - loss: 1.5695 - acc: 0.8058[[  13   13   68 ...,    0    0    0]\n",
      " [  10  888   13 ...,    0    0    0]\n",
      " [9482  486  240 ...,    0    0    0]\n",
      " ..., \n",
      " [ 108  210 1468 ...,    0    0    0]\n",
      " [2797 4459    9 ...,    0    0    0]\n",
      " [1068 4127  247 ...,    0    0    0]]\n",
      " 24/200 [==>...........................] - ETA: 82s - loss: 1.5787 - acc: 0.8049[[8163 8613 5159 ...,    0    0    0]\n",
      " [3484  610   86 ...,    0    0    0]\n",
      " [  18    2  153 ...,    0    0    0]\n",
      " ..., \n",
      " [  10    2 3037 ...,    0    0    0]\n",
      " [1068 9485  192 ...,    0    0    0]\n",
      " [3079 3363    9 ...,    0    0    0]]\n",
      " 25/200 [==>...........................] - ETA: 82s - loss: 1.5802 - acc: 0.8046[[ 535 1398   13 ...,    0    0    0]\n",
      " [ 300   21    1 ...,    0    0    0]\n",
      " [ 108   68   23 ...,    0    0    0]\n",
      " ..., \n",
      " [   8  155   10 ...,    0    0    0]\n",
      " [ 535    1 3423 ...,    0    0    0]\n",
      " [4571 2417  703 ...,    0    0    0]]\n",
      " 26/200 [==>...........................] - ETA: 81s - loss: 1.5799 - acc: 0.8047[[ 1740  1635    13 ...,     0     0     0]\n",
      " [ 1019   747 10354 ...,     0     0     0]\n",
      " [   89    27    20 ...,     0     0     0]\n",
      " ..., \n",
      " [   80  2199    13 ...,     0     0     0]\n",
      " [    1  3089    23 ...,     0     0     0]\n",
      " [    4     1   264 ...,     0     0     0]]\n",
      " 27/200 [===>..........................] - ETA: 81s - loss: 1.5818 - acc: 0.8045[[  93  724   90 ...,    0    0    0]\n",
      " [2309 3927  684 ...,    0    0    0]\n",
      " [   2 2437    5 ...,    0    0    0]\n",
      " ..., \n",
      " [ 174  446   13 ...,    0    0    0]\n",
      " [5338 4002    7 ...,    0    0    0]\n",
      " [   1   25 3212 ...,    0    0    0]]\n",
      " 28/200 [===>..........................] - ETA: 80s - loss: 1.5887 - acc: 0.8036[[  13 8440  523 ...,    0    0    0]\n",
      " [ 763 6237 1934 ...,    0    0    0]\n",
      " [ 203 1646   79 ...,    0    0    0]\n",
      " ..., \n",
      " [  12   13   13 ...,    0    0    0]\n",
      " [ 730   13 1846 ...,    0    0    0]\n",
      " [ 104  114   48 ...,    0    0    0]]\n",
      " 29/200 [===>..........................] - ETA: 80s - loss: 1.5976 - acc: 0.8025[[  89    7   22 ...,    0    0    0]\n",
      " [  15    7   48 ...,    0    0    0]\n",
      " [  13   26  115 ...,    0    0    0]\n",
      " ..., \n",
      " [ 406    7 1265 ...,    0    0    0]\n",
      " [ 770  299    5 ...,    0    0    0]\n",
      " [  78   94   13 ...,    0    0    0]]\n",
      " 30/200 [===>..........................] - ETA: 79s - loss: 1.5912 - acc: 0.8034[[  13   63  144 ...,    0    0    0]\n",
      " [  15    9   80 ...,    0    0    0]\n",
      " [   1  167  191 ...,    0    0    0]\n",
      " ..., \n",
      " [   3   20 1560 ...,    0    0    0]\n",
      " [   1 1274  276 ...,    0    0    0]\n",
      " [  13  114  155 ...,    0    0    0]]\n",
      " 31/200 [===>..........................] - ETA: 78s - loss: 1.5975 - acc: 0.8028[[   70    13 11859 ...,     0     0     0]\n",
      " [   80    41    14 ...,     0     0     0]\n",
      " [  232  3054   384 ...,     0     0     0]\n",
      " ..., \n",
      " [ 1931  1772    29 ...,     0     0     0]\n",
      " [ 1382  1963    11 ...,     0     0     0]\n",
      " [  698  5800  1429 ...,     0     0     0]]\n",
      " 32/200 [===>..........................] - ETA: 78s - loss: 1.5964 - acc: 0.8029[[   1  177   70 ...,    0    0    0]\n",
      " [  41  330  674 ...,    0    0    0]\n",
      " [ 104   14  233 ...,    0    0    0]\n",
      " ..., \n",
      " [ 194   63  144 ...,    0    0    0]\n",
      " [  13  104 1619 ...,    0    0    0]\n",
      " [ 245 1225   13 ...,    0    0    0]]\n",
      " 33/200 [===>..........................] - ETA: 77s - loss: 1.5922 - acc: 0.8037[[1226   97   13 ...,    0    0    0]\n",
      " [1233 3058   25 ...,    0    0    0]\n",
      " [  10  402   13 ...,    0    0    0]\n",
      " ..., \n",
      " [  15   14    2 ...,    0    0    0]\n",
      " [1401 8027   81 ...,    0    0    0]\n",
      " [  13 1049   13 ...,    0    0    0]]\n",
      " 34/200 [====>.........................] - ETA: 77s - loss: 1.5929 - acc: 0.8037[[ 503    9  305 ...,    0    0    0]\n",
      " [1629    1 1798 ...,    0    0    0]\n",
      " [ 565    1  189 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [ 547   69 4400 ...,    0    0    0]\n",
      " [   1 1276 3182 ...,    0    0    0]]\n",
      " 35/200 [====>.........................] - ETA: 76s - loss: 1.5938 - acc: 0.8035[[3158  217 1453 ...,    0    0    0]\n",
      " [   1  261 2012 ...,    0    0    0]\n",
      " [  13  167  523 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [ 167 6286 4386 ...,    0    0    0]\n",
      " [   1   13 3414 ...,    0    0    0]]\n",
      " 36/200 [====>.........................] - ETA: 76s - loss: 1.5907 - acc: 0.8039[[   1 2230  199 ...,    0    0    0]\n",
      " [   1  220   73 ...,    0    0    0]\n",
      " [2553  594  205 ...,    0    0    0]\n",
      " ..., \n",
      " [  55   27 2904 ...,    0    0    0]\n",
      " [ 274   55    7 ...,    0    0    0]\n",
      " [   1   13   91 ...,    0    0    0]]\n",
      " 37/200 [====>.........................] - ETA: 75s - loss: 1.5890 - acc: 0.8041[[   1   13   91 ...,    0    0    0]\n",
      " [ 481   66  106 ...,    0    0    0]\n",
      " [ 456  121   26 ...,    0    0    0]\n",
      " ..., \n",
      " [  13    3 7124 ...,    0    0    0]\n",
      " [ 599 1780   23 ...,    0    0    0]\n",
      " [ 422  755  312 ...,    0    0    0]]\n",
      " 38/200 [====>.........................] - ETA: 75s - loss: 1.5876 - acc: 0.8043[[2032  610  168 ...,    0    0    0]\n",
      " [ 232 1991    4 ...,    0    0    0]\n",
      " [  49  102  112 ...,    0    0    0]\n",
      " ..., \n",
      " [ 150 2695  947 ...,    0    0    0]\n",
      " [   2 3709   13 ...,    0    0    0]\n",
      " [  92 2036  462 ...,    0    0    0]]\n",
      " 39/200 [====>.........................] - ETA: 74s - loss: 1.5877 - acc: 0.8043[[5401 3039   13 ...,    0    0    0]\n",
      " [  34    9   41 ...,    0    0    0]\n",
      " [1082  295  353 ...,    0    0    0]\n",
      " ..., \n",
      " [4748 2617  141 ...,    0    0    0]\n",
      " [  10  697 1295 ...,    0    0    0]\n",
      " [   1  547 6865 ...,    0    0    0]]\n",
      " 40/200 [=====>........................] - ETA: 74s - loss: 1.5880 - acc: 0.8043[[  37   56   37 ...,    0    0    0]\n",
      " [ 880  903   92 ...,    0    0    0]\n",
      " [4008   43 3511 ...,    0    0    0]\n",
      " ..., \n",
      " [ 347   61    2 ...,    0    0    0]\n",
      " [ 654  145   11 ...,    0    0    0]\n",
      " [ 456  119   21 ...,    0    0    0]]\n",
      " 41/200 [=====>........................] - ETA: 73s - loss: 1.5893 - acc: 0.8042[[   4    1 3064 ...,    0    0    0]\n",
      " [  12 5230   13 ...,    0    0    0]\n",
      " [ 246   11 4044 ...,    0    0    0]\n",
      " ..., \n",
      " [  13    4 1453 ...,    0    0    0]\n",
      " [1109  332 8047 ...,    0    0    0]\n",
      " [  13 9504 5172 ...,    0    0    0]]\n",
      " 42/200 [=====>........................] - ETA: 73s - loss: 1.5883 - acc: 0.8044[[ 685   38   62 ...,    0    0    0]\n",
      " [ 913    7 3013 ...,    0    0    0]\n",
      " [ 224    7 4494 ...,    0    0    0]\n",
      " ..., \n",
      " [ 416   13    1 ...,    0    0    0]\n",
      " [3350 2858    9 ...,    0    0    0]\n",
      " [   1  682  189 ...,    0    0    0]]\n",
      " 43/200 [=====>........................] - ETA: 72s - loss: 1.5885 - acc: 0.8045[[ 1149  5222  1429 ...,     0     0     0]\n",
      " [   99   881  2396 ...,     0     0     0]\n",
      " [  726   419     3 ...,     0     0     0]\n",
      " ..., \n",
      " [    2  2011    16 ...,     0     0     0]\n",
      " [  967   130  3006 ...,     0     0     0]\n",
      " [10699    11   130 ...,     0     0     0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 44/200 [=====>........................] - ETA: 72s - loss: 1.5885 - acc: 0.8045[[   2   13  405 ...,    0    0    0]\n",
      " [   1  221  230 ...,    0    0    0]\n",
      " [3847 8196    3 ...,    0    0    0]\n",
      " ..., \n",
      " [   2  361    5 ...,    0    0    0]\n",
      " [  48  171    1 ...,    0    0    0]\n",
      " [  10  116  203 ...,    0    0    0]]\n",
      " 45/200 [=====>........................] - ETA: 71s - loss: 1.5830 - acc: 0.8050[[ 150 8632  390 ...,    0    0    0]\n",
      " [1469  995    8 ...,    0    0    0]\n",
      " [  19  120  117 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  916  336 ...,    0    0    0]\n",
      " [   1 1797  610 ...,    0    0    0]\n",
      " [ 321   10  343 ...,    0    0    0]]\n",
      " 46/200 [=====>........................] - ETA: 71s - loss: 1.5760 - acc: 0.8055[[1062   11   45 ...,    0    0    0]\n",
      " [  18   42 1535 ...,    0    0    0]\n",
      " [   2   19 1811 ...,    0    0    0]\n",
      " ..., \n",
      " [ 665  473   13 ...,    0    0    0]\n",
      " [4488   13 3072 ...,    0    0    0]\n",
      " [   1   78  360 ...,    0    0    0]]\n",
      " 47/200 [======>.......................] - ETA: 71s - loss: 1.5686 - acc: 0.8062[[   2   13   14 ...,    0    0    0]\n",
      " [2909  168   41 ...,    0    0    0]\n",
      " [ 257   15   32 ...,    0    0    0]\n",
      " ..., \n",
      " [5409   11 1048 ...,    0    0    0]\n",
      " [ 246  604 5651 ...,    0    0    0]\n",
      " [ 248  604 5651 ...,    0    0    0]]\n",
      " 48/200 [======>.......................] - ETA: 70s - loss: 1.5644 - acc: 0.8066[[   13 11979     9 ...,     0     0     0]\n",
      " [  978   967     7 ...,     0     0     0]\n",
      " [    2  1346  2405 ...,     0     0     0]\n",
      " ..., \n",
      " [   89     7   586 ...,     0     0     0]\n",
      " [  232    13  3269 ...,     0     0     0]\n",
      " [  347   259    63 ...,     0     0     0]]\n",
      " 49/200 [======>.......................] - ETA: 70s - loss: 1.5640 - acc: 0.8066[[ 2894 11190    13 ...,     0     0     0]\n",
      " [    1  4282     8 ...,     0     0     0]\n",
      " [ 2900    13     7 ...,     0     0     0]\n",
      " ..., \n",
      " [   18     2  1884 ...,     0     0     0]\n",
      " [   15     7     1 ...,     0     0     0]\n",
      " [    1  2233    29 ...,     0     0     0]]\n",
      " 50/200 [======>.......................] - ETA: 69s - loss: 1.5650 - acc: 0.8065[[7006 1123   13 ...,    0    0    0]\n",
      " [4209  971    9 ...,    0    0    0]\n",
      " [  70 2215  231 ...,    0    0    0]\n",
      " ..., \n",
      " [  13 2230   13 ...,    0    0    0]\n",
      " [  23   13  136 ...,    0    0    0]\n",
      " [ 730   13  108 ...,    0    0    0]]\n",
      " 51/200 [======>.......................] - ETA: 69s - loss: 1.5687 - acc: 0.8061[[10549    13    11 ...,     0     0     0]\n",
      " [ 2820  6055   530 ...,     0     0     0]\n",
      " [  523  5302    13 ...,     0     0     0]\n",
      " ..., \n",
      " [  202    71     7 ...,     0     0     0]\n",
      " [   32     1    47 ...,     0     0     0]\n",
      " [    1  1238   336 ...,     0     0     0]]\n",
      " 52/200 [======>.......................] - ETA: 68s - loss: 1.5699 - acc: 0.8059[[   34     9     1 ...,     0     0     0]\n",
      " [    1  6327     7 ...,     0     0     0]\n",
      " [   89     9     2 ...,     0     0     0]\n",
      " ..., \n",
      " [   13 10095    44 ...,     0     0     0]\n",
      " [  406    13  7620 ...,     0     0     0]\n",
      " [    1   845   770 ...,     0     0     0]]\n",
      " 53/200 [======>.......................] - ETA: 68s - loss: 1.5687 - acc: 0.8061[[ 379   23 3609 ...,    0    0    0]\n",
      " [  10 1196   13 ...,    0    0    0]\n",
      " [ 166    2  259 ...,    0    0    0]\n",
      " ..., \n",
      " [ 133   39 1165 ...,    0    0    0]\n",
      " [   1 3703   11 ...,    0    0    0]\n",
      " [   1  823 5216 ...,    0    0    0]]\n",
      " 54/200 [=======>......................] - ETA: 67s - loss: 1.5724 - acc: 0.8056[[ 244 2381  123 ...,    0    0    0]\n",
      " [ 409  192    2 ...,    0    0    0]\n",
      " [  13 1825    9 ...,    0    0    0]\n",
      " ..., \n",
      " [1892 7257    9 ...,    0    0    0]\n",
      " [1328   13   83 ...,    0    0    0]\n",
      " [   1  175 5681 ...,    0    0    0]]\n",
      " 55/200 [=======>......................] - ETA: 67s - loss: 1.5757 - acc: 0.8053[[  54  234   63 ...,    0    0    0]\n",
      " [   1 1341   21 ...,    0    0    0]\n",
      " [  15  448   29 ...,    0    0    0]\n",
      " ..., \n",
      " [   4    1  645 ...,    0    0    0]\n",
      " [5542 2931   14 ...,    0    0    0]\n",
      " [ 586    9   18 ...,    0    0    0]]\n",
      " 56/200 [=======>......................] - ETA: 66s - loss: 1.5822 - acc: 0.8046[[1265    3 2312 ...,    0    0    0]\n",
      " [   1 2456 2248 ...,    0    0    0]\n",
      " [  13  301   23 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 4946   21 ...,    0    0    0]\n",
      " [1209   13  574 ...,    0    0    0]\n",
      " [  69  451   83 ...,    0    0    0]]\n",
      " 57/200 [=======>......................] - ETA: 66s - loss: 1.5823 - acc: 0.8047[[   4 1097   13 ...,    0    0    0]\n",
      " [1070 2004   23 ...,    0    0    0]\n",
      " [5232  247 1268 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   13    9 ...,    0    0    0]\n",
      " [ 171   43 7345 ...,    0    0    0]\n",
      " [ 137    2 7421 ...,    0    0    0]]\n",
      " 58/200 [=======>......................] - ETA: 65s - loss: 1.5853 - acc: 0.8043[[   13    13  3647 ...,     0     0     0]\n",
      " [   13 11605     9 ...,     0     0     0]\n",
      " [  181    13   105 ...,     0     0     0]\n",
      " ..., \n",
      " [ 4851    13 10762 ...,     0     0     0]\n",
      " [ 9718     5     2 ...,     0     0     0]\n",
      " [   89     9   693 ...,     0     0     0]]\n",
      " 59/200 [=======>......................] - ETA: 65s - loss: 1.5829 - acc: 0.8047[[  13 1442   13 ...,    0    0    0]\n",
      " [2461   13    9 ...,    0    0    0]\n",
      " [  13 1442   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 951    2 1118 ...,    0    0    0]\n",
      " [   1   13   98 ...,    0    0    0]\n",
      " [  17  431   14 ...,    0    0    0]]\n",
      " 60/200 [========>.....................] - ETA: 64s - loss: 1.5810 - acc: 0.8050[[   4   22 2404 ...,    0    0    0]\n",
      " [1925   11 1243 ...,    0    0    0]\n",
      " [1287   13 5519 ...,    0    0    0]\n",
      " ..., \n",
      " [ 318    9 2492 ...,    0    0    0]\n",
      " [   2   13 1300 ...,    0    0    0]\n",
      " [   1   13   38 ...,    0    0    0]]\n",
      " 61/200 [========>.....................] - ETA: 64s - loss: 1.5824 - acc: 0.8048[[6214  172   41 ...,    0    0    0]\n",
      " [4280  292   40 ...,    0    0    0]\n",
      " [2192   55    7 ...,    0    0    0]\n",
      " ..., \n",
      " [ 226  217  140 ...,    0    0    0]\n",
      " [3608  119   13 ...,    0    0    0]\n",
      " [ 373  423   55 ...,    0    0    0]]\n",
      " 62/200 [========>.....................] - ETA: 63s - loss: 1.5831 - acc: 0.8048[[ 318    7   49 ...,    0    0    0]\n",
      " [  13   26  922 ...,    0    0    0]\n",
      " [  55   11   13 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  220  527 ...,    0    0    0]\n",
      " [   1  422 2108 ...,    0    0    0]\n",
      " [  55    7  682 ...,    0    0    0]]\n",
      " 63/200 [========>.....................] - ETA: 63s - loss: 1.5835 - acc: 0.8047[[  456   307   867 ...,     0     0     0]\n",
      " [   73   240     4 ...,     0     0     0]\n",
      " [ 3906    69 11375 ...,     0     0     0]\n",
      " ..., \n",
      " [    1    13    91 ...,     0     0     0]\n",
      " [    1   547   732 ...,     0     0     0]\n",
      " [   13   275    99 ...,     0     0     0]]\n",
      " 64/200 [========>.....................] - ETA: 62s - loss: 1.5843 - acc: 0.8046[[ 632   47  867 ...,    0    0    0]\n",
      " [1005   11 1492 ...,    0    0    0]\n",
      " [   2 4390   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 140  583  100 ...,    0    0    0]\n",
      " [  19  352  187 ...,    0    0    0]\n",
      " [   1   19  352 ...,    0    0    0]]\n",
      " 65/200 [========>.....................] - ETA: 62s - loss: 1.5836 - acc: 0.8047[[ 884    8  491 ...,    0    0    0]\n",
      " [ 176   66  106 ...,    0    0    0]\n",
      " [  13   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  823 1876 ...,    0    0    0]\n",
      " [   1  180    7 ...,    0    0    0]\n",
      " [2176 3115   23 ...,    0    0    0]]\n",
      " 66/200 [========>.....................] - ETA: 61s - loss: 1.5849 - acc: 0.8046[[   3 1428  159 ...,    0    0    0]\n",
      " [  15    7 7374 ...,    0    0    0]\n",
      " [ 717 3637  256 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13 1438 ...,    0    0    0]\n",
      " [1390 2704 3787 ...,    0    0    0]\n",
      " [1219   17 2281 ...,    0    0    0]]\n",
      " 67/200 [=========>....................] - ETA: 61s - loss: 1.5837 - acc: 0.8048[[ 585 3731 1002 ...,    0    0    0]\n",
      " [   1   38 6760 ...,    0    0    0]\n",
      " [   1 5327  499 ...,    0    0    0]\n",
      " ..., \n",
      " [  89    7   80 ...,    0    0    0]\n",
      " [   2 3717  146 ...,    0    0    0]\n",
      " [   2 4572 1129 ...,    0    0    0]]\n",
      " 68/200 [=========>....................] - ETA: 60s - loss: 1.5841 - acc: 0.8047[[  66    6    1 ...,    0    0    0]\n",
      " [1446   13   23 ...,    0    0    0]\n",
      " [  22  405   16 ...,    0    0    0]\n",
      " ..., \n",
      " [1577 2630   14 ...,    0    0    0]\n",
      " [ 221  230  659 ...,    0    0    0]\n",
      " [ 132   73  240 ...,    0    0    0]]\n",
      " 69/200 [=========>....................] - ETA: 60s - loss: 1.5848 - acc: 0.8046[[   1 3845   11 ...,    0    0    0]\n",
      " [   1 1753 1634 ...,    0    0    0]\n",
      " [  26  115    4 ...,    0    0    0]\n",
      " ..., \n",
      " [ 545   69 5333 ...,    0    0    0]\n",
      " [ 300  133    1 ...,    0    0    0]\n",
      " [2461 8349    9 ...,    0    0    0]]\n",
      " 70/200 [=========>....................] - ETA: 59s - loss: 1.5838 - acc: 0.8048[[ 350  289  129 ...,    0    0    0]\n",
      " [   1 1015    5 ...,    0    0    0]\n",
      " [ 170 1599   32 ...,    0    0    0]\n",
      " ..., \n",
      " [1822   13    7 ...,    0    0    0]\n",
      " [ 108   15   14 ...,    0    0    0]\n",
      " [ 280 1987   14 ...,    0    0    0]]\n",
      " 71/200 [=========>....................] - ETA: 59s - loss: 1.5810 - acc: 0.8050[[9077   50  173 ...,    0    0    0]\n",
      " [1961 2587   11 ...,    0    0    0]\n",
      " [3697  119  157 ...,    0    0    0]\n",
      " ..., \n",
      " [1486  299    5 ...,    0    0    0]\n",
      " [7828   13   11 ...,    0    0    0]\n",
      " [ 496   11 1220 ...,    0    0    0]]\n",
      " 72/200 [=========>....................] - ETA: 58s - loss: 1.5768 - acc: 0.8054[[ 355   13   11 ...,    0    0    0]\n",
      " [ 284  941 1465 ...,    0    0    0]\n",
      " [   1 1054    6 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   11 3565 ...,    0    0    0]\n",
      " [  17   13   83 ...,    0    0    0]\n",
      " [ 126  264    7 ...,    0    0    0]]\n",
      " 73/200 [=========>....................] - ETA: 58s - loss: 1.5724 - acc: 0.8057[[    1   567   522 ...,     0     0     0]\n",
      " [    2    19   352 ...,     0     0     0]\n",
      " [  166    13    13 ...,     0     0     0]\n",
      " ..., \n",
      " [  812  1064 10285 ...,     0     0     0]\n",
      " [   13  1512    11 ...,     0     0     0]\n",
      " [ 1911  5863    11 ...,     0     0     0]]\n",
      " 74/200 [==========>...................] - ETA: 57s - loss: 1.5685 - acc: 0.8061[[   13  2060  8660 ...,     0     0     0]\n",
      " [   13  3523  5816 ...,     0     0     0]\n",
      " [   13  1149 11626 ...,     0     0     0]\n",
      " ..., \n",
      " [  443    13    81 ...,     0     0     0]\n",
      " [    1  2791    27 ...,     0     0     0]\n",
      " [  978   967   604 ...,     0     0     0]]\n",
      " 75/200 [==========>...................] - ETA: 57s - loss: 1.5656 - acc: 0.8064[[    4   347   793 ...,     0     0     0]\n",
      " [ 8530    13    27 ...,     0     0     0]\n",
      " [  599    13   112 ...,     0     0     0]\n",
      " ..., \n",
      " [   32 10814     3 ...,     0     0     0]\n",
      " [ 2704  6929     7 ...,     0     0     0]\n",
      " [  348     2   846 ...,     0     0     0]]\n",
      " 76/200 [==========>...................] - ETA: 56s - loss: 1.5652 - acc: 0.8064[[ 108 4250    9 ...,    0    0    0]\n",
      " [ 301 8908 7838 ...,    0    0    0]\n",
      " [6110  222 2838 ...,    0    0    0]\n",
      " ..., \n",
      " [ 276  178   13 ...,    0    0    0]\n",
      " [ 102 7048   29 ...,    0    0    0]\n",
      " [3012    8 9083 ...,    0    0    0]]\n",
      " 77/200 [==========>...................] - ETA: 56s - loss: 1.5672 - acc: 0.8062[[   68   471    39 ...,     0     0     0]\n",
      " [11204    11   269 ...,     0     0     0]\n",
      " [ 7859  1562    13 ...,     0     0     0]\n",
      " ..., \n",
      " [   15    11    45 ...,     0     0     0]\n",
      " [   75    13  4214 ...,     0     0     0]\n",
      " [   13     1   801 ...,     0     0     0]]\n",
      " 78/200 [==========>...................] - ETA: 56s - loss: 1.5679 - acc: 0.8061[[    4    13    13 ...,     0     0     0]\n",
      " [11258    13    13 ...,     0     0     0]\n",
      " [ 3664    13    11 ...,     0     0     0]\n",
      " ..., \n",
      " [   80  1327    29 ...,     0     0     0]\n",
      " [  108    68  1573 ...,     0     0     0]\n",
      " [   10   116     5 ...,     0     0     0]]\n",
      " 79/200 [==========>...................] - ETA: 55s - loss: 1.5689 - acc: 0.8060[[   2 7796    3 ...,    0    0    0]\n",
      " [ 301   79   21 ...,    0    0    0]\n",
      " [1720   13 3192 ...,    0    0    0]\n",
      " ..., \n",
      " [  70  291 1018 ...,    0    0    0]\n",
      " [  10   63   13 ...,    0    0    0]\n",
      " [3604   13   14 ...,    0    0    0]]\n",
      " 80/200 [===========>..................] - ETA: 55s - loss: 1.5687 - acc: 0.8060[[  34    9    2 ...,    0    0    0]\n",
      " [3309   13   10 ...,    0    0    0]\n",
      " [3138  192   39 ...,    0    0    0]\n",
      " ..., \n",
      " [9776  744    3 ...,    0    0    0]\n",
      " [  32    1  908 ...,    0    0    0]\n",
      " [  33   13 1218 ...,    0    0    0]]\n",
      " 81/200 [===========>..................] - ETA: 54s - loss: 1.5716 - acc: 0.8057[[   1 9590  397 ...,    0    0    0]\n",
      " [ 803 3021  103 ...,    0    0    0]\n",
      " [ 564   13  297 ...,    0    0    0]\n",
      " ..., \n",
      " [ 558    5 2142 ...,    0    0    0]\n",
      " [ 171   70  644 ...,    0    0    0]\n",
      " [  70   15  392 ...,    0    0    0]]\n",
      " 82/200 [===========>..................] - ETA: 54s - loss: 1.5736 - acc: 0.8054[[  18    1   13 ...,    0    0    0]\n",
      " [  15    9 7198 ...,    0    0    0]\n",
      " [  15   11   45 ...,    0    0    0]\n",
      " ..., \n",
      " [1381 9770    3 ...,    0    0    0]\n",
      " [6832   13 1864 ...,    0    0    0]\n",
      " [1621  546    9 ...,    0    0    0]]\n",
      " 83/200 [===========>..................] - ETA: 53s - loss: 1.5779 - acc: 0.8050[[  15   11  147 ...,    0    0    0]\n",
      " [  70   15 1648 ...,    0    0    0]\n",
      " [1635   13  265 ...,    0    0    0]\n",
      " ..., \n",
      " [2069    7 1818 ...,    0    0    0]\n",
      " [  68  114 1523 ...,    0    0    0]\n",
      " [   1 1996    5 ...,    0    0    0]]\n",
      " 84/200 [===========>..................] - ETA: 53s - loss: 1.5774 - acc: 0.8051[[    1  1825     5 ...,     0     0     0]\n",
      " [   16    41   826 ...,     0     0     0]\n",
      " [ 1066  2530     8 ...,     0     0     0]\n",
      " ..., \n",
      " [   13  3328    44 ...,     0     0     0]\n",
      " [   32    79 11010 ...,     0     0     0]\n",
      " [  730    13   227 ...,     0     0     0]]\n",
      " 85/200 [===========>..................] - ETA: 52s - loss: 1.5797 - acc: 0.8047[[   15     7     2 ...,     0     0     0]\n",
      " [  108    68    21 ...,     0     0     0]\n",
      " [ 3903   105   505 ...,     0     0     0]\n",
      " ..., \n",
      " [    2   188   144 ...,     0     0     0]\n",
      " [    1   493  2588 ...,     0     0     0]\n",
      " [11730   303   102 ...,     0     0     0]]\n",
      " 86/200 [===========>..................] - ETA: 52s - loss: 1.5801 - acc: 0.8047[[  13   68  574 ...,    0    0    0]\n",
      " [ 159   13  336 ...,    0    0    0]\n",
      " [  53    9    1 ...,    0    0    0]\n",
      " ..., \n",
      " [1236    3    1 ...,    0    0    0]\n",
      " [  13  141   39 ...,    0    0    0]\n",
      " [ 443 1112    7 ...,    0    0    0]]\n",
      " 87/200 [============>.................] - ETA: 51s - loss: 1.5794 - acc: 0.8049[[ 2905    51  1765 ...,     0     0     0]\n",
      " [ 7920    13    11 ...,     0     0     0]\n",
      " [11831   695     6 ...,     0     0     0]\n",
      " ..., \n",
      " [  109    26    65 ...,     0     0     0]\n",
      " [    2   426  2162 ...,     0     0     0]\n",
      " [ 6620  6804   100 ...,     0     0     0]]\n",
      " 88/200 [============>.................] - ETA: 51s - loss: 1.5803 - acc: 0.8048[[ 154   66    6 ...,    0    0    0]\n",
      " [  58   59 2805 ...,    0    0    0]\n",
      " [   1  785  115 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 1896  119 ...,    0    0    0]\n",
      " [  78   37   13 ...,    0    0    0]\n",
      " [   2   13    5 ...,    0    0    0]]\n",
      " 89/200 [============>.................] - ETA: 50s - loss: 1.5801 - acc: 0.8048[[   2  258    5 ...,    0    0    0]\n",
      " [  13   26  441 ...,    0    0    0]\n",
      " [  55    7 2803 ...,    0    0    0]\n",
      " ..., \n",
      " [ 219   26  441 ...,    0    0    0]\n",
      " [2928 2633    6 ...,    0    0    0]\n",
      " [ 116  191   13 ...,    0    0    0]]\n",
      " 90/200 [============>.................] - ETA: 50s - loss: 1.5798 - acc: 0.8049[[   1 1276 3182 ...,    0    0    0]\n",
      " [  38  176   66 ...,    0    0    0]\n",
      " [   1 1276 3182 ...,    0    0    0]\n",
      " ..., \n",
      " [  13 4441    5 ...,    0    0    0]\n",
      " [2253  808  514 ...,    0    0    0]\n",
      " [  13   26  113 ...,    0    0    0]]\n",
      " 91/200 [============>.................] - ETA: 49s - loss: 1.5792 - acc: 0.8049[[ 131 2788 2973 ...,    0    0    0]\n",
      " [ 109   26  101 ...,    0    0    0]\n",
      " [   2   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [1390 2704 3787 ...,    0    0    0]\n",
      " [1827 1582   10 ...,    0    0    0]\n",
      " [   1  236  477 ...,    0    0    0]]\n",
      " 92/200 [============>.................] - ETA: 49s - loss: 1.5792 - acc: 0.8049[[   2  582  405 ...,    0    0    0]\n",
      " [ 884  154   66 ...,    0    0    0]\n",
      " [ 654  117  332 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [1986    8 1431 ...,    0    0    0]\n",
      " [5682    9    4 ...,    0    0    0]]\n",
      " 93/200 [============>.................] - ETA: 49s - loss: 1.5803 - acc: 0.8048[[ 3013  9457  1060 ...,     0     0     0]\n",
      " [  109    26  1481 ...,     0     0     0]\n",
      " [10316    13    13 ...,     0     0     0]\n",
      " ..., \n",
      " [   38    62    13 ...,     0     0     0]\n",
      " [  623   157    13 ...,     0     0     0]\n",
      " [   10    13    13 ...,     0     0     0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 94/200 [=============>................] - ETA: 48s - loss: 1.5805 - acc: 0.8048[[1846   13   11 ...,    0    0    0]\n",
      " [3319 1708  205 ...,    0    0    0]\n",
      " [  22 8203  310 ...,    0    0    0]\n",
      " ..., \n",
      " [2425   27 1059 ...,    0    0    0]\n",
      " [ 844  217 1679 ...,    0    0    0]\n",
      " [5387  969   11 ...,    0    0    0]]\n",
      " 95/200 [=============>................] - ETA: 48s - loss: 1.5800 - acc: 0.8049[[ 3377    11  4318 ...,     0     0     0]\n",
      " [10997   128    39 ...,     0     0     0]\n",
      " [   10  1461     5 ...,     0     0     0]\n",
      " ..., \n",
      " [  137     7     1 ...,     0     0     0]\n",
      " [    1  2195   236 ...,     0     0     0]\n",
      " [ 1405   100   566 ...,     0     0     0]]\n",
      " 96/200 [=============>................] - ETA: 47s - loss: 1.5802 - acc: 0.8049[[  15    7 6030 ...,    0    0    0]\n",
      " [  79  121  255 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " ..., \n",
      " [ 150  199  287 ...,    0    0    0]\n",
      " [ 751   11  399 ...,    0    0    0]\n",
      " [1742    9  155 ...,    0    0    0]]\n",
      " 97/200 [=============>................] - ETA: 47s - loss: 1.5805 - acc: 0.8049[[ 579    7 1010 ...,    0    0    0]\n",
      " [ 665 1252    9 ...,    0    0    0]\n",
      " [  80  199 6663 ...,    0    0    0]\n",
      " ..., \n",
      " [1385  968 1360 ...,    0    0    0]\n",
      " [8877   13   14 ...,    0    0    0]\n",
      " [   1 2097  152 ...,    0    0    0]]\n",
      " 98/200 [=============>................] - ETA: 46s - loss: 1.5788 - acc: 0.8050[[ 3010   430   590 ...,     0     0     0]\n",
      " [   13  6010    11 ...,     0     0     0]\n",
      " [ 3571     9  5456 ...,     0     0     0]\n",
      " ..., \n",
      " [11295    83    15 ...,     0     0     0]\n",
      " [  219   119   157 ...,     0     0     0]\n",
      " [   22  9314  5292 ...,     0     0     0]]\n",
      " 99/200 [=============>................] - ETA: 46s - loss: 1.5758 - acc: 0.8053[[ 267  157   22 ...,    0    0    0]\n",
      " [7723 1091  941 ...,    0    0    0]\n",
      " [1549  455    3 ...,    0    0    0]\n",
      " ..., \n",
      " [   2   13  394 ...,    0    0    0]\n",
      " [   2   19  545 ...,    0    0    0]\n",
      " [4883   13    5 ...,    0    0    0]]\n",
      "100/200 [==============>...............] - ETA: 45s - loss: 1.5724 - acc: 0.8056[[  13 3137  600 ...,    0    0    0]\n",
      " [7760   13   27 ...,    0    0    0]\n",
      " [3079 3363   11 ...,    0    0    0]\n",
      " ..., \n",
      " [1381    8 2084 ...,    0    0    0]\n",
      " [   1  214   23 ...,    0    0    0]\n",
      " [ 109   26 1317 ...,    0    0    0]]\n",
      "101/200 [==============>...............] - ETA: 45s - loss: 1.5698 - acc: 0.8058[[   13    13    13 ...,     0     0     0]\n",
      " [   13  2435 11097 ...,     0     0     0]\n",
      " [    1   191     6 ...,     0     0     0]\n",
      " ..., \n",
      " [    1   214  1301 ...,     0     0     0]\n",
      " [   34    14    48 ...,     0     0     0]\n",
      " [    1   406  5815 ...,     0     0     0]]\n",
      "102/200 [==============>...............] - ETA: 44s - loss: 1.5676 - acc: 0.8059[[    1  9836    23 ...,     0     0     0]\n",
      " [  154    66     6 ...,     0     0     0]\n",
      " [ 2541   748     3 ...,     0     0     0]\n",
      " ..., \n",
      " [  195    15    13 ...,     0     0     0]\n",
      " [    1 11532    14 ...,     0     0     0]\n",
      " [   56  4391     6 ...,     0     0     0]]\n",
      "103/200 [==============>...............] - ETA: 44s - loss: 1.5672 - acc: 0.8060[[   1 1693 3514 ...,    0    0    0]\n",
      " [3827 4729   25 ...,    0    0    0]\n",
      " [4034 5683   10 ...,    0    0    0]\n",
      " ..., \n",
      " [ 221  230   13 ...,    0    0    0]\n",
      " [  70   15  392 ...,    0    0    0]\n",
      " [ 335    9    2 ...,    0    0    0]]\n",
      "104/200 [==============>...............] - ETA: 43s - loss: 1.5667 - acc: 0.8061[[  15  748   90 ...,    0    0    0]\n",
      " [   1 1217  231 ...,    0    0    0]\n",
      " [ 152  139   11 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13   13 ...,    0    0    0]\n",
      " [   1 9395   23 ...,    0    0    0]\n",
      " [  15 1272 1558 ...,    0    0    0]]\n",
      "105/200 [==============>...............] - ETA: 43s - loss: 1.5686 - acc: 0.8059[[  34  592   13 ...,    0    0    0]\n",
      " [  18   22 5726 ...,    0    0    0]\n",
      " [7167   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   13   44 ...,    0    0    0]\n",
      " [9077   50   13 ...,    0    0    0]\n",
      " [   4  189  343 ...,    0    0    0]]\n",
      "106/200 [==============>...............] - ETA: 42s - loss: 1.5692 - acc: 0.8059[[  15    9    2 ...,    0    0    0]\n",
      " [  89    7   80 ...,    0    0    0]\n",
      " [  15   14   41 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  611   86 ...,    0    0    0]\n",
      " [   1  485 1456 ...,    0    0    0]\n",
      " [  15  744   90 ...,    0    0    0]]\n",
      "107/200 [===============>..............] - ETA: 42s - loss: 1.5696 - acc: 0.8058[[  56  290    5 ...,    0    0    0]\n",
      " [ 108 1971    9 ...,    0    0    0]\n",
      " [1460 1503   89 ...,    0    0    0]\n",
      " ..., \n",
      " [  78   77 9528 ...,    0    0    0]\n",
      " [ 127   63  144 ...,    0    0    0]\n",
      " [4802   76   43 ...,    0    0    0]]\n",
      "108/200 [===============>..............] - ETA: 41s - loss: 1.5696 - acc: 0.8058[[ 245  431    9 ...,    0    0    0]\n",
      " [   1   73  138 ...,    0    0    0]\n",
      " [  56  706  290 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 1540  737 ...,    0    0    0]\n",
      " [  12 2850   13 ...,    0    0    0]\n",
      " [3194  102   67 ...,    0    0    0]]\n",
      "109/200 [===============>..............] - ETA: 41s - loss: 1.5724 - acc: 0.8055[[ 202    1 2814 ...,    0    0    0]\n",
      " [   1  847   16 ...,    0    0    0]\n",
      " [2346   13   81 ...,    0    0    0]\n",
      " ..., \n",
      " [  13 1645  568 ...,    0    0    0]\n",
      " [ 535    1 3643 ...,    0    0    0]\n",
      " [5119 1903    9 ...,    0    0    0]]\n",
      "110/200 [===============>..............] - ETA: 41s - loss: 1.5743 - acc: 0.8053[[  64  598   82 ...,    0    0    0]\n",
      " [5095 1115 1312 ...,    0    0    0]\n",
      " [ 739  396   13 ...,    0    0    0]\n",
      " ..., \n",
      " [8251 4061   86 ...,    0    0    0]\n",
      " [  56   63    4 ...,    0    0    0]\n",
      " [   1 1011 1463 ...,    0    0    0]]\n",
      "111/200 [===============>..............] - ETA: 40s - loss: 1.5789 - acc: 0.8048[[  69  263   30 ...,    0    0    0]\n",
      " [ 159   13  141 ...,    0    0    0]\n",
      " [ 116   67    1 ...,    0    0    0]\n",
      " ..., \n",
      " [  89   67 5801 ...,    0    0    0]\n",
      " [   1 1033   86 ...,    0    0    0]\n",
      " [  32   13   13 ...,    0    0    0]]\n",
      "112/200 [===============>..............] - ETA: 40s - loss: 1.5771 - acc: 0.8051[[  10  885 1705 ...,    0    0    0]\n",
      " [  13 1442  947 ...,    0    0    0]\n",
      " [  34  592  630 ...,    0    0    0]\n",
      " ..., \n",
      " [7813 2029    9 ...,    0    0    0]\n",
      " [4534   43 4534 ...,    0    0    0]\n",
      " [  72 7076   83 ...,    0    0    0]]\n",
      "113/200 [===============>..............] - ETA: 39s - loss: 1.5790 - acc: 0.8048[[  13  817   17 ...,    0    0    0]\n",
      " [  10  888   13 ...,    0    0    0]\n",
      " [ 133   39   20 ...,    0    0    0]\n",
      " ..., \n",
      " [   2  223 1745 ...,    0    0    0]\n",
      " [   1  463   13 ...,    0    0    0]\n",
      " [ 194  102  504 ...,    0    0    0]]\n",
      "114/200 [================>.............] - ETA: 39s - loss: 1.5800 - acc: 0.8047[[ 550 8168   13 ...,    0    0    0]\n",
      " [ 245   13   13 ...,    0    0    0]\n",
      " [  18    1 7564 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 6402  462 ...,    0    0    0]\n",
      " [1742  455    3 ...,    0    0    0]\n",
      " [ 104 1340   48 ...,    0    0    0]]\n",
      "115/200 [================>.............] - ETA: 38s - loss: 1.5793 - acc: 0.8049[[  658    14   276 ...,     0     0     0]\n",
      " [    4   116  1595 ...,     0     0     0]\n",
      " [    1   416   381 ...,     0     0     0]\n",
      " ..., \n",
      " [  127  4833    63 ...,     0     0     0]\n",
      " [    1   282   339 ...,     0     0     0]\n",
      " [11976     9   111 ...,     0     0     0]]\n",
      "116/200 [================>.............] - ETA: 38s - loss: 1.5788 - acc: 0.8049[[  93 1629   60 ...,    0    0    0]\n",
      " [1357    8 6176 ...,    0    0    0]\n",
      " [ 150 1718  133 ...,    0    0    0]\n",
      " ..., \n",
      " [ 884   73   66 ...,    0    0    0]\n",
      " [  55 9128 1070 ...,    0    0    0]\n",
      " [  13   26  182 ...,    0    0    0]]\n",
      "117/200 [================>.............] - ETA: 37s - loss: 1.5792 - acc: 0.8049[[    1    13    91 ...,     0     0     0]\n",
      " [ 5582   217 11411 ...,     0     0     0]\n",
      " [  109    26   113 ...,     0     0     0]\n",
      " ..., \n",
      " [    1  8532   169 ...,     0     0     0]\n",
      " [  248  3499   280 ...,     0     0     0]\n",
      " [ 1695   623     6 ...,     0     0     0]]\n",
      "118/200 [================>.............] - ETA: 37s - loss: 1.5796 - acc: 0.8049[[   1 1896  191 ...,    0    0    0]\n",
      " [  58   59 1032 ...,    0    0    0]\n",
      " [   1  884  191 ...,    0    0    0]\n",
      " ..., \n",
      " [  73 1479    4 ...,    0    0    0]\n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [1430  811   13 ...,    0    0    0]]\n",
      "119/200 [================>.............] - ETA: 36s - loss: 1.5792 - acc: 0.8049[[  19  120 2442 ...,    0    0    0]\n",
      " [1379    1  126 ...,    0    0    0]\n",
      " [5183    4  367 ...,    0    0    0]\n",
      " ..., \n",
      " [2191    8  880 ...,    0    0    0]\n",
      " [ 546  510    6 ...,    0    0    0]\n",
      " [  13 2639 9459 ...,    0    0    0]]\n",
      "120/200 [=================>............] - ETA: 36s - loss: 1.5795 - acc: 0.8049[[   13    26   441 ...,     0     0     0]\n",
      " [   58    59   187 ...,     0     0     0]\n",
      " [    1  1508  1687 ...,     0     0     0]\n",
      " ..., \n",
      " [  255   160  1938 ...,     0     0     0]\n",
      " [ 7406 10480  1673 ...,     0     0     0]\n",
      " [   19   352   154 ...,     0     0     0]]\n",
      "121/200 [=================>............] - ETA: 35s - loss: 1.5788 - acc: 0.8050[[ 711  168   53 ...,    0    0    0]\n",
      " [   2  179  734 ...,    0    0    0]\n",
      " [1757  187  115 ...,    0    0    0]\n",
      " ..., \n",
      " [  22  864    8 ...,    0    0    0]\n",
      " [  47  867   13 ...,    0    0    0]\n",
      " [ 234 9748  289 ...,    0    0    0]]\n",
      "122/200 [=================>............] - ETA: 35s - loss: 1.5800 - acc: 0.8049[[ 166 7677   27 ...,    0    0    0]\n",
      " [ 654  145   11 ...,    0    0    0]\n",
      " [ 131  429 1187 ...,    0    0    0]\n",
      " ..., \n",
      " [  13 8443   11 ...,    0    0    0]\n",
      " [2084 2581 1392 ...,    0    0    0]\n",
      " [ 236  477  246 ...,    0    0    0]]\n",
      "123/200 [=================>............] - ETA: 35s - loss: 1.5802 - acc: 0.8049[[    2   412    12 ...,     0     0     0]\n",
      " [ 3909   267    23 ...,     0     0     0]\n",
      " [    1  6447    13 ...,     0     0     0]\n",
      " ..., \n",
      " [ 1497     8   148 ...,     0     0     0]\n",
      " [   22  4477 10665 ...,     0     0     0]\n",
      " [ 2965    13    30 ...,     0     0     0]]\n",
      "124/200 [=================>............] - ETA: 34s - loss: 1.5807 - acc: 0.8048[[   1  406 5815 ...,    0    0    0]\n",
      " [  13  505  105 ...,    0    0    0]\n",
      " [  22  150   13 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 4705 8115 ...,    0    0    0]\n",
      " [2453   13   13 ...,    0    0    0]\n",
      " [ 566    1 2604 ...,    0    0    0]]\n",
      "125/200 [=================>............] - ETA: 34s - loss: 1.5810 - acc: 0.8048[[  93   23   13 ...,    0    0    0]\n",
      " [ 147  202   13 ...,    0    0    0]\n",
      " [1693 3716 1232 ...,    0    0    0]\n",
      " ..., \n",
      " [ 119   21  616 ...,    0    0    0]\n",
      " [ 377    5   15 ...,    0    0    0]\n",
      " [3827   67 5652 ...,    0    0    0]]\n",
      "126/200 [=================>............] - ETA: 33s - loss: 1.5806 - acc: 0.8049[[ 1819     8  5136 ...,     0     0     0]\n",
      " [ 1770     5 11027 ...,     0     0     0]\n",
      " [    2  1355    13 ...,     0     0     0]\n",
      " ..., \n",
      " [  987    83    41 ...,     0     0     0]\n",
      " [   10  1334   123 ...,     0     0     0]\n",
      " [   15    14     1 ...,     0     0     0]]\n",
      "127/200 [==================>...........] - ETA: 33s - loss: 1.5780 - acc: 0.8051[[  47 1907 1911 ...,    0    0    0]\n",
      " [   1   19  120 ...,    0    0    0]\n",
      " [1668   13  925 ...,    0    0    0]\n",
      " ..., \n",
      " [  15 1893   90 ...,    0    0    0]\n",
      " [   1 2757   11 ...,    0    0    0]\n",
      " [ 973 6406   11 ...,    0    0    0]]\n",
      "128/200 [==================>...........] - ETA: 32s - loss: 1.5759 - acc: 0.8053[[  173     5    69 ...,     0     0     0]\n",
      " [11368     5  3219 ...,     0     0     0]\n",
      " [ 4915   941 11116 ...,     0     0     0]\n",
      " ..., \n",
      " [  108    68   595 ...,     0     0     0]\n",
      " [ 1224  1890    13 ...,     0     0     0]\n",
      " [ 3054   130  1046 ...,     0     0     0]]\n",
      "129/200 [==================>...........] - ETA: 32s - loss: 1.5736 - acc: 0.8055[[  13 2097   11 ...,    0    0    0]\n",
      " [ 849 1211   10 ...,    0    0    0]\n",
      " [9739 1535    4 ...,    0    0    0]\n",
      " ..., \n",
      " [5617 3345 1822 ...,    0    0    0]\n",
      " [ 633 3324   23 ...,    0    0    0]\n",
      " [3125 1254   11 ...,    0    0    0]]\n",
      "130/200 [==================>...........] - ETA: 31s - loss: 1.5716 - acc: 0.8056[[    1  5180 10336 ...,     0     0     0]\n",
      " [  519  5445  2648 ...,     0     0     0]\n",
      " [    1  2400    13 ...,     0     0     0]\n",
      " ..., \n",
      " [ 1369  3750   192 ...,     0     0     0]\n",
      " [ 3327     9    48 ...,     0     0     0]\n",
      " [    1    13  3351 ...,     0     0     0]]\n",
      "131/200 [==================>...........] - ETA: 31s - loss: 1.5708 - acc: 0.8056[[   1 2510    5 ...,    0    0    0]\n",
      " [ 824    9   76 ...,    0    0    0]\n",
      " [3393 7762    8 ...,    0    0    0]\n",
      " ..., \n",
      " [ 132   26   65 ...,    0    0    0]\n",
      " [4911 2964    8 ...,    0    0    0]\n",
      " [ 930   13   14 ...,    0    0    0]]\n",
      "132/200 [==================>...........] - ETA: 30s - loss: 1.5714 - acc: 0.8056[[ 159 5589   11 ...,    0    0    0]\n",
      " [1067  314   13 ...,    0    0    0]\n",
      " [   1 1289 3073 ...,    0    0    0]\n",
      " ..., \n",
      " [  17 4581   11 ...,    0    0    0]\n",
      " [  10    1   47 ...,    0    0    0]\n",
      " [ 155   68  718 ...,    0    0    0]]\n",
      "133/200 [==================>...........] - ETA: 30s - loss: 1.5722 - acc: 0.8055[[ 102  123  442 ...,    0    0    0]\n",
      " [ 145  757    9 ...,    0    0    0]\n",
      " [   1 1115  291 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 7219   38 ...,    0    0    0]\n",
      " [  99 5343 2628 ...,    0    0    0]\n",
      " [7155   81    2 ...,    0    0    0]]\n",
      "134/200 [===================>..........] - ETA: 30s - loss: 1.5724 - acc: 0.8055[[  79    5  600 ...,    0    0    0]\n",
      " [  13 1751  541 ...,    0    0    0]\n",
      " [1346 2013  163 ...,    0    0    0]\n",
      " ..., \n",
      " [1694 2380  247 ...,    0    0    0]\n",
      " [  19 1848 4197 ...,    0    0    0]\n",
      " [  70   13   13 ...,    0    0    0]]\n",
      "135/200 [===================>..........] - ETA: 29s - loss: 1.5739 - acc: 0.8053[[  41    5    1 ...,    0    0    0]\n",
      " [  42    7  111 ...,    0    0    0]\n",
      " [   1 3532    4 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  680   13 ...,    0    0    0]\n",
      " [ 293 5775   23 ...,    0    0    0]\n",
      " [   6 4325   86 ...,    0    0    0]]\n",
      "136/200 [===================>..........] - ETA: 29s - loss: 1.5727 - acc: 0.8054[[  12   47 4618 ...,    0    0    0]\n",
      " [  32   61    3 ...,    0    0    0]\n",
      " [   1   47  872 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   13    9 ...,    0    0    0]\n",
      " [  13 1226  876 ...,    0    0    0]\n",
      " [ 730   13  995 ...,    0    0    0]]\n",
      "137/200 [===================>..........] - ETA: 28s - loss: 1.5734 - acc: 0.8053[[6290   23   48 ...,    0    0    0]\n",
      " [  70 2860 4117 ...,    0    0    0]\n",
      " [ 639   37   13 ...,    0    0    0]\n",
      " ..., \n",
      " [   2   19  563 ...,    0    0    0]\n",
      " [   1  747   14 ...,    0    0    0]\n",
      " [  15    7 6004 ...,    0    0    0]]\n",
      "138/200 [===================>..........] - ETA: 28s - loss: 1.5760 - acc: 0.8050[[ 302   13  154 ...,    0    0    0]\n",
      " [  15  105   21 ...,    0    0    0]\n",
      " [5814   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [  15  871   20 ...,    0    0    0]\n",
      " [2410 9350    9 ...,    0    0    0]\n",
      " [ 644   13   81 ...,    0    0    0]]\n",
      "139/200 [===================>..........] - ETA: 27s - loss: 1.5803 - acc: 0.8046[[   1   69    7 ...,    0    0    0]\n",
      " [ 108   68  410 ...,    0    0    0]\n",
      " [  15    7   48 ...,    0    0    0]\n",
      " ..., \n",
      " [  13  104   21 ...,    0    0    0]\n",
      " [  12  393   13 ...,    0    0    0]\n",
      " [2113    9   39 ...,    0    0    0]]\n",
      "140/200 [====================>.........] - ETA: 27s - loss: 1.5811 - acc: 0.8045[[   1   13    5 ...,    0    0    0]\n",
      " [ 483    1  474 ...,    0    0    0]\n",
      " [ 104   13   97 ...,    0    0    0]\n",
      " ..., \n",
      " [1360 3930   11 ...,    0    0    0]\n",
      " [  43  383  244 ...,    0    0    0]\n",
      " [  15  530    3 ...,    0    0    0]]\n",
      "141/200 [====================>.........] - ETA: 26s - loss: 1.5807 - acc: 0.8045[[  301  3343 11699 ...,     0     0     0]\n",
      " [ 9173  7862    81 ...,     0     0     0]\n",
      " [   13    13  5463 ...,     0     0     0]\n",
      " ..., \n",
      " [    4     2  1307 ...,     0     0     0]\n",
      " [   13 11062     1 ...,     0     0     0]\n",
      " [   13    13   385 ...,     0     0     0]]\n",
      "142/200 [====================>.........] - ETA: 26s - loss: 1.5821 - acc: 0.8044[[  962   450   283 ...,     0     0     0]\n",
      " [    1   659 10774 ...,     0     0     0]\n",
      " [    2  1045   910 ...,     0     0     0]\n",
      " ..., \n",
      " [    5   738    13 ...,     0     0     0]\n",
      " [    1    13    13 ...,     0     0     0]\n",
      " [ 3056   355  1433 ...,     0     0     0]]\n",
      "143/200 [====================>.........] - ETA: 25s - loss: 1.5816 - acc: 0.8045[[    1  1876    81 ...,     0     0     0]\n",
      " [   13    13    13 ...,     0     0     0]\n",
      " [   13  7673  2325 ...,     0     0     0]\n",
      " ..., \n",
      " [   13     1    13 ...,     0     0     0]\n",
      " [    1    13  5660 ...,     0     0     0]\n",
      " [ 4094    13 10706 ...,     0     0     0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/200 [====================>.........] - ETA: 25s - loss: 1.5807 - acc: 0.8046[[   13    13     4 ...,     0     0     0]\n",
      " [   41   264  1023 ...,     0     0     0]\n",
      " [ 1092    13   264 ...,     0     0     0]\n",
      " ..., \n",
      " [ 1038  5235    10 ...,     0     0     0]\n",
      " [    1  1124    27 ...,     0     0     0]\n",
      " [11578  7361     4 ...,     0     0     0]]\n",
      "145/200 [====================>.........] - ETA: 24s - loss: 1.5813 - acc: 0.8046[[  58   59  154 ...,    0    0    0]\n",
      " [1056 1719  267 ...,    0    0    0]\n",
      " [  13   69 2399 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [   2   13  405 ...,    0    0    0]]\n",
      "146/200 [====================>.........] - ETA: 24s - loss: 1.5812 - acc: 0.8046[[ 109   26  106 ...,    0    0    0]\n",
      " [   1 1202    5 ...,    0    0    0]\n",
      " [   1 1276 3182 ...,    0    0    0]\n",
      " ..., \n",
      " [2990  674  308 ...,    0    0    0]\n",
      " [ 491   26  113 ...,    0    0    0]\n",
      " [ 152  139  106 ...,    0    0    0]]\n",
      "147/200 [=====================>........] - ETA: 24s - loss: 1.5813 - acc: 0.8046[[ 1189   224     7 ...,     0     0     0]\n",
      " [    1    13    91 ...,     0     0     0]\n",
      " [ 2574    30    36 ...,     0     0     0]\n",
      " ..., \n",
      " [    1   551    13 ...,     0     0     0]\n",
      " [   13   104   945 ...,     0     0     0]\n",
      " [  306    27 11880 ...,     0     0     0]]\n",
      "148/200 [=====================>........] - ETA: 23s - loss: 1.5810 - acc: 0.8046[[   1   13   91 ...,    0    0    0]\n",
      " [   1  306  119 ...,    0    0    0]\n",
      " [   1   13   91 ...,    0    0    0]\n",
      " ..., \n",
      " [ 456  187 1924 ...,    0    0    0]\n",
      " [ 234  102   67 ...,    0    0    0]\n",
      " [ 456 4785   32 ...,    0    0    0]]\n",
      "149/200 [=====================>........] - ETA: 23s - loss: 1.5813 - acc: 0.8046[[ 456  187 1924 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [   1 6434  384 ...,    0    0    0]\n",
      " ..., \n",
      " [1195 1916   11 ...,    0    0    0]\n",
      " [ 372   11  269 ...,    0    0    0]\n",
      " [ 318    8   92 ...,    0    0    0]]\n",
      "150/200 [=====================>........] - ETA: 22s - loss: 1.5814 - acc: 0.8046[[ 342  196    4 ...,    0    0    0]\n",
      " [ 661   10    1 ...,    0    0    0]\n",
      " [ 342  196    4 ...,    0    0    0]\n",
      " ..., \n",
      " [ 390 3598   27 ...,    0    0    0]\n",
      " [  16 4647 1418 ...,    0    0    0]\n",
      " [ 171  108 1150 ...,    0    0    0]]\n",
      "151/200 [=====================>........] - ETA: 22s - loss: 1.5816 - acc: 0.8046[[  109    26   115 ...,     0     0     0]\n",
      " [    1    19   120 ...,     0     0     0]\n",
      " [  203   295  1943 ...,     0     0     0]\n",
      " ..., \n",
      " [ 1961  3177    14 ...,     0     0     0]\n",
      " [    1  5396     4 ...,     0     0     0]\n",
      " [   13 11404    61 ...,     0     0     0]]\n",
      "152/200 [=====================>........] - ETA: 21s - loss: 1.5822 - acc: 0.8045[[   2   13 7793 ...,    0    0    0]\n",
      " [2932   13   13 ...,    0    0    0]\n",
      " [   1  132  732 ...,    0    0    0]\n",
      " ..., \n",
      " [  70   15  392 ...,    0    0    0]\n",
      " [2350   11  631 ...,    0    0    0]\n",
      " [  60  110   11 ...,    0    0    0]]\n",
      "153/200 [=====================>........] - ETA: 21s - loss: 1.5823 - acc: 0.8045[[10963  3063    83 ...,     0     0     0]\n",
      " [  987    83   318 ...,     0     0     0]\n",
      " [  193    14    13 ...,     0     0     0]\n",
      " ..., \n",
      " [   99   255    73 ...,     0     0     0]\n",
      " [    2    19   545 ...,     0     0     0]\n",
      " [  119     6    36 ...,     0     0     0]]\n",
      "154/200 [======================>.......] - ETA: 20s - loss: 1.5824 - acc: 0.8045[[    1   339  1897 ...,     0     0     0]\n",
      " [   68   337     3 ...,     0     0     0]\n",
      " [   49    38    62 ...,     0     0     0]\n",
      " ..., \n",
      " [ 1397     1    13 ...,     0     0     0]\n",
      " [   13 11624     8 ...,     0     0     0]\n",
      " [   70  5936  6089 ...,     0     0     0]]\n",
      "155/200 [======================>.......] - ETA: 20s - loss: 1.5819 - acc: 0.8046[[   1  785  283 ...,    0    0    0]\n",
      " [1170  159  390 ...,    0    0    0]\n",
      " [   1   13   91 ...,    0    0    0]\n",
      " ..., \n",
      " [  55    7  191 ...,    0    0    0]\n",
      " [  49 4490 7088 ...,    0    0    0]\n",
      " [   1   13  343 ...,    0    0    0]]\n",
      "156/200 [======================>.......] - ETA: 19s - loss: 1.5799 - acc: 0.8047[[  69  418  335 ...,    0    0    0]\n",
      " [1961 8415   11 ...,    0    0    0]\n",
      " [5175  694  103 ...,    0    0    0]\n",
      " ..., \n",
      " [ 309 4632 5172 ...,    0    0    0]\n",
      " [3402 2029    7 ...,    0    0    0]\n",
      " [  13  816  276 ...,    0    0    0]]\n",
      "157/200 [======================>.......] - ETA: 19s - loss: 1.5785 - acc: 0.8048[[  797 11533   186 ...,     0     0     0]\n",
      " [ 1801  2135   451 ...,     0     0     0]\n",
      " [ 2406    13   903 ...,     0     0     0]\n",
      " ..., \n",
      " [ 1050    13   647 ...,     0     0     0]\n",
      " [  866  4106    21 ...,     0     0     0]\n",
      " [   70     1  9107 ...,     0     0     0]]\n",
      "158/200 [======================>.......] - ETA: 19s - loss: 1.5764 - acc: 0.8050[[6389 2097  694 ...,    0    0    0]\n",
      " [   1   13   13 ...,    0    0    0]\n",
      " [ 363 3764 1205 ...,    0    0    0]\n",
      " ..., \n",
      " [2015   11 2025 ...,    0    0    0]\n",
      " [  13   26   23 ...,    0    0    0]\n",
      " [ 761  621   13 ...,    0    0    0]]\n",
      "159/200 [======================>.......] - ETA: 18s - loss: 1.5747 - acc: 0.8051[[  13   13  807 ...,    0    0    0]\n",
      " [ 491  187  182 ...,    0    0    0]\n",
      " [ 365    7   13 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  883 2440 ...,    0    0    0]\n",
      " [  13 1248 1710 ...,    0    0    0]\n",
      " [2613  141   39 ...,    0    0    0]]\n",
      "160/200 [=======================>......] - ETA: 18s - loss: 1.5734 - acc: 0.8053[[  16   13    5 ...,    0    0    0]\n",
      " [5945 2617  168 ...,    0    0    0]\n",
      " [  49  177  144 ...,    0    0    0]\n",
      " ..., \n",
      " [5517 2123 6731 ...,    0    0    0]\n",
      " [   1  221  230 ...,    0    0    0]\n",
      " [ 140  553  697 ...,    0    0    0]]\n",
      "161/200 [=======================>......] - ETA: 17s - loss: 1.5729 - acc: 0.8053[[5490    5    1 ...,    0    0    0]\n",
      " [  13   13   13 ...,    0    0    0]\n",
      " [  89    7   80 ...,    0    0    0]\n",
      " ..., \n",
      " [  93   23    1 ...,    0    0    0]\n",
      " [  12   13  161 ...,    0    0    0]\n",
      " [1770    5   13 ...,    0    0    0]]\n",
      "162/200 [=======================>......] - ETA: 17s - loss: 1.5725 - acc: 0.8053[[  70   68  377 ...,    0    0    0]\n",
      " [   1 1556 6068 ...,    0    0    0]\n",
      " [ 194 1156  853 ...,    0    0    0]\n",
      " ..., \n",
      " [ 137    9   15 ...,    0    0    0]\n",
      " [  13   13   44 ...,    0    0    0]\n",
      " [3711  210   13 ...,    0    0    0]]\n",
      "163/200 [=======================>......] - ETA: 16s - loss: 1.5732 - acc: 0.8053[[ 137    7   19 ...,    0    0    0]\n",
      " [   1  214   23 ...,    0    0    0]\n",
      " [ 599 2846 1433 ...,    0    0    0]\n",
      " ..., \n",
      " [1150 1900    9 ...,    0    0    0]\n",
      " [  15   11   45 ...,    0    0    0]\n",
      " [ 245 1192    8 ...,    0    0    0]]\n",
      "164/200 [=======================>......] - ETA: 16s - loss: 1.5737 - acc: 0.8052[[  13   13    4 ...,    0    0    0]\n",
      " [1742    7 2878 ...,    0    0    0]\n",
      " [  13   13  141 ...,    0    0    0]\n",
      " ..., \n",
      " [ 644  435 5264 ...,    0    0    0]\n",
      " [   2   13  146 ...,    0    0    0]\n",
      " [   1 6418   13 ...,    0    0    0]]\n",
      "165/200 [=======================>......] - ETA: 15s - loss: 1.5741 - acc: 0.8052[[ 630  164   13 ...,    0    0    0]\n",
      " [   4   60 9835 ...,    0    0    0]\n",
      " [ 103 1075  779 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 1274    5 ...,    0    0    0]\n",
      " [  89   23  693 ...,    0    0    0]\n",
      " [   4    2   37 ...,    0    0    0]]\n",
      "166/200 [=======================>......] - ETA: 15s - loss: 1.5737 - acc: 0.8052[[  13   13   86 ...,    0    0    0]\n",
      " [3550    9  254 ...,    0    0    0]\n",
      " [ 605 2648   23 ...,    0    0    0]\n",
      " ..., \n",
      " [6382 6947   30 ...,    0    0    0]\n",
      " [  13  418  335 ...,    0    0    0]\n",
      " [  13 4125 5709 ...,    0    0    0]]\n",
      "167/200 [========================>.....] - ETA: 14s - loss: 1.5753 - acc: 0.8050[[   1 1927    5 ...,    0    0    0]\n",
      " [  13   13   67 ...,    0    0    0]\n",
      " [  29 5307   13 ...,    0    0    0]\n",
      " ..., \n",
      " [6482 6781   13 ...,    0    0    0]\n",
      " [2139  210 3422 ...,    0    0    0]\n",
      " [   1 7826  218 ...,    0    0    0]]\n",
      "168/200 [========================>.....] - ETA: 14s - loss: 1.5762 - acc: 0.8049[[ 171    4  318 ...,    0    0    0]\n",
      " [   4   22 4218 ...,    0    0    0]\n",
      " [  89    7  439 ...,    0    0    0]\n",
      " ..., \n",
      " [ 486  537   57 ...,    0    0    0]\n",
      " [  13   13   51 ...,    0    0    0]\n",
      " [4511 4278   41 ...,    0    0    0]]\n",
      "169/200 [========================>.....] - ETA: 14s - loss: 1.5784 - acc: 0.8047[[  42   11   45 ...,    0    0    0]\n",
      " [ 586    9  939 ...,    0    0    0]\n",
      " [ 751   13  171 ...,    0    0    0]\n",
      " ..., \n",
      " [   2 9906 1477 ...,    0    0    0]\n",
      " [  13  104 1619 ...,    0    0    0]\n",
      " [   1   19  120 ...,    0    0    0]]\n",
      "170/200 [========================>.....] - ETA: 13s - loss: 1.5779 - acc: 0.8048[[ 1546  4893    81 ...,     0     0     0]\n",
      " [  443   900    11 ...,     0     0     0]\n",
      " [   22  1241     9 ...,     0     0     0]\n",
      " ..., \n",
      " [    1  1238 11900 ...,     0     0     0]\n",
      " [ 1675  1415    11 ...,     0     0     0]\n",
      " [   13    13   292 ...,     0     0     0]]\n",
      "171/200 [========================>.....] - ETA: 13s - loss: 1.5790 - acc: 0.8047[[  49   63  144 ...,    0    0    0]\n",
      " [   1  751 2224 ...,    0    0    0]\n",
      " [ 173  831   32 ...,    0    0    0]\n",
      " ..., \n",
      " [  13  321  285 ...,    0    0    0]\n",
      " [  34  400   77 ...,    0    0    0]\n",
      " [   2 7121    3 ...,    0    0    0]]\n",
      "172/200 [========================>.....] - ETA: 12s - loss: 1.5798 - acc: 0.8046[[   1  156   61 ...,    0    0    0]\n",
      " [  64   82   13 ...,    0    0    0]\n",
      " [  15    7   45 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 7812    5 ...,    0    0    0]\n",
      " [ 535   13   34 ...,    0    0    0]\n",
      " [   1  541   10 ...,    0    0    0]]\n",
      "173/200 [========================>.....] - ETA: 12s - loss: 1.5791 - acc: 0.8047[[3798  160  265 ...,    0    0    0]\n",
      " [  43   99 3083 ...,    0    0    0]\n",
      " [  22   13  736 ...,    0    0    0]\n",
      " ..., \n",
      " [1164   13    1 ...,    0    0    0]\n",
      " [  92 1800   67 ...,    0    0    0]\n",
      " [   1 4878    4 ...,    0    0    0]]\n",
      "174/200 [=========================>....] - ETA: 11s - loss: 1.5787 - acc: 0.8048[[   17   431 11930 ...,     0     0     0]\n",
      " [ 1019  3939   103 ...,     0     0     0]\n",
      " [ 1164     1    13 ...,     0     0     0]\n",
      " ..., \n",
      " [  367    27   269 ...,     0     0     0]\n",
      " [  219    26   441 ...,     0     0     0]\n",
      " [ 1905   809  7684 ...,     0     0     0]]\n",
      "175/200 [=========================>....] - ETA: 11s - loss: 1.5790 - acc: 0.8048[[   1 2105  941 ...,    0    0    0]\n",
      " [1324 4909   69 ...,    0    0    0]\n",
      " [   2  397 5043 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   69  297 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [6741 2232   23 ...,    0    0    0]]\n",
      "176/200 [=========================>....] - ETA: 10s - loss: 1.5789 - acc: 0.8048[[ 214   23    1 ...,    0    0    0]\n",
      " [  13  301  155 ...,    0    0    0]\n",
      " [ 373  423   55 ...,    0    0    0]\n",
      " ..., \n",
      " [1005    9 7106 ...,    0    0    0]\n",
      " [5992   69 3226 ...,    0    0    0]\n",
      " [ 373  423   55 ...,    0    0    0]]\n",
      "177/200 [=========================>....] - ETA: 10s - loss: 1.5785 - acc: 0.8049[[5937 1321 5794 ...,    0    0    0]\n",
      " [   1   13 3967 ...,    0    0    0]\n",
      " [  49  919 7088 ...,    0    0    0]\n",
      " ..., \n",
      " [1137 3695    4 ...,    0    0    0]\n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [   1   13   91 ...,    0    0    0]]\n",
      "178/200 [=========================>....] - ETA: 9s - loss: 1.5783 - acc: 0.8049 [[  89   14   39 ...,    0    0    0]\n",
      " [ 481   66 1215 ...,    0    0    0]\n",
      " [   1  868   26 ...,    0    0    0]\n",
      " ..., \n",
      " [ 179  946  677 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [3491  680   13 ...,    0    0    0]]\n",
      "179/200 [=========================>....] - ETA: 9s - loss: 1.5788 - acc: 0.8049[[ 108   68   23 ...,    0    0    0]\n",
      " [   2   19  417 ...,    0    0    0]\n",
      " [  55    7 2921 ...,    0    0    0]\n",
      " ..., \n",
      " [ 456  187  687 ...,    0    0    0]\n",
      " [ 241    7 8494 ...,    0    0    0]\n",
      " [  13 4086 3289 ...,    0    0    0]]\n",
      "180/200 [==========================>...] - ETA: 9s - loss: 1.5791 - acc: 0.8048[[  47   15   14 ...,    0    0    0]\n",
      " [2012    5  142 ...,    0    0    0]\n",
      " [4418   11 2389 ...,    0    0    0]\n",
      " ..., \n",
      " [1449 1148   13 ...,    0    0    0]\n",
      " [   1 3494  161 ...,    0    0    0]\n",
      " [  13 2654    4 ...,    0    0    0]]\n",
      "181/200 [==========================>...] - ETA: 8s - loss: 1.5792 - acc: 0.8048[[  64   82  107 ...,    0    0    0]\n",
      " [ 276  178   13 ...,    0    0    0]\n",
      " [ 488    8    1 ...,    0    0    0]\n",
      " ..., \n",
      " [  34   61   98 ...,    0    0    0]\n",
      " [2022 2923  205 ...,    0    0    0]\n",
      " [ 109   26   65 ...,    0    0    0]]\n",
      "182/200 [==========================>...] - ETA: 8s - loss: 1.5791 - acc: 0.8048[[   1   91   14 ...,    0    0    0]\n",
      " [ 325  829  662 ...,    0    0    0]\n",
      " [   3  356  767 ...,    0    0    0]\n",
      " ..., \n",
      " [ 390 3686    9 ...,    0    0    0]\n",
      " [ 226   13  284 ...,    0    0    0]\n",
      " [   1 1228  808 ...,    0    0    0]]\n",
      "183/200 [==========================>...] - ETA: 7s - loss: 1.5792 - acc: 0.8049[[ 749   12    2 ...,    0    0    0]\n",
      " [   1   13 1666 ...,    0    0    0]\n",
      " [1536   13  385 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   13   13 ...,    0    0    0]\n",
      " [ 500  455    3 ...,    0    0    0]\n",
      " [  13 3939 4822 ...,    0    0    0]]\n",
      "184/200 [==========================>...] - ETA: 7s - loss: 1.5792 - acc: 0.8049[[  647    13   462 ...,     0     0     0]\n",
      " [    1  1343    76 ...,     0     0     0]\n",
      " [   13  9175    14 ...,     0     0     0]\n",
      " ..., \n",
      " [ 5592 10575     5 ...,     0     0     0]\n",
      " [  241    13    18 ...,     0     0     0]\n",
      " [  967  1533     3 ...,     0     0     0]]\n",
      "185/200 [==========================>...] - ETA: 6s - loss: 1.5785 - acc: 0.8049[[2455  424 1301 ...,    0    0    0]\n",
      " [ 380    7   13 ...,    0    0    0]\n",
      " [   1   38   62 ...,    0    0    0]\n",
      " ..., \n",
      " [ 316  583 1628 ...,    0    0    0]\n",
      " [ 304 3255 1010 ...,    0    0    0]\n",
      " [ 149  186   10 ...,    0    0    0]]\n",
      "186/200 [==========================>...] - ETA: 6s - loss: 1.5771 - acc: 0.8051[[  795    13   363 ...,     0     0     0]\n",
      " [    1  1693  3716 ...,     0     0     0]\n",
      " [   13    13    13 ...,     0     0     0]\n",
      " ..., \n",
      " [ 3696    13  4556 ...,     0     0     0]\n",
      " [ 9945    13    86 ...,     0     0     0]\n",
      " [    1  1208 11348 ...,     0     0     0]]\n",
      "187/200 [===========================>..] - ETA: 5s - loss: 1.5755 - acc: 0.8052[[3292   13    5 ...,    0    0    0]\n",
      " [   2 8614 1737 ...,    0    0    0]\n",
      " [2939   13   14 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   13    7 ...,    0    0    0]\n",
      " [   4    1  145 ...,    0    0    0]\n",
      " [5850   13  128 ...,    0    0    0]]\n",
      "188/200 [===========================>..] - ETA: 5s - loss: 1.5740 - acc: 0.8053[[    2    13   146 ...,     0     0     0]\n",
      " [ 2525  5419 11672 ...,     0     0     0]\n",
      " [  491  2381    13 ...,     0     0     0]\n",
      " ..., \n",
      " [   49    13   851 ...,     0     0     0]\n",
      " [ 4385    13    14 ...,     0     0     0]\n",
      " [ 3791  1634   761 ...,     0     0     0]]\n",
      "189/200 [===========================>..] - ETA: 4s - loss: 1.5727 - acc: 0.8054[[ 2002  4124     9 ...,     0     0     0]\n",
      " [  280  1987     7 ...,     0     0     0]\n",
      " [ 4404    27 11508 ...,     0     0     0]\n",
      " ..., \n",
      " [ 2883  5521  4566 ...,     0     0     0]\n",
      " [  226     7   212 ...,     0     0     0]\n",
      " [   10   430    13 ...,     0     0     0]]\n",
      "190/200 [===========================>..] - ETA: 4s - loss: 1.5713 - acc: 0.8055[[ 131  491  522 ...,    0    0    0]\n",
      " [1862   30   24 ...,    0    0    0]\n",
      " [ 749   80  678 ...,    0    0    0]\n",
      " ..., \n",
      " [ 433  471   39 ...,    0    0    0]\n",
      " [ 345 3419 1044 ...,    0    0    0]\n",
      " [1550 1366    7 ...,    0    0    0]]\n",
      "191/200 [===========================>..] - ETA: 4s - loss: 1.5703 - acc: 0.8056[[5746 6464  253 ...,    0    0    0]\n",
      " [   4  444   13 ...,    0    0    0]\n",
      " [ 425   27  174 ...,    0    0    0]\n",
      " ..., \n",
      " [5814   13   14 ...,    0    0    0]\n",
      " [2642 2297   40 ...,    0    0    0]\n",
      " [   2  146 1129 ...,    0    0    0]]\n",
      "192/200 [===========================>..] - ETA: 3s - loss: 1.5702 - acc: 0.8056[[   1 5049 9636 ...,    0    0    0]\n",
      " [  55 1574    6 ...,    0    0    0]\n",
      " [2700    8 1429 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  429 1887 ...,    0    0    0]\n",
      " [   1 1245 1136 ...,    0    0    0]\n",
      " [   1   49   19 ...,    0    0    0]]\n",
      "193/200 [===========================>..] - ETA: 3s - loss: 1.5705 - acc: 0.8056[[ 108   68   67 ...,    0    0    0]\n",
      " [ 930   13  415 ...,    0    0    0]\n",
      " [ 621 1404 1184 ...,    0    0    0]\n",
      " ..., \n",
      " [   2  153 3973 ...,    0    0    0]\n",
      " [  80   41   14 ...,    0    0    0]\n",
      " [1761   23   13 ...,    0    0    0]]\n",
      "194/200 [============================>.] - ETA: 2s - loss: 1.5712 - acc: 0.8055[[ 149   53    7 ...,    0    0    0]\n",
      " [  18 1167  513 ...,    0    0    0]\n",
      " [ 337    3  338 ...,    0    0    0]\n",
      " ..., \n",
      " [  15    7    1 ...,    0    0    0]\n",
      " [  72  155    1 ...,    0    0    0]\n",
      " [   3 2748    1 ...,    0    0    0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/200 [============================>.] - ETA: 2s - loss: 1.5717 - acc: 0.8054[[ 105    9  385 ...,    0    0    0]\n",
      " [   6    1   13 ...,    0    0    0]\n",
      " [1696 7717   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 626   13   13 ...,    0    0    0]\n",
      " [2459 7832 1904 ...,    0    0    0]\n",
      " [  15  530    3 ...,    0    0    0]]\n",
      "196/200 [============================>.] - ETA: 1s - loss: 1.5722 - acc: 0.8054[[ 416 2716    8 ...,    0    0    0]\n",
      " [ 245 1192    8 ...,    0    0    0]\n",
      " [ 137   13    1 ...,    0    0    0]\n",
      " ..., \n",
      " [ 317   34  525 ...,    0    0    0]\n",
      " [   1  181  170 ...,    0    0    0]\n",
      " [ 618   13    5 ...,    0    0    0]]\n",
      "197/200 [============================>.] - ETA: 1s - loss: 1.5721 - acc: 0.8054[[  13 1163   12 ...,    0    0    0]\n",
      " [ 582 1211   10 ...,    0    0    0]\n",
      " [1063 6802 3370 ...,    0    0    0]\n",
      " ..., \n",
      " [ 137    7    4 ...,    0    0    0]\n",
      " [  10   63   13 ...,    0    0    0]\n",
      " [ 644   13  521 ...,    0    0    0]]\n",
      "198/200 [============================>.] - ETA: 0s - loss: 1.5737 - acc: 0.8052[[  13 9256    7 ...,    0    0    0]\n",
      " [6629   13   30 ...,    0    0    0]\n",
      " [  60 2510    5 ...,    0    0    0]\n",
      " ..., \n",
      " [  18   68  265 ...,    0    0    0]\n",
      " [  56   13   63 ...,    0    0    0]\n",
      " [1952 1630   13 ...,    0    0    0]]\n",
      "199/200 [============================>.] - ETA: 0s - loss: 1.5743 - acc: 0.8051[[ 535   41   37 ...,    0    0    0]\n",
      " [  93 1671   32 ...,    0    0    0]\n",
      " [  19  120    1 ...,    0    0    0]\n",
      " ..., \n",
      " [7200   13   11 ...,    0    0    0]\n",
      " [  10    2  146 ...,    0    0    0]\n",
      " [1246   13  816 ...,    0    0    0]]\n",
      "200/200 [==============================] - 90s - loss: 1.5762 - acc: 0.8049    \n",
      "Epoch 2/10\n",
      "[[ 3470    13   626 ...,     0     0     0]\n",
      " [ 9663 10549    11 ...,     0     0     0]\n",
      " [ 6526    13   898 ...,     0     0     0]\n",
      " ..., \n",
      " [  250    98     1 ...,     0     0     0]\n",
      " [  947    13   684 ...,     0     0     0]\n",
      " [ 3362   105    21 ...,     0     0     0]]\n",
      "  1/200 [..............................] - ETA: 90s - loss: 1.5764 - acc: 0.8097[[2697   50  105 ...,    0    0    0]\n",
      " [1344 3402 6866 ...,    0    0    0]\n",
      " [  10  276   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 202    1  463 ...,    0    0    0]\n",
      " [  15   27 1087 ...,    0    0    0]\n",
      " [  13  390 1415 ...,    0    0    0]]\n",
      "  2/200 [..............................] - ETA: 88s - loss: 1.6258 - acc: 0.8021[[  260    13     7 ...,     0     0     0]\n",
      " [11288  2473  8019 ...,     0     0     0]\n",
      " [ 1524     2    74 ...,     0     0     0]\n",
      " ..., \n",
      " [ 2765    23   207 ...,     0     0     0]\n",
      " [  438    13  1232 ...,     0     0     0]\n",
      " [    1  2131    23 ...,     0     0     0]]\n",
      "  3/200 [..............................] - ETA: 87s - loss: 1.6465 - acc: 0.8012[[  344     7    73 ...,     0     0     0]\n",
      " [  194 10634    34 ...,     0     0     0]\n",
      " [    1    78   177 ...,     0     0     0]\n",
      " ..., \n",
      " [   13  3645  3446 ...,     0     0     0]\n",
      " [    1    13  1442 ...,     0     0     0]\n",
      " [   15    11    45 ...,     0     0     0]]\n",
      "  4/200 [..............................] - ETA: 88s - loss: 1.6043 - acc: 0.8058[[1153    1   13 ...,    0    0    0]\n",
      " [ 149   13  333 ...,    0    0    0]\n",
      " [ 233  358  222 ...,    0    0    0]\n",
      " ..., \n",
      " [ 341   13    6 ...,    0    0    0]\n",
      " [  70    1  611 ...,    0    0    0]\n",
      " [6586 6960    9 ...,    0    0    0]]\n",
      "  5/200 [..............................] - ETA: 87s - loss: 1.5830 - acc: 0.8091[[  80  678    9 ...,    0    0    0]\n",
      " [ 746  117 4585 ...,    0    0    0]\n",
      " [   1  685  135 ...,    0    0    0]\n",
      " ..., \n",
      " [ 491   26  113 ...,    0    0    0]\n",
      " [ 579   11 1749 ...,    0    0    0]\n",
      " [   2  179 2444 ...,    0    0    0]]\n",
      "  6/200 [..............................] - ETA: 87s - loss: 1.5919 - acc: 0.8077[[ 154   66    6 ...,    0    0    0]\n",
      " [  55    7 1937 ...,    0    0    0]\n",
      " [   2 1413 1260 ...,    0    0    0]\n",
      " ..., \n",
      " [1472    7   13 ...,    0    0    0]\n",
      " [   1   47  287 ...,    0    0    0]\n",
      " [   1 9181  199 ...,    0    0    0]]\n",
      "  7/200 [>.............................] - ETA: 86s - loss: 1.5816 - acc: 0.8092[[ 496   27 1663 ...,    0    0    0]\n",
      " [3491  389  209 ...,    0    0    0]\n",
      " [   1  931    5 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13  169 ...,    0    0    0]\n",
      " [ 496  217   55 ...,    0    0    0]\n",
      " [2562   26  113 ...,    0    0    0]]\n",
      "  8/200 [>.............................] - ETA: 86s - loss: 1.5763 - acc: 0.8099[[ 373  423   55 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " ..., \n",
      " [ 496  941 3279 ...,    0    0    0]\n",
      " [   1   13   10 ...,    0    0    0]\n",
      " [   2  845  282 ...,    0    0    0]]\n",
      "  9/200 [>.............................] - ETA: 85s - loss: 1.5828 - acc: 0.8089[[  456  1494   692 ...,     0     0     0]\n",
      " [    1    13    91 ...,     0     0     0]\n",
      " [ 1382  1963   231 ...,     0     0     0]\n",
      " ..., \n",
      " [    1 11353   191 ...,     0     0     0]\n",
      " [    1    47  3229 ...,     0     0     0]\n",
      " [  248  2193   209 ...,     0     0     0]]\n",
      " 10/200 [>.............................] - ETA: 85s - loss: 1.5796 - acc: 0.8093[[  58   59   26 ...,    0    0    0]\n",
      " [   1  156   55 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " ..., \n",
      " [1454    7   13 ...,    0    0    0]\n",
      " [ 503  960    3 ...,    0    0    0]\n",
      " [ 248  800 1733 ...,    0    0    0]]\n",
      " 11/200 [>.............................] - ETA: 84s - loss: 1.5834 - acc: 0.8086[[ 5687     9    39 ...,     0     0     0]\n",
      " [    1  2182   191 ...,     0     0     0]\n",
      " [  127   102   112 ...,     0     0     0]\n",
      " ..., \n",
      " [   15    14    13 ...,     0     0     0]\n",
      " [10926    11   130 ...,     0     0     0]\n",
      " [    1  4595     5 ...,     0     0     0]]\n",
      " 12/200 [>.............................] - ETA: 84s - loss: 1.5890 - acc: 0.8076[[3236 2644   11 ...,    0    0    0]\n",
      " [  10    1   19 ...,    0    0    0]\n",
      " [   1   19   37 ...,    0    0    0]\n",
      " ..., \n",
      " [ 746  117 2526 ...,    0    0    0]\n",
      " [1268 4298  265 ...,    0    0    0]\n",
      " [2082 2177   23 ...,    0    0    0]]\n",
      " 13/200 [>.............................] - ETA: 84s - loss: 1.5912 - acc: 0.8071[[  13   13   13 ...,    0    0    0]\n",
      " [2797 4842 2347 ...,    0    0    0]\n",
      " [   2 1809  405 ...,    0    0    0]\n",
      " ..., \n",
      " [ 606    7  232 ...,    0    0    0]\n",
      " [  89   27   20 ...,    0    0    0]\n",
      " [ 546  276  178 ...,    0    0    0]]\n",
      " 14/200 [=>............................] - ETA: 83s - loss: 1.5905 - acc: 0.8070[[   1   13   91 ...,    0    0    0]\n",
      " [  15   14    1 ...,    0    0    0]\n",
      " [ 353   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [8129    7 3248 ...,    0    0    0]\n",
      " [ 353    8  603 ...,    0    0    0]\n",
      " [ 532    5  131 ...,    0    0    0]]\n",
      " 15/200 [=>............................] - ETA: 83s - loss: 1.5882 - acc: 0.8073[[ 267  157    2 ...,    0    0    0]\n",
      " [3295    7   19 ...,    0    0    0]\n",
      " [  58   59    7 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 2248   63 ...,    0    0    0]\n",
      " [ 119  172    2 ...,    0    0    0]\n",
      " [   4    1 3064 ...,    0    0    0]]\n",
      " 16/200 [=>............................] - ETA: 82s - loss: 1.5811 - acc: 0.8077[[ 868   13   13 ...,    0    0    0]\n",
      " [  13  119  157 ...,    0    0    0]\n",
      " [ 119   21 2208 ...,    0    0    0]\n",
      " ..., \n",
      " [  43  194 6631 ...,    0    0    0]\n",
      " [ 591 6515 3079 ...,    0    0    0]\n",
      " [ 280 1987    7 ...,    0    0    0]]\n",
      " 17/200 [=>............................] - ETA: 82s - loss: 1.5604 - acc: 0.8096[[1742   11 3959 ...,    0    0    0]\n",
      " [   1  199 7911 ...,    0    0    0]\n",
      " [3989  604   13 ...,    0    0    0]\n",
      " ..., \n",
      " [2735 5332   83 ...,    0    0    0]\n",
      " [  13   11 1793 ...,    0    0    0]\n",
      " [4022 7272    8 ...,    0    0    0]]\n",
      " 18/200 [=>............................] - ETA: 82s - loss: 1.5433 - acc: 0.8110[[   92   456   851 ...,     0     0     0]\n",
      " [11092  8523    11 ...,     0     0     0]\n",
      " [    1  2999    91 ...,     0     0     0]\n",
      " ..., \n",
      " [   16     1   602 ...,     0     0     0]\n",
      " [ 2525  5419  2506 ...,     0     0     0]\n",
      " [ 1653  4875  1136 ...,     0     0     0]]\n",
      " 19/200 [=>............................] - ETA: 81s - loss: 1.5292 - acc: 0.8118[[   1  427 1856 ...,    0    0    0]\n",
      " [ 626 3961 3254 ...,    0    0    0]\n",
      " [   2 2024 2067 ...,    0    0    0]\n",
      " ..., \n",
      " [   2  485 3233 ...,    0    0    0]\n",
      " [ 226    7   13 ...,    0    0    0]\n",
      " [   2  440  405 ...,    0    0    0]]\n",
      " 20/200 [==>...........................] - ETA: 81s - loss: 1.5191 - acc: 0.8124[[   1 2503   56 ...,    0    0    0]\n",
      " [   1 2266  793 ...,    0    0    0]\n",
      " [  22 1423    4 ...,    0    0    0]\n",
      " ..., \n",
      " [2490  103   13 ...,    0    0    0]\n",
      " [  13 1804  128 ...,    0    0    0]\n",
      " [ 623  157    2 ...,    0    0    0]]\n",
      " 21/200 [==>...........................] - ETA: 80s - loss: 1.5145 - acc: 0.8126[[ 807 1855 4922 ...,    0    0    0]\n",
      " [ 654  145  103 ...,    0    0    0]\n",
      " [   1  785    9 ...,    0    0    0]\n",
      " ..., \n",
      " [2323 2339   13 ...,    0    0    0]\n",
      " [2698    7   13 ...,    0    0    0]\n",
      " [ 979   66  664 ...,    0    0    0]]\n",
      " 22/200 [==>...........................] - ETA: 80s - loss: 1.5091 - acc: 0.8129[[  109    26   106 ...,     0     0     0]\n",
      " [ 1500  7999   521 ...,     0     0     0]\n",
      " [    2    13   806 ...,     0     0     0]\n",
      " ..., \n",
      " [ 3022  6500   163 ...,     0     0     0]\n",
      " [    1 11634   245 ...,     0     0     0]\n",
      " [ 3909    69  2775 ...,     0     0     0]]\n",
      " 23/200 [==>...........................] - ETA: 80s - loss: 1.5106 - acc: 0.8127[[ 681 3499  887 ...,    0    0    0]\n",
      " [   2   13 2444 ...,    0    0    0]\n",
      " [  13   13   27 ...,    0    0    0]\n",
      " ..., \n",
      " [2033   90    2 ...,    0    0    0]\n",
      " [  15    9    2 ...,    0    0    0]\n",
      " [ 827 1400 1298 ...,    0    0    0]]\n",
      " 24/200 [==>...........................] - ETA: 79s - loss: 1.5196 - acc: 0.8115[[ 706 1296    5 ...,    0    0    0]\n",
      " [   1 9248    5 ...,    0    0    0]\n",
      " [ 531  163 1980 ...,    0    0    0]\n",
      " ..., \n",
      " [ 361 5218 1328 ...,    0    0    0]\n",
      " [  72   15    7 ...,    0    0    0]\n",
      " [  13   13   13 ...,    0    0    0]]\n",
      " 25/200 [==>...........................] - ETA: 79s - loss: 1.5270 - acc: 0.8108[[   4 1971    7 ...,    0    0    0]\n",
      " [ 630    7 1188 ...,    0    0    0]\n",
      " [ 264    9    2 ...,    0    0    0]\n",
      " ..., \n",
      " [ 137    2  417 ...,    0    0    0]\n",
      " [2434    7   74 ...,    0    0    0]\n",
      " [  57  125   13 ...,    0    0    0]]\n",
      " 26/200 [==>...........................] - ETA: 78s - loss: 1.5352 - acc: 0.8096[[   1 1130    9 ...,    0    0    0]\n",
      " [1433   76    1 ...,    0    0    0]\n",
      " [ 585 7398   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 630    7  512 ...,    0    0    0]\n",
      " [2481 2736   11 ...,    0    0    0]\n",
      " [   1 5535   13 ...,    0    0    0]]\n",
      " 27/200 [===>..........................] - ETA: 78s - loss: 1.5428 - acc: 0.8090[[  15    7   45 ...,    0    0    0]\n",
      " [2861  103  887 ...,    0    0    0]\n",
      " [6448   13    7 ...,    0    0    0]\n",
      " ..., \n",
      " [ 234  290   96 ...,    0    0    0]\n",
      " [ 325  829   13 ...,    0    0    0]\n",
      " [ 879   13   30 ...,    0    0    0]]\n",
      " 28/200 [===>..........................] - ETA: 78s - loss: 1.5425 - acc: 0.8090[[   10    63    13 ...,     0     0     0]\n",
      " [    1    13 11795 ...,     0     0     0]\n",
      " [    4    22  1829 ...,     0     0     0]\n",
      " ..., \n",
      " [  222  2013    21 ...,     0     0     0]\n",
      " [  233   670  3884 ...,     0     0     0]\n",
      " [   70    15   392 ...,     0     0     0]]\n",
      " 29/200 [===>..........................] - ETA: 77s - loss: 1.5522 - acc: 0.8081[[  41  516    5 ...,    0    0    0]\n",
      " [  13   26  115 ...,    0    0    0]\n",
      " [4122 3172 2726 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  474  429 ...,    0    0    0]\n",
      " [  13  301  354 ...,    0    0    0]\n",
      " [   1  897 1175 ...,    0    0    0]]\n",
      " 30/200 [===>..........................] - ETA: 77s - loss: 1.5571 - acc: 0.8075[[  18 1387    4 ...,    0    0    0]\n",
      " [7131   13    9 ...,    0    0    0]\n",
      " [ 108   89  320 ...,    0    0    0]\n",
      " ..., \n",
      " [3587   13  128 ...,    0    0    0]\n",
      " [  13 3861   14 ...,    0    0    0]\n",
      " [ 131 1003 2940 ...,    0    0    0]]\n",
      " 31/200 [===>..........................] - ETA: 76s - loss: 1.5718 - acc: 0.8060[[   1 5576  467 ...,    0    0    0]\n",
      " [  13    3  809 ...,    0    0    0]\n",
      " [ 343 3183  384 ...,    0    0    0]\n",
      " ..., \n",
      " [  15    7  155 ...,    0    0    0]\n",
      " [   1   38   95 ...,    0    0    0]\n",
      " [ 228 3503  114 ...,    0    0    0]]\n",
      " 32/200 [===>..........................] - ETA: 76s - loss: 1.5706 - acc: 0.8063[[ 108    1 6103 ...,    0    0    0]\n",
      " [5401   21  256 ...,    0    0    0]\n",
      " [   1 2393  294 ...,    0    0    0]\n",
      " ..., \n",
      " [ 242   38  271 ...,    0    0    0]\n",
      " [  13  695   14 ...,    0    0    0]\n",
      " [   4    1  274 ...,    0    0    0]]\n",
      " 33/200 [===>..........................] - ETA: 76s - loss: 1.5737 - acc: 0.8061[[    6    33    13 ...,     0     0     0]\n",
      " [  234   290   144 ...,     0     0     0]\n",
      " [ 2270  1190    90 ...,     0     0     0]\n",
      " ..., \n",
      " [ 4686  8679 11273 ...,     0     0     0]\n",
      " [  108  1209  2508 ...,     0     0     0]\n",
      " [   34   400    77 ...,     0     0     0]]\n",
      " 34/200 [====>.........................] - ETA: 75s - loss: 1.5792 - acc: 0.8055[[ 232  725  141 ...,    0    0    0]\n",
      " [ 276  178   13 ...,    0    0    0]\n",
      " [4359 4673  247 ...,    0    0    0]\n",
      " ..., \n",
      " [2792 1898   81 ...,    0    0    0]\n",
      " [6292   13    9 ...,    0    0    0]\n",
      " [  19  226    7 ...,    0    0    0]]\n",
      " 35/200 [====>.........................] - ETA: 75s - loss: 1.5788 - acc: 0.8057[[1188    1 4704 ...,    0    0    0]\n",
      " [  13   15    7 ...,    0    0    0]\n",
      " [  93   67  190 ...,    0    0    0]\n",
      " ..., \n",
      " [ 406   13    1 ...,    0    0    0]\n",
      " [  68   21   41 ...,    0    0    0]\n",
      " [ 986 1865  105 ...,    0    0    0]]\n",
      " 36/200 [====>.........................] - ETA: 74s - loss: 1.5749 - acc: 0.8063[[   2   37   32 ...,    0    0    0]\n",
      " [  22 2679   13 ...,    0    0    0]\n",
      " [2334    2 8471 ...,    0    0    0]\n",
      " ..., \n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]]\n",
      " 37/200 [====>.........................] - ETA: 74s - loss: 1.5759 - acc: 0.8062[[4062   13    2 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [1434   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  868   91 ...,    0    0    0]\n",
      " [   1   19  274 ...,    0    0    0]\n",
      " [  55    7  655 ...,    0    0    0]]\n",
      " 38/200 [====>.........................] - ETA: 74s - loss: 1.5757 - acc: 0.8062[[1357    8  797 ...,    0    0    0]\n",
      " [  18  194   18 ...,    0    0    0]\n",
      " [   1  220   91 ...,    0    0    0]\n",
      " ..., \n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [  55   11 4380 ...,    0    0    0]\n",
      " [  12  296   13 ...,    0    0    0]]\n",
      " 39/200 [====>.........................] - ETA: 73s - loss: 1.5772 - acc: 0.8060[[2504 1870 3322 ...,    0    0    0]\n",
      " [ 140  609   73 ...,    0    0    0]\n",
      " [  13  808    5 ...,    0    0    0]\n",
      " ..., \n",
      " [  55    8  284 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [ 491   26  113 ...,    0    0    0]]\n",
      " 40/200 [=====>........................] - ETA: 73s - loss: 1.5759 - acc: 0.8062[[ 481   66  115 ...,    0    0    0]\n",
      " [   1   13  140 ...,    0    0    0]\n",
      " [ 318    8  913 ...,    0    0    0]\n",
      " ..., \n",
      " [2157   27  487 ...,    0    0    0]\n",
      " [  54   13 2972 ...,    0    0    0]\n",
      " [3359   67  289 ...,    0    0    0]]\n",
      " 41/200 [=====>........................] - ETA: 72s - loss: 1.5771 - acc: 0.8060[[  58   59   26 ...,    0    0    0]\n",
      " [ 167  187   65 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " ..., \n",
      " [  58   59    7 ...,    0    0    0]\n",
      " [  38  170 4160 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]]\n",
      " 42/200 [=====>........................] - ETA: 72s - loss: 1.5773 - acc: 0.8060[[  58   59   26 ...,    0    0    0]\n",
      " [ 220   26   65 ...,    0    0    0]\n",
      " [  55    7   73 ...,    0    0    0]\n",
      " ..., \n",
      " [ 342  196    4 ...,    0    0    0]\n",
      " [ 342  196    4 ...,    0    0    0]\n",
      " [1757  154   66 ...,    0    0    0]]\n",
      " 43/200 [=====>........................] - ETA: 71s - loss: 1.5776 - acc: 0.8060[[  1  78  13 ...,   0   0   0]\n",
      " [501   6  33 ...,   0   0   0]\n",
      " [ 38 825 433 ...,   0   0   0]\n",
      " ..., \n",
      " [501   6  24 ...,   0   0   0]\n",
      " [325 829 662 ...,   0   0   0]\n",
      " [824   6  28 ...,   0   0   0]]\n",
      " 44/200 [=====>........................] - ETA: 71s - loss: 1.5784 - acc: 0.8059[[  70   15  392 ...,    0    0    0]\n",
      " [8464 2259   67 ...,    0    0    0]\n",
      " [   2 4067 2268 ...,    0    0    0]\n",
      " ..., \n",
      " [  99  255   73 ...,    0    0    0]\n",
      " [ 819   26   65 ...,    0    0    0]\n",
      " [  48  950    6 ...,    0    0    0]]\n",
      " 45/200 [=====>........................] - ETA: 70s - loss: 1.5811 - acc: 0.8056[[1431  450   86 ...,    0    0    0]\n",
      " [  38   13   13 ...,    0    0    0]\n",
      " [   1  424   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 442  216   51 ...,    0    0    0]\n",
      " [ 159 1832   14 ...,    0    0    0]\n",
      " [  13  694  103 ...,    0    0    0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 46/200 [=====>........................] - ETA: 70s - loss: 1.5810 - acc: 0.8057[[   2 2444   14 ...,    0    0    0]\n",
      " [ 919   69 7067 ...,    0    0    0]\n",
      " [ 107   10 1555 ...,    0    0    0]\n",
      " ..., \n",
      " [ 433    7 2066 ...,    0    0    0]\n",
      " [1189  150   26 ...,    0    0    0]\n",
      " [1600   11  511 ...,    0    0    0]]\n",
      " 47/200 [======>.......................] - ETA: 69s - loss: 1.5832 - acc: 0.8054[[   1   13   91 ...,    0    0    0]\n",
      " [ 422  755   11 ...,    0    0    0]\n",
      " [   2 2321 4020 ...,    0    0    0]\n",
      " ..., \n",
      " [2095  745 2520 ...,    0    0    0]\n",
      " [ 206   66  115 ...,    0    0    0]\n",
      " [3365 5674  850 ...,    0    0    0]]\n",
      " 48/200 [======>.......................] - ETA: 69s - loss: 1.5758 - acc: 0.8060[[    1    13    91 ...,     0     0     0]\n",
      " [ 8738   139     7 ...,     0     0     0]\n",
      " [    1  2897   188 ...,     0     0     0]\n",
      " ..., \n",
      " [  644  8658     7 ...,     0     0     0]\n",
      " [   89    23    80 ...,     0     0     0]\n",
      " [11134  1064    13 ...,     0     0     0]]\n",
      " 49/200 [======>.......................] - ETA: 68s - loss: 1.5679 - acc: 0.8066[[3833 2322   13 ...,    0    0    0]\n",
      " [ 284    7   13 ...,    0    0    0]\n",
      " [ 481  176  196 ...,    0    0    0]\n",
      " ..., \n",
      " [1701 4256 2968 ...,    0    0    0]\n",
      " [3313 1131   32 ...,    0    0    0]\n",
      " [  64   82  590 ...,    0    0    0]]\n",
      " 50/200 [======>.......................] - ETA: 68s - loss: 1.5625 - acc: 0.8070[[1275  650  217 ...,    0    0    0]\n",
      " [ 986  721    5 ...,    0    0    0]\n",
      " [3318 9332  114 ...,    0    0    0]\n",
      " ..., \n",
      " [2555 2115  141 ...,    0    0    0]\n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [   2  146 1214 ...,    0    0    0]]\n",
      " 51/200 [======>.......................] - ETA: 68s - loss: 1.5575 - acc: 0.8074[[ 119   21   13 ...,    0    0    0]\n",
      " [3135   13   13 ...,    0    0    0]\n",
      " [   1  221  230 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 1007  674 ...,    0    0    0]\n",
      " [3587 7061    7 ...,    0    0    0]\n",
      " [  15   14    2 ...,    0    0    0]]\n",
      " 52/200 [======>.......................] - ETA: 67s - loss: 1.5528 - acc: 0.8077[[   2 1373   13 ...,    0    0    0]\n",
      " [ 154   66    4 ...,    0    0    0]\n",
      " [ 167    4   13 ...,    0    0    0]\n",
      " ..., \n",
      " [3689 3693    9 ...,    0    0    0]\n",
      " [4040  505   13 ...,    0    0    0]\n",
      " [  22 1738   13 ...,    0    0    0]]\n",
      " 53/200 [======>.......................] - ETA: 67s - loss: 1.5476 - acc: 0.8081[[   2  221  230 ...,    0    0    0]\n",
      " [  19  344 1113 ...,    0    0    0]\n",
      " [2237 1642   13 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  132 2251 ...,    0    0    0]\n",
      " [  64 8144   82 ...,    0    0    0]\n",
      " [ 255  598   23 ...,    0    0    0]]\n",
      " 54/200 [=======>......................] - ETA: 66s - loss: 1.5446 - acc: 0.8084[[  819    26   182 ...,     0     0     0]\n",
      " [ 1792    11  1048 ...,     0     0     0]\n",
      " [ 3054   130   131 ...,     0     0     0]\n",
      " ..., \n",
      " [ 1364 11506     9 ...,     0     0     0]\n",
      " [  413   558    11 ...,     0     0     0]\n",
      " [   34   188     7 ...,     0     0     0]]\n",
      " 55/200 [=======>......................] - ETA: 66s - loss: 1.5473 - acc: 0.8081[[ 293    7 2445 ...,    0    0    0]\n",
      " [  18 2693   13 ...,    0    0    0]\n",
      " [3643 1207 2940 ...,    0    0    0]\n",
      " ..., \n",
      " [7456 9503   11 ...,    0    0    0]\n",
      " [ 280 1987  190 ...,    0    0    0]\n",
      " [8321 8845 8425 ...,    0    0    0]]\n",
      " 56/200 [=======>......................] - ETA: 65s - loss: 1.5485 - acc: 0.8080[[    1    13   506 ...,     0     0     0]\n",
      " [  150  2173    13 ...,     0     0     0]\n",
      " [    2   538   123 ...,     0     0     0]\n",
      " ..., \n",
      " [ 1111   135   811 ...,     0     0     0]\n",
      " [  159  4081    81 ...,     0     0     0]\n",
      " [ 4482    13 11705 ...,     0     0     0]]\n",
      " 57/200 [=======>......................] - ETA: 65s - loss: 1.5498 - acc: 0.8078[[ 873  374  289 ...,    0    0    0]\n",
      " [ 317   13   13 ...,    0    0    0]\n",
      " [2142  747 2705 ...,    0    0    0]\n",
      " ..., \n",
      " [  53    7  137 ...,    0    0    0]\n",
      " [   1   78  150 ...,    0    0    0]\n",
      " [ 633 1936   13 ...,    0    0    0]]\n",
      " 58/200 [=======>......................] - ETA: 64s - loss: 1.5521 - acc: 0.8075[[   1 9492   38 ...,    0    0    0]\n",
      " [ 658    4   13 ...,    0    0    0]\n",
      " [  13   13   44 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 2039  361 ...,    0    0    0]\n",
      " [   1  459    7 ...,    0    0    0]\n",
      " [ 301   23  787 ...,    0    0    0]]\n",
      " 59/200 [=======>......................] - ETA: 64s - loss: 1.5522 - acc: 0.8075[[  27 9816 3873 ...,    0    0    0]\n",
      " [ 865   13  301 ...,    0    0    0]\n",
      " [  10    2 3216 ...,    0    0    0]\n",
      " ..., \n",
      " [  10 2453 7036 ...,    0    0    0]\n",
      " [   4   40 4165 ...,    0    0    0]\n",
      " [  15    7   48 ...,    0    0    0]]\n",
      " 60/200 [========>.....................] - ETA: 63s - loss: 1.5513 - acc: 0.8076[[ 184  810    1 ...,    0    0    0]\n",
      " [  13 1442   79 ...,    0    0    0]\n",
      " [1733   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 202    1 5659 ...,    0    0    0]\n",
      " [5691 1345    9 ...,    0    0    0]\n",
      " [   3 1428  116 ...,    0    0    0]]\n",
      " 61/200 [========>.....................] - ETA: 63s - loss: 1.5565 - acc: 0.8071[[  943    13 11557 ...,     0     0     0]\n",
      " [   12     1   645 ...,     0     0     0]\n",
      " [ 3140    13  6136 ...,     0     0     0]\n",
      " ..., \n",
      " [   15     7   776 ...,     0     0     0]\n",
      " [ 1698     4     1 ...,     0     0     0]\n",
      " [   13  2336    21 ...,     0     0     0]]\n",
      " 62/200 [========>.....................] - ETA: 62s - loss: 1.5609 - acc: 0.8065[[ 535  133   39 ...,    0    0    0]\n",
      " [ 873 2778 9301 ...,    0    0    0]\n",
      " [  13   13  802 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   49   13 ...,    0    0    0]\n",
      " [   1 7520   19 ...,    0    0    0]\n",
      " [ 161  426 1053 ...,    0    0    0]]\n",
      " 63/200 [========>.....................] - ETA: 62s - loss: 1.5640 - acc: 0.8062[[ 108   68   13 ...,    0    0    0]\n",
      " [  13  104   21 ...,    0    0    0]\n",
      " [2365   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [  75  103  626 ...,    0    0    0]\n",
      " [ 276  178   13 ...,    0    0    0]\n",
      " [  10  383    2 ...,    0    0    0]]\n",
      " 64/200 [========>.....................] - ETA: 61s - loss: 1.5714 - acc: 0.8054[[   13    26    67 ...,     0     0     0]\n",
      " [    1   179   161 ...,     0     0     0]\n",
      " [ 5206 10059     5 ...,     0     0     0]\n",
      " ..., \n",
      " [   90    99  1156 ...,     0     0     0]\n",
      " [    6     1   310 ...,     0     0     0]\n",
      " [ 1720    13     7 ...,     0     0     0]]\n",
      " 65/200 [========>.....................] - ETA: 61s - loss: 1.5677 - acc: 0.8059[[    1   127    13 ...,     0     0     0]\n",
      " [    2   287     5 ...,     0     0     0]\n",
      " [   93    23   428 ...,     0     0     0]\n",
      " ..., \n",
      " [  606    13   606 ...,     0     0     0]\n",
      " [    1   794    11 ...,     0     0     0]\n",
      " [  584 10173  1345 ...,     0     0     0]]\n",
      " 66/200 [========>.....................] - ETA: 60s - loss: 1.5712 - acc: 0.8055[[ 535    1 3629 ...,    0    0    0]\n",
      " [3685 6496   14 ...,    0    0    0]\n",
      " [ 276  178   13 ...,    0    0    0]\n",
      " ..., \n",
      " [5680   13  141 ...,    0    0    0]\n",
      " [2142  252  103 ...,    0    0    0]\n",
      " [6137   13 2621 ...,    0    0    0]]\n",
      " 67/200 [=========>....................] - ETA: 60s - loss: 1.5728 - acc: 0.8054[[3485 8007   11 ...,    0    0    0]\n",
      " [  13   13  292 ...,    0    0    0]\n",
      " [  13   13    9 ...,    0    0    0]\n",
      " ..., \n",
      " [ 349    9   76 ...,    0    0    0]\n",
      " [  13   13   11 ...,    0    0    0]\n",
      " [  18 1530   13 ...,    0    0    0]]\n",
      " 68/200 [=========>....................] - ETA: 60s - loss: 1.5725 - acc: 0.8055[[1768   13 1425 ...,    0    0    0]\n",
      " [3679    4 5243 ...,    0    0    0]\n",
      " [3138  105 1980 ...,    0    0    0]\n",
      " ..., \n",
      " [3022 2349 1585 ...,    0    0    0]\n",
      " [  15    7  229 ...,    0    0    0]\n",
      " [   1  221  230 ...,    0    0    0]]\n",
      " 69/200 [=========>....................] - ETA: 59s - loss: 1.5709 - acc: 0.8058[[4791   13   27 ...,    0    0    0]\n",
      " [   6   25  151 ...,    0    0    0]\n",
      " [ 702  123  338 ...,    0    0    0]\n",
      " ..., \n",
      " [  15  265  107 ...,    0    0    0]\n",
      " [6796   63 1105 ...,    0    0    0]\n",
      " [  73   66 2451 ...,    0    0    0]]\n",
      " 70/200 [=========>....................] - ETA: 59s - loss: 1.5725 - acc: 0.8056[[   4   13   13 ...,    0    0    0]\n",
      " [  13   13 5118 ...,    0    0    0]\n",
      " [  13  690 2463 ...,    0    0    0]\n",
      " ..., \n",
      " [1588   69   13 ...,    0    0    0]\n",
      " [ 219  970 2002 ...,    0    0    0]\n",
      " [   1  956   55 ...,    0    0    0]]\n",
      " 71/200 [=========>....................] - ETA: 58s - loss: 1.5744 - acc: 0.8055[[   2 2487   32 ...,    0    0    0]\n",
      " [  13   69  297 ...,    0    0    0]\n",
      " [2181    7 1802 ...,    0    0    0]\n",
      " ..., \n",
      " [ 140  369    8 ...,    0    0    0]\n",
      " [ 491   26  113 ...,    0    0    0]\n",
      " [1396    6    2 ...,    0    0    0]]\n",
      " 72/200 [=========>....................] - ETA: 58s - loss: 1.5742 - acc: 0.8055[[4946 2438 2101 ...,    0    0    0]\n",
      " [  19  352 1400 ...,    0    0    0]\n",
      " [4245   13    4 ...,    0    0    0]\n",
      " ..., \n",
      " [6465  172   12 ...,    0    0    0]\n",
      " [ 131  395  456 ...,    0    0    0]\n",
      " [   1   13 1847 ...,    0    0    0]]\n",
      " 73/200 [=========>....................] - ETA: 57s - loss: 1.5744 - acc: 0.8055[[ 763 9690   21 ...,    0    0    0]\n",
      " [ 373  423   55 ...,    0    0    0]\n",
      " [   1   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 2893 2824 ...,    0    0    0]\n",
      " [  55    8 4432 ...,    0    0    0]\n",
      " [  13  792   86 ...,    0    0    0]]\n",
      " 74/200 [==========>...................] - ETA: 57s - loss: 1.5743 - acc: 0.8055[[ 844    8 3029 ...,    0    0    0]\n",
      " [1910   55    7 ...,    0    0    0]\n",
      " [   1  220   73 ...,    0    0    0]\n",
      " ..., \n",
      " [ 937   13   13 ...,    0    0    0]\n",
      " [   1 1008 2973 ...,    0    0    0]\n",
      " [   1   13  191 ...,    0    0    0]]\n",
      " 75/200 [==========>...................] - ETA: 56s - loss: 1.5748 - acc: 0.8055[[  58   59   26 ...,    0    0    0]\n",
      " [   1  740    5 ...,    0    0    0]\n",
      " [6094 7169  130 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  740    5 ...,    0    0    0]\n",
      " [  13 1056 6390 ...,    0    0    0]\n",
      " [ 154  635  143 ...,    0    0    0]]\n",
      " 76/200 [==========>...................] - ETA: 56s - loss: 1.5739 - acc: 0.8057[[ 481   66   14 ...,    0    0    0]\n",
      " [  49   13  704 ...,    0    0    0]\n",
      " [ 167  187  106 ...,    0    0    0]\n",
      " ..., \n",
      " [1339 1553   11 ...,    0    0    0]\n",
      " [1635   13    9 ...,    0    0    0]\n",
      " [2589    5  220 ...,    0    0    0]]\n",
      " 77/200 [==========>...................] - ETA: 55s - loss: 1.5742 - acc: 0.8057[[   1  132  509 ...,    0    0    0]\n",
      " [1896  187   65 ...,    0    0    0]\n",
      " [2395   13  100 ...,    0    0    0]\n",
      " ..., \n",
      " [ 185 1780   21 ...,    0    0    0]\n",
      " [ 255  154   66 ...,    0    0    0]\n",
      " [ 524   10   22 ...,    0    0    0]]\n",
      " 78/200 [==========>...................] - ETA: 55s - loss: 1.5748 - acc: 0.8057[[   16  5877 11689 ...,     0     0     0]\n",
      " [11630    13    13 ...,     0     0     0]\n",
      " [    1    13    13 ...,     0     0     0]\n",
      " ..., \n",
      " [   13    13   253 ...,     0     0     0]\n",
      " [    1    13  4128 ...,     0     0     0]\n",
      " [   15   448    29 ...,     0     0     0]]\n",
      " 79/200 [==========>...................] - ETA: 54s - loss: 1.5758 - acc: 0.8056[[    1    13   879 ...,     0     0     0]\n",
      " [  364   375   411 ...,     0     0     0]\n",
      " [ 6528 11277  6082 ...,     0     0     0]\n",
      " ..., \n",
      " [10681 10044   253 ...,     0     0     0]\n",
      " [  481   176    66 ...,     0     0     0]\n",
      " [    1   919   736 ...,     0     0     0]]\n",
      " 80/200 [===========>..................] - ETA: 54s - loss: 1.5760 - acc: 0.8056[[ 1360    13     9 ...,     0     0     0]\n",
      " [ 2196   418   335 ...,     0     0     0]\n",
      " [   15   247   234 ...,     0     0     0]\n",
      " ..., \n",
      " [10926     8    13 ...,     0     0     0]\n",
      " [   92  1755  3347 ...,     0     0     0]\n",
      " [  206    66    23 ...,     0     0     0]]\n",
      " 81/200 [===========>..................] - ETA: 54s - loss: 1.5743 - acc: 0.8057[[   41     5     1 ...,     0     0     0]\n",
      " [10509 11024    83 ...,     0     0     0]\n",
      " [  131   248    85 ...,     0     0     0]\n",
      " ..., \n",
      " [   13    13     1 ...,     0     0     0]\n",
      " [ 1090  9071   461 ...,     0     0     0]\n",
      " [ 1491  2550  1950 ...,     0     0     0]]\n",
      " 82/200 [===========>..................] - ETA: 53s - loss: 1.5705 - acc: 0.8060[[  70  152  139 ...,    0    0    0]\n",
      " [ 987    7  615 ...,    0    0    0]\n",
      " [2151   11    2 ...,    0    0    0]\n",
      " ..., \n",
      " [ 109   26  115 ...,    0    0    0]\n",
      " [1150   13   13 ...,    0    0    0]\n",
      " [   2 3865 1346 ...,    0    0    0]]\n",
      " 83/200 [===========>..................] - ETA: 53s - loss: 1.5666 - acc: 0.8063[[   1 8252    5 ...,    0    0    0]\n",
      " [   1  474 1341 ...,    0    0    0]\n",
      " [ 500    7   19 ...,    0    0    0]\n",
      " ..., \n",
      " [ 962 6266    8 ...,    0    0    0]\n",
      " [   2  121 8811 ...,    0    0    0]\n",
      " [  56   13  397 ...,    0    0    0]]\n",
      " 84/200 [===========>..................] - ETA: 52s - loss: 1.5629 - acc: 0.8066[[   4    1  117 ...,    0    0    0]\n",
      " [  13    7   13 ...,    0    0    0]\n",
      " [   1 4920    5 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  145  608 ...,    0    0    0]\n",
      " [   2   13  150 ...,    0    0    0]\n",
      " [1170  159  390 ...,    0    0    0]]\n",
      " 85/200 [===========>..................] - ETA: 52s - loss: 1.5596 - acc: 0.8068[[2567 2560  217 ...,    0    0    0]\n",
      " [   2 1147   32 ...,    0    0    0]\n",
      " [  89   14 2631 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 5475    5 ...,    0    0    0]\n",
      " [ 955  814    5 ...,    0    0    0]\n",
      " [ 284    7   69 ...,    0    0    0]]\n",
      " 86/200 [===========>..................] - ETA: 51s - loss: 1.5562 - acc: 0.8071[[3756   13    8 ...,    0    0    0]\n",
      " [2490    7  732 ...,    0    0    0]\n",
      " [  73   13    4 ...,    0    0    0]\n",
      " ..., \n",
      " [3236 2644   27 ...,    0    0    0]\n",
      " [1507   10 1061 ...,    0    0    0]\n",
      " [5489    7  390 ...,    0    0    0]]\n",
      " 87/200 [============>.................] - ETA: 51s - loss: 1.5535 - acc: 0.8074[[   2 1624 2642 ...,    0    0    0]\n",
      " [   2 1580 1048 ...,    0    0    0]\n",
      " [   1  261  401 ...,    0    0    0]\n",
      " ..., \n",
      " [   2  763  740 ...,    0    0    0]\n",
      " [  89  105   20 ...,    0    0    0]\n",
      " [1757 1483   27 ...,    0    0    0]]\n",
      " 88/200 [============>.................] - ETA: 50s - loss: 1.5514 - acc: 0.8075[[    2    74    56 ...,     0     0     0]\n",
      " [    1   528   142 ...,     0     0     0]\n",
      " [ 6686  8975  1850 ...,     0     0     0]\n",
      " ..., \n",
      " [    1   221   230 ...,     0     0     0]\n",
      " [ 1162  8454  2103 ...,     0     0     0]\n",
      " [11856  1993    11 ...,     0     0     0]]\n",
      " 89/200 [============>.................] - ETA: 50s - loss: 1.5507 - acc: 0.8076[[   1 3135  161 ...,    0    0    0]\n",
      " [3282 3426   11 ...,    0    0    0]\n",
      " [4182 2308   11 ...,    0    0    0]\n",
      " ..., \n",
      " [ 497   13   69 ...,    0    0    0]\n",
      " [ 280   13  100 ...,    0    0    0]\n",
      " [7546   13 1564 ...,    0    0    0]]\n",
      " 90/200 [============>.................] - ETA: 49s - loss: 1.5508 - acc: 0.8076[[   13    69   297 ...,     0     0     0]\n",
      " [ 2558  1063  8611 ...,     0     0     0]\n",
      " [ 3549   130   131 ...,     0     0     0]\n",
      " ..., \n",
      " [    1    91   106 ...,     0     0     0]\n",
      " [ 2461   900  3066 ...,     0     0     0]\n",
      " [11627   779    13 ...,     0     0     0]]\n",
      " 91/200 [============>.................] - ETA: 49s - loss: 1.5532 - acc: 0.8074[[  109    26    65 ...,     0     0     0]\n",
      " [  893   232 11645 ...,     0     0     0]\n",
      " [   89   684    20 ...,     0     0     0]\n",
      " ..., \n",
      " [    1   549     5 ...,     0     0     0]\n",
      " [  108  1350   543 ...,     0     0     0]\n",
      " [    5    79     1 ...,     0     0     0]]\n",
      " 92/200 [============>.................] - ETA: 49s - loss: 1.5538 - acc: 0.8073[[ 606    9 2477 ...,    0    0    0]\n",
      " [  89  684   20 ...,    0    0    0]\n",
      " [  13 2652 1558 ...,    0    0    0]\n",
      " ..., \n",
      " [1746 1574 6367 ...,    0    0    0]\n",
      " [ 508   15    1 ...,    0    0    0]\n",
      " [ 194    5    1 ...,    0    0    0]]\n",
      " 93/200 [============>.................] - ETA: 48s - loss: 1.5561 - acc: 0.8070[[    6     1  5556 ...,     0     0     0]\n",
      " [ 5526    13     1 ...,     0     0     0]\n",
      " [  108  4713    51 ...,     0     0     0]\n",
      " ..., \n",
      " [10537   558    30 ...,     0     0     0]\n",
      " [   13    13   430 ...,     0     0     0]\n",
      " [ 7029    13     9 ...,     0     0     0]]\n",
      " 94/200 [=============>................] - ETA: 48s - loss: 1.5549 - acc: 0.8072[[   49    63   144 ...,     0     0     0]\n",
      " [11254    13    13 ...,     0     0     0]\n",
      " [ 1851     9  2938 ...,     0     0     0]\n",
      " ..., \n",
      " [   13    13   221 ...,     0     0     0]\n",
      " [  584     1  7157 ...,     0     0     0]\n",
      " [   13  8426  6054 ...,     0     0     0]]\n",
      " 95/200 [=============>................] - ETA: 47s - loss: 1.5558 - acc: 0.8071[[   1 2324    5 ...,    0    0    0]\n",
      " [  13  104   21 ...,    0    0    0]\n",
      " [2543    1 1744 ...,    0    0    0]\n",
      " ..., \n",
      " [9196 5800    7 ...,    0    0    0]\n",
      " [  81   42 7503 ...,    0    0    0]\n",
      " [   1  166  371 ...,    0    0    0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 96/200 [=============>................] - ETA: 47s - loss: 1.5588 - acc: 0.8068[[1384   15   51 ...,    0    0    0]\n",
      " [  12   47  643 ...,    0    0    0]\n",
      " [  13    3 2537 ...,    0    0    0]\n",
      " ..., \n",
      " [  13 1432   10 ...,    0    0    0]\n",
      " [1386    7   73 ...,    0    0    0]\n",
      " [3954   13  192 ...,    0    0    0]]\n",
      " 97/200 [=============>................] - ETA: 46s - loss: 1.5617 - acc: 0.8064[[   1 3955    9 ...,    0    0    0]\n",
      " [   1 2943  217 ...,    0    0    0]\n",
      " [ 278    1   63 ...,    0    0    0]\n",
      " ..., \n",
      " [ 439   90   34 ...,    0    0    0]\n",
      " [  32  155    6 ...,    0    0    0]\n",
      " [9404  375 8160 ...,    0    0    0]]\n",
      " 98/200 [=============>................] - ETA: 46s - loss: 1.5648 - acc: 0.8061[[ 116  163  157 ...,    0    0    0]\n",
      " [ 220  324  209 ...,    0    0    0]\n",
      " [   1 1130   14 ...,    0    0    0]\n",
      " ..., \n",
      " [  13    1  681 ...,    0    0    0]\n",
      " [ 104  107 3647 ...,    0    0    0]\n",
      " [  12    1  908 ...,    0    0    0]]\n",
      " 99/200 [=============>................] - ETA: 45s - loss: 1.5650 - acc: 0.8061[[1811    7   47 ...,    0    0    0]\n",
      " [  93   67   13 ...,    0    0    0]\n",
      " [3884  176  298 ...,    0    0    0]\n",
      " ..., \n",
      " [ 531   67  207 ...,    0    0    0]\n",
      " [  27 2828  247 ...,    0    0    0]\n",
      " [  13 2635   67 ...,    0    0    0]]\n",
      "100/200 [==============>...............] - ETA: 45s - loss: 1.5661 - acc: 0.8060[[7069  123    7 ...,    0    0    0]\n",
      " [  13   13  200 ...,    0    0    0]\n",
      " [   1 1443   67 ...,    0    0    0]\n",
      " ..., \n",
      " [   4   22  408 ...,    0    0    0]\n",
      " [  10   63   13 ...,    0    0    0]\n",
      " [  18   22   13 ...,    0    0    0]]\n",
      "101/200 [==============>...............] - ETA: 44s - loss: 1.5681 - acc: 0.8058[[  13    6    1 ...,    0    0    0]\n",
      " [  27 1415  128 ...,    0    0    0]\n",
      " [   1  831   99 ...,    0    0    0]\n",
      " ..., \n",
      " [ 116   13 9748 ...,    0    0    0]\n",
      " [5391   13   13 ...,    0    0    0]\n",
      " [   1 6447   13 ...,    0    0    0]]\n",
      "102/200 [==============>...............] - ETA: 44s - loss: 1.5684 - acc: 0.8057[[   1 1769 2672 ...,    0    0    0]\n",
      " [ 557  733   13 ...,    0    0    0]\n",
      " [ 427   21 2318 ...,    0    0    0]\n",
      " ..., \n",
      " [ 108   93  959 ...,    0    0    0]\n",
      " [1304   23    2 ...,    0    0    0]\n",
      " [  12   34  692 ...,    0    0    0]]\n",
      "103/200 [==============>...............] - ETA: 43s - loss: 1.5674 - acc: 0.8059[[  80   41  384 ...,    0    0    0]\n",
      " [   1  474  558 ...,    0    0    0]\n",
      " [  15   27  257 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   13   13 ...,    0    0    0]\n",
      " [  18    1  381 ...,    0    0    0]\n",
      " [ 958 5040  747 ...,    0    0    0]]\n",
      "104/200 [==============>...............] - ETA: 43s - loss: 1.5676 - acc: 0.8059[[  10   34   13 ...,    0    0    0]\n",
      " [1853  135 2585 ...,    0    0    0]\n",
      " [  70   15  392 ...,    0    0    0]\n",
      " ..., \n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [ 109   26   65 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]]\n",
      "105/200 [==============>...............] - ETA: 43s - loss: 1.5688 - acc: 0.8058[[4504 3102    1 ...,    0    0    0]\n",
      " [2504    8 1654 ...,    0    0    0]\n",
      " [   1  286    5 ...,    0    0    0]\n",
      " ..., \n",
      " [ 599  102    4 ...,    0    0    0]\n",
      " [1247   11  850 ...,    0    0    0]\n",
      " [5164   21  269 ...,    0    0    0]]\n",
      "106/200 [==============>...............] - ETA: 42s - loss: 1.5684 - acc: 0.8058[[   1   47 2903 ...,    0    0    0]\n",
      " [   2   13 3238 ...,    0    0    0]\n",
      " [   1 2059 1158 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  214   23 ...,    0    0    0]\n",
      " [ 167 1865   13 ...,    0    0    0]\n",
      " [2017   67  694 ...,    0    0    0]]\n",
      "107/200 [===============>..............] - ETA: 42s - loss: 1.5684 - acc: 0.8059[[   1 3635    5 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " ..., \n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [2562   26  249 ...,    0    0    0]\n",
      " [  55   11 3290 ...,    0    0    0]]\n",
      "108/200 [===============>..............] - ETA: 41s - loss: 1.5689 - acc: 0.8058[[1267   26  113 ...,    0    0    0]\n",
      " [ 167  161  162 ...,    0    0    0]\n",
      " [ 234  435  167 ...,    0    0    0]\n",
      " ..., \n",
      " [1863   13   69 ...,    0    0    0]\n",
      " [  38  481  176 ...,    0    0    0]\n",
      " [   1 3317  310 ...,    0    0    0]]\n",
      "109/200 [===============>..............] - ETA: 41s - loss: 1.5683 - acc: 0.8059[[ 109   26  113 ...,    0    0    0]\n",
      " [  55  231   53 ...,    0    0    0]\n",
      " [1695  736 1528 ...,    0    0    0]\n",
      " ..., \n",
      " [  55   11 1220 ...,    0    0    0]\n",
      " [   1 1653 1614 ...,    0    0    0]\n",
      " [ 444 5769   40 ...,    0    0    0]]\n",
      "110/200 [===============>..............] - ETA: 40s - loss: 1.5687 - acc: 0.8059[[  19  352   30 ...,    0    0    0]\n",
      " [1757  119   27 ...,    0    0    0]\n",
      " [ 193   27  971 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  161  657 ...,    0    0    0]\n",
      " [   1  156 8704 ...,    0    0    0]\n",
      " [2198   69 8009 ...,    0    0    0]]\n",
      "111/200 [===============>..............] - ETA: 40s - loss: 1.5693 - acc: 0.8058[[  55   11 2025 ...,    0    0    0]\n",
      " [  58   59    7 ...,    0    0    0]\n",
      " [  49 1839    4 ...,    0    0    0]\n",
      " ..., \n",
      " [ 553  509   13 ...,    0    0    0]\n",
      " [ 342  196   66 ...,    0    0    0]\n",
      " [  32    2 2393 ...,    0    0    0]]\n",
      "112/200 [===============>..............] - ETA: 39s - loss: 1.5696 - acc: 0.8058[[1848  249   13 ...,    0    0    0]\n",
      " [   2   13 1373 ...,    0    0    0]\n",
      " [ 501  154   66 ...,    0    0    0]\n",
      " ..., \n",
      " [  55  100    1 ...,    0    0    0]\n",
      " [  55    7   13 ...,    0    0    0]\n",
      " [5591 5759    5 ...,    0    0    0]]\n",
      "113/200 [===============>..............] - ETA: 39s - loss: 1.5696 - acc: 0.8059[[ 131  179   69 ...,    0    0    0]\n",
      " [1745 3701    4 ...,    0    0    0]\n",
      " [1695  424  240 ...,    0    0    0]\n",
      " ..., \n",
      " [2323 2339  587 ...,    0    0    0]\n",
      " [1109    7  660 ...,    0    0    0]\n",
      " [   2 6148   74 ...,    0    0    0]]\n",
      "114/200 [================>.............] - ETA: 39s - loss: 1.5694 - acc: 0.8059[[ 109   26  268 ...,    0    0    0]\n",
      " [ 447  200    9 ...,    0    0    0]\n",
      " [6526   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 514 2246   13 ...,    0    0    0]\n",
      " [ 108 6764   13 ...,    0    0    0]\n",
      " [  42   14 7660 ...,    0    0    0]]\n",
      "115/200 [================>.............] - ETA: 38s - loss: 1.5682 - acc: 0.8060[[5230  558   83 ...,    0    0    0]\n",
      " [  13  800  390 ...,    0    0    0]\n",
      " [2535 6304   28 ...,    0    0    0]\n",
      " ..., \n",
      " [6992   11 1402 ...,    0    0    0]\n",
      " [ 299    5   19 ...,    0    0    0]\n",
      " [7181  721    7 ...,    0    0    0]]\n",
      "116/200 [================>.............] - ETA: 38s - loss: 1.5653 - acc: 0.8061[[  55    7 4530 ...,    0    0    0]\n",
      " [   1  601    5 ...,    0    0    0]\n",
      " [   2  582  405 ...,    0    0    0]\n",
      " ..., \n",
      " [2002 4124 1060 ...,    0    0    0]\n",
      " [2000    5 3866 ...,    0    0    0]\n",
      " [  26   67   84 ...,    0    0    0]]\n",
      "117/200 [================>.............] - ETA: 37s - loss: 1.5620 - acc: 0.8064[[  429  1887   484 ...,     0     0     0]\n",
      " [10146   971  9777 ...,     0     0     0]\n",
      " [  133    39  1899 ...,     0     0     0]\n",
      " ..., \n",
      " [ 9355 10993    11 ...,     0     0     0]\n",
      " [   22    13     9 ...,     0     0     0]\n",
      " [ 5353   963    13 ...,     0     0     0]]\n",
      "118/200 [================>.............] - ETA: 37s - loss: 1.5595 - acc: 0.8066[[ 276  178   13 ...,    0    0    0]\n",
      " [1573 2461  450 ...,    0    0    0]\n",
      " [1727  812   13 ...,    0    0    0]\n",
      " ..., \n",
      " [1431  450    9 ...,    0    0    0]\n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [  26  113   88 ...,    0    0    0]]\n",
      "119/200 [================>.............] - ETA: 36s - loss: 1.5568 - acc: 0.8068[[  15 1312   79 ...,    0    0    0]\n",
      " [1267  970 5527 ...,    0    0    0]\n",
      " [ 155  790 2047 ...,    0    0    0]\n",
      " ..., \n",
      " [5274 6861   11 ...,    0    0    0]\n",
      " [ 685  720 1150 ...,    0    0    0]\n",
      " [2371  532 1090 ...,    0    0    0]]\n",
      "120/200 [=================>............] - ETA: 36s - loss: 1.5545 - acc: 0.8070[[ 819   26   65 ...,    0    0    0]\n",
      " [  15   27   20 ...,    0    0    0]\n",
      " [1046  332 4746 ...,    0    0    0]\n",
      " ..., \n",
      " [   2   19  432 ...,    0    0    0]\n",
      " [ 131   69  309 ...,    0    0    0]\n",
      " [   1   13 3709 ...,    0    0    0]]\n",
      "121/200 [=================>............] - ETA: 35s - loss: 1.5521 - acc: 0.8071[[  22 1830   13 ...,    0    0    0]\n",
      " [1644 4243   13 ...,    0    0    0]\n",
      " [2160    2   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 706 3156   21 ...,    0    0    0]\n",
      " [  22  529 1376 ...,    0    0    0]\n",
      " [ 654  145    9 ...,    0    0    0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/200 [=================>............] - ETA: 35s - loss: 1.5498 - acc: 0.8073[[   2  440 3626 ...,    0    0    0]\n",
      " [ 150 4118 1345 ...,    0    0    0]\n",
      " [6629   27 3067 ...,    0    0    0]\n",
      " ..., \n",
      " [4526 2393 3885 ...,    0    0    0]\n",
      " [5829    7  732 ...,    0    0    0]\n",
      " [  13  761 6404 ...,    0    0    0]]\n",
      "123/200 [=================>............] - ETA: 35s - loss: 1.5481 - acc: 0.8075[[   2  676 2398 ...,    0    0    0]\n",
      " [ 792    7   13 ...,    0    0    0]\n",
      " [3408  157    2 ...,    0    0    0]\n",
      " ..., \n",
      " [3007    4  672 ...,    0    0    0]\n",
      " [ 226  752   13 ...,    0    0    0]\n",
      " [5933 5876 1425 ...,    0    0    0]]\n",
      "124/200 [=================>............] - ETA: 34s - loss: 1.5479 - acc: 0.8074[[ 226 1448  280 ...,    0    0    0]\n",
      " [   1  145  608 ...,    0    0    0]\n",
      " [ 807 4022   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 381  228  615 ...,    0    0    0]\n",
      " [   2 4374 9858 ...,    0    0    0]\n",
      " [  49 7088   21 ...,    0    0    0]]\n",
      "125/200 [=================>............] - ETA: 34s - loss: 1.5477 - acc: 0.8074[[ 676   19  352 ...,    0    0    0]\n",
      " [ 221  230  782 ...,    0    0    0]\n",
      " [5028   13  100 ...,    0    0    0]\n",
      " ..., \n",
      " [  15   14 1222 ...,    0    0    0]\n",
      " [  56  430    2 ...,    0    0    0]\n",
      " [   1   73  138 ...,    0    0    0]]\n",
      "126/200 [=================>............] - ETA: 33s - loss: 1.5498 - acc: 0.8072[[   1   13   91 ...,    0    0    0]\n",
      " [   1 3272 1040 ...,    0    0    0]\n",
      " [   1  330   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 219  324  209 ...,    0    0    0]\n",
      " [ 219  414  808 ...,    0    0    0]\n",
      " [ 697 1295  268 ...,    0    0    0]]\n",
      "127/200 [==================>...........] - ETA: 33s - loss: 1.5498 - acc: 0.8072[[324 209  13 ...,   0   0   0]\n",
      " [745  11  39 ...,   0   0   0]\n",
      " [ 13   7 131 ...,   0   0   0]\n",
      " ..., \n",
      " [  4   1  38 ...,   0   0   0]\n",
      " [ 15   7   2 ...,   0   0   0]\n",
      " [ 43  41  13 ...,   0   0   0]]\n",
      "128/200 [==================>...........] - ETA: 32s - loss: 1.5501 - acc: 0.8072[[  13 1578   15 ...,    0    0    0]\n",
      " [1578   13  105 ...,    0    0    0]\n",
      " [  70  159 1505 ...,    0    0    0]\n",
      " ..., \n",
      " [ 102  123 1944 ...,    0    0    0]\n",
      " [ 158  165    6 ...,    0    0    0]\n",
      " [   1   49   19 ...,    0    0    0]]\n",
      "129/200 [==================>...........] - ETA: 32s - loss: 1.5510 - acc: 0.8071[[  41  237 1212 ...,    0    0    0]\n",
      " [2343   13    9 ...,    0    0    0]\n",
      " [   1   13  124 ...,    0    0    0]\n",
      " ..., \n",
      " [2265 3954    9 ...,    0    0    0]\n",
      " [ 104 1585   96 ...,    0    0    0]\n",
      " [   1   13 1459 ...,    0    0    0]]\n",
      "130/200 [==================>...........] - ETA: 31s - loss: 1.5511 - acc: 0.8071[[  13   27 1181 ...,    0    0    0]\n",
      " [  13   15    7 ...,    0    0    0]\n",
      " [ 730   13 1067 ...,    0    0    0]\n",
      " ..., \n",
      " [  13  301 1384 ...,    0    0    0]\n",
      " [ 309  451   11 ...,    0    0    0]\n",
      " [   1 1017  182 ...,    0    0    0]]\n",
      "131/200 [==================>...........] - ETA: 31s - loss: 1.5535 - acc: 0.8069[[ 463   27   20 ...,    0    0    0]\n",
      " [ 194  563  374 ...,    0    0    0]\n",
      " [  56   13   63 ...,    0    0    0]\n",
      " ..., \n",
      " [ 443  900    7 ...,    0    0    0]\n",
      " [3491   26  619 ...,    0    0    0]\n",
      " [1940  536   13 ...,    0    0    0]]\n",
      "132/200 [==================>...........] - ETA: 30s - loss: 1.5554 - acc: 0.8067[[ 626    8 6161 ...,    0    0    0]\n",
      " [ 232   13 3343 ...,    0    0    0]\n",
      " [   1  751 2224 ...,    0    0    0]\n",
      " ..., \n",
      " [1014   13  381 ...,    0    0    0]\n",
      " [   2  259 2110 ...,    0    0    0]\n",
      " [3578  510   24 ...,    0    0    0]]\n",
      "133/200 [==================>...........] - ETA: 30s - loss: 1.5567 - acc: 0.8065[[    1  4995    86 ...,     0     0     0]\n",
      " [   93  1163    13 ...,     0     0     0]\n",
      " [   15     7  2204 ...,     0     0     0]\n",
      " ..., \n",
      " [  458  3535     9 ...,     0     0     0]\n",
      " [  882   283    50 ...,     0     0     0]\n",
      " [   93 11772  1166 ...,     0     0     0]]\n",
      "134/200 [===================>..........] - ETA: 30s - loss: 1.5595 - acc: 0.8062[[    1  1086   123 ...,     0     0     0]\n",
      " [    1   730  3049 ...,     0     0     0]\n",
      " [    1  1559  2887 ...,     0     0     0]\n",
      " ..., \n",
      " [  564    13  1068 ...,     0     0     0]\n",
      " [  116   589 11609 ...,     0     0     0]\n",
      " [   10    92   888 ...,     0     0     0]]\n",
      "135/200 [===================>..........] - ETA: 29s - loss: 1.5597 - acc: 0.8062[[ 232 3459   81 ...,    0    0    0]\n",
      " [ 379  177   13 ...,    0    0    0]\n",
      " [  19  120  105 ...,    0    0    0]\n",
      " ..., \n",
      " [  70    2 5322 ...,    0    0    0]\n",
      " [  13 1171   13 ...,    0    0    0]\n",
      " [ 599   63 1105 ...,    0    0    0]]\n",
      "136/200 [===================>..........] - ETA: 29s - loss: 1.5603 - acc: 0.8062[[   3 1141    2 ...,    0    0    0]\n",
      " [  13  104 2467 ...,    0    0    0]\n",
      " [  15  105   21 ...,    0    0    0]\n",
      " ..., \n",
      " [   4  552  173 ...,    0    0    0]\n",
      " [5707  610   11 ...,    0    0    0]\n",
      " [   1 5269   23 ...,    0    0    0]]\n",
      "137/200 [===================>..........] - ETA: 28s - loss: 1.5624 - acc: 0.8060[[  166   234    63 ...,     0     0     0]\n",
      " [   13     9   407 ...,     0     0     0]\n",
      " [    4    13  4290 ...,     0     0     0]\n",
      " ..., \n",
      " [   70   193 11373 ...,     0     0     0]\n",
      " [ 1760   898     1 ...,     0     0     0]\n",
      " [   15     7    54 ...,     0     0     0]]\n",
      "138/200 [===================>..........] - ETA: 28s - loss: 1.5616 - acc: 0.8061[[  72   29    7 ...,    0    0    0]\n",
      " [ 108    1   13 ...,    0    0    0]\n",
      " [ 304 1173  695 ...,    0    0    0]\n",
      " ..., \n",
      " [  99  102 2728 ...,    0    0    0]\n",
      " [2203   13  260 ...,    0    0    0]\n",
      " [ 382    3 2264 ...,    0    0    0]]\n",
      "139/200 [===================>..........] - ETA: 27s - loss: 1.5612 - acc: 0.8061[[   1  629    5 ...,    0    0    0]\n",
      " [ 221  230   13 ...,    0    0    0]\n",
      " [  15    7   18 ...,    0    0    0]\n",
      " ..., \n",
      " [  34    9    1 ...,    0    0    0]\n",
      " [   1  526 2248 ...,    0    0    0]\n",
      " [   1  431    5 ...,    0    0    0]]\n",
      "140/200 [====================>.........] - ETA: 27s - loss: 1.5610 - acc: 0.8062[[  26 1533   24 ...,    0    0    0]\n",
      " [  13  137    7 ...,    0    0    0]\n",
      " [   2 5193  165 ...,    0    0    0]\n",
      " ..., \n",
      " [  13 4006 7600 ...,    0    0    0]\n",
      " [ 108 3929   13 ...,    0    0    0]\n",
      " [  42   13    1 ...,    0    0    0]]\n",
      "141/200 [====================>.........] - ETA: 26s - loss: 1.5623 - acc: 0.8061[[ 229    2   13 ...,    0    0    0]\n",
      " [  68 1108  377 ...,    0    0    0]\n",
      " [  90  244 6505 ...,    0    0    0]\n",
      " ..., \n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [ 248   85  295 ...,    0    0    0]]\n",
      "142/200 [====================>.........] - ETA: 26s - loss: 1.5627 - acc: 0.8060[[    1   545   191 ...,     0     0     0]\n",
      " [    1   701     5 ...,     0     0     0]\n",
      " [  561    75   329 ...,     0     0     0]\n",
      " ..., \n",
      " [  561     8  1386 ...,     0     0     0]\n",
      " [11855   252   205 ...,     0     0     0]\n",
      " [  727     6    57 ...,     0     0     0]]\n",
      "143/200 [====================>.........] - ETA: 25s - loss: 1.5630 - acc: 0.8060[[  58   59   26 ...,    0    0    0]\n",
      " [   2  146   11 ...,    0    0    0]\n",
      " [ 109   26  619 ...,    0    0    0]\n",
      " ..., \n",
      " [  55    6   28 ...,    0    0    0]\n",
      " [ 109   26 1452 ...,    0    0    0]\n",
      " [  38  481  176 ...,    0    0    0]]\n",
      "144/200 [====================>.........] - ETA: 25s - loss: 1.5629 - acc: 0.8061[[ 214   23    1 ...,    0    0    0]\n",
      " [ 214   23    1 ...,    0    0    0]\n",
      " [ 214   23    1 ...,    0    0    0]\n",
      " ..., \n",
      " [ 546    6   25 ...,    0    0    0]\n",
      " [1717   13    5 ...,    0    0    0]\n",
      " [  13    9  498 ...,    0    0    0]]\n",
      "145/200 [====================>.........] - ETA: 25s - loss: 1.5629 - acc: 0.8061[[   1   13  736 ...,    0    0    0]\n",
      " [ 167  187  113 ...,    0    0    0]\n",
      " [1337    7 2059 ...,    0    0    0]\n",
      " ..., \n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [ 119    4  140 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]]\n",
      "146/200 [====================>.........] - ETA: 24s - loss: 1.5633 - acc: 0.8061[[   1   13   91 ...,    0    0    0]\n",
      " [  26   12 2893 ...,    0    0    0]\n",
      " [ 454  205 2072 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 2011  283 ...,    0    0    0]\n",
      " [ 219   73  138 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]]\n",
      "147/200 [=====================>........] - ETA: 24s - loss: 1.5634 - acc: 0.8061[[    1    19   352 ...,     0     0     0]\n",
      " [  284   550   940 ...,     0     0     0]\n",
      " [ 2593 10809   555 ...,     0     0     0]\n",
      " ..., \n",
      " [10034   398  4821 ...,     0     0     0]\n",
      " [    1    55  2892 ...,     0     0     0]\n",
      " [  547  3499    13 ...,     0     0     0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/200 [=====================>........] - ETA: 23s - loss: 1.5635 - acc: 0.8061[[  884  4570     6 ...,     0     0     0]\n",
      " [    1   956   199 ...,     0     0     0]\n",
      " [   58    59   975 ...,     0     0     0]\n",
      " ..., \n",
      " [ 3213  4089     5 ...,     0     0     0]\n",
      " [11193   532  3291 ...,     0     0     0]\n",
      " [ 1525   398    13 ...,     0     0     0]]\n",
      "149/200 [=====================>........] - ETA: 23s - loss: 1.5638 - acc: 0.8061[[1757  187   65 ...,    0    0    0]\n",
      " [ 444   36  921 ...,    0    0    0]\n",
      " [ 342  196   66 ...,    0    0    0]\n",
      " ..., \n",
      " [1896  187  182 ...,    0    0    0]\n",
      " [  13 2757  455 ...,    0    0    0]\n",
      " [   1 1669 3689 ...,    0    0    0]]\n",
      "150/200 [=====================>........] - ETA: 22s - loss: 1.5642 - acc: 0.8061[[   1  881  509 ...,    0    0    0]\n",
      " [  12  296   49 ...,    0    0    0]\n",
      " [  15    7   61 ...,    0    0    0]\n",
      " ..., \n",
      " [ 119    4 1910 ...,    0    0    0]\n",
      " [1275  650  103 ...,    0    0    0]\n",
      " [  13   13    5 ...,    0    0    0]]\n",
      "151/200 [=====================>........] - ETA: 22s - loss: 1.5644 - acc: 0.8061[[ 2387    93   281 ...,     0     0     0]\n",
      " [11592    13    27 ...,     0     0     0]\n",
      " [ 1236    34     3 ...,     0     0     0]\n",
      " ..., \n",
      " [   10   152   139 ...,     0     0     0]\n",
      " [   13   192    39 ...,     0     0     0]\n",
      " [   13  1844    13 ...,     0     0     0]]\n",
      "152/200 [=====================>........] - ETA: 21s - loss: 1.5630 - acc: 0.8061[[  92   13 4159 ...,    0    0    0]\n",
      " [ 171  108   15 ...,    0    0    0]\n",
      " [2455  119 2005 ...,    0    0    0]\n",
      " ..., \n",
      " [ 309 4293    9 ...,    0    0    0]\n",
      " [2991 1171  100 ...,    0    0    0]\n",
      " [ 206   65   12 ...,    0    0    0]]\n",
      "153/200 [=====================>........] - ETA: 21s - loss: 1.5601 - acc: 0.8063[[ 224    9  539 ...,    0    0    0]\n",
      " [   1   13  223 ...,    0    0    0]\n",
      " [ 978 4090   14 ...,    0    0    0]\n",
      " ..., \n",
      " [6373   11  694 ...,    0    0    0]\n",
      " [   1 3530  692 ...,    0    0    0]\n",
      " [ 131  573  478 ...,    0    0    0]]\n",
      "154/200 [======================>.......] - ETA: 20s - loss: 1.5579 - acc: 0.8065[[ 391    5   17 ...,    0    0    0]\n",
      " [  17 1583   13 ...,    0    0    0]\n",
      " [   2 2442 1103 ...,    0    0    0]\n",
      " ..., \n",
      " [1248 3664 2995 ...,    0    0    0]\n",
      " [1862   27 2804 ...,    0    0    0]\n",
      " [3289  604 2206 ...,    0    0    0]]\n",
      "155/200 [======================>.......] - ETA: 20s - loss: 1.5559 - acc: 0.8066[[    1   132   509 ...,     0     0     0]\n",
      " [    4   173   472 ...,     0     0     0]\n",
      " [   80   160    67 ...,     0     0     0]\n",
      " ..., \n",
      " [ 7394  6442    14 ...,     0     0     0]\n",
      " [ 3597  7808   715 ...,     0     0     0]\n",
      " [ 2966 10273    13 ...,     0     0     0]]\n",
      "156/200 [======================>.......] - ETA: 20s - loss: 1.5539 - acc: 0.8068[[11032    13   289 ...,     0     0     0]\n",
      " [   15   247  4604 ...,     0     0     0]\n",
      " [    4     2   430 ...,     0     0     0]\n",
      " ..., \n",
      " [   13    13    27 ...,     0     0     0]\n",
      " [    1  1912  3553 ...,     0     0     0]\n",
      " [ 1339  1553    27 ...,     0     0     0]]\n",
      "157/200 [======================>.......] - ETA: 19s - loss: 1.5526 - acc: 0.8068[[   1 4023   21 ...,    0    0    0]\n",
      " [   1  884 1054 ...,    0    0    0]\n",
      " [  55    7 1263 ...,    0    0    0]\n",
      " ..., \n",
      " [   2 1373   13 ...,    0    0    0]\n",
      " [   2  633  417 ...,    0    0    0]\n",
      " [   1  456  732 ...,    0    0    0]]\n",
      "158/200 [======================>.......] - ETA: 19s - loss: 1.5512 - acc: 0.8069[[  55    7 4244 ...,    0    0    0]\n",
      " [  26   21  691 ...,    0    0    0]\n",
      " [ 425  217   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 626 2846    7 ...,    0    0    0]\n",
      " [ 127   19  661 ...,    0    0    0]\n",
      " [   1 1610    5 ...,    0    0    0]]\n",
      "159/200 [======================>.......] - ETA: 18s - loss: 1.5497 - acc: 0.8070[[ 545 2882  267 ...,    0    0    0]\n",
      " [ 488   11  336 ...,    0    0    0]\n",
      " [1546 1415 1270 ...,    0    0    0]\n",
      " ..., \n",
      " [  49 2455 9170 ...,    0    0    0]\n",
      " [1337   30   33 ...,    0    0    0]\n",
      " [ 987    7  705 ...,    0    0    0]]\n",
      "160/200 [=======================>......] - ETA: 18s - loss: 1.5484 - acc: 0.8071[[  38  499  295 ...,    0    0    0]\n",
      " [4384  130  880 ...,    0    0    0]\n",
      " [1935  295 7857 ...,    0    0    0]\n",
      " ..., \n",
      " [ 116 2700    8 ...,    0    0    0]\n",
      " [4358   13 7852 ...,    0    0    0]\n",
      " [1172  720   13 ...,    0    0    0]]\n",
      "161/200 [=======================>......] - ETA: 17s - loss: 1.5481 - acc: 0.8071[[1075  280    8 ...,    0    0    0]\n",
      " [   1  214   23 ...,    0    0    0]\n",
      " [ 987    6   36 ...,    0    0    0]\n",
      " ..., \n",
      " [ 485   13   19 ...,    0    0    0]\n",
      " [1753  135 1266 ...,    0    0    0]\n",
      " [3062    8 1597 ...,    0    0    0]]\n",
      "162/200 [=======================>......] - ETA: 17s - loss: 1.5489 - acc: 0.8070[[3733   13 3322 ...,    0    0    0]\n",
      " [  15    7   48 ...,    0    0    0]\n",
      " [3674 2252    4 ...,    0    0    0]\n",
      " ..., \n",
      " [ 844  329   24 ...,    0    0    0]\n",
      " [ 109   26   67 ...,    0    0    0]\n",
      " [ 107   70   15 ...,    0    0    0]]\n",
      "163/200 [=======================>......] - ETA: 16s - loss: 1.5482 - acc: 0.8071[[ 930 9779   14 ...,    0    0    0]\n",
      " [ 109   26  106 ...,    0    0    0]\n",
      " [1405    7 1096 ...,    0    0    0]\n",
      " ..., \n",
      " [ 390 3380   11 ...,    0    0    0]\n",
      " [ 790 2047    9 ...,    0    0    0]\n",
      " [ 131  488  103 ...,    0    0    0]]\n",
      "164/200 [=======================>......] - ETA: 16s - loss: 1.5494 - acc: 0.8070[[1339 1553    9 ...,    0    0    0]\n",
      " [3194   13  165 ...,    0    0    0]\n",
      " [  13   13    9 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13  568 ...,    0    0    0]\n",
      " [4368 5452  265 ...,    0    0    0]\n",
      " [ 109  154   66 ...,    0    0    0]]\n",
      "165/200 [=======================>......] - ETA: 15s - loss: 1.5498 - acc: 0.8070[[1597  196 2573 ...,    0    0    0]\n",
      " [  15   14 1237 ...,    0    0    0]\n",
      " [   1 3982   13 ...,    0    0    0]\n",
      " ..., \n",
      " [  16   22  355 ...,    0    0    0]\n",
      " [   2 2041 1874 ...,    0    0    0]\n",
      " [ 280 9433 4699 ...,    0    0    0]]\n",
      "166/200 [=======================>......] - ETA: 15s - loss: 1.5510 - acc: 0.8068[[10386     4    34 ...,     0     0     0]\n",
      " [ 9006  2116     9 ...,     0     0     0]\n",
      " [    1  9067     5 ...,     0     0     0]\n",
      " ..., \n",
      " [ 8231  3112    13 ...,     0     0     0]\n",
      " [ 3279    11   385 ...,     0     0     0]\n",
      " [   44    13   857 ...,     0     0     0]]\n",
      "167/200 [========================>.....] - ETA: 15s - loss: 1.5506 - acc: 0.8069[[10745   112    36 ...,     0     0     0]\n",
      " [    1   542     9 ...,     0     0     0]\n",
      " [   93    67     1 ...,     0     0     0]\n",
      " ..., \n",
      " [ 7442  2021  1913 ...,     0     0     0]\n",
      " [  107    70     1 ...,     0     0     0]\n",
      " [    4    64    82 ...,     0     0     0]]\n",
      "168/200 [========================>.....] - ETA: 14s - loss: 1.5509 - acc: 0.8069[[   10    99  1044 ...,     0     0     0]\n",
      " [   15     9    48 ...,     0     0     0]\n",
      " [10062  6003     4 ...,     0     0     0]\n",
      " ..., \n",
      " [  165   349   252 ...,     0     0     0]\n",
      " [  949     3     1 ...,     0     0     0]\n",
      " [   26  2920    60 ...,     0     0     0]]\n",
      "169/200 [========================>.....] - ETA: 14s - loss: 1.5525 - acc: 0.8067[[   1   13  400 ...,    0    0    0]\n",
      " [ 474    1 1475 ...,    0    0    0]\n",
      " [ 931  309   13 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   13    1 ...,    0    0    0]\n",
      " [  80  110    4 ...,    0    0    0]\n",
      " [   2 1762  368 ...,    0    0    0]]\n",
      "170/200 [========================>.....] - ETA: 13s - loss: 1.5543 - acc: 0.8065[[ 531   23  149 ...,    0    0    0]\n",
      " [   1 2923  253 ...,    0    0    0]\n",
      " [4685   54   13 ...,    0    0    0]\n",
      " ..., \n",
      " [2965   13    7 ...,    0    0    0]\n",
      " [ 276   13   15 ...,    0    0    0]\n",
      " [   4    1 1161 ...,    0    0    0]]\n",
      "171/200 [========================>.....] - ETA: 13s - loss: 1.5563 - acc: 0.8063[[ 350   21 2683 ...,    0    0    0]\n",
      " [2379  627  247 ...,    0    0    0]\n",
      " [   1 1341   86 ...,    0    0    0]\n",
      " ..., \n",
      " [  43 1798    5 ...,    0    0    0]\n",
      " [  15  448   29 ...,    0    0    0]\n",
      " [ 937   13    8 ...,    0    0    0]]\n",
      "172/200 [========================>.....] - ETA: 12s - loss: 1.5575 - acc: 0.8061[[   3 4041    2 ...,    0    0    0]\n",
      " [  95    1   63 ...,    0    0    0]\n",
      " [   4 1408   13 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 2192  757 ...,    0    0    0]\n",
      " [ 893 3353 1117 ...,    0    0    0]\n",
      " [  34 1226   96 ...,    0    0    0]]\n",
      "173/200 [========================>.....] - ETA: 12s - loss: 1.5568 - acc: 0.8062[[  49    5    1 ...,    0    0    0]\n",
      " [1500   13 6988 ...,    0    0    0]\n",
      " [   1  873   13 ...,    0    0    0]\n",
      " ..., \n",
      " [   4   13   13 ...,    0    0    0]\n",
      " [ 108   68   23 ...,    0    0    0]\n",
      " [ 232  725   14 ...,    0    0    0]]\n",
      "174/200 [=========================>....] - ETA: 11s - loss: 1.5572 - acc: 0.8062[[  74    5    1 ...,    0    0    0]\n",
      " [ 187    5   13 ...,    0    0    0]\n",
      " [ 264  105   20 ...,    0    0    0]\n",
      " ..., \n",
      " [   4    1   78 ...,    0    0    0]\n",
      " [9224 1119  993 ...,    0    0    0]\n",
      " [ 221  230   13 ...,    0    0    0]]\n",
      "175/200 [=========================>....] - ETA: 11s - loss: 1.5587 - acc: 0.8061[[  16  166   49 ...,    0    0    0]\n",
      " [   2 1983  302 ...,    0    0    0]\n",
      " [  13 1287   13 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13 1211 ...,    0    0    0]\n",
      " [5470    8   13 ...,    0    0    0]\n",
      " [4315 4331   81 ...,    0    0    0]]\n",
      "176/200 [=========================>....] - ETA: 10s - loss: 1.5587 - acc: 0.8061[[   13    13    13 ...,     0     0     0]\n",
      " [  137     2  5678 ...,     0     0     0]\n",
      " [  721    74    13 ...,     0     0     0]\n",
      " ..., \n",
      " [ 9513 11644  2385 ...,     0     0     0]\n",
      " [  104  1340    80 ...,     0     0     0]\n",
      " [   85     1  3845 ...,     0     0     0]]\n",
      "177/200 [=========================>....] - ETA: 10s - loss: 1.5583 - acc: 0.8062[[ 812   13    9 ...,    0    0    0]\n",
      " [6382 6947    9 ...,    0    0    0]\n",
      " [ 153  729  574 ...,    0    0    0]\n",
      " ..., \n",
      " [  89   23  702 ...,    0    0    0]\n",
      " [  13   23 5447 ...,    0    0    0]\n",
      " [ 299    5  474 ...,    0    0    0]]\n",
      "178/200 [=========================>....] - ETA: 10s - loss: 1.5579 - acc: 0.8063[[   1 1676 4129 ...,    0    0    0]\n",
      " [  12    1 5062 ...,    0    0    0]\n",
      " [ 242   69  263 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   27 3418 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]]\n",
      "179/200 [=========================>....] - ETA: 9s - loss: 1.5584 - acc: 0.8062 [[  22  905 1755 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [   1 2065 2164 ...,    0    0    0]\n",
      " ..., \n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [   1  191    5 ...,    0    0    0]]\n",
      "180/200 [==========================>...] - ETA: 9s - loss: 1.5583 - acc: 0.8063[[  58   59   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [   1 1522  433 ...,    0    0    0]\n",
      " ..., \n",
      " [ 214   23    1 ...,    0    0    0]\n",
      " [2079   12    1 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]]\n",
      "181/200 [==========================>...] - ETA: 8s - loss: 1.5584 - acc: 0.8063[[ 140  609   73 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [   1   13 2164 ...,    0    0    0]\n",
      " ..., \n",
      " [ 444    9  155 ...,    0    0    0]\n",
      " [ 127   76    5 ...,    0    0    0]\n",
      " [7042 2036   75 ...,    0    0    0]]\n",
      "182/200 [==========================>...] - ETA: 8s - loss: 1.5582 - acc: 0.8063[[    2    13   701 ...,     0     0     0]\n",
      " [ 1189   224     7 ...,     0     0     0]\n",
      " [  200     7   176 ...,     0     0     0]\n",
      " ..., \n",
      " [    2    13 10143 ...,     0     0     0]\n",
      " [   13    26   182 ...,     0     0     0]\n",
      " [   42  1808    29 ...,     0     0     0]]\n",
      "183/200 [==========================>...] - ETA: 7s - loss: 1.5582 - acc: 0.8063[[ 176   66  115 ...,    0    0    0]\n",
      " [   1  102    7 ...,    0    0    0]\n",
      " [ 167   69 3369 ...,    0    0    0]\n",
      " ..., \n",
      " [ 167   13   21 ...,    0    0    0]\n",
      " [4370 1038    8 ...,    0    0    0]\n",
      " [   2   13  167 ...,    0    0    0]]\n",
      "184/200 [==========================>...] - ETA: 7s - loss: 1.5585 - acc: 0.8063[[ 131  226  398 ...,    0    0    0]\n",
      " [   1   13 1438 ...,    0    0    0]\n",
      " [   1   13   38 ...,    0    0    0]\n",
      " ..., \n",
      " [ 491   26  113 ...,    0    0    0]\n",
      " [ 727  292   13 ...,    0    0    0]\n",
      " [1221   13  941 ...,    0    0    0]]\n",
      "185/200 [==========================>...] - ETA: 6s - loss: 1.5586 - acc: 0.8063[[ 109   26  113 ...,    0    0    0]\n",
      " [ 546 8112  200 ...,    0    0    0]\n",
      " [ 632  528  142 ...,    0    0    0]\n",
      " ..., \n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [   1   13   58 ...,    0    0    0]\n",
      " [1355 2777   13 ...,    0    0    0]]\n",
      "186/200 [==========================>...] - ETA: 6s - loss: 1.5586 - acc: 0.8064[[9786 2086   13 ...,    0    0    0]\n",
      " [  13    4  429 ...,    0    0    0]\n",
      " [ 884   26  115 ...,    0    0    0]\n",
      " ..., \n",
      " [ 383   13   46 ...,    0    0    0]\n",
      " [1827   25  308 ...,    0    0    0]\n",
      " [  13 3689 3693 ...,    0    0    0]]\n",
      "187/200 [===========================>..] - ETA: 5s - loss: 1.5589 - acc: 0.8063[[  55  292  728 ...,    0    0    0]\n",
      " [  19  352   26 ...,    0    0    0]\n",
      " [8676   13    5 ...,    0    0    0]\n",
      " ..., \n",
      " [ 444 5335    1 ...,    0    0    0]\n",
      " [ 154   66    4 ...,    0    0    0]\n",
      " [1827   36 2934 ...,    0    0    0]]\n",
      "188/200 [===========================>..] - ETA: 5s - loss: 1.5595 - acc: 0.8063[[    1    19   352 ...,     0     0     0]\n",
      " [11098  3659     9 ...,     0     0     0]\n",
      " [  501   154    66 ...,     0     0     0]\n",
      " ..., \n",
      " [    1   529   223 ...,     0     0     0]\n",
      " [ 1454   100     1 ...,     0     0     0]\n",
      " [ 2405  7209   700 ...,     0     0     0]]\n",
      "189/200 [===========================>..] - ETA: 5s - loss: 1.5595 - acc: 0.8063[[   1   13   13 ...,    0    0    0]\n",
      " [   2  440  842 ...,    0    0    0]\n",
      " [ 255   73  240 ...,    0    0    0]\n",
      " ..., \n",
      " [ 109   26  115 ...,    0    0    0]\n",
      " [   1 2930   86 ...,    0    0    0]\n",
      " [3830 1927 1531 ...,    0    0    0]]\n",
      "190/200 [===========================>..] - ETA: 4s - loss: 1.5574 - acc: 0.8064[[  66    6    1 ...,    0    0    0]\n",
      " [ 726 2576 4672 ...,    0    0    0]\n",
      " [   2   13   12 ...,    0    0    0]\n",
      " ..., \n",
      " [  22   13  704 ...,    0    0    0]\n",
      " [   1   19  120 ...,    0    0    0]\n",
      " [2346 4931 7102 ...,    0    0    0]]\n",
      "191/200 [===========================>..] - ETA: 4s - loss: 1.5560 - acc: 0.8065[[   1  260  438 ...,    0    0    0]\n",
      " [ 849  394 1610 ...,    0    0    0]\n",
      " [ 356  767  484 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 3525  294 ...,    0    0    0]\n",
      " [  13 3323    9 ...,    0    0    0]\n",
      " [  10    2   13 ...,    0    0    0]]\n",
      "192/200 [===========================>..] - ETA: 3s - loss: 1.5540 - acc: 0.8066[[ 654  145  398 ...,    0    0    0]\n",
      " [   1 2181    8 ...,    0    0    0]\n",
      " [  49   64 4137 ...,    0    0    0]\n",
      " ..., \n",
      " [1337  217    1 ...,    0    0    0]\n",
      " [  15  336   64 ...,    0    0    0]\n",
      " [1536 4331   13 ...,    0    0    0]]\n",
      "193/200 [===========================>..] - ETA: 3s - loss: 1.5525 - acc: 0.8067[[4424 4371  227 ...,    0    0    0]\n",
      " [ 119  267  157 ...,    0    0    0]\n",
      " [4139  398 2129 ...,    0    0    0]\n",
      " ..., \n",
      " [2536 2391  212 ...,    0    0    0]\n",
      " [1224   69 4841 ...,    0    0    0]\n",
      " [   1   13  241 ...,    0    0    0]]\n",
      "194/200 [============================>.] - ETA: 2s - loss: 1.5511 - acc: 0.8068[[3492 4168  766 ...,    0    0    0]\n",
      " [   1   13   86 ...,    0    0    0]\n",
      " [ 790 2426   11 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   11 2586 ...,    0    0    0]\n",
      " [ 206   66   21 ...,    0    0    0]\n",
      " [1282    7  732 ...,    0    0    0]]\n",
      "195/200 [============================>.] - ETA: 2s - loss: 1.5498 - acc: 0.8070[[6829 5421    9 ...,    0    0    0]\n",
      " [3153 1924    4 ...,    0    0    0]\n",
      " [  13   13  312 ...,    0    0    0]\n",
      " ..., \n",
      " [6292 9645   11 ...,    0    0    0]\n",
      " [1742    7 6252 ...,    0    0    0]\n",
      " [1331   11 1992 ...,    0    0    0]]\n",
      "196/200 [============================>.] - ETA: 1s - loss: 1.5484 - acc: 0.8071[[  150  1697    13 ...,     0     0     0]\n",
      " [ 4458     8 11411 ...,     0     0     0]\n",
      " [  158   268     4 ...,     0     0     0]\n",
      " ..., \n",
      " [    1    13   680 ...,     0     0     0]\n",
      " [    1  2657   680 ...,     0     0     0]\n",
      " [ 6308   694  5350 ...,     0     0     0]]\n",
      "197/200 [============================>.] - ETA: 1s - loss: 1.5474 - acc: 0.8071[[ 623  157   22 ...,    0    0    0]\n",
      " [  69  297   13 ...,    0    0    0]\n",
      " [ 344   83   15 ...,    0    0    0]\n",
      " ..., \n",
      " [   2   13  282 ...,    0    0    0]\n",
      " [  13   13    1 ...,    0    0    0]\n",
      " [  13   13 2385 ...,    0    0    0]]\n",
      "198/200 [============================>.] - ETA: 0s - loss: 1.5463 - acc: 0.8072[[ 727   30   25 ...,    0    0    0]\n",
      " [ 119  462    8 ...,    0    0    0]\n",
      " [ 719  137    1 ...,    0    0    0]\n",
      " ..., \n",
      " [  13 8281 2278 ...,    0    0    0]\n",
      " [   2   13 1489 ...,    0    0    0]\n",
      " [ 708   82    2 ...,    0    0    0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/200 [============================>.] - ETA: 0s - loss: 1.5456 - acc: 0.8072[[ 547 1206    2 ...,    0    0    0]\n",
      " [  19  120  662 ...,    0    0    0]\n",
      " [   2 1779  321 ...,    0    0    0]\n",
      " ..., \n",
      " [6404   27 5918 ...,    0    0    0]\n",
      " [1680   13  484 ...,    0    0    0]\n",
      " [   1  167  117 ...,    0    0    0]]\n",
      "200/200 [==============================] - 90s - loss: 1.5459 - acc: 0.8072    \n",
      "Epoch 3/10\n",
      "[[1046   11  510 ...,    0    0    0]\n",
      " [  15    7  461 ...,    0    0    0]\n",
      " [  15 1272 1322 ...,    0    0    0]\n",
      " ..., \n",
      " [ 116    5    1 ...,    0    0    0]\n",
      " [5209   13   83 ...,    0    0    0]\n",
      " [   1 1547 1127 ...,    0    0    0]]\n",
      "  1/200 [..............................] - ETA: 90s - loss: 1.7534 - acc: 0.7933[[  790  3805    11 ...,     0     0     0]\n",
      " [ 1635 10089    13 ...,     0     0     0]\n",
      " [ 1052     8  1465 ...,     0     0     0]\n",
      " ..., \n",
      " [  206   113    24 ...,     0     0     0]\n",
      " [  220    13    21 ...,     0     0     0]\n",
      " [   13    13     7 ...,     0     0     0]]\n",
      "  2/200 [..............................] - ETA: 89s - loss: 1.8085 - acc: 0.7836[[4800 4919  247 ...,    0    0    0]\n",
      " [1696  729    8 ...,    0    0    0]\n",
      " [ 545 1007  674 ...,    0    0    0]\n",
      " ..., \n",
      " [7710   13   51 ...,    0    0    0]\n",
      " [ 108   68  410 ...,    0    0    0]\n",
      " [ 232 3054    9 ...,    0    0    0]]\n",
      "  3/200 [..............................] - ETA: 89s - loss: 1.7679 - acc: 0.7864[[ 1332  9266    27 ...,     0     0     0]\n",
      " [    1   288 11255 ...,     0     0     0]\n",
      " [    1   580   473 ...,     0     0     0]\n",
      " ..., \n",
      " [  353  4319     7 ...,     0     0     0]\n",
      " [   70    15   283 ...,     0     0     0]\n",
      " [  353    13    14 ...,     0     0     0]]\n",
      "  4/200 [..............................] - ETA: 88s - loss: 1.7428 - acc: 0.7878[[3252 3114   11 ...,    0    0    0]\n",
      " [   1  535  765 ...,    0    0    0]\n",
      " [1490 3312 1528 ...,    0    0    0]\n",
      " ..., \n",
      " [   2  131 4181 ...,    0    0    0]\n",
      " [   1 6409  360 ...,    0    0    0]\n",
      " [4181 2149   21 ...,    0    0    0]]\n",
      "  5/200 [..............................] - ETA: 88s - loss: 1.6865 - acc: 0.7946[[ 1802    13    68 ...,     0     0     0]\n",
      " [   13 11267  8560 ...,     0     0     0]\n",
      " [  213    14  1099 ...,     0     0     0]\n",
      " ..., \n",
      " [   15     7    48 ...,     0     0     0]\n",
      " [  133    39   321 ...,     0     0     0]\n",
      " [    1  1942     5 ...,     0     0     0]]\n",
      "  6/200 [..............................] - ETA: 87s - loss: 1.6541 - acc: 0.7979[[9231  112    5 ...,    0    0    0]\n",
      " [  13   13   44 ...,    0    0    0]\n",
      " [  68  114  321 ...,    0    0    0]\n",
      " ..., \n",
      " [  13  104   21 ...,    0    0    0]\n",
      " [  93  265  337 ...,    0    0    0]\n",
      " [ 171  108   13 ...,    0    0    0]]\n",
      "  7/200 [>.............................] - ETA: 87s - loss: 1.6673 - acc: 0.7960[[   1  166  371 ...,    0    0    0]\n",
      " [  13  572 3510 ...,    0    0    0]\n",
      " [   1 3776   10 ...,    0    0    0]\n",
      " ..., \n",
      " [  89   67    2 ...,    0    0    0]\n",
      " [ 137  336   18 ...,    0    0    0]\n",
      " [ 150  466  142 ...,    0    0    0]]\n",
      "  8/200 [>.............................] - ETA: 86s - loss: 1.6804 - acc: 0.7944[[   42   471    39 ...,     0     0     0]\n",
      " [    1   214     9 ...,     0     0     0]\n",
      " [    1    13    13 ...,     0     0     0]\n",
      " ..., \n",
      " [   41  2088  4006 ...,     0     0     0]\n",
      " [    1  2538  2476 ...,     0     0     0]\n",
      " [   13  1442 10169 ...,     0     0     0]]\n",
      "  9/200 [>.............................] - ETA: 86s - loss: 1.6978 - acc: 0.7923[[ 301 1351    3 ...,    0    0    0]\n",
      " [2860   13 1184 ...,    0    0    0]\n",
      " [ 719  577   10 ...,    0    0    0]\n",
      " ..., \n",
      " [ 156  213   27 ...,    0    0    0]\n",
      " [ 751 2527  532 ...,    0    0    0]\n",
      " [  80   41  805 ...,    0    0    0]]\n",
      " 10/200 [>.............................] - ETA: 85s - loss: 1.7164 - acc: 0.7899[[   1 1761    5 ...,    0    0    0]\n",
      " [ 194   63  144 ...,    0    0    0]\n",
      " [1054    9   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 280   13   13 ...,    0    0    0]\n",
      " [ 693    2  181 ...,    0    0    0]\n",
      " [ 474  572    7 ...,    0    0    0]]\n",
      " 11/200 [>.............................] - ETA: 85s - loss: 1.7012 - acc: 0.7917[[  89    7    2 ...,    0    0    0]\n",
      " [   1  662  934 ...,    0    0    0]\n",
      " [ 108   15   67 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   99 4777 ...,    0    0    0]\n",
      " [1232 3185   13 ...,    0    0    0]\n",
      " [1036   16  728 ...,    0    0    0]]\n",
      " 12/200 [>.............................] - ETA: 84s - loss: 1.6827 - acc: 0.7942[[   2  487    5 ...,    0    0    0]\n",
      " [   1   38  949 ...,    0    0    0]\n",
      " [5734   13   14 ...,    0    0    0]\n",
      " ..., \n",
      " [1000 2290    8 ...,    0    0    0]\n",
      " [   1   38   62 ...,    0    0    0]\n",
      " [ 250 1318  105 ...,    0    0    0]]\n",
      " 13/200 [>.............................] - ETA: 84s - loss: 1.6866 - acc: 0.7932[[ 194   63  144 ...,    0    0    0]\n",
      " [  10   92  888 ...,    0    0    0]\n",
      " [   1  467    5 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  170   29 ...,    0    0    0]\n",
      " [  80   41 1018 ...,    0    0    0]\n",
      " [  10   13  558 ...,    0    0    0]]\n",
      " 14/200 [=>............................] - ETA: 83s - loss: 1.6826 - acc: 0.7939[[ 823   13    1 ...,    0    0    0]\n",
      " [ 341   13  104 ...,    0    0    0]\n",
      " [2308   13 6010 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13   13 ...,    0    0    0]\n",
      " [  56    2  497 ...,    0    0    0]\n",
      " [  13  458 7740 ...,    0    0    0]]\n",
      " 15/200 [=>............................] - ETA: 83s - loss: 1.6729 - acc: 0.7951[[4496 3567  385 ...,    0    0    0]\n",
      " [  78   94   13 ...,    0    0    0]\n",
      " [3007  256    1 ...,    0    0    0]\n",
      " ..., \n",
      " [   4   17 3237 ...,    0    0    0]\n",
      " [  92   63  144 ...,    0    0    0]\n",
      " [  49   63  144 ...,    0    0    0]]\n",
      " 16/200 [=>............................] - ETA: 82s - loss: 1.6612 - acc: 0.7970[[1753  676 6299 ...,    0    0    0]\n",
      " [   2 3272   74 ...,    0    0    0]\n",
      " [  13    7 4633 ...,    0    0    0]\n",
      " ..., \n",
      " [  13  104   21 ...,    0    0    0]\n",
      " [ 309 4211    9 ...,    0    0    0]\n",
      " [2071   11  147 ...,    0    0    0]]\n",
      " 17/200 [=>............................] - ETA: 82s - loss: 1.6600 - acc: 0.7976[[ 379  177   13 ...,    0    0    0]\n",
      " [  99  177   13 ...,    0    0    0]\n",
      " [ 973   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [  18 1780   10 ...,    0    0    0]\n",
      " [  15  128   48 ...,    0    0    0]\n",
      " [  13   13   81 ...,    0    0    0]]\n",
      " 18/200 [=>............................] - ETA: 82s - loss: 1.6566 - acc: 0.7982[[   1  885  981 ...,    0    0    0]\n",
      " [  13  133   68 ...,    0    0    0]\n",
      " [2318  133   92 ...,    0    0    0]\n",
      " ..., \n",
      " [  13 1186    4 ...,    0    0    0]\n",
      " [  89   23  155 ...,    0    0    0]\n",
      " [  55   27   13 ...,    0    0    0]]\n",
      " 19/200 [=>............................] - ETA: 81s - loss: 1.6479 - acc: 0.7995[[  58   59   26 ...,    0    0    0]\n",
      " [ 454  883 2440 ...,    0    0    0]\n",
      " [   1   13  518 ...,    0    0    0]\n",
      " ..., \n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [5182   11  130 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]]\n",
      " 20/200 [==>...........................] - ETA: 81s - loss: 1.6436 - acc: 0.8000[[1267 7727 2130 ...,    0    0    0]\n",
      " [   1  220   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  187  635 ...,    0    0    0]\n",
      " [   2 1267 1547 ...,    0    0    0]\n",
      " [2239  720 2558 ...,    0    0    0]]\n",
      " 21/200 [==>...........................] - ETA: 80s - loss: 1.6454 - acc: 0.7998[[   58    59    26 ...,     0     0     0]\n",
      " [  681  1281    13 ...,     0     0     0]\n",
      " [  318     7    49 ...,     0     0     0]\n",
      " ..., \n",
      " [  844     8   284 ...,     0     0     0]\n",
      " [   58    59    26 ...,     0     0     0]\n",
      " [10907    46     5 ...,     0     0     0]]\n",
      " 22/200 [==>...........................] - ETA: 80s - loss: 1.6446 - acc: 0.7998[[ 318  329   10 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " ..., \n",
      " [   2  806    8 ...,    0    0    0]\n",
      " [  13   26  115 ...,    0    0    0]\n",
      " [   2 1135   13 ...,    0    0    0]]\n",
      " 23/200 [==>...........................] - ETA: 79s - loss: 1.6419 - acc: 0.8002[[1811 2457    1 ...,    0    0    0]\n",
      " [3730  326  209 ...,    0    0    0]\n",
      " [1282    7  732 ...,    0    0    0]\n",
      " ..., \n",
      " [4244  404   27 ...,    0    0    0]\n",
      " [ 481   66  106 ...,    0    0    0]\n",
      " [   1  214   23 ...,    0    0    0]]\n",
      " 24/200 [==>...........................] - ETA: 79s - loss: 1.6402 - acc: 0.8004[[ 167 2079  664 ...,    0    0    0]\n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [ 167 2004  336 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13 1997 ...,    0    0    0]\n",
      " [ 913    7 1014 ...,    0    0    0]\n",
      " [  55    7  536 ...,    0    0    0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 25/200 [==>...........................] - ETA: 78s - loss: 1.6396 - acc: 0.8004[[    2    19  5809 ...,     0     0     0]\n",
      " [    1   884   223 ...,     0     0     0]\n",
      " [    2   258     5 ...,     0     0     0]\n",
      " ..., \n",
      " [    1  9295     5 ...,     0     0     0]\n",
      " [10274    13  1362 ...,     0     0     0]\n",
      " [    1   367  2161 ...,     0     0     0]]\n",
      " 26/200 [==>...........................] - ETA: 78s - loss: 1.6390 - acc: 0.8004[[   1   13 1333 ...,    0    0    0]\n",
      " [   1  367 2161 ...,    0    0    0]\n",
      " [ 481   66 1160 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   11   45 ...,    0    0    0]\n",
      " [4943   13   11 ...,    0    0    0]\n",
      " [  10    1  156 ...,    0    0    0]]\n",
      " 27/200 [===>..........................] - ETA: 77s - loss: 1.6416 - acc: 0.7999[[  55  292  607 ...,    0    0    0]\n",
      " [  55   25  292 ...,    0    0    0]\n",
      " [ 116   13 3115 ...,    0    0    0]\n",
      " ..., \n",
      " [   2  712  778 ...,    0    0    0]\n",
      " [   1   91 3267 ...,    0    0    0]\n",
      " [  15    7  211 ...,    0    0    0]]\n",
      " 28/200 [===>..........................] - ETA: 77s - loss: 1.6436 - acc: 0.7998[[1896  187   66 ...,    0    0    0]\n",
      " [   1  601    5 ...,    0    0    0]\n",
      " [ 342  196   66 ...,    0    0    0]\n",
      " ..., \n",
      " [  15 1272   29 ...,    0    0    0]\n",
      " [   1 1606 2590 ...,    0    0    0]\n",
      " [ 553 5541   23 ...,    0    0    0]]\n",
      " 29/200 [===>..........................] - ETA: 77s - loss: 1.6396 - acc: 0.8002[[ 131  522 7535 ...,    0    0    0]\n",
      " [   2   94  144 ...,    0    0    0]\n",
      " [5180    8  717 ...,    0    0    0]\n",
      " ..., \n",
      " [  13  236  477 ...,    0    0    0]\n",
      " [   2  117    4 ...,    0    0    0]\n",
      " [3838    8 6077 ...,    0    0    0]]\n",
      " 30/200 [===>..........................] - ETA: 76s - loss: 1.6256 - acc: 0.8010[[9096 8866    7 ...,    0    0    0]\n",
      " [   2   13 3220 ...,    0    0    0]\n",
      " [   1  145  218 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 3839  737 ...,    0    0    0]\n",
      " [ 119 4410    2 ...,    0    0    0]\n",
      " [3516 1053   33 ...,    0    0    0]]\n",
      " 31/200 [===>..........................] - ETA: 76s - loss: 1.6137 - acc: 0.8019[[ 365    7  326 ...,    0    0    0]\n",
      " [  13  248   85 ...,    0    0    0]\n",
      " [ 116 2185   10 ...,    0    0    0]\n",
      " ..., \n",
      " [  13  811 1415 ...,    0    0    0]\n",
      " [2081    6   57 ...,    0    0    0]\n",
      " [3409   13  969 ...,    0    0    0]]\n",
      " 32/200 [===>..........................] - ETA: 76s - loss: 1.6010 - acc: 0.8028[[   2   13 3238 ...,    0    0    0]\n",
      " [ 514 2246   13 ...,    0    0    0]\n",
      " [  22  282   83 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  161 7867 ...,    0    0    0]\n",
      " [ 603 5303    7 ...,    0    0    0]\n",
      " [ 119   30   28 ...,    0    0    0]]\n",
      " 33/200 [===>..........................] - ETA: 75s - loss: 1.5918 - acc: 0.8036[[  89    7    2 ...,    0    0    0]\n",
      " [1600    8  444 ...,    0    0    0]\n",
      " [ 425    8 2535 ...,    0    0    0]\n",
      " ..., \n",
      " [ 187    4  109 ...,    0    0    0]\n",
      " [  13 8417   13 ...,    0    0    0]\n",
      " [3398 8587    7 ...,    0    0    0]]\n",
      " 34/200 [====>.........................] - ETA: 75s - loss: 1.5802 - acc: 0.8045[[  607   816   878 ...,     0     0     0]\n",
      " [    2    13   905 ...,     0     0     0]\n",
      " [    2   877   172 ...,     0     0     0]\n",
      " ..., \n",
      " [  190  1455 11957 ...,     0     0     0]\n",
      " [ 1792   455     3 ...,     0     0     0]\n",
      " [  131   721   765 ...,     0     0     0]]\n",
      " 35/200 [====>.........................] - ETA: 74s - loss: 1.5742 - acc: 0.8048[[  69 1710   13 ...,    0    0    0]\n",
      " [2486   13   13 ...,    0    0    0]\n",
      " [ 185  102   67 ...,    0    0    0]\n",
      " ..., \n",
      " [2523  398 4359 ...,    0    0    0]\n",
      " [1431  450   13 ...,    0    0    0]\n",
      " [  13  199 1448 ...,    0    0    0]]\n",
      " 36/200 [====>.........................] - ETA: 74s - loss: 1.5635 - acc: 0.8056[[ 131 1194  295 ...,    0    0    0]\n",
      " [ 365    7  326 ...,    0    0    0]\n",
      " [2237 4702 1748 ...,    0    0    0]\n",
      " ..., \n",
      " [ 389  209 6340 ...,    0    0    0]\n",
      " [3207  128   20 ...,    0    0    0]\n",
      " [  13   13 1465 ...,    0    0    0]]\n",
      " 37/200 [====>.........................] - ETA: 73s - loss: 1.5568 - acc: 0.8061[[ 425    7  169 ...,    0    0    0]\n",
      " [8008  565  444 ...,    0    0    0]\n",
      " [ 978 4090    7 ...,    0    0    0]\n",
      " ..., \n",
      " [ 905  162 2004 ...,    0    0    0]\n",
      " [5171   66 1869 ...,    0    0    0]\n",
      " [   2  943  258 ...,    0    0    0]]\n",
      " 38/200 [====>.........................] - ETA: 73s - loss: 1.5511 - acc: 0.8064[[ 1848    11  1632 ...,     0     0     0]\n",
      " [ 1625   266    13 ...,     0     0     0]\n",
      " [   26    65  1709 ...,     0     0     0]\n",
      " ..., \n",
      " [  131  1194   295 ...,     0     0     0]\n",
      " [  893 10455  2073 ...,     0     0     0]\n",
      " [  154    66     6 ...,     0     0     0]]\n",
      " 39/200 [====>.........................] - ETA: 72s - loss: 1.5473 - acc: 0.8066[[ 155   29    1 ...,    0    0    0]\n",
      " [  13   13    5 ...,    0    0    0]\n",
      " [  13 8751   23 ...,    0    0    0]\n",
      " ..., \n",
      " [9174 7457 3359 ...,    0    0    0]\n",
      " [1717   13  100 ...,    0    0    0]\n",
      " [1558  455    3 ...,    0    0    0]]\n",
      " 40/200 [=====>........................] - ETA: 72s - loss: 1.5504 - acc: 0.8063[[  913     7  2134 ...,     0     0     0]\n",
      " [   13    68   871 ...,     0     0     0]\n",
      " [    1   221   230 ...,     0     0     0]\n",
      " ..., \n",
      " [   89     7     2 ...,     0     0     0]\n",
      " [   13  2459 10892 ...,     0     0     0]\n",
      " [  171    70    60 ...,     0     0     0]]\n",
      " 41/200 [=====>........................] - ETA: 71s - loss: 1.5490 - acc: 0.8067[[5631 5868 1796 ...,    0    0    0]\n",
      " [ 131   69  263 ...,    0    0    0]\n",
      " [5040 1880  204 ...,    0    0    0]\n",
      " ..., \n",
      " [3400    8 6841 ...,    0    0    0]\n",
      " [  15   14   39 ...,    0    0    0]\n",
      " [ 119   30   36 ...,    0    0    0]]\n",
      " 42/200 [=====>........................] - ETA: 71s - loss: 1.5528 - acc: 0.8062[[ 119  616  127 ...,    0    0    0]\n",
      " [   2 5523 3632 ...,    0    0    0]\n",
      " [   1  304 3255 ...,    0    0    0]\n",
      " ..., \n",
      " [ 140  150 4086 ...,    0    0    0]\n",
      " [   1 4874    5 ...,    0    0    0]\n",
      " [  13    9 2370 ...,    0    0    0]]\n",
      " 43/200 [=====>........................] - ETA: 70s - loss: 1.5556 - acc: 0.8059[[ 444   83   40 ...,    0    0    0]\n",
      " [1634   13   13 ...,    0    0    0]\n",
      " [   1  248  252 ...,    0    0    0]\n",
      " ..., \n",
      " [ 291  126 1512 ...,    0    0    0]\n",
      " [   2 4493  167 ...,    0    0    0]\n",
      " [ 501  154   66 ...,    0    0    0]]\n",
      " 44/200 [=====>........................] - ETA: 70s - loss: 1.5577 - acc: 0.8056[[  13  119   21 ...,    0    0    0]\n",
      " [   2  501 5214 ...,    0    0    0]\n",
      " [ 501    6   25 ...,    0    0    0]\n",
      " ..., \n",
      " [  15   14 1676 ...,    0    0    0]\n",
      " [2215  170   86 ...,    0    0    0]\n",
      " [9754 6508  276 ...,    0    0    0]]\n",
      " 45/200 [=====>........................] - ETA: 70s - loss: 1.5602 - acc: 0.8054[[1115 3628   23 ...,    0    0    0]\n",
      " [  70   13   13 ...,    0    0    0]\n",
      " [  34    9    1 ...,    0    0    0]\n",
      " ..., \n",
      " [ 104   21  184 ...,    0    0    0]\n",
      " [  13  199    9 ...,    0    0    0]\n",
      " [ 137  336   18 ...,    0    0    0]]\n",
      " 46/200 [=====>........................] - ETA: 69s - loss: 1.5589 - acc: 0.8056[[  13   13   14 ...,    0    0    0]\n",
      " [   1 1456  310 ...,    0    0    0]\n",
      " [   2  131  883 ...,    0    0    0]\n",
      " ..., \n",
      " [2603    6    1 ...,    0    0    0]\n",
      " [2565    1  482 ...,    0    0    0]\n",
      " [7079 1435    4 ...,    0    0    0]]\n",
      " 47/200 [======>.......................] - ETA: 69s - loss: 1.5628 - acc: 0.8052[[    1    13 10332 ...,     0     0     0]\n",
      " [   42    14     1 ...,     0     0     0]\n",
      " [  149   495    13 ...,     0     0     0]\n",
      " ..., \n",
      " [   34   629    14 ...,     0     0     0]\n",
      " [   89     7     2 ...,     0     0     0]\n",
      " [    1  2013   312 ...,     0     0     0]]\n",
      " 48/200 [======>.......................] - ETA: 68s - loss: 1.5665 - acc: 0.8048[[  245  2713    13 ...,     0     0     0]\n",
      " [   13  8595    14 ...,     0     0     0]\n",
      " [ 2731    34    77 ...,     0     0     0]\n",
      " ..., \n",
      " [   13   104  1108 ...,     0     0     0]\n",
      " [   13   159 10506 ...,     0     0     0]\n",
      " [ 1675  3294     9 ...,     0     0     0]]\n",
      " 49/200 [======>.......................] - ETA: 68s - loss: 1.5732 - acc: 0.8041[[ 13 492  12 ...,   0   0   0]\n",
      " [ 48 194 629 ...,   0   0   0]\n",
      " [264   7  53 ...,   0   0   0]\n",
      " ..., \n",
      " [ 13  13  13 ...,   0   0   0]\n",
      " [108  68 253 ...,   0   0   0]\n",
      " [ 13  13 221 ...,   0   0   0]]\n",
      " 50/200 [======>.......................] - ETA: 67s - loss: 1.5808 - acc: 0.8034[[ 1395  8395    14 ...,     0     0     0]\n",
      " [ 2333   610   249 ...,     0     0     0]\n",
      " [  116   350    21 ...,     0     0     0]\n",
      " ..., \n",
      " [ 3599    13   198 ...,     0     0     0]\n",
      " [    2 10742     5 ...,     0     0     0]\n",
      " [ 1332    13     9 ...,     0     0     0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 51/200 [======>.......................] - ETA: 67s - loss: 1.5807 - acc: 0.8034[[ 281  713   13 ...,    0    0    0]\n",
      " [6628   13    8 ...,    0    0    0]\n",
      " [  10  790 2047 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  177  676 ...,    0    0    0]\n",
      " [ 730   13    1 ...,    0    0    0]\n",
      " [  18  318    9 ...,    0    0    0]]\n",
      " 52/200 [======>.......................] - ETA: 67s - loss: 1.5802 - acc: 0.8036[[   1  576 5200 ...,    0    0    0]\n",
      " [1066  912   23 ...,    0    0    0]\n",
      " [  89   11  184 ...,    0    0    0]\n",
      " ..., \n",
      " [ 234  402  144 ...,    0    0    0]\n",
      " [6839 1112   83 ...,    0    0    0]\n",
      " [ 159 3747    9 ...,    0    0    0]]\n",
      " 53/200 [======>.......................] - ETA: 66s - loss: 1.5829 - acc: 0.8032[[ 746  117    8 ...,    0    0    0]\n",
      " [ 328   13   15 ...,    0    0    0]\n",
      " [  34   61   13 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   13 1846 ...,    0    0    0]\n",
      " [   2  999  144 ...,    0    0    0]\n",
      " [   4    1  204 ...,    0    0    0]]\n",
      " 54/200 [=======>......................] - ETA: 66s - loss: 1.5845 - acc: 0.8030[[  13   26  106 ...,    0    0    0]\n",
      " [   1 2352   86 ...,    0    0    0]\n",
      " [1014   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [  18   69   13 ...,    0    0    0]\n",
      " [ 108   68 1632 ...,    0    0    0]\n",
      " [  89   23   39 ...,    0    0    0]]\n",
      " 55/200 [=======>......................] - ETA: 65s - loss: 1.5837 - acc: 0.8032[[3599   13   13 ...,    0    0    0]\n",
      " [4956   13 1836 ...,    0    0    0]\n",
      " [   1   13 6850 ...,    0    0    0]\n",
      " ..., \n",
      " [ 415    6  210 ...,    0    0    0]\n",
      " [ 193    7   13 ...,    0    0    0]\n",
      " [   1  131  523 ...,    0    0    0]]\n",
      " 56/200 [=======>......................] - ETA: 65s - loss: 1.5825 - acc: 0.8035[[   1 5684 9095 ...,    0    0    0]\n",
      " [2568 5828    9 ...,    0    0    0]\n",
      " [5543 1537 1471 ...,    0    0    0]\n",
      " ..., \n",
      " [   2  259  290 ...,    0    0    0]\n",
      " [  89   23 2497 ...,    0    0    0]\n",
      " [ 104 1629    1 ...,    0    0    0]]\n",
      " 57/200 [=======>......................] - ETA: 64s - loss: 1.5845 - acc: 0.8034[[   1   13 1978 ...,    0    0    0]\n",
      " [ 697 2427  798 ...,    0    0    0]\n",
      " [ 333   13 1334 ...,    0    0    0]\n",
      " ..., \n",
      " [ 805   34   94 ...,    0    0    0]\n",
      " [  15    7   13 ...,    0    0    0]\n",
      " [6306 5860   13 ...,    0    0    0]]\n",
      " 58/200 [=======>......................] - ETA: 64s - loss: 1.5848 - acc: 0.8035[[ 316  583 1622 ...,    0    0    0]\n",
      " [  34   94    7 ...,    0    0    0]\n",
      " [  78 1362   13 ...,    0    0    0]\n",
      " ..., \n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [5163 1765   29 ...,    0    0    0]]\n",
      " 59/200 [=======>......................] - ETA: 63s - loss: 1.5854 - acc: 0.8035[[2574    7   19 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " ..., \n",
      " [6152   69 3226 ...,    0    0    0]\n",
      " [3222   13  163 ...,    0    0    0]\n",
      " [   1   13  191 ...,    0    0    0]]\n",
      " 60/200 [========>.....................] - ETA: 63s - loss: 1.5858 - acc: 0.8035[[ 131  284 2368 ...,    0    0    0]\n",
      " [2065   69 5102 ...,    0    0    0]\n",
      " [ 167   13 3369 ...,    0    0    0]\n",
      " ..., \n",
      " [1324 1657   27 ...,    0    0    0]\n",
      " [ 284  100    1 ...,    0    0    0]\n",
      " [2808 2755  130 ...,    0    0    0]]\n",
      " 61/200 [========>.....................] - ETA: 62s - loss: 1.5864 - acc: 0.8035[[6030   13   12 ...,    0    0    0]\n",
      " [4759   19  324 ...,    0    0    0]\n",
      " [   2   19 3634 ...,    0    0    0]\n",
      " ..., \n",
      " [1434   27 4474 ...,    0    0    0]\n",
      " [   2  852    3 ...,    0    0    0]\n",
      " [   1   19  352 ...,    0    0    0]]\n",
      " 62/200 [========>.....................] - ETA: 62s - loss: 1.5870 - acc: 0.8035[[   1  143    5 ...,    0    0    0]\n",
      " [  55    8 1792 ...,    0    0    0]\n",
      " [   1  132  509 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13 1847 ...,    0    0    0]\n",
      " [   1  469    8 ...,    0    0    0]\n",
      " [ 140  553    8 ...,    0    0    0]]\n",
      " 63/200 [========>.....................] - ETA: 62s - loss: 1.5880 - acc: 0.8034[[ 523 1898  925 ...,    0    0    0]\n",
      " [   2 1569 2114 ...,    0    0    0]\n",
      " [   1 6528  191 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [3050   55  100 ...,    0    0    0]\n",
      " [ 316   55    7 ...,    0    0    0]]\n",
      " 64/200 [========>.....................] - ETA: 61s - loss: 1.5883 - acc: 0.8034[[3258    4 2081 ...,    0    0    0]\n",
      " [   1   47 6189 ...,    0    0    0]\n",
      " [1434    7  161 ...,    0    0    0]\n",
      " ..., \n",
      " [   2  145  608 ...,    0    0    0]\n",
      " [ 561 3076   36 ...,    0    0    0]\n",
      " [   1  220   73 ...,    0    0    0]]\n",
      " 65/200 [========>.....................] - ETA: 61s - loss: 1.5883 - acc: 0.8034[[   1   13   11 ...,    0    0    0]\n",
      " [   2   58   59 ...,    0    0    0]\n",
      " [   1  220   91 ...,    0    0    0]\n",
      " ..., \n",
      " [ 366    6    1 ...,    0    0    0]\n",
      " [ 306 3262   13 ...,    0    0    0]\n",
      " [   1 1363  199 ...,    0    0    0]]\n",
      " 66/200 [========>.....................] - ETA: 60s - loss: 1.5875 - acc: 0.8035[[   58    59    26 ...,     0     0     0]\n",
      " [   58    59    26 ...,     0     0     0]\n",
      " [   41     5  1056 ...,     0     0     0]\n",
      " ..., \n",
      " [   13    13    14 ...,     0     0     0]\n",
      " [ 1248 10206 10206 ...,     0     0     0]\n",
      " [   13     8  5949 ...,     0     0     0]]\n",
      " 67/200 [=========>....................] - ETA: 60s - loss: 1.5876 - acc: 0.8036[[1224   27 3823 ...,    0    0    0]\n",
      " [  58   59  154 ...,    0    0    0]\n",
      " [ 501  154   66 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   13   13 ...,    0    0    0]\n",
      " [  12  296   13 ...,    0    0    0]\n",
      " [1491  102   67 ...,    0    0    0]]\n",
      " 68/200 [=========>....................] - ETA: 59s - loss: 1.5872 - acc: 0.8037[[ 179 1315 4973 ...,    0    0    0]\n",
      " [ 234 4869  112 ...,    0    0    0]\n",
      " [   1  214   23 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  635    5 ...,    0    0    0]\n",
      " [ 342  196   66 ...,    0    0    0]\n",
      " [ 155   29  697 ...,    0    0    0]]\n",
      " 69/200 [=========>....................] - ETA: 59s - loss: 1.5824 - acc: 0.8038[[ 958  998    7 ...,    0    0    0]\n",
      " [2490    9 2492 ...,    0    0    0]\n",
      " [   2 2602    4 ...,    0    0    0]\n",
      " ..., \n",
      " [  26   23  974 ...,    0    0    0]\n",
      " [  56   79    1 ...,    0    0    0]\n",
      " [ 561   11 1913 ...,    0    0    0]]\n",
      " 70/200 [=========>....................] - ETA: 58s - loss: 1.5772 - acc: 0.8042[[ 478    2 1319 ...,    0    0    0]\n",
      " [1935  295 8426 ...,    0    0    0]\n",
      " [1525  326  267 ...,    0    0    0]\n",
      " ..., \n",
      " [ 108   13    9 ...,    0    0    0]\n",
      " [  26   23 7417 ...,    0    0    0]\n",
      " [ 579  217  226 ...,    0    0    0]]\n",
      " 71/200 [=========>....................] - ETA: 58s - loss: 1.5726 - acc: 0.8045[[4458   21  933 ...,    0    0    0]\n",
      " [1248 2508   13 ...,    0    0    0]\n",
      " [  22  405   16 ...,    0    0    0]\n",
      " ..., \n",
      " [  22  405 2244 ...,    0    0    0]\n",
      " [ 166   41  970 ...,    0    0    0]\n",
      " [   1  751 2224 ...,    0    0    0]]\n",
      " 72/200 [=========>....................] - ETA: 57s - loss: 1.5679 - acc: 0.8049[[ 131 2642   13 ...,    0    0    0]\n",
      " [  13   13  247 ...,    0    0    0]\n",
      " [   2  146   11 ...,    0    0    0]\n",
      " ..., \n",
      " [3689 3693   13 ...,    0    0    0]\n",
      " [ 500    7 1791 ...,    0    0    0]\n",
      " [ 374    5   13 ...,    0    0    0]]\n",
      " 73/200 [=========>....................] - ETA: 57s - loss: 1.5642 - acc: 0.8052[[ 912    5    1 ...,    0    0    0]\n",
      " [2036  462  470 ...,    0    0    0]\n",
      " [1171 5423   13 ...,    0    0    0]\n",
      " ..., \n",
      " [8266  694  131 ...,    0    0    0]\n",
      " [   2   13 7637 ...,    0    0    0]\n",
      " [ 582 1927 1531 ...,    0    0    0]]\n",
      " 74/200 [==========>...................] - ETA: 57s - loss: 1.5600 - acc: 0.8055[[3213 4089 1732 ...,    0    0    0]\n",
      " [ 390   13 8287 ...,    0    0    0]\n",
      " [ 246  190   10 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 1152 2403 ...,    0    0    0]\n",
      " [  87  632    9 ...,    0    0    0]\n",
      " [   1  474  429 ...,    0    0    0]]\n",
      " 75/200 [==========>...................] - ETA: 56s - loss: 1.5567 - acc: 0.8058[[ 186   11   45 ...,    0    0    0]\n",
      " [  13 3488  521 ...,    0    0    0]\n",
      " [3396   13   49 ...,    0    0    0]\n",
      " ..., \n",
      " [  10  234 4098 ...,    0    0    0]\n",
      " [ 232  627    8 ...,    0    0    0]\n",
      " [3491  119  157 ...,    0    0    0]]\n",
      " 76/200 [==========>...................] - ETA: 56s - loss: 1.5533 - acc: 0.8060[[   73   196   441 ...,     0     0     0]\n",
      " [11981  4113    27 ...,     0     0     0]\n",
      " [  380     7   322 ...,     0     0     0]\n",
      " ..., \n",
      " [ 5138  6683    83 ...,     0     0     0]\n",
      " [  185   854     5 ...,     0     0     0]\n",
      " [ 2746  7951  9616 ...,     0     0     0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 77/200 [==========>...................] - ETA: 55s - loss: 1.5500 - acc: 0.8062[[ 140  369 6301 ...,    0    0    0]\n",
      " [  42  471   39 ...,    0    0    0]\n",
      " [3007  157    2 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  580  473 ...,    0    0    0]\n",
      " [ 456  970 8511 ...,    0    0    0]\n",
      " [1046  217 2808 ...,    0    0    0]]\n",
      " 78/200 [==========>...................] - ETA: 55s - loss: 1.5475 - acc: 0.8063[[   2  287 7391 ...,    0    0    0]\n",
      " [1446   13    9 ...,    0    0    0]\n",
      " [   2  146 1214 ...,    0    0    0]\n",
      " ..., \n",
      " [  10    2   61 ...,    0    0    0]\n",
      " [   1  717  117 ...,    0    0    0]\n",
      " [   4   13   13 ...,    0    0    0]]\n",
      " 79/200 [==========>...................] - ETA: 54s - loss: 1.5454 - acc: 0.8065[[ 131  381  228 ...,    0    0    0]\n",
      " [1562 4241   14 ...,    0    0    0]\n",
      " [  13   21   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 284    7  274 ...,    0    0    0]\n",
      " [   2  219  734 ...,    0    0    0]\n",
      " [ 623  631   24 ...,    0    0    0]]\n",
      " 80/200 [===========>..................] - ETA: 54s - loss: 1.5466 - acc: 0.8063[[  108    68   410 ...,     0     0     0]\n",
      " [ 3928   600 11308 ...,     0     0     0]\n",
      " [  492    13     5 ...,     0     0     0]\n",
      " ..., \n",
      " [   19  1620     6 ...,     0     0     0]\n",
      " [ 8181    63    56 ...,     0     0     0]\n",
      " [10148 10148   231 ...,     0     0     0]]\n",
      " 81/200 [===========>..................] - ETA: 53s - loss: 1.5468 - acc: 0.8064[[ 131 1767  332 ...,    0    0    0]\n",
      " [   6    1 2532 ...,    0    0    0]\n",
      " [1381  147  407 ...,    0    0    0]\n",
      " ..., \n",
      " [ 109    7 1276 ...,    0    0    0]\n",
      " [   2   13  613 ...,    0    0    0]\n",
      " [1230  951    4 ...,    0    0    0]]\n",
      " 82/200 [===========>..................] - ETA: 53s - loss: 1.5493 - acc: 0.8061[[ 131  121 3113 ...,    0    0    0]\n",
      " [ 623   21 7905 ...,    0    0    0]\n",
      " [   1  785    9 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13  203 ...,    0    0    0]\n",
      " [   2  146 1129 ...,    0    0    0]\n",
      " [  10    2 1090 ...,    0    0    0]]\n",
      " 83/200 [===========>..................] - ETA: 53s - loss: 1.5498 - acc: 0.8061[[   1   13   91 ...,    0    0    0]\n",
      " [   1  199 4208 ...,    0    0    0]\n",
      " [  58   59  187 ...,    0    0    0]\n",
      " ..., \n",
      " [ 495   32    2 ...,    0    0    0]\n",
      " [   2   13  734 ...,    0    0    0]\n",
      " [1573 6341 5974 ...,    0    0    0]]\n",
      " 84/200 [===========>..................] - ETA: 52s - loss: 1.5518 - acc: 0.8058[[   1  998 3979 ...,    0    0    0]\n",
      " [ 263  267   13 ...,    0    0    0]\n",
      " [1247    7   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 650   13  365 ...,    0    0    0]\n",
      " [  34    1   61 ...,    0    0    0]\n",
      " [3819    7  780 ...,    0    0    0]]\n",
      " 85/200 [===========>..................] - ETA: 52s - loss: 1.5542 - acc: 0.8056[[   2  551  861 ...,    0    0    0]\n",
      " [1675   13  192 ...,    0    0    0]\n",
      " [ 293 1222 2501 ...,    0    0    0]\n",
      " ..., \n",
      " [ 344  117   13 ...,    0    0    0]\n",
      " [1004  421 2149 ...,    0    0    0]\n",
      " [1761   23  210 ...,    0    0    0]]\n",
      " 86/200 [===========>..................] - ETA: 51s - loss: 1.5539 - acc: 0.8057[[ 300   23  400 ...,    0    0    0]\n",
      " [  15    9 6069 ...,    0    0    0]\n",
      " [3978  157    1 ...,    0    0    0]\n",
      " ..., \n",
      " [3100   15    9 ...,    0    0    0]\n",
      " [ 348 2320 5144 ...,    0    0    0]\n",
      " [  13   13 3164 ...,    0    0    0]]\n",
      " 87/200 [============>.................] - ETA: 51s - loss: 1.5550 - acc: 0.8055[[   49   164   816 ...,     0     0     0]\n",
      " [  301   934  8133 ...,     0     0     0]\n",
      " [11585   112     5 ...,     0     0     0]\n",
      " ..., \n",
      " [    1    19    13 ...,     0     0     0]\n",
      " [   13     6  3737 ...,     0     0     0]\n",
      " [11163    13  1243 ...,     0     0     0]]\n",
      " 88/200 [============>.................] - ETA: 50s - loss: 1.5576 - acc: 0.8053[[  15   11   45 ...,    0    0    0]\n",
      " [ 184  810   29 ...,    0    0    0]\n",
      " [  89    7   22 ...,    0    0    0]\n",
      " ..., \n",
      " [1925 1207 2354 ...,    0    0    0]\n",
      " [  10    1  345 ...,    0    0    0]\n",
      " [ 108   68  410 ...,    0    0    0]]\n",
      " 89/200 [============>.................] - ETA: 50s - loss: 1.5617 - acc: 0.8048[[2206   13 2298 ...,    0    0    0]\n",
      " [  10  383    2 ...,    0    0    0]\n",
      " [9208   67 9798 ...,    0    0    0]\n",
      " ..., \n",
      " [  68   21    3 ...,    0    0    0]\n",
      " [  13  744    3 ...,    0    0    0]\n",
      " [  89   27  317 ...,    0    0    0]]\n",
      " 90/200 [============>.................] - ETA: 49s - loss: 1.5635 - acc: 0.8046[[1892 7168    4 ...,    0    0    0]\n",
      " [3006 2446   14 ...,    0    0    0]\n",
      " [1170 2169 2080 ...,    0    0    0]\n",
      " ..., \n",
      " [ 726    7  191 ...,    0    0    0]\n",
      " [1231   70   68 ...,    0    0    0]\n",
      " [   2  293 1244 ...,    0    0    0]]\n",
      " 91/200 [============>.................] - ETA: 49s - loss: 1.5672 - acc: 0.8042[[   13 10823     7 ...,     0     0     0]\n",
      " [   13   435  7769 ...,     0     0     0]\n",
      " [   13    13     9 ...,     0     0     0]\n",
      " ..., \n",
      " [    2  1745  3196 ...,     0     0     0]\n",
      " [ 8017  1395     9 ...,     0     0     0]\n",
      " [    2    13   796 ...,     0     0     0]]\n",
      " 92/200 [============>.................] - ETA: 49s - loss: 1.5689 - acc: 0.8040[[   19   352     8 ...,     0     0     0]\n",
      " [  187     5  4712 ...,     0     0     0]\n",
      " [ 3222  7637    13 ...,     0     0     0]\n",
      " ..., \n",
      " [  500     7 10824 ...,     0     0     0]\n",
      " [   69   297    13 ...,     0     0     0]\n",
      " [ 1152  4028   252 ...,     0     0     0]]\n",
      " 93/200 [============>.................] - ETA: 48s - loss: 1.5673 - acc: 0.8043[[8602    9 2859 ...,    0    0    0]\n",
      " [   2 6397    3 ...,    0    0    0]\n",
      " [3252   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 325 1063 1998 ...,    0    0    0]\n",
      " [   1  126 2437 ...,    0    0    0]\n",
      " [  13   13   14 ...,    0    0    0]]\n",
      " 94/200 [=============>................] - ETA: 48s - loss: 1.5702 - acc: 0.8040[[   1   99 4711 ...,    0    0    0]\n",
      " [ 154   66    6 ...,    0    0    0]\n",
      " [ 154   66    6 ...,    0    0    0]\n",
      " ..., \n",
      " [2288   13  105 ...,    0    0    0]\n",
      " [  15  748   90 ...,    0    0    0]\n",
      " [ 356  767  811 ...,    0    0    0]]\n",
      " 95/200 [=============>................] - ETA: 47s - loss: 1.5712 - acc: 0.8038[[    2   222 10613 ...,     0     0     0]\n",
      " [   10    63    13 ...,     0     0     0]\n",
      " [    1    13    32 ...,     0     0     0]\n",
      " ..., \n",
      " [   13    13   298 ...,     0     0     0]\n",
      " [   19   120   438 ...,     0     0     0]\n",
      " [   34    61  6449 ...,     0     0     0]]\n",
      " 96/200 [=============>................] - ETA: 47s - loss: 1.5713 - acc: 0.8038[[  304  3255   103 ...,     0     0     0]\n",
      " [ 2379  7422     8 ...,     0     0     0]\n",
      " [10485 10333   100 ...,     0     0     0]\n",
      " ..., \n",
      " [    4    13   816 ...,     0     0     0]\n",
      " [   13     9    48 ...,     0     0     0]\n",
      " [  890  2211   114 ...,     0     0     0]]\n",
      " 97/200 [=============>................] - ETA: 46s - loss: 1.5708 - acc: 0.8039[[5267 2367   14 ...,    0    0    0]\n",
      " [ 108  104 2357 ...,    0    0    0]\n",
      " [   4    1  894 ...,    0    0    0]\n",
      " ..., \n",
      " [ 155  301  338 ...,    0    0    0]\n",
      " [ 377 4559   13 ...,    0    0    0]\n",
      " [   4  432   68 ...,    0    0    0]]\n",
      " 98/200 [=============>................] - ETA: 46s - loss: 1.5712 - acc: 0.8039[[  18    1 1558 ...,    0    0    0]\n",
      " [ 986 5031  703 ...,    0    0    0]\n",
      " [3001 6530 5388 ...,    0    0    0]\n",
      " ..., \n",
      " [1289   13    2 ...,    0    0    0]\n",
      " [ 406   13 8740 ...,    0    0    0]\n",
      " [   1  387 3348 ...,    0    0    0]]\n",
      " 99/200 [=============>................] - ETA: 45s - loss: 1.5717 - acc: 0.8039[[ 3470    13   626 ...,     0     0     0]\n",
      " [ 7322     9  1842 ...,     0     0     0]\n",
      " [  483  4428    10 ...,     0     0     0]\n",
      " ..., \n",
      " [   13   391     5 ...,     0     0     0]\n",
      " [ 7029  2222    81 ...,     0     0     0]\n",
      " [10683  9535    11 ...,     0     0     0]]\n",
      "100/200 [==============>...............] - ETA: 45s - loss: 1.5736 - acc: 0.8038[[3822 3881    3 ...,    0    0    0]\n",
      " [ 103  280   13 ...,    0    0    0]\n",
      " [ 280 4960   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 670  559  114 ...,    0    0    0]\n",
      " [  47 1401 3981 ...,    0    0    0]\n",
      " [  34   74   13 ...,    0    0    0]]\n",
      "101/200 [==============>...............] - ETA: 44s - loss: 1.5738 - acc: 0.8038[[   22  2086   255 ...,     0     0     0]\n",
      " [ 1360   585    13 ...,     0     0     0]\n",
      " [  514  2246    11 ...,     0     0     0]\n",
      " ..., \n",
      " [10878    13   219 ...,     0     0     0]\n",
      " [   12   366    13 ...,     0     0     0]\n",
      " [  535    15     7 ...,     0     0     0]]\n",
      "102/200 [==============>...............] - ETA: 44s - loss: 1.5749 - acc: 0.8037[[5707   13  141 ...,    0    0    0]\n",
      " [  70 1807   13 ...,    0    0    0]\n",
      " [  13   13  114 ...,    0    0    0]\n",
      " ..., \n",
      " [1577   13   11 ...,    0    0    0]\n",
      " [1562   13 1191 ...,    0    0    0]\n",
      " [6551   11   81 ...,    0    0    0]]\n",
      "103/200 [==============>...............] - ETA: 44s - loss: 1.5768 - acc: 0.8035[[   4   13 2514 ...,    0    0    0]\n",
      " [  34   61   13 ...,    0    0    0]\n",
      " [  69  263    9 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 1033   67 ...,    0    0    0]\n",
      " [  32  348    1 ...,    0    0    0]\n",
      " [  68  128   39 ...,    0    0    0]]\n",
      "104/200 [==============>...............] - ETA: 43s - loss: 1.5789 - acc: 0.8033[[ 558    5 2055 ...,    0    0    0]\n",
      " [  10   13    8 ...,    0    0    0]\n",
      " [  15  448   29 ...,    0    0    0]\n",
      " ..., \n",
      " [6422   13  192 ...,    0    0    0]\n",
      " [2495    5   13 ...,    0    0    0]\n",
      " [   1 2407    5 ...,    0    0    0]]\n",
      "105/200 [==============>...............] - ETA: 43s - loss: 1.5816 - acc: 0.8030[[ 297   13  263 ...,    0    0    0]\n",
      " [  13  104   14 ...,    0    0    0]\n",
      " [  13  448    3 ...,    0    0    0]\n",
      " ..., \n",
      " [  15    7   48 ...,    0    0    0]\n",
      " [  89   23  177 ...,    0    0    0]\n",
      " [   2 1099   13 ...,    0    0    0]]\n",
      "106/200 [==============>...............] - ETA: 42s - loss: 1.5822 - acc: 0.8029[[ 347  110 7274 ...,    0    0    0]\n",
      " [ 432   13   13 ...,    0    0    0]\n",
      " [  80 2742 2468 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  679  527 ...,    0    0    0]\n",
      " [  15    7  282 ...,    0    0    0]\n",
      " [  13   26  106 ...,    0    0    0]]\n",
      "107/200 [===============>..............] - ETA: 42s - loss: 1.5839 - acc: 0.8028[[1563   13 1393 ...,    0    0    0]\n",
      " [ 104  898   99 ...,    0    0    0]\n",
      " [3432  605   13 ...,    0    0    0]\n",
      " ..., \n",
      " [6448   13   14 ...,    0    0    0]\n",
      " [   1 6322    5 ...,    0    0    0]\n",
      " [ 341   13  245 ...,    0    0    0]]\n",
      "108/200 [===============>..............] - ETA: 41s - loss: 1.5841 - acc: 0.8028[[ 380    7 4121 ...,    0    0    0]\n",
      " [ 140  609   26 ...,    0    0    0]\n",
      " [ 127  179  851 ...,    0    0    0]\n",
      " ..., \n",
      " [ 140  609   26 ...,    0    0    0]\n",
      " [ 355 4849   11 ...,    0    0    0]\n",
      " [7486   13    5 ...,    0    0    0]]\n",
      "109/200 [===============>..............] - ETA: 41s - loss: 1.5837 - acc: 0.8029[[   2 1261 2099 ...,    0    0    0]\n",
      " [   2  121 1421 ...,    0    0    0]\n",
      " [ 726  217  255 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [ 176   66 2512 ...,    0    0    0]\n",
      " [   1  468 2949 ...,    0    0    0]]\n",
      "110/200 [===============>..............] - ETA: 40s - loss: 1.5844 - acc: 0.8029[[ 38 481 176 ...,   0   0   0]\n",
      " [ 13  26 441 ...,   0   0   0]\n",
      " [187  66   6 ...,   0   0   0]\n",
      " ..., \n",
      " [284   7  26 ...,   0   0   0]\n",
      " [  1  13  91 ...,   0   0   0]\n",
      " [  1  13  91 ...,   0   0   0]]\n",
      "111/200 [===============>..............] - ETA: 40s - loss: 1.5850 - acc: 0.8028[[   1   13   91 ...,    0    0    0]\n",
      " [ 140  609   26 ...,    0    0    0]\n",
      " [   1  220   73 ...,    0    0    0]\n",
      " ..., \n",
      " [ 154   66 1215 ...,    0    0    0]\n",
      " [   2  179  680 ...,    0    0    0]\n",
      " [ 390   13   11 ...,    0    0    0]]\n",
      "112/200 [===============>..............] - ETA: 39s - loss: 1.5844 - acc: 0.8029[[  456  1542   662 ...,     0     0     0]\n",
      " [  131   547  1438 ...,     0     0     0]\n",
      " [ 2351    10     1 ...,     0     0     0]\n",
      " ..., \n",
      " [    1    13  3217 ...,     0     0     0]\n",
      " [   15    14 11683 ...,     0     0     0]\n",
      " [    1  1356     5 ...,     0     0     0]]\n",
      "113/200 [===============>..............] - ETA: 39s - loss: 1.5842 - acc: 0.8030[[  13   13   13 ...,    0    0    0]\n",
      " [ 751  103 4071 ...,    0    0    0]\n",
      " [  10 2939 3751 ...,    0    0    0]\n",
      " ..., \n",
      " [ 488    7  324 ...,    0    0    0]\n",
      " [  64   82   13 ...,    0    0    0]\n",
      " [   1  412 1011 ...,    0    0    0]]\n",
      "114/200 [================>.............] - ETA: 38s - loss: 1.5840 - acc: 0.8030[[   1 1660 2134 ...,    0    0    0]\n",
      " [  13  956 4275 ...,    0    0    0]\n",
      " [ 111    4    1 ...,    0    0    0]\n",
      " ..., \n",
      " [3289   30   24 ...,    0    0    0]\n",
      " [2095  745 2520 ...,    0    0    0]\n",
      " [5171   66  115 ...,    0    0    0]]\n",
      "115/200 [================>.............] - ETA: 38s - loss: 1.5838 - acc: 0.8031[[    1   736  1616 ...,     0     0     0]\n",
      " [ 4701 10213     9 ...,     0     0     0]\n",
      " [    2   866  3775 ...,     0     0     0]\n",
      " ..., \n",
      " [   55     6    57 ...,     0     0     0]\n",
      " [    2  1649  1715 ...,     0     0     0]\n",
      " [   19   120    13 ...,     0     0     0]]\n",
      "116/200 [================>.............] - ETA: 38s - loss: 1.5842 - acc: 0.8031[[ 585 9701 6296 ...,    0    0    0]\n",
      " [3626 2067   13 ...,    0    0    0]\n",
      " [   1   91  106 ...,    0    0    0]\n",
      " ..., \n",
      " [  66    6    1 ...,    0    0    0]\n",
      " [5527 5689    9 ...,    0    0    0]\n",
      " [   1   47   49 ...,    0    0    0]]\n",
      "117/200 [================>.............] - ETA: 37s - loss: 1.5838 - acc: 0.8032[[ 1635 11261     8 ...,     0     0     0]\n",
      " [    1  3005  1719 ...,     0     0     0]\n",
      " [  109    26   115 ...,     0     0     0]\n",
      " ..., \n",
      " [  109    26   113 ...,     0     0     0]\n",
      " [   90   194  1044 ...,     0     0     0]\n",
      " [ 1287    13    81 ...,     0     0     0]]\n",
      "118/200 [================>.............] - ETA: 37s - loss: 1.5836 - acc: 0.8032[[2425    8   55 ...,    0    0    0]\n",
      " [2309 3927   11 ...,    0    0    0]\n",
      " [ 173 4190   10 ...,    0    0    0]\n",
      " ..., \n",
      " [1822   13    9 ...,    0    0    0]\n",
      " [3061   13   13 ...,    0    0    0]\n",
      " [   1  261   13 ...,    0    0    0]]\n",
      "119/200 [================>.............] - ETA: 36s - loss: 1.5808 - acc: 0.8035[[   2  904  405 ...,    0    0    0]\n",
      " [3062  196 9581 ...,    0    0    0]\n",
      " [  13   13   27 ...,    0    0    0]\n",
      " ..., \n",
      " [ 681  187  399 ...,    0    0    0]\n",
      " [   1  126  198 ...,    0    0    0]\n",
      " [ 131  456 1127 ...,    0    0    0]]\n",
      "120/200 [=================>............] - ETA: 36s - loss: 1.5780 - acc: 0.8037[[ 276  178   13 ...,    0    0    0]\n",
      " [ 154   66   67 ...,    0    0    0]\n",
      " [  13    1 3430 ...,    0    0    0]\n",
      " ..., \n",
      " [6341 5974    7 ...,    0    0    0]\n",
      " [   1  263 1691 ...,    0    0    0]\n",
      " [   2   37  144 ...,    0    0    0]]\n",
      "121/200 [=================>............] - ETA: 35s - loss: 1.5749 - acc: 0.8039[[  15    7  166 ...,    0    0    0]\n",
      " [1811  217  514 ...,    0    0    0]\n",
      " [ 267  157   92 ...,    0    0    0]\n",
      " ..., \n",
      " [3718   29  337 ...,    0    0    0]\n",
      " [   4    2  188 ...,    0    0    0]\n",
      " [  54    2   94 ...,    0    0    0]]\n",
      "122/200 [=================>............] - ETA: 35s - loss: 1.5728 - acc: 0.8041[[   2 8865  819 ...,    0    0    0]\n",
      " [  18   15 3368 ...,    0    0    0]\n",
      " [ 302   11  319 ...,    0    0    0]\n",
      " ..., \n",
      " [   4    2   13 ...,    0    0    0]\n",
      " [  13 9772   13 ...,    0    0    0]\n",
      " [ 592 8142    1 ...,    0    0    0]]\n",
      "123/200 [=================>............] - ETA: 34s - loss: 1.5723 - acc: 0.8042[[  13   13   68 ...,    0    0    0]\n",
      " [  10  888   13 ...,    0    0    0]\n",
      " [9482  486  240 ...,    0    0    0]\n",
      " ..., \n",
      " [ 108  210 1468 ...,    0    0    0]\n",
      " [2797 4459    9 ...,    0    0    0]\n",
      " [1068 4127  247 ...,    0    0    0]]\n",
      "124/200 [=================>............] - ETA: 34s - loss: 1.5740 - acc: 0.8040[[8163 8613 5159 ...,    0    0    0]\n",
      " [3484  610   86 ...,    0    0    0]\n",
      " [  18    2  153 ...,    0    0    0]\n",
      " ..., \n",
      " [  10    2 3037 ...,    0    0    0]\n",
      " [1068 9485  192 ...,    0    0    0]\n",
      " [3079 3363    9 ...,    0    0    0]]\n",
      "125/200 [=================>............] - ETA: 33s - loss: 1.5743 - acc: 0.8040[[ 535 1398   13 ...,    0    0    0]\n",
      " [ 300   21    1 ...,    0    0    0]\n",
      " [ 108   68   23 ...,    0    0    0]\n",
      " ..., \n",
      " [   8  155   10 ...,    0    0    0]\n",
      " [ 535    1 3423 ...,    0    0    0]\n",
      " [4571 2417  703 ...,    0    0    0]]\n",
      "126/200 [=================>............] - ETA: 33s - loss: 1.5743 - acc: 0.8040[[ 1740  1635    13 ...,     0     0     0]\n",
      " [ 1019   747 10354 ...,     0     0     0]\n",
      " [   89    27    20 ...,     0     0     0]\n",
      " ..., \n",
      " [   80  2199    13 ...,     0     0     0]\n",
      " [    1  3089    23 ...,     0     0     0]\n",
      " [    4     1   264 ...,     0     0     0]]\n",
      "127/200 [==================>...........] - ETA: 33s - loss: 1.5747 - acc: 0.8040[[  93  724   90 ...,    0    0    0]\n",
      " [2309 3927  684 ...,    0    0    0]\n",
      " [   2 2437    5 ...,    0    0    0]\n",
      " ..., \n",
      " [ 174  446   13 ...,    0    0    0]\n",
      " [5338 4002    7 ...,    0    0    0]\n",
      " [   1   25 3212 ...,    0    0    0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/200 [==================>...........] - ETA: 32s - loss: 1.5763 - acc: 0.8037[[  13 8440  523 ...,    0    0    0]\n",
      " [ 763 6237 1934 ...,    0    0    0]\n",
      " [ 203 1646   79 ...,    0    0    0]\n",
      " ..., \n",
      " [  12   13   13 ...,    0    0    0]\n",
      " [ 730   13 1846 ...,    0    0    0]\n",
      " [ 104  114   48 ...,    0    0    0]]\n",
      "129/200 [==================>...........] - ETA: 32s - loss: 1.5783 - acc: 0.8035[[  89    7   22 ...,    0    0    0]\n",
      " [  15    7   48 ...,    0    0    0]\n",
      " [  13   26  115 ...,    0    0    0]\n",
      " ..., \n",
      " [ 406    7 1265 ...,    0    0    0]\n",
      " [ 770  299    5 ...,    0    0    0]\n",
      " [  78   94   13 ...,    0    0    0]]\n",
      "130/200 [==================>...........] - ETA: 31s - loss: 1.5770 - acc: 0.8037[[  13   63  144 ...,    0    0    0]\n",
      " [  15    9   80 ...,    0    0    0]\n",
      " [   1  167  191 ...,    0    0    0]\n",
      " ..., \n",
      " [   3   20 1560 ...,    0    0    0]\n",
      " [   1 1274  276 ...,    0    0    0]\n",
      " [  13  114  155 ...,    0    0    0]]\n",
      "131/200 [==================>...........] - ETA: 31s - loss: 1.5786 - acc: 0.8036[[   70    13 11859 ...,     0     0     0]\n",
      " [   80    41    14 ...,     0     0     0]\n",
      " [  232  3054   384 ...,     0     0     0]\n",
      " ..., \n",
      " [ 1931  1772    29 ...,     0     0     0]\n",
      " [ 1382  1963    11 ...,     0     0     0]\n",
      " [  698  5800  1429 ...,     0     0     0]]\n",
      "132/200 [==================>...........] - ETA: 30s - loss: 1.5784 - acc: 0.8036[[   1  177   70 ...,    0    0    0]\n",
      " [  41  330  674 ...,    0    0    0]\n",
      " [ 104   14  233 ...,    0    0    0]\n",
      " ..., \n",
      " [ 194   63  144 ...,    0    0    0]\n",
      " [  13  104 1619 ...,    0    0    0]\n",
      " [ 245 1225   13 ...,    0    0    0]]\n",
      "133/200 [==================>...........] - ETA: 30s - loss: 1.5775 - acc: 0.8038[[1226   97   13 ...,    0    0    0]\n",
      " [1233 3058   25 ...,    0    0    0]\n",
      " [  10  402   13 ...,    0    0    0]\n",
      " ..., \n",
      " [  15   14    2 ...,    0    0    0]\n",
      " [1401 8027   81 ...,    0    0    0]\n",
      " [  13 1049   13 ...,    0    0    0]]\n",
      "134/200 [===================>..........] - ETA: 29s - loss: 1.5778 - acc: 0.8038[[ 503    9  305 ...,    0    0    0]\n",
      " [1629    1 1798 ...,    0    0    0]\n",
      " [ 565    1  189 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [ 547   69 4400 ...,    0    0    0]\n",
      " [   1 1276 3182 ...,    0    0    0]]\n",
      "135/200 [===================>..........] - ETA: 29s - loss: 1.5781 - acc: 0.8037[[3158  217 1453 ...,    0    0    0]\n",
      " [   1  261 2012 ...,    0    0    0]\n",
      " [  13  167  523 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [ 167 6286 4386 ...,    0    0    0]\n",
      " [   1   13 3414 ...,    0    0    0]]\n",
      "136/200 [===================>..........] - ETA: 29s - loss: 1.5774 - acc: 0.8038[[   1 2230  199 ...,    0    0    0]\n",
      " [   1  220   73 ...,    0    0    0]\n",
      " [2553  594  205 ...,    0    0    0]\n",
      " ..., \n",
      " [  55   27 2904 ...,    0    0    0]\n",
      " [ 274   55    7 ...,    0    0    0]\n",
      " [   1   13   91 ...,    0    0    0]]\n",
      "137/200 [===================>..........] - ETA: 28s - loss: 1.5770 - acc: 0.8039[[   1   13   91 ...,    0    0    0]\n",
      " [ 481   66  106 ...,    0    0    0]\n",
      " [ 456  121   26 ...,    0    0    0]\n",
      " ..., \n",
      " [  13    3 7124 ...,    0    0    0]\n",
      " [ 599 1780   23 ...,    0    0    0]\n",
      " [ 422  755  312 ...,    0    0    0]]\n",
      "138/200 [===================>..........] - ETA: 28s - loss: 1.5767 - acc: 0.8039[[2032  610  168 ...,    0    0    0]\n",
      " [ 232 1991    4 ...,    0    0    0]\n",
      " [  49  102  112 ...,    0    0    0]\n",
      " ..., \n",
      " [ 150 2695  947 ...,    0    0    0]\n",
      " [   2 3709   13 ...,    0    0    0]\n",
      " [  92 2036  462 ...,    0    0    0]]\n",
      "139/200 [===================>..........] - ETA: 27s - loss: 1.5768 - acc: 0.8039[[5401 3039   13 ...,    0    0    0]\n",
      " [  34    9   41 ...,    0    0    0]\n",
      " [1082  295  353 ...,    0    0    0]\n",
      " ..., \n",
      " [4748 2617  141 ...,    0    0    0]\n",
      " [  10  697 1295 ...,    0    0    0]\n",
      " [   1  547 6865 ...,    0    0    0]]\n",
      "140/200 [====================>.........] - ETA: 27s - loss: 1.5770 - acc: 0.8039[[  37   56   37 ...,    0    0    0]\n",
      " [ 880  903   92 ...,    0    0    0]\n",
      " [4008   43 3511 ...,    0    0    0]\n",
      " ..., \n",
      " [ 347   61    2 ...,    0    0    0]\n",
      " [ 654  145   11 ...,    0    0    0]\n",
      " [ 456  119   21 ...,    0    0    0]]\n",
      "141/200 [====================>.........] - ETA: 26s - loss: 1.5774 - acc: 0.8039[[   4    1 3064 ...,    0    0    0]\n",
      " [  12 5230   13 ...,    0    0    0]\n",
      " [ 246   11 4044 ...,    0    0    0]\n",
      " ..., \n",
      " [  13    4 1453 ...,    0    0    0]\n",
      " [1109  332 8047 ...,    0    0    0]\n",
      " [  13 9504 5172 ...,    0    0    0]]\n",
      "142/200 [====================>.........] - ETA: 26s - loss: 1.5772 - acc: 0.8040[[ 685   38   62 ...,    0    0    0]\n",
      " [ 913    7 3013 ...,    0    0    0]\n",
      " [ 224    7 4494 ...,    0    0    0]\n",
      " ..., \n",
      " [ 416   13    1 ...,    0    0    0]\n",
      " [3350 2858    9 ...,    0    0    0]\n",
      " [   1  682  189 ...,    0    0    0]]\n",
      "143/200 [====================>.........] - ETA: 25s - loss: 1.5773 - acc: 0.8040[[ 1149  5222  1429 ...,     0     0     0]\n",
      " [   99   881  2396 ...,     0     0     0]\n",
      " [  726   419     3 ...,     0     0     0]\n",
      " ..., \n",
      " [    2  2011    16 ...,     0     0     0]\n",
      " [  967   130  3006 ...,     0     0     0]\n",
      " [10699    11   130 ...,     0     0     0]]\n",
      "144/200 [====================>.........] - ETA: 25s - loss: 1.5774 - acc: 0.8040[[   2   13  405 ...,    0    0    0]\n",
      " [   1  221  230 ...,    0    0    0]\n",
      " [3847 8196    3 ...,    0    0    0]\n",
      " ..., \n",
      " [   2  361    5 ...,    0    0    0]\n",
      " [  48  171    1 ...,    0    0    0]\n",
      " [  10  116  203 ...,    0    0    0]]\n",
      "145/200 [====================>.........] - ETA: 24s - loss: 1.5757 - acc: 0.8042[[ 150 8632  390 ...,    0    0    0]\n",
      " [1469  995    8 ...,    0    0    0]\n",
      " [  19  120  117 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  916  336 ...,    0    0    0]\n",
      " [   1 1797  610 ...,    0    0    0]\n",
      " [ 321   10  343 ...,    0    0    0]]\n",
      "146/200 [====================>.........] - ETA: 24s - loss: 1.5735 - acc: 0.8043[[1062   11   45 ...,    0    0    0]\n",
      " [  18   42 1535 ...,    0    0    0]\n",
      " [   2   19 1811 ...,    0    0    0]\n",
      " ..., \n",
      " [ 665  473   13 ...,    0    0    0]\n",
      " [4488   13 3072 ...,    0    0    0]\n",
      " [   1   78  360 ...,    0    0    0]]\n",
      "147/200 [=====================>........] - ETA: 24s - loss: 1.5712 - acc: 0.8046[[   2   13   14 ...,    0    0    0]\n",
      " [2909  168   41 ...,    0    0    0]\n",
      " [ 257   15   32 ...,    0    0    0]\n",
      " ..., \n",
      " [5409   11 1048 ...,    0    0    0]\n",
      " [ 246  604 5651 ...,    0    0    0]\n",
      " [ 248  604 5651 ...,    0    0    0]]\n",
      "148/200 [=====================>........] - ETA: 23s - loss: 1.5698 - acc: 0.8047[[   13 11979     9 ...,     0     0     0]\n",
      " [  978   967     7 ...,     0     0     0]\n",
      " [    2  1346  2405 ...,     0     0     0]\n",
      " ..., \n",
      " [   89     7   586 ...,     0     0     0]\n",
      " [  232    13  3269 ...,     0     0     0]\n",
      " [  347   259    63 ...,     0     0     0]]\n",
      "149/200 [=====================>........] - ETA: 23s - loss: 1.5696 - acc: 0.8047[[ 2894 11190    13 ...,     0     0     0]\n",
      " [    1  4282     8 ...,     0     0     0]\n",
      " [ 2900    13     7 ...,     0     0     0]\n",
      " ..., \n",
      " [   18     2  1884 ...,     0     0     0]\n",
      " [   15     7     1 ...,     0     0     0]\n",
      " [    1  2233    29 ...,     0     0     0]]\n",
      "150/200 [=====================>........] - ETA: 22s - loss: 1.5699 - acc: 0.8047[[7006 1123   13 ...,    0    0    0]\n",
      " [4209  971    9 ...,    0    0    0]\n",
      " [  70 2215  231 ...,    0    0    0]\n",
      " ..., \n",
      " [  13 2230   13 ...,    0    0    0]\n",
      " [  23   13  136 ...,    0    0    0]\n",
      " [ 730   13  108 ...,    0    0    0]]\n",
      "151/200 [=====================>........] - ETA: 22s - loss: 1.5711 - acc: 0.8046[[10549    13    11 ...,     0     0     0]\n",
      " [ 2820  6055   530 ...,     0     0     0]\n",
      " [  523  5302    13 ...,     0     0     0]\n",
      " ..., \n",
      " [  202    71     7 ...,     0     0     0]\n",
      " [   32     1    47 ...,     0     0     0]\n",
      " [    1  1238   336 ...,     0     0     0]]\n",
      "152/200 [=====================>........] - ETA: 21s - loss: 1.5715 - acc: 0.8045[[   34     9     1 ...,     0     0     0]\n",
      " [    1  6327     7 ...,     0     0     0]\n",
      " [   89     9     2 ...,     0     0     0]\n",
      " ..., \n",
      " [   13 10095    44 ...,     0     0     0]\n",
      " [  406    13  7620 ...,     0     0     0]\n",
      " [    1   845   770 ...,     0     0     0]]\n",
      "153/200 [=====================>........] - ETA: 21s - loss: 1.5710 - acc: 0.8046[[ 379   23 3609 ...,    0    0    0]\n",
      " [  10 1196   13 ...,    0    0    0]\n",
      " [ 166    2  259 ...,    0    0    0]\n",
      " ..., \n",
      " [ 133   39 1165 ...,    0    0    0]\n",
      " [   1 3703   11 ...,    0    0    0]\n",
      " [   1  823 5216 ...,    0    0    0]]\n",
      "154/200 [======================>.......] - ETA: 20s - loss: 1.5723 - acc: 0.8044[[ 244 2381  123 ...,    0    0    0]\n",
      " [ 409  192    2 ...,    0    0    0]\n",
      " [  13 1825    9 ...,    0    0    0]\n",
      " ..., \n",
      " [1892 7257    9 ...,    0    0    0]\n",
      " [1328   13   83 ...,    0    0    0]\n",
      " [   1  175 5681 ...,    0    0    0]]\n",
      "155/200 [======================>.......] - ETA: 20s - loss: 1.5734 - acc: 0.8043[[  54  234   63 ...,    0    0    0]\n",
      " [   1 1341   21 ...,    0    0    0]\n",
      " [  15  448   29 ...,    0    0    0]\n",
      " ..., \n",
      " [   4    1  645 ...,    0    0    0]\n",
      " [5542 2931   14 ...,    0    0    0]\n",
      " [ 586    9   18 ...,    0    0    0]]\n",
      "156/200 [======================>.......] - ETA: 19s - loss: 1.5757 - acc: 0.8041[[1265    3 2312 ...,    0    0    0]\n",
      " [   1 2456 2248 ...,    0    0    0]\n",
      " [  13  301   23 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 4946   21 ...,    0    0    0]\n",
      " [1209   13  574 ...,    0    0    0]\n",
      " [  69  451   83 ...,    0    0    0]]\n",
      "157/200 [======================>.......] - ETA: 19s - loss: 1.5758 - acc: 0.8041[[   4 1097   13 ...,    0    0    0]\n",
      " [1070 2004   23 ...,    0    0    0]\n",
      " [5232  247 1268 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   13    9 ...,    0    0    0]\n",
      " [ 171   43 7345 ...,    0    0    0]\n",
      " [ 137    2 7421 ...,    0    0    0]]\n",
      "158/200 [======================>.......] - ETA: 19s - loss: 1.5769 - acc: 0.8040[[   13    13  3647 ...,     0     0     0]\n",
      " [   13 11605     9 ...,     0     0     0]\n",
      " [  181    13   105 ...,     0     0     0]\n",
      " ..., \n",
      " [ 4851    13 10762 ...,     0     0     0]\n",
      " [ 9718     5     2 ...,     0     0     0]\n",
      " [   89     9   693 ...,     0     0     0]]\n",
      "159/200 [======================>.......] - ETA: 18s - loss: 1.5761 - acc: 0.8041[[  13 1442   13 ...,    0    0    0]\n",
      " [2461   13    9 ...,    0    0    0]\n",
      " [  13 1442   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 951    2 1118 ...,    0    0    0]\n",
      " [   1   13   98 ...,    0    0    0]\n",
      " [  17  431   14 ...,    0    0    0]]\n",
      "160/200 [=======================>......] - ETA: 18s - loss: 1.5754 - acc: 0.8042[[   4   22 2404 ...,    0    0    0]\n",
      " [1925   11 1243 ...,    0    0    0]\n",
      " [1287   13 5519 ...,    0    0    0]\n",
      " ..., \n",
      " [ 318    9 2492 ...,    0    0    0]\n",
      " [   2   13 1300 ...,    0    0    0]\n",
      " [   1   13   38 ...,    0    0    0]]\n",
      "161/200 [=======================>......] - ETA: 17s - loss: 1.5760 - acc: 0.8042[[6214  172   41 ...,    0    0    0]\n",
      " [4280  292   40 ...,    0    0    0]\n",
      " [2192   55    7 ...,    0    0    0]\n",
      " ..., \n",
      " [ 226  217  140 ...,    0    0    0]\n",
      " [3608  119   13 ...,    0    0    0]\n",
      " [ 373  423   55 ...,    0    0    0]]\n",
      "162/200 [=======================>......] - ETA: 17s - loss: 1.5763 - acc: 0.8042[[ 318    7   49 ...,    0    0    0]\n",
      " [  13   26  922 ...,    0    0    0]\n",
      " [  55   11   13 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  220  527 ...,    0    0    0]\n",
      " [   1  422 2108 ...,    0    0    0]\n",
      " [  55    7  682 ...,    0    0    0]]\n",
      "163/200 [=======================>......] - ETA: 16s - loss: 1.5764 - acc: 0.8042[[  456   307   867 ...,     0     0     0]\n",
      " [   73   240     4 ...,     0     0     0]\n",
      " [ 3906    69 11375 ...,     0     0     0]\n",
      " ..., \n",
      " [    1    13    91 ...,     0     0     0]\n",
      " [    1   547   732 ...,     0     0     0]\n",
      " [   13   275    99 ...,     0     0     0]]\n",
      "164/200 [=======================>......] - ETA: 16s - loss: 1.5768 - acc: 0.8041[[ 632   47  867 ...,    0    0    0]\n",
      " [1005   11 1492 ...,    0    0    0]\n",
      " [   2 4390   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 140  583  100 ...,    0    0    0]\n",
      " [  19  352  187 ...,    0    0    0]\n",
      " [   1   19  352 ...,    0    0    0]]\n",
      "165/200 [=======================>......] - ETA: 15s - loss: 1.5765 - acc: 0.8041[[ 884    8  491 ...,    0    0    0]\n",
      " [ 176   66  106 ...,    0    0    0]\n",
      " [  13   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  823 1876 ...,    0    0    0]\n",
      " [   1  180    7 ...,    0    0    0]\n",
      " [2176 3115   23 ...,    0    0    0]]\n",
      "166/200 [=======================>......] - ETA: 15s - loss: 1.5771 - acc: 0.8041[[   3 1428  159 ...,    0    0    0]\n",
      " [  15    7 7374 ...,    0    0    0]\n",
      " [ 717 3637  256 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13 1438 ...,    0    0    0]\n",
      " [1390 2704 3787 ...,    0    0    0]\n",
      " [1219   17 2281 ...,    0    0    0]]\n",
      "167/200 [========================>.....] - ETA: 14s - loss: 1.5766 - acc: 0.8042[[ 585 3731 1002 ...,    0    0    0]\n",
      " [   1   38 6760 ...,    0    0    0]\n",
      " [   1 5327  499 ...,    0    0    0]\n",
      " ..., \n",
      " [  89    7   80 ...,    0    0    0]\n",
      " [   2 3717  146 ...,    0    0    0]\n",
      " [   2 4572 1129 ...,    0    0    0]]\n",
      "168/200 [========================>.....] - ETA: 14s - loss: 1.5768 - acc: 0.8042[[  66    6    1 ...,    0    0    0]\n",
      " [1446   13   23 ...,    0    0    0]\n",
      " [  22  405   16 ...,    0    0    0]\n",
      " ..., \n",
      " [1577 2630   14 ...,    0    0    0]\n",
      " [ 221  230  659 ...,    0    0    0]\n",
      " [ 132   73  240 ...,    0    0    0]]\n",
      "169/200 [========================>.....] - ETA: 14s - loss: 1.5771 - acc: 0.8041[[   1 3845   11 ...,    0    0    0]\n",
      " [   1 1753 1634 ...,    0    0    0]\n",
      " [  26  115    4 ...,    0    0    0]\n",
      " ..., \n",
      " [ 545   69 5333 ...,    0    0    0]\n",
      " [ 300  133    1 ...,    0    0    0]\n",
      " [2461 8349    9 ...,    0    0    0]]\n",
      "170/200 [========================>.....] - ETA: 13s - loss: 1.5768 - acc: 0.8042[[ 350  289  129 ...,    0    0    0]\n",
      " [   1 1015    5 ...,    0    0    0]\n",
      " [ 170 1599   32 ...,    0    0    0]\n",
      " ..., \n",
      " [1822   13    7 ...,    0    0    0]\n",
      " [ 108   15   14 ...,    0    0    0]\n",
      " [ 280 1987   14 ...,    0    0    0]]\n",
      "171/200 [========================>.....] - ETA: 13s - loss: 1.5756 - acc: 0.8043[[9077   50  173 ...,    0    0    0]\n",
      " [1961 2587   11 ...,    0    0    0]\n",
      " [3697  119  157 ...,    0    0    0]\n",
      " ..., \n",
      " [1486  299    5 ...,    0    0    0]\n",
      " [7828   13   11 ...,    0    0    0]\n",
      " [ 496   11 1220 ...,    0    0    0]]\n",
      "172/200 [========================>.....] - ETA: 12s - loss: 1.5738 - acc: 0.8045[[ 355   13   11 ...,    0    0    0]\n",
      " [ 284  941 1465 ...,    0    0    0]\n",
      " [   1 1054    6 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   11 3565 ...,    0    0    0]\n",
      " [  17   13   83 ...,    0    0    0]\n",
      " [ 126  264    7 ...,    0    0    0]]\n",
      "173/200 [========================>.....] - ETA: 12s - loss: 1.5720 - acc: 0.8046[[    1   567   522 ...,     0     0     0]\n",
      " [    2    19   352 ...,     0     0     0]\n",
      " [  166    13    13 ...,     0     0     0]\n",
      " ..., \n",
      " [  812  1064 10285 ...,     0     0     0]\n",
      " [   13  1512    11 ...,     0     0     0]\n",
      " [ 1911  5863    11 ...,     0     0     0]]\n",
      "174/200 [=========================>....] - ETA: 11s - loss: 1.5703 - acc: 0.8048[[   13  2060  8660 ...,     0     0     0]\n",
      " [   13  3523  5816 ...,     0     0     0]\n",
      " [   13  1149 11626 ...,     0     0     0]\n",
      " ..., \n",
      " [  443    13    81 ...,     0     0     0]\n",
      " [    1  2791    27 ...,     0     0     0]\n",
      " [  978   967   604 ...,     0     0     0]]\n",
      "175/200 [=========================>....] - ETA: 11s - loss: 1.5690 - acc: 0.8049[[    4   347   793 ...,     0     0     0]\n",
      " [ 8530    13    27 ...,     0     0     0]\n",
      " [  599    13   112 ...,     0     0     0]\n",
      " ..., \n",
      " [   32 10814     3 ...,     0     0     0]\n",
      " [ 2704  6929     7 ...,     0     0     0]\n",
      " [  348     2   846 ...,     0     0     0]]\n",
      "176/200 [=========================>....] - ETA: 10s - loss: 1.5688 - acc: 0.8049[[ 108 4250    9 ...,    0    0    0]\n",
      " [ 301 8908 7838 ...,    0    0    0]\n",
      " [6110  222 2838 ...,    0    0    0]\n",
      " ..., \n",
      " [ 276  178   13 ...,    0    0    0]\n",
      " [ 102 7048   29 ...,    0    0    0]\n",
      " [3012    8 9083 ...,    0    0    0]]\n",
      "177/200 [=========================>....] - ETA: 10s - loss: 1.5697 - acc: 0.8048[[   68   471    39 ...,     0     0     0]\n",
      " [11204    11   269 ...,     0     0     0]\n",
      " [ 7859  1562    13 ...,     0     0     0]\n",
      " ..., \n",
      " [   15    11    45 ...,     0     0     0]\n",
      " [   75    13  4214 ...,     0     0     0]\n",
      " [   13     1   801 ...,     0     0     0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/200 [=========================>....] - ETA: 9s - loss: 1.5699 - acc: 0.8048 [[    4    13    13 ...,     0     0     0]\n",
      " [11258    13    13 ...,     0     0     0]\n",
      " [ 3664    13    11 ...,     0     0     0]\n",
      " ..., \n",
      " [   80  1327    29 ...,     0     0     0]\n",
      " [  108    68  1573 ...,     0     0     0]\n",
      " [   10   116     5 ...,     0     0     0]]\n",
      "179/200 [=========================>....] - ETA: 9s - loss: 1.5704 - acc: 0.8048[[   2 7796    3 ...,    0    0    0]\n",
      " [ 301   79   21 ...,    0    0    0]\n",
      " [1720   13 3192 ...,    0    0    0]\n",
      " ..., \n",
      " [  70  291 1018 ...,    0    0    0]\n",
      " [  10   63   13 ...,    0    0    0]\n",
      " [3604   13   14 ...,    0    0    0]]\n",
      "180/200 [==========================>...] - ETA: 9s - loss: 1.5703 - acc: 0.8048[[  34    9    2 ...,    0    0    0]\n",
      " [3309   13   10 ...,    0    0    0]\n",
      " [3138  192   39 ...,    0    0    0]\n",
      " ..., \n",
      " [9776  744    3 ...,    0    0    0]\n",
      " [  32    1  908 ...,    0    0    0]\n",
      " [  33   13 1218 ...,    0    0    0]]\n",
      "181/200 [==========================>...] - ETA: 8s - loss: 1.5715 - acc: 0.8046[[   1 9590  397 ...,    0    0    0]\n",
      " [ 803 3021  103 ...,    0    0    0]\n",
      " [ 564   13  297 ...,    0    0    0]\n",
      " ..., \n",
      " [ 558    5 2142 ...,    0    0    0]\n",
      " [ 171   70  644 ...,    0    0    0]\n",
      " [  70   15  392 ...,    0    0    0]]\n",
      "182/200 [==========================>...] - ETA: 8s - loss: 1.5724 - acc: 0.8045[[  18    1   13 ...,    0    0    0]\n",
      " [  15    9 7198 ...,    0    0    0]\n",
      " [  15   11   45 ...,    0    0    0]\n",
      " ..., \n",
      " [1381 9770    3 ...,    0    0    0]\n",
      " [6832   13 1864 ...,    0    0    0]\n",
      " [1621  546    9 ...,    0    0    0]]\n",
      "183/200 [==========================>...] - ETA: 7s - loss: 1.5743 - acc: 0.8043[[  15   11  147 ...,    0    0    0]\n",
      " [  70   15 1648 ...,    0    0    0]\n",
      " [1635   13  265 ...,    0    0    0]\n",
      " ..., \n",
      " [2069    7 1818 ...,    0    0    0]\n",
      " [  68  114 1523 ...,    0    0    0]\n",
      " [   1 1996    5 ...,    0    0    0]]\n",
      "184/200 [==========================>...] - ETA: 7s - loss: 1.5741 - acc: 0.8044[[    1  1825     5 ...,     0     0     0]\n",
      " [   16    41   826 ...,     0     0     0]\n",
      " [ 1066  2530     8 ...,     0     0     0]\n",
      " ..., \n",
      " [   13  3328    44 ...,     0     0     0]\n",
      " [   32    79 11010 ...,     0     0     0]\n",
      " [  730    13   227 ...,     0     0     0]]\n",
      "185/200 [==========================>...] - ETA: 6s - loss: 1.5752 - acc: 0.8042[[   15     7     2 ...,     0     0     0]\n",
      " [  108    68    21 ...,     0     0     0]\n",
      " [ 3903   105   505 ...,     0     0     0]\n",
      " ..., \n",
      " [    2   188   144 ...,     0     0     0]\n",
      " [    1   493  2588 ...,     0     0     0]\n",
      " [11730   303   102 ...,     0     0     0]]\n",
      "186/200 [==========================>...] - ETA: 6s - loss: 1.5754 - acc: 0.8042[[  13   68  574 ...,    0    0    0]\n",
      " [ 159   13  336 ...,    0    0    0]\n",
      " [  53    9    1 ...,    0    0    0]\n",
      " ..., \n",
      " [1236    3    1 ...,    0    0    0]\n",
      " [  13  141   39 ...,    0    0    0]\n",
      " [ 443 1112    7 ...,    0    0    0]]\n",
      "187/200 [===========================>..] - ETA: 5s - loss: 1.5751 - acc: 0.8043[[ 2905    51  1765 ...,     0     0     0]\n",
      " [ 7920    13    11 ...,     0     0     0]\n",
      " [11831   695     6 ...,     0     0     0]\n",
      " ..., \n",
      " [  109    26    65 ...,     0     0     0]\n",
      " [    2   426  2162 ...,     0     0     0]\n",
      " [ 6620  6804   100 ...,     0     0     0]]\n",
      "188/200 [===========================>..] - ETA: 5s - loss: 1.5755 - acc: 0.8042[[ 154   66    6 ...,    0    0    0]\n",
      " [  58   59 2805 ...,    0    0    0]\n",
      " [   1  785  115 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 1896  119 ...,    0    0    0]\n",
      " [  78   37   13 ...,    0    0    0]\n",
      " [   2   13    5 ...,    0    0    0]]\n",
      "189/200 [===========================>..] - ETA: 4s - loss: 1.5754 - acc: 0.8043[[   2  258    5 ...,    0    0    0]\n",
      " [  13   26  441 ...,    0    0    0]\n",
      " [  55    7 2803 ...,    0    0    0]\n",
      " ..., \n",
      " [ 219   26  441 ...,    0    0    0]\n",
      " [2928 2633    6 ...,    0    0    0]\n",
      " [ 116  191   13 ...,    0    0    0]]\n",
      "190/200 [===========================>..] - ETA: 4s - loss: 1.5753 - acc: 0.8043[[   1 1276 3182 ...,    0    0    0]\n",
      " [  38  176   66 ...,    0    0    0]\n",
      " [   1 1276 3182 ...,    0    0    0]\n",
      " ..., \n",
      " [  13 4441    5 ...,    0    0    0]\n",
      " [2253  808  514 ...,    0    0    0]\n",
      " [  13   26  113 ...,    0    0    0]]\n",
      "191/200 [===========================>..] - ETA: 4s - loss: 1.5750 - acc: 0.8043[[ 131 2788 2973 ...,    0    0    0]\n",
      " [ 109   26  101 ...,    0    0    0]\n",
      " [   2   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [1390 2704 3787 ...,    0    0    0]\n",
      " [1827 1582   10 ...,    0    0    0]\n",
      " [   1  236  477 ...,    0    0    0]]\n",
      "192/200 [===========================>..] - ETA: 3s - loss: 1.5750 - acc: 0.8043[[   2  582  405 ...,    0    0    0]\n",
      " [ 884  154   66 ...,    0    0    0]\n",
      " [ 654  117  332 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [1986    8 1431 ...,    0    0    0]\n",
      " [5682    9    4 ...,    0    0    0]]\n",
      "193/200 [===========================>..] - ETA: 3s - loss: 1.5756 - acc: 0.8043[[ 3013  9457  1060 ...,     0     0     0]\n",
      " [  109    26  1481 ...,     0     0     0]\n",
      " [10316    13    13 ...,     0     0     0]\n",
      " ..., \n",
      " [   38    62    13 ...,     0     0     0]\n",
      " [  623   157    13 ...,     0     0     0]\n",
      " [   10    13    13 ...,     0     0     0]]\n",
      "194/200 [============================>.] - ETA: 2s - loss: 1.5757 - acc: 0.8043[[1846   13   11 ...,    0    0    0]\n",
      " [3319 1708  205 ...,    0    0    0]\n",
      " [  22 8203  310 ...,    0    0    0]\n",
      " ..., \n",
      " [2425   27 1059 ...,    0    0    0]\n",
      " [ 844  217 1679 ...,    0    0    0]\n",
      " [5387  969   11 ...,    0    0    0]]\n",
      "195/200 [============================>.] - ETA: 2s - loss: 1.5755 - acc: 0.8043[[ 3377    11  4318 ...,     0     0     0]\n",
      " [10997   128    39 ...,     0     0     0]\n",
      " [   10  1461     5 ...,     0     0     0]\n",
      " ..., \n",
      " [  137     7     1 ...,     0     0     0]\n",
      " [    1  2195   236 ...,     0     0     0]\n",
      " [ 1405   100   566 ...,     0     0     0]]\n",
      "196/200 [============================>.] - ETA: 1s - loss: 1.5756 - acc: 0.8043[[  15    7 6030 ...,    0    0    0]\n",
      " [  79  121  255 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " ..., \n",
      " [ 150  199  287 ...,    0    0    0]\n",
      " [ 751   11  399 ...,    0    0    0]\n",
      " [1742    9  155 ...,    0    0    0]]\n",
      "197/200 [============================>.] - ETA: 1s - loss: 1.5757 - acc: 0.8043[[ 579    7 1010 ...,    0    0    0]\n",
      " [ 665 1252    9 ...,    0    0    0]\n",
      " [  80  199 6663 ...,    0    0    0]\n",
      " ..., \n",
      " [1385  968 1360 ...,    0    0    0]\n",
      " [8877   13   14 ...,    0    0    0]\n",
      " [   1 2097  152 ...,    0    0    0]]\n",
      "198/200 [============================>.] - ETA: 0s - loss: 1.5749 - acc: 0.8044[[ 3010   430   590 ...,     0     0     0]\n",
      " [   13  6010    11 ...,     0     0     0]\n",
      " [ 3571     9  5456 ...,     0     0     0]\n",
      " ..., \n",
      " [11295    83    15 ...,     0     0     0]\n",
      " [  219   119   157 ...,     0     0     0]\n",
      " [   22  9314  5292 ...,     0     0     0]]\n",
      "199/200 [============================>.] - ETA: 0s - loss: 1.5734 - acc: 0.8045[[ 267  157   22 ...,    0    0    0]\n",
      " [7723 1091  941 ...,    0    0    0]\n",
      " [1549  455    3 ...,    0    0    0]\n",
      " ..., \n",
      " [   2   13  394 ...,    0    0    0]\n",
      " [   2   19  545 ...,    0    0    0]\n",
      " [4883   13    5 ...,    0    0    0]]\n",
      "200/200 [==============================] - 90s - loss: 1.5717 - acc: 0.8047    \n",
      "Epoch 4/10\n",
      "[[  13 3137  600 ...,    0    0    0]\n",
      " [7760   13   27 ...,    0    0    0]\n",
      " [3079 3363   11 ...,    0    0    0]\n",
      " ..., \n",
      " [1381    8 2084 ...,    0    0    0]\n",
      " [   1  214   23 ...,    0    0    0]\n",
      " [ 109   26 1317 ...,    0    0    0]]\n",
      "  1/200 [..............................] - ETA: 88s - loss: 1.3158 - acc: 0.8239[[   13    13    13 ...,     0     0     0]\n",
      " [   13  2435 11097 ...,     0     0     0]\n",
      " [    1   191     6 ...,     0     0     0]\n",
      " ..., \n",
      " [    1   214  1301 ...,     0     0     0]\n",
      " [   34    14    48 ...,     0     0     0]\n",
      " [    1   406  5815 ...,     0     0     0]]\n",
      "  2/200 [..............................] - ETA: 86s - loss: 1.3296 - acc: 0.8229[[    1  9836    23 ...,     0     0     0]\n",
      " [  154    66     6 ...,     0     0     0]\n",
      " [ 2541   748     3 ...,     0     0     0]\n",
      " ..., \n",
      " [  195    15    13 ...,     0     0     0]\n",
      " [    1 11532    14 ...,     0     0     0]\n",
      " [   56  4391     6 ...,     0     0     0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3/200 [..............................] - ETA: 87s - loss: 1.3935 - acc: 0.8188[[   1 1693 3514 ...,    0    0    0]\n",
      " [3827 4729   25 ...,    0    0    0]\n",
      " [4034 5683   10 ...,    0    0    0]\n",
      " ..., \n",
      " [ 221  230   13 ...,    0    0    0]\n",
      " [  70   15  392 ...,    0    0    0]\n",
      " [ 335    9    2 ...,    0    0    0]]\n",
      "  4/200 [..............................] - ETA: 87s - loss: 1.4241 - acc: 0.8185[[  15  748   90 ...,    0    0    0]\n",
      " [   1 1217  231 ...,    0    0    0]\n",
      " [ 152  139   11 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13   13 ...,    0    0    0]\n",
      " [   1 9395   23 ...,    0    0    0]\n",
      " [  15 1272 1558 ...,    0    0    0]]\n",
      "  5/200 [..............................] - ETA: 86s - loss: 1.4916 - acc: 0.8123[[  34  592   13 ...,    0    0    0]\n",
      " [  18   22 5726 ...,    0    0    0]\n",
      " [7167   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   13   44 ...,    0    0    0]\n",
      " [9077   50   13 ...,    0    0    0]\n",
      " [   4  189  343 ...,    0    0    0]]\n",
      "  6/200 [..............................] - ETA: 86s - loss: 1.5145 - acc: 0.8104[[  15    9    2 ...,    0    0    0]\n",
      " [  89    7   80 ...,    0    0    0]\n",
      " [  15   14   41 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  611   86 ...,    0    0    0]\n",
      " [   1  485 1456 ...,    0    0    0]\n",
      " [  15  744   90 ...,    0    0    0]]\n",
      "  7/200 [>.............................] - ETA: 86s - loss: 1.5274 - acc: 0.8087[[  56  290    5 ...,    0    0    0]\n",
      " [ 108 1971    9 ...,    0    0    0]\n",
      " [1460 1503   89 ...,    0    0    0]\n",
      " ..., \n",
      " [  78   77 9528 ...,    0    0    0]\n",
      " [ 127   63  144 ...,    0    0    0]\n",
      " [4802   76   43 ...,    0    0    0]]\n",
      "  8/200 [>.............................] - ETA: 86s - loss: 1.5328 - acc: 0.8084[[ 245  431    9 ...,    0    0    0]\n",
      " [   1   73  138 ...,    0    0    0]\n",
      " [  56  706  290 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 1540  737 ...,    0    0    0]\n",
      " [  12 2850   13 ...,    0    0    0]\n",
      " [3194  102   67 ...,    0    0    0]]\n",
      "  9/200 [>.............................] - ETA: 86s - loss: 1.5700 - acc: 0.8044[[ 202    1 2814 ...,    0    0    0]\n",
      " [   1  847   16 ...,    0    0    0]\n",
      " [2346   13   81 ...,    0    0    0]\n",
      " ..., \n",
      " [  13 1645  568 ...,    0    0    0]\n",
      " [ 535    1 3643 ...,    0    0    0]\n",
      " [5119 1903    9 ...,    0    0    0]]\n",
      " 10/200 [>.............................] - ETA: 86s - loss: 1.5911 - acc: 0.8021[[  64  598   82 ...,    0    0    0]\n",
      " [5095 1115 1312 ...,    0    0    0]\n",
      " [ 739  396   13 ...,    0    0    0]\n",
      " ..., \n",
      " [8251 4061   86 ...,    0    0    0]\n",
      " [  56   63    4 ...,    0    0    0]\n",
      " [   1 1011 1463 ...,    0    0    0]]\n",
      " 11/200 [>.............................] - ETA: 85s - loss: 1.6353 - acc: 0.7974[[  69  263   30 ...,    0    0    0]\n",
      " [ 159   13  141 ...,    0    0    0]\n",
      " [ 116   67    1 ...,    0    0    0]\n",
      " ..., \n",
      " [  89   67 5801 ...,    0    0    0]\n",
      " [   1 1033   86 ...,    0    0    0]\n",
      " [  32   13   13 ...,    0    0    0]]\n",
      " 12/200 [>.............................] - ETA: 85s - loss: 1.6139 - acc: 0.8007[[  10  885 1705 ...,    0    0    0]\n",
      " [  13 1442  947 ...,    0    0    0]\n",
      " [  34  592  630 ...,    0    0    0]\n",
      " ..., \n",
      " [7813 2029    9 ...,    0    0    0]\n",
      " [4534   43 4534 ...,    0    0    0]\n",
      " [  72 7076   83 ...,    0    0    0]]\n",
      " 13/200 [>.............................] - ETA: 85s - loss: 1.6271 - acc: 0.7990[[  13  817   17 ...,    0    0    0]\n",
      " [  10  888   13 ...,    0    0    0]\n",
      " [ 133   39   20 ...,    0    0    0]\n",
      " ..., \n",
      " [   2  223 1745 ...,    0    0    0]\n",
      " [   1  463   13 ...,    0    0    0]\n",
      " [ 194  102  504 ...,    0    0    0]]\n",
      " 14/200 [=>............................] - ETA: 84s - loss: 1.6322 - acc: 0.7988[[ 550 8168   13 ...,    0    0    0]\n",
      " [ 245   13   13 ...,    0    0    0]\n",
      " [  18    1 7564 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 6402  462 ...,    0    0    0]\n",
      " [1742  455    3 ...,    0    0    0]\n",
      " [ 104 1340   48 ...,    0    0    0]]\n",
      " 15/200 [=>............................] - ETA: 84s - loss: 1.6230 - acc: 0.8001[[  658    14   276 ...,     0     0     0]\n",
      " [    4   116  1595 ...,     0     0     0]\n",
      " [    1   416   381 ...,     0     0     0]\n",
      " ..., \n",
      " [  127  4833    63 ...,     0     0     0]\n",
      " [    1   282   339 ...,     0     0     0]\n",
      " [11976     9   111 ...,     0     0     0]]\n",
      " 16/200 [=>............................] - ETA: 83s - loss: 1.6165 - acc: 0.8010[[  93 1629   60 ...,    0    0    0]\n",
      " [1357    8 6176 ...,    0    0    0]\n",
      " [ 150 1718  133 ...,    0    0    0]\n",
      " ..., \n",
      " [ 884   73   66 ...,    0    0    0]\n",
      " [  55 9128 1070 ...,    0    0    0]\n",
      " [  13   26  182 ...,    0    0    0]]\n",
      " 17/200 [=>............................] - ETA: 83s - loss: 1.6173 - acc: 0.8011[[    1    13    91 ...,     0     0     0]\n",
      " [ 5582   217 11411 ...,     0     0     0]\n",
      " [  109    26   113 ...,     0     0     0]\n",
      " ..., \n",
      " [    1  8532   169 ...,     0     0     0]\n",
      " [  248  3499   280 ...,     0     0     0]\n",
      " [ 1695   623     6 ...,     0     0     0]]\n",
      " 18/200 [=>............................] - ETA: 83s - loss: 1.6175 - acc: 0.8010[[   1 1896  191 ...,    0    0    0]\n",
      " [  58   59 1032 ...,    0    0    0]\n",
      " [   1  884  191 ...,    0    0    0]\n",
      " ..., \n",
      " [  73 1479    4 ...,    0    0    0]\n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [1430  811   13 ...,    0    0    0]]\n",
      " 19/200 [=>............................] - ETA: 82s - loss: 1.6129 - acc: 0.8016[[  19  120 2442 ...,    0    0    0]\n",
      " [1379    1  126 ...,    0    0    0]\n",
      " [5183    4  367 ...,    0    0    0]\n",
      " ..., \n",
      " [2191    8  880 ...,    0    0    0]\n",
      " [ 546  510    6 ...,    0    0    0]\n",
      " [  13 2639 9459 ...,    0    0    0]]\n",
      " 20/200 [==>...........................] - ETA: 82s - loss: 1.6127 - acc: 0.8015[[   13    26   441 ...,     0     0     0]\n",
      " [   58    59   187 ...,     0     0     0]\n",
      " [    1  1508  1687 ...,     0     0     0]\n",
      " ..., \n",
      " [  255   160  1938 ...,     0     0     0]\n",
      " [ 7406 10480  1673 ...,     0     0     0]\n",
      " [   19   352   154 ...,     0     0     0]]\n",
      " 21/200 [==>...........................] - ETA: 81s - loss: 1.6068 - acc: 0.8024[[ 711  168   53 ...,    0    0    0]\n",
      " [   2  179  734 ...,    0    0    0]\n",
      " [1757  187  115 ...,    0    0    0]\n",
      " ..., \n",
      " [  22  864    8 ...,    0    0    0]\n",
      " [  47  867   13 ...,    0    0    0]\n",
      " [ 234 9748  289 ...,    0    0    0]]\n",
      " 22/200 [==>...........................] - ETA: 81s - loss: 1.6122 - acc: 0.8019[[ 166 7677   27 ...,    0    0    0]\n",
      " [ 654  145   11 ...,    0    0    0]\n",
      " [ 131  429 1187 ...,    0    0    0]\n",
      " ..., \n",
      " [  13 8443   11 ...,    0    0    0]\n",
      " [2084 2581 1392 ...,    0    0    0]\n",
      " [ 236  477  246 ...,    0    0    0]]\n",
      " 23/200 [==>...........................] - ETA: 80s - loss: 1.6118 - acc: 0.8018[[    2   412    12 ...,     0     0     0]\n",
      " [ 3909   267    23 ...,     0     0     0]\n",
      " [    1  6447    13 ...,     0     0     0]\n",
      " ..., \n",
      " [ 1497     8   148 ...,     0     0     0]\n",
      " [   22  4477 10665 ...,     0     0     0]\n",
      " [ 2965    13    30 ...,     0     0     0]]\n",
      " 24/200 [==>...........................] - ETA: 80s - loss: 1.6130 - acc: 0.8018[[   1  406 5815 ...,    0    0    0]\n",
      " [  13  505  105 ...,    0    0    0]\n",
      " [  22  150   13 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 4705 8115 ...,    0    0    0]\n",
      " [2453   13   13 ...,    0    0    0]\n",
      " [ 566    1 2604 ...,    0    0    0]]\n",
      " 25/200 [==>...........................] - ETA: 79s - loss: 1.6130 - acc: 0.8018[[  93   23   13 ...,    0    0    0]\n",
      " [ 147  202   13 ...,    0    0    0]\n",
      " [1693 3716 1232 ...,    0    0    0]\n",
      " ..., \n",
      " [ 119   21  616 ...,    0    0    0]\n",
      " [ 377    5   15 ...,    0    0    0]\n",
      " [3827   67 5652 ...,    0    0    0]]\n",
      " 26/200 [==>...........................] - ETA: 79s - loss: 1.6099 - acc: 0.8023[[ 1819     8  5136 ...,     0     0     0]\n",
      " [ 1770     5 11027 ...,     0     0     0]\n",
      " [    2  1355    13 ...,     0     0     0]\n",
      " ..., \n",
      " [  987    83    41 ...,     0     0     0]\n",
      " [   10  1334   123 ...,     0     0     0]\n",
      " [   15    14     1 ...,     0     0     0]]\n",
      " 27/200 [===>..........................] - ETA: 78s - loss: 1.5966 - acc: 0.8034[[  47 1907 1911 ...,    0    0    0]\n",
      " [   1   19  120 ...,    0    0    0]\n",
      " [1668   13  925 ...,    0    0    0]\n",
      " ..., \n",
      " [  15 1893   90 ...,    0    0    0]\n",
      " [   1 2757   11 ...,    0    0    0]\n",
      " [ 973 6406   11 ...,    0    0    0]]\n",
      " 28/200 [===>..........................] - ETA: 78s - loss: 1.5861 - acc: 0.8043[[  173     5    69 ...,     0     0     0]\n",
      " [11368     5  3219 ...,     0     0     0]\n",
      " [ 4915   941 11116 ...,     0     0     0]\n",
      " ..., \n",
      " [  108    68   595 ...,     0     0     0]\n",
      " [ 1224  1890    13 ...,     0     0     0]\n",
      " [ 3054   130  1046 ...,     0     0     0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 29/200 [===>..........................] - ETA: 77s - loss: 1.5755 - acc: 0.8050[[  13 2097   11 ...,    0    0    0]\n",
      " [ 849 1211   10 ...,    0    0    0]\n",
      " [9739 1535    4 ...,    0    0    0]\n",
      " ..., \n",
      " [5617 3345 1822 ...,    0    0    0]\n",
      " [ 633 3324   23 ...,    0    0    0]\n",
      " [3125 1254   11 ...,    0    0    0]]\n",
      " 30/200 [===>..........................] - ETA: 77s - loss: 1.5666 - acc: 0.8057[[    1  5180 10336 ...,     0     0     0]\n",
      " [  519  5445  2648 ...,     0     0     0]\n",
      " [    1  2400    13 ...,     0     0     0]\n",
      " ..., \n",
      " [ 1369  3750   192 ...,     0     0     0]\n",
      " [ 3327     9    48 ...,     0     0     0]\n",
      " [    1    13  3351 ...,     0     0     0]]\n",
      " 31/200 [===>..........................] - ETA: 76s - loss: 1.5636 - acc: 0.8058[[   1 2510    5 ...,    0    0    0]\n",
      " [ 824    9   76 ...,    0    0    0]\n",
      " [3393 7762    8 ...,    0    0    0]\n",
      " ..., \n",
      " [ 132   26   65 ...,    0    0    0]\n",
      " [4911 2964    8 ...,    0    0    0]\n",
      " [ 930   13   14 ...,    0    0    0]]\n",
      " 32/200 [===>..........................] - ETA: 76s - loss: 1.5660 - acc: 0.8055[[ 159 5589   11 ...,    0    0    0]\n",
      " [1067  314   13 ...,    0    0    0]\n",
      " [   1 1289 3073 ...,    0    0    0]\n",
      " ..., \n",
      " [  17 4581   11 ...,    0    0    0]\n",
      " [  10    1   47 ...,    0    0    0]\n",
      " [ 155   68  718 ...,    0    0    0]]\n",
      " 33/200 [===>..........................] - ETA: 75s - loss: 1.5694 - acc: 0.8053[[ 102  123  442 ...,    0    0    0]\n",
      " [ 145  757    9 ...,    0    0    0]\n",
      " [   1 1115  291 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 7219   38 ...,    0    0    0]\n",
      " [  99 5343 2628 ...,    0    0    0]\n",
      " [7155   81    2 ...,    0    0    0]]\n",
      " 34/200 [====>.........................] - ETA: 75s - loss: 1.5703 - acc: 0.8052[[  79    5  600 ...,    0    0    0]\n",
      " [  13 1751  541 ...,    0    0    0]\n",
      " [1346 2013  163 ...,    0    0    0]\n",
      " ..., \n",
      " [1694 2380  247 ...,    0    0    0]\n",
      " [  19 1848 4197 ...,    0    0    0]\n",
      " [  70   13   13 ...,    0    0    0]]\n",
      " 35/200 [====>.........................] - ETA: 74s - loss: 1.5760 - acc: 0.8045[[  41    5    1 ...,    0    0    0]\n",
      " [  42    7  111 ...,    0    0    0]\n",
      " [   1 3532    4 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  680   13 ...,    0    0    0]\n",
      " [ 293 5775   23 ...,    0    0    0]\n",
      " [   6 4325   86 ...,    0    0    0]]\n",
      " 36/200 [====>.........................] - ETA: 74s - loss: 1.5712 - acc: 0.8050[[  12   47 4618 ...,    0    0    0]\n",
      " [  32   61    3 ...,    0    0    0]\n",
      " [   1   47  872 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   13    9 ...,    0    0    0]\n",
      " [  13 1226  876 ...,    0    0    0]\n",
      " [ 730   13  995 ...,    0    0    0]]\n",
      " 37/200 [====>.........................] - ETA: 73s - loss: 1.5737 - acc: 0.8047[[6290   23   48 ...,    0    0    0]\n",
      " [  70 2860 4117 ...,    0    0    0]\n",
      " [ 639   37   13 ...,    0    0    0]\n",
      " ..., \n",
      " [   2   19  563 ...,    0    0    0]\n",
      " [   1  747   14 ...,    0    0    0]\n",
      " [  15    7 6004 ...,    0    0    0]]\n",
      " 38/200 [====>.........................] - ETA: 73s - loss: 1.5833 - acc: 0.8037[[ 302   13  154 ...,    0    0    0]\n",
      " [  15  105   21 ...,    0    0    0]\n",
      " [5814   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [  15  871   20 ...,    0    0    0]\n",
      " [2410 9350    9 ...,    0    0    0]\n",
      " [ 644   13   81 ...,    0    0    0]]\n",
      " 39/200 [====>.........................] - ETA: 72s - loss: 1.5981 - acc: 0.8020[[   1   69    7 ...,    0    0    0]\n",
      " [ 108   68  410 ...,    0    0    0]\n",
      " [  15    7   48 ...,    0    0    0]\n",
      " ..., \n",
      " [  13  104   21 ...,    0    0    0]\n",
      " [  12  393   13 ...,    0    0    0]\n",
      " [2113    9   39 ...,    0    0    0]]\n",
      " 40/200 [=====>........................] - ETA: 72s - loss: 1.6005 - acc: 0.8018[[   1   13    5 ...,    0    0    0]\n",
      " [ 483    1  474 ...,    0    0    0]\n",
      " [ 104   13   97 ...,    0    0    0]\n",
      " ..., \n",
      " [1360 3930   11 ...,    0    0    0]\n",
      " [  43  383  244 ...,    0    0    0]\n",
      " [  15  530    3 ...,    0    0    0]]\n",
      " 41/200 [=====>........................] - ETA: 71s - loss: 1.5985 - acc: 0.8021[[  301  3343 11699 ...,     0     0     0]\n",
      " [ 9173  7862    81 ...,     0     0     0]\n",
      " [   13    13  5463 ...,     0     0     0]\n",
      " ..., \n",
      " [    4     2  1307 ...,     0     0     0]\n",
      " [   13 11062     1 ...,     0     0     0]\n",
      " [   13    13   385 ...,     0     0     0]]\n",
      " 42/200 [=====>........................] - ETA: 71s - loss: 1.6030 - acc: 0.8017[[  962   450   283 ...,     0     0     0]\n",
      " [    1   659 10774 ...,     0     0     0]\n",
      " [    2  1045   910 ...,     0     0     0]\n",
      " ..., \n",
      " [    5   738    13 ...,     0     0     0]\n",
      " [    1    13    13 ...,     0     0     0]\n",
      " [ 3056   355  1433 ...,     0     0     0]]\n",
      " 43/200 [=====>........................] - ETA: 71s - loss: 1.6007 - acc: 0.8020[[    1  1876    81 ...,     0     0     0]\n",
      " [   13    13    13 ...,     0     0     0]\n",
      " [   13  7673  2325 ...,     0     0     0]\n",
      " ..., \n",
      " [   13     1    13 ...,     0     0     0]\n",
      " [    1    13  5660 ...,     0     0     0]\n",
      " [ 4094    13 10706 ...,     0     0     0]]\n",
      " 44/200 [=====>........................] - ETA: 70s - loss: 1.5973 - acc: 0.8025[[   13    13     4 ...,     0     0     0]\n",
      " [   41   264  1023 ...,     0     0     0]\n",
      " [ 1092    13   264 ...,     0     0     0]\n",
      " ..., \n",
      " [ 1038  5235    10 ...,     0     0     0]\n",
      " [    1  1124    27 ...,     0     0     0]\n",
      " [11578  7361     4 ...,     0     0     0]]\n",
      " 45/200 [=====>........................] - ETA: 70s - loss: 1.5987 - acc: 0.8025[[  58   59  154 ...,    0    0    0]\n",
      " [1056 1719  267 ...,    0    0    0]\n",
      " [  13   69 2399 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [   2   13  405 ...,    0    0    0]]\n",
      " 46/200 [=====>........................] - ETA: 69s - loss: 1.5979 - acc: 0.8026[[ 109   26  106 ...,    0    0    0]\n",
      " [   1 1202    5 ...,    0    0    0]\n",
      " [   1 1276 3182 ...,    0    0    0]\n",
      " ..., \n",
      " [2990  674  308 ...,    0    0    0]\n",
      " [ 491   26  113 ...,    0    0    0]\n",
      " [ 152  139  106 ...,    0    0    0]]\n",
      " 47/200 [======>.......................] - ETA: 69s - loss: 1.5979 - acc: 0.8025[[ 1189   224     7 ...,     0     0     0]\n",
      " [    1    13    91 ...,     0     0     0]\n",
      " [ 2574    30    36 ...,     0     0     0]\n",
      " ..., \n",
      " [    1   551    13 ...,     0     0     0]\n",
      " [   13   104   945 ...,     0     0     0]\n",
      " [  306    27 11880 ...,     0     0     0]]\n",
      " 48/200 [======>.......................] - ETA: 68s - loss: 1.5964 - acc: 0.8028[[   1   13   91 ...,    0    0    0]\n",
      " [   1  306  119 ...,    0    0    0]\n",
      " [   1   13   91 ...,    0    0    0]\n",
      " ..., \n",
      " [ 456  187 1924 ...,    0    0    0]\n",
      " [ 234  102   67 ...,    0    0    0]\n",
      " [ 456 4785   32 ...,    0    0    0]]\n",
      " 49/200 [======>.......................] - ETA: 68s - loss: 1.5970 - acc: 0.8027[[ 456  187 1924 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [   1 6434  384 ...,    0    0    0]\n",
      " ..., \n",
      " [1195 1916   11 ...,    0    0    0]\n",
      " [ 372   11  269 ...,    0    0    0]\n",
      " [ 318    8   92 ...,    0    0    0]]\n",
      " 50/200 [======>.......................] - ETA: 67s - loss: 1.5971 - acc: 0.8027[[ 342  196    4 ...,    0    0    0]\n",
      " [ 661   10    1 ...,    0    0    0]\n",
      " [ 342  196    4 ...,    0    0    0]\n",
      " ..., \n",
      " [ 390 3598   27 ...,    0    0    0]\n",
      " [  16 4647 1418 ...,    0    0    0]\n",
      " [ 171  108 1150 ...,    0    0    0]]\n",
      " 51/200 [======>.......................] - ETA: 67s - loss: 1.5974 - acc: 0.8027[[  109    26   115 ...,     0     0     0]\n",
      " [    1    19   120 ...,     0     0     0]\n",
      " [  203   295  1943 ...,     0     0     0]\n",
      " ..., \n",
      " [ 1961  3177    14 ...,     0     0     0]\n",
      " [    1  5396     4 ...,     0     0     0]\n",
      " [   13 11404    61 ...,     0     0     0]]\n",
      " 52/200 [======>.......................] - ETA: 67s - loss: 1.5988 - acc: 0.8026[[   2   13 7793 ...,    0    0    0]\n",
      " [2932   13   13 ...,    0    0    0]\n",
      " [   1  132  732 ...,    0    0    0]\n",
      " ..., \n",
      " [  70   15  392 ...,    0    0    0]\n",
      " [2350   11  631 ...,    0    0    0]\n",
      " [  60  110   11 ...,    0    0    0]]\n",
      " 53/200 [======>.......................] - ETA: 66s - loss: 1.5987 - acc: 0.8025[[10963  3063    83 ...,     0     0     0]\n",
      " [  987    83   318 ...,     0     0     0]\n",
      " [  193    14    13 ...,     0     0     0]\n",
      " ..., \n",
      " [   99   255    73 ...,     0     0     0]\n",
      " [    2    19   545 ...,     0     0     0]\n",
      " [  119     6    36 ...,     0     0     0]]\n",
      " 54/200 [=======>......................] - ETA: 66s - loss: 1.5985 - acc: 0.8027[[    1   339  1897 ...,     0     0     0]\n",
      " [   68   337     3 ...,     0     0     0]\n",
      " [   49    38    62 ...,     0     0     0]\n",
      " ..., \n",
      " [ 1397     1    13 ...,     0     0     0]\n",
      " [   13 11624     8 ...,     0     0     0]\n",
      " [   70  5936  6089 ...,     0     0     0]]\n",
      " 55/200 [=======>......................] - ETA: 65s - loss: 1.5970 - acc: 0.8028[[   1  785  283 ...,    0    0    0]\n",
      " [1170  159  390 ...,    0    0    0]\n",
      " [   1   13   91 ...,    0    0    0]\n",
      " ..., \n",
      " [  55    7  191 ...,    0    0    0]\n",
      " [  49 4490 7088 ...,    0    0    0]\n",
      " [   1   13  343 ...,    0    0    0]]\n",
      " 56/200 [=======>......................] - ETA: 65s - loss: 1.5910 - acc: 0.8033[[  69  418  335 ...,    0    0    0]\n",
      " [1961 8415   11 ...,    0    0    0]\n",
      " [5175  694  103 ...,    0    0    0]\n",
      " ..., \n",
      " [ 309 4632 5172 ...,    0    0    0]\n",
      " [3402 2029    7 ...,    0    0    0]\n",
      " [  13  816  276 ...,    0    0    0]]\n",
      " 57/200 [=======>......................] - ETA: 64s - loss: 1.5868 - acc: 0.8036[[  797 11533   186 ...,     0     0     0]\n",
      " [ 1801  2135   451 ...,     0     0     0]\n",
      " [ 2406    13   903 ...,     0     0     0]\n",
      " ..., \n",
      " [ 1050    13   647 ...,     0     0     0]\n",
      " [  866  4106    21 ...,     0     0     0]\n",
      " [   70     1  9107 ...,     0     0     0]]\n",
      " 58/200 [=======>......................] - ETA: 64s - loss: 1.5807 - acc: 0.8041[[6389 2097  694 ...,    0    0    0]\n",
      " [   1   13   13 ...,    0    0    0]\n",
      " [ 363 3764 1205 ...,    0    0    0]\n",
      " ..., \n",
      " [2015   11 2025 ...,    0    0    0]\n",
      " [  13   26   23 ...,    0    0    0]\n",
      " [ 761  621   13 ...,    0    0    0]]\n",
      " 59/200 [=======>......................] - ETA: 64s - loss: 1.5762 - acc: 0.8045[[  13   13  807 ...,    0    0    0]\n",
      " [ 491  187  182 ...,    0    0    0]\n",
      " [ 365    7   13 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  883 2440 ...,    0    0    0]\n",
      " [  13 1248 1710 ...,    0    0    0]\n",
      " [2613  141   39 ...,    0    0    0]]\n",
      " 60/200 [========>.....................] - ETA: 63s - loss: 1.5726 - acc: 0.8048[[  16   13    5 ...,    0    0    0]\n",
      " [5945 2617  168 ...,    0    0    0]\n",
      " [  49  177  144 ...,    0    0    0]\n",
      " ..., \n",
      " [5517 2123 6731 ...,    0    0    0]\n",
      " [   1  221  230 ...,    0    0    0]\n",
      " [ 140  553  697 ...,    0    0    0]]\n",
      " 61/200 [========>.....................] - ETA: 63s - loss: 1.5711 - acc: 0.8049[[5490    5    1 ...,    0    0    0]\n",
      " [  13   13   13 ...,    0    0    0]\n",
      " [  89    7   80 ...,    0    0    0]\n",
      " ..., \n",
      " [  93   23    1 ...,    0    0    0]\n",
      " [  12   13  161 ...,    0    0    0]\n",
      " [1770    5   13 ...,    0    0    0]]\n",
      " 62/200 [========>.....................] - ETA: 62s - loss: 1.5702 - acc: 0.8050[[  70   68  377 ...,    0    0    0]\n",
      " [   1 1556 6068 ...,    0    0    0]\n",
      " [ 194 1156  853 ...,    0    0    0]\n",
      " ..., \n",
      " [ 137    9   15 ...,    0    0    0]\n",
      " [  13   13   44 ...,    0    0    0]\n",
      " [3711  210   13 ...,    0    0    0]]\n",
      " 63/200 [========>.....................] - ETA: 62s - loss: 1.5718 - acc: 0.8048[[ 137    7   19 ...,    0    0    0]\n",
      " [   1  214   23 ...,    0    0    0]\n",
      " [ 599 2846 1433 ...,    0    0    0]\n",
      " ..., \n",
      " [1150 1900    9 ...,    0    0    0]\n",
      " [  15   11   45 ...,    0    0    0]\n",
      " [ 245 1192    8 ...,    0    0    0]]\n",
      " 64/200 [========>.....................] - ETA: 61s - loss: 1.5732 - acc: 0.8047[[  13   13    4 ...,    0    0    0]\n",
      " [1742    7 2878 ...,    0    0    0]\n",
      " [  13   13  141 ...,    0    0    0]\n",
      " ..., \n",
      " [ 644  435 5264 ...,    0    0    0]\n",
      " [   2   13  146 ...,    0    0    0]\n",
      " [   1 6418   13 ...,    0    0    0]]\n",
      " 65/200 [========>.....................] - ETA: 61s - loss: 1.5740 - acc: 0.8046[[ 630  164   13 ...,    0    0    0]\n",
      " [   4   60 9835 ...,    0    0    0]\n",
      " [ 103 1075  779 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 1274    5 ...,    0    0    0]\n",
      " [  89   23  693 ...,    0    0    0]\n",
      " [   4    2   37 ...,    0    0    0]]\n",
      " 66/200 [========>.....................] - ETA: 60s - loss: 1.5731 - acc: 0.8047[[  13   13   86 ...,    0    0    0]\n",
      " [3550    9  254 ...,    0    0    0]\n",
      " [ 605 2648   23 ...,    0    0    0]\n",
      " ..., \n",
      " [6382 6947   30 ...,    0    0    0]\n",
      " [  13  418  335 ...,    0    0    0]\n",
      " [  13 4125 5709 ...,    0    0    0]]\n",
      " 67/200 [=========>....................] - ETA: 60s - loss: 1.5771 - acc: 0.8043[[   1 1927    5 ...,    0    0    0]\n",
      " [  13   13   67 ...,    0    0    0]\n",
      " [  29 5307   13 ...,    0    0    0]\n",
      " ..., \n",
      " [6482 6781   13 ...,    0    0    0]\n",
      " [2139  210 3422 ...,    0    0    0]\n",
      " [   1 7826  218 ...,    0    0    0]]\n",
      " 68/200 [=========>....................] - ETA: 59s - loss: 1.5793 - acc: 0.8041[[ 171    4  318 ...,    0    0    0]\n",
      " [   4   22 4218 ...,    0    0    0]\n",
      " [  89    7  439 ...,    0    0    0]\n",
      " ..., \n",
      " [ 486  537   57 ...,    0    0    0]\n",
      " [  13   13   51 ...,    0    0    0]\n",
      " [4511 4278   41 ...,    0    0    0]]\n",
      " 69/200 [=========>....................] - ETA: 59s - loss: 1.5845 - acc: 0.8035[[  42   11   45 ...,    0    0    0]\n",
      " [ 586    9  939 ...,    0    0    0]\n",
      " [ 751   13  171 ...,    0    0    0]\n",
      " ..., \n",
      " [   2 9906 1477 ...,    0    0    0]\n",
      " [  13  104 1619 ...,    0    0    0]\n",
      " [   1   19  120 ...,    0    0    0]]\n",
      " 70/200 [=========>....................] - ETA: 58s - loss: 1.5832 - acc: 0.8037[[ 1546  4893    81 ...,     0     0     0]\n",
      " [  443   900    11 ...,     0     0     0]\n",
      " [   22  1241     9 ...,     0     0     0]\n",
      " ..., \n",
      " [    1  1238 11900 ...,     0     0     0]\n",
      " [ 1675  1415    11 ...,     0     0     0]\n",
      " [   13    13   292 ...,     0     0     0]]\n",
      " 71/200 [=========>....................] - ETA: 58s - loss: 1.5857 - acc: 0.8035[[  49   63  144 ...,    0    0    0]\n",
      " [   1  751 2224 ...,    0    0    0]\n",
      " [ 173  831   32 ...,    0    0    0]\n",
      " ..., \n",
      " [  13  321  285 ...,    0    0    0]\n",
      " [  34  400   77 ...,    0    0    0]\n",
      " [   2 7121    3 ...,    0    0    0]]\n",
      " 72/200 [=========>....................] - ETA: 58s - loss: 1.5873 - acc: 0.8034[[   1  156   61 ...,    0    0    0]\n",
      " [  64   82   13 ...,    0    0    0]\n",
      " [  15    7   45 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 7812    5 ...,    0    0    0]\n",
      " [ 535   13   34 ...,    0    0    0]\n",
      " [   1  541   10 ...,    0    0    0]]\n",
      " 73/200 [=========>....................] - ETA: 57s - loss: 1.5858 - acc: 0.8036[[3798  160  265 ...,    0    0    0]\n",
      " [  43   99 3083 ...,    0    0    0]\n",
      " [  22   13  736 ...,    0    0    0]\n",
      " ..., \n",
      " [1164   13    1 ...,    0    0    0]\n",
      " [  92 1800   67 ...,    0    0    0]\n",
      " [   1 4878    4 ...,    0    0    0]]\n",
      " 74/200 [==========>...................] - ETA: 57s - loss: 1.5847 - acc: 0.8038[[   17   431 11930 ...,     0     0     0]\n",
      " [ 1019  3939   103 ...,     0     0     0]\n",
      " [ 1164     1    13 ...,     0     0     0]\n",
      " ..., \n",
      " [  367    27   269 ...,     0     0     0]\n",
      " [  219    26   441 ...,     0     0     0]\n",
      " [ 1905   809  7684 ...,     0     0     0]]\n",
      " 75/200 [==========>...................] - ETA: 56s - loss: 1.5852 - acc: 0.8038[[   1 2105  941 ...,    0    0    0]\n",
      " [1324 4909   69 ...,    0    0    0]\n",
      " [   2  397 5043 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   69  297 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [6741 2232   23 ...,    0    0    0]]\n",
      " 76/200 [==========>...................] - ETA: 56s - loss: 1.5850 - acc: 0.8039[[ 214   23    1 ...,    0    0    0]\n",
      " [  13  301  155 ...,    0    0    0]\n",
      " [ 373  423   55 ...,    0    0    0]\n",
      " ..., \n",
      " [1005    9 7106 ...,    0    0    0]\n",
      " [5992   69 3226 ...,    0    0    0]\n",
      " [ 373  423   55 ...,    0    0    0]]\n",
      " 77/200 [==========>...................] - ETA: 55s - loss: 1.5839 - acc: 0.8041[[5937 1321 5794 ...,    0    0    0]\n",
      " [   1   13 3967 ...,    0    0    0]\n",
      " [  49  919 7088 ...,    0    0    0]\n",
      " ..., \n",
      " [1137 3695    4 ...,    0    0    0]\n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [   1   13   91 ...,    0    0    0]]\n",
      " 78/200 [==========>...................] - ETA: 55s - loss: 1.5833 - acc: 0.8042[[  89   14   39 ...,    0    0    0]\n",
      " [ 481   66 1215 ...,    0    0    0]\n",
      " [   1  868   26 ...,    0    0    0]\n",
      " ..., \n",
      " [ 179  946  677 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [3491  680   13 ...,    0    0    0]]\n",
      " 79/200 [==========>...................] - ETA: 54s - loss: 1.5844 - acc: 0.8041[[ 108   68   23 ...,    0    0    0]\n",
      " [   2   19  417 ...,    0    0    0]\n",
      " [  55    7 2921 ...,    0    0    0]\n",
      " ..., \n",
      " [ 456  187  687 ...,    0    0    0]\n",
      " [ 241    7 8494 ...,    0    0    0]\n",
      " [  13 4086 3289 ...,    0    0    0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80/200 [===========>..................] - ETA: 54s - loss: 1.5850 - acc: 0.8040[[  47   15   14 ...,    0    0    0]\n",
      " [2012    5  142 ...,    0    0    0]\n",
      " [4418   11 2389 ...,    0    0    0]\n",
      " ..., \n",
      " [1449 1148   13 ...,    0    0    0]\n",
      " [   1 3494  161 ...,    0    0    0]\n",
      " [  13 2654    4 ...,    0    0    0]]\n",
      " 81/200 [===========>..................] - ETA: 54s - loss: 1.5851 - acc: 0.8040[[  64   82  107 ...,    0    0    0]\n",
      " [ 276  178   13 ...,    0    0    0]\n",
      " [ 488    8    1 ...,    0    0    0]\n",
      " ..., \n",
      " [  34   61   98 ...,    0    0    0]\n",
      " [2022 2923  205 ...,    0    0    0]\n",
      " [ 109   26   65 ...,    0    0    0]]\n",
      " 82/200 [===========>..................] - ETA: 53s - loss: 1.5848 - acc: 0.8041[[   1   91   14 ...,    0    0    0]\n",
      " [ 325  829  662 ...,    0    0    0]\n",
      " [   3  356  767 ...,    0    0    0]\n",
      " ..., \n",
      " [ 390 3686    9 ...,    0    0    0]\n",
      " [ 226   13  284 ...,    0    0    0]\n",
      " [   1 1228  808 ...,    0    0    0]]\n",
      " 83/200 [===========>..................] - ETA: 53s - loss: 1.5849 - acc: 0.8041[[ 749   12    2 ...,    0    0    0]\n",
      " [   1   13 1666 ...,    0    0    0]\n",
      " [1536   13  385 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   13   13 ...,    0    0    0]\n",
      " [ 500  455    3 ...,    0    0    0]\n",
      " [  13 3939 4822 ...,    0    0    0]]\n",
      " 84/200 [===========>..................] - ETA: 52s - loss: 1.5848 - acc: 0.8041[[  647    13   462 ...,     0     0     0]\n",
      " [    1  1343    76 ...,     0     0     0]\n",
      " [   13  9175    14 ...,     0     0     0]\n",
      " ..., \n",
      " [ 5592 10575     5 ...,     0     0     0]\n",
      " [  241    13    18 ...,     0     0     0]\n",
      " [  967  1533     3 ...,     0     0     0]]\n",
      " 85/200 [===========>..................] - ETA: 52s - loss: 1.5832 - acc: 0.8043[[2455  424 1301 ...,    0    0    0]\n",
      " [ 380    7   13 ...,    0    0    0]\n",
      " [   1   38   62 ...,    0    0    0]\n",
      " ..., \n",
      " [ 316  583 1628 ...,    0    0    0]\n",
      " [ 304 3255 1010 ...,    0    0    0]\n",
      " [ 149  186   10 ...,    0    0    0]]\n",
      " 86/200 [===========>..................] - ETA: 51s - loss: 1.5802 - acc: 0.8046[[  795    13   363 ...,     0     0     0]\n",
      " [    1  1693  3716 ...,     0     0     0]\n",
      " [   13    13    13 ...,     0     0     0]\n",
      " ..., \n",
      " [ 3696    13  4556 ...,     0     0     0]\n",
      " [ 9945    13    86 ...,     0     0     0]\n",
      " [    1  1208 11348 ...,     0     0     0]]\n",
      " 87/200 [============>.................] - ETA: 51s - loss: 1.5766 - acc: 0.8048[[3292   13    5 ...,    0    0    0]\n",
      " [   2 8614 1737 ...,    0    0    0]\n",
      " [2939   13   14 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   13    7 ...,    0    0    0]\n",
      " [   4    1  145 ...,    0    0    0]\n",
      " [5850   13  128 ...,    0    0    0]]\n",
      " 88/200 [============>.................] - ETA: 50s - loss: 1.5733 - acc: 0.8051[[    2    13   146 ...,     0     0     0]\n",
      " [ 2525  5419 11672 ...,     0     0     0]\n",
      " [  491  2381    13 ...,     0     0     0]\n",
      " ..., \n",
      " [   49    13   851 ...,     0     0     0]\n",
      " [ 4385    13    14 ...,     0     0     0]\n",
      " [ 3791  1634   761 ...,     0     0     0]]\n",
      " 89/200 [============>.................] - ETA: 50s - loss: 1.5706 - acc: 0.8053[[ 2002  4124     9 ...,     0     0     0]\n",
      " [  280  1987     7 ...,     0     0     0]\n",
      " [ 4404    27 11508 ...,     0     0     0]\n",
      " ..., \n",
      " [ 2883  5521  4566 ...,     0     0     0]\n",
      " [  226     7   212 ...,     0     0     0]\n",
      " [   10   430    13 ...,     0     0     0]]\n",
      " 90/200 [============>.................] - ETA: 50s - loss: 1.5675 - acc: 0.8055[[ 131  491  522 ...,    0    0    0]\n",
      " [1862   30   24 ...,    0    0    0]\n",
      " [ 749   80  678 ...,    0    0    0]\n",
      " ..., \n",
      " [ 433  471   39 ...,    0    0    0]\n",
      " [ 345 3419 1044 ...,    0    0    0]\n",
      " [1550 1366    7 ...,    0    0    0]]\n",
      " 91/200 [============>.................] - ETA: 49s - loss: 1.5656 - acc: 0.8058[[5746 6464  253 ...,    0    0    0]\n",
      " [   4  444   13 ...,    0    0    0]\n",
      " [ 425   27  174 ...,    0    0    0]\n",
      " ..., \n",
      " [5814   13   14 ...,    0    0    0]\n",
      " [2642 2297   40 ...,    0    0    0]\n",
      " [   2  146 1129 ...,    0    0    0]]\n",
      " 92/200 [============>.................] - ETA: 49s - loss: 1.5653 - acc: 0.8058[[   1 5049 9636 ...,    0    0    0]\n",
      " [  55 1574    6 ...,    0    0    0]\n",
      " [2700    8 1429 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  429 1887 ...,    0    0    0]\n",
      " [   1 1245 1136 ...,    0    0    0]\n",
      " [   1   49   19 ...,    0    0    0]]\n",
      " 93/200 [============>.................] - ETA: 48s - loss: 1.5660 - acc: 0.8057[[ 108   68   67 ...,    0    0    0]\n",
      " [ 930   13  415 ...,    0    0    0]\n",
      " [ 621 1404 1184 ...,    0    0    0]\n",
      " ..., \n",
      " [   2  153 3973 ...,    0    0    0]\n",
      " [  80   41   14 ...,    0    0    0]\n",
      " [1761   23   13 ...,    0    0    0]]\n",
      " 94/200 [=============>................] - ETA: 48s - loss: 1.5674 - acc: 0.8055[[ 149   53    7 ...,    0    0    0]\n",
      " [  18 1167  513 ...,    0    0    0]\n",
      " [ 337    3  338 ...,    0    0    0]\n",
      " ..., \n",
      " [  15    7    1 ...,    0    0    0]\n",
      " [  72  155    1 ...,    0    0    0]\n",
      " [   3 2748    1 ...,    0    0    0]]\n",
      " 95/200 [=============>................] - ETA: 47s - loss: 1.5685 - acc: 0.8054[[ 105    9  385 ...,    0    0    0]\n",
      " [   6    1   13 ...,    0    0    0]\n",
      " [1696 7717   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 626   13   13 ...,    0    0    0]\n",
      " [2459 7832 1904 ...,    0    0    0]\n",
      " [  15  530    3 ...,    0    0    0]]\n",
      " 96/200 [=============>................] - ETA: 47s - loss: 1.5696 - acc: 0.8053[[ 416 2716    8 ...,    0    0    0]\n",
      " [ 245 1192    8 ...,    0    0    0]\n",
      " [ 137   13    1 ...,    0    0    0]\n",
      " ..., \n",
      " [ 317   34  525 ...,    0    0    0]\n",
      " [   1  181  170 ...,    0    0    0]\n",
      " [ 618   13    5 ...,    0    0    0]]\n",
      " 97/200 [=============>................] - ETA: 46s - loss: 1.5694 - acc: 0.8053[[  13 1163   12 ...,    0    0    0]\n",
      " [ 582 1211   10 ...,    0    0    0]\n",
      " [1063 6802 3370 ...,    0    0    0]\n",
      " ..., \n",
      " [ 137    7    4 ...,    0    0    0]\n",
      " [  10   63   13 ...,    0    0    0]\n",
      " [ 644   13  521 ...,    0    0    0]]\n",
      " 98/200 [=============>................] - ETA: 46s - loss: 1.5726 - acc: 0.8050[[  13 9256    7 ...,    0    0    0]\n",
      " [6629   13   30 ...,    0    0    0]\n",
      " [  60 2510    5 ...,    0    0    0]\n",
      " ..., \n",
      " [  18   68  265 ...,    0    0    0]\n",
      " [  56   13   63 ...,    0    0    0]\n",
      " [1952 1630   13 ...,    0    0    0]]\n",
      " 99/200 [=============>................] - ETA: 46s - loss: 1.5738 - acc: 0.8048[[ 535   41   37 ...,    0    0    0]\n",
      " [  93 1671   32 ...,    0    0    0]\n",
      " [  19  120    1 ...,    0    0    0]\n",
      " ..., \n",
      " [7200   13   11 ...,    0    0    0]\n",
      " [  10    2  146 ...,    0    0    0]\n",
      " [1246   13  816 ...,    0    0    0]]\n",
      "100/200 [==============>...............] - ETA: 45s - loss: 1.5775 - acc: 0.8044[[ 3470    13   626 ...,     0     0     0]\n",
      " [ 9663 10549    11 ...,     0     0     0]\n",
      " [ 6526    13   898 ...,     0     0     0]\n",
      " ..., \n",
      " [  250    98     1 ...,     0     0     0]\n",
      " [  947    13   684 ...,     0     0     0]\n",
      " [ 3362   105    21 ...,     0     0     0]]\n",
      "101/200 [==============>...............] - ETA: 45s - loss: 1.5775 - acc: 0.8044[[2697   50  105 ...,    0    0    0]\n",
      " [1344 3402 6866 ...,    0    0    0]\n",
      " [  10  276   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 202    1  463 ...,    0    0    0]\n",
      " [  15   27 1087 ...,    0    0    0]\n",
      " [  13  390 1415 ...,    0    0    0]]\n",
      "102/200 [==============>...............] - ETA: 44s - loss: 1.5784 - acc: 0.8043[[  260    13     7 ...,     0     0     0]\n",
      " [11288  2473  8019 ...,     0     0     0]\n",
      " [ 1524     2    74 ...,     0     0     0]\n",
      " ..., \n",
      " [ 2765    23   207 ...,     0     0     0]\n",
      " [  438    13  1232 ...,     0     0     0]\n",
      " [    1  2131    23 ...,     0     0     0]]\n",
      "103/200 [==============>...............] - ETA: 44s - loss: 1.5795 - acc: 0.8043[[  344     7    73 ...,     0     0     0]\n",
      " [  194 10634    34 ...,     0     0     0]\n",
      " [    1    78   177 ...,     0     0     0]\n",
      " ..., \n",
      " [   13  3645  3446 ...,     0     0     0]\n",
      " [    1    13  1442 ...,     0     0     0]\n",
      " [   15    11    45 ...,     0     0     0]]\n",
      "104/200 [==============>...............] - ETA: 43s - loss: 1.5785 - acc: 0.8044[[1153    1   13 ...,    0    0    0]\n",
      " [ 149   13  333 ...,    0    0    0]\n",
      " [ 233  358  222 ...,    0    0    0]\n",
      " ..., \n",
      " [ 341   13    6 ...,    0    0    0]\n",
      " [  70    1  611 ...,    0    0    0]\n",
      " [6586 6960    9 ...,    0    0    0]]\n",
      "105/200 [==============>...............] - ETA: 43s - loss: 1.5777 - acc: 0.8046[[  80  678    9 ...,    0    0    0]\n",
      " [ 746  117 4585 ...,    0    0    0]\n",
      " [   1  685  135 ...,    0    0    0]\n",
      " ..., \n",
      " [ 491   26  113 ...,    0    0    0]\n",
      " [ 579   11 1749 ...,    0    0    0]\n",
      " [   2  179 2444 ...,    0    0    0]]\n",
      "106/200 [==============>...............] - ETA: 42s - loss: 1.5782 - acc: 0.8046[[ 154   66    6 ...,    0    0    0]\n",
      " [  55    7 1937 ...,    0    0    0]\n",
      " [   2 1413 1260 ...,    0    0    0]\n",
      " ..., \n",
      " [1472    7   13 ...,    0    0    0]\n",
      " [   1   47  287 ...,    0    0    0]\n",
      " [   1 9181  199 ...,    0    0    0]]\n",
      "107/200 [===============>..............] - ETA: 42s - loss: 1.5776 - acc: 0.8047[[ 496   27 1663 ...,    0    0    0]\n",
      " [3491  389  209 ...,    0    0    0]\n",
      " [   1  931    5 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13  169 ...,    0    0    0]\n",
      " [ 496  217   55 ...,    0    0    0]\n",
      " [2562   26  113 ...,    0    0    0]]\n",
      "108/200 [===============>..............] - ETA: 41s - loss: 1.5773 - acc: 0.8048[[ 373  423   55 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " ..., \n",
      " [ 496  941 3279 ...,    0    0    0]\n",
      " [   1   13   10 ...,    0    0    0]\n",
      " [   2  845  282 ...,    0    0    0]]\n",
      "109/200 [===============>..............] - ETA: 41s - loss: 1.5778 - acc: 0.8047[[  456  1494   692 ...,     0     0     0]\n",
      " [    1    13    91 ...,     0     0     0]\n",
      " [ 1382  1963   231 ...,     0     0     0]\n",
      " ..., \n",
      " [    1 11353   191 ...,     0     0     0]\n",
      " [    1    47  3229 ...,     0     0     0]\n",
      " [  248  2193   209 ...,     0     0     0]]\n",
      "110/200 [===============>..............] - ETA: 41s - loss: 1.5775 - acc: 0.8048[[  58   59   26 ...,    0    0    0]\n",
      " [   1  156   55 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " ..., \n",
      " [1454    7   13 ...,    0    0    0]\n",
      " [ 503  960    3 ...,    0    0    0]\n",
      " [ 248  800 1733 ...,    0    0    0]]\n",
      "111/200 [===============>..............] - ETA: 40s - loss: 1.5779 - acc: 0.8048[[ 5687     9    39 ...,     0     0     0]\n",
      " [    1  2182   191 ...,     0     0     0]\n",
      " [  127   102   112 ...,     0     0     0]\n",
      " ..., \n",
      " [   15    14    13 ...,     0     0     0]\n",
      " [10926    11   130 ...,     0     0     0]\n",
      " [    1  4595     5 ...,     0     0     0]]\n",
      "112/200 [===============>..............] - ETA: 40s - loss: 1.5785 - acc: 0.8047[[3236 2644   11 ...,    0    0    0]\n",
      " [  10    1   19 ...,    0    0    0]\n",
      " [   1   19   37 ...,    0    0    0]\n",
      " ..., \n",
      " [ 746  117 2526 ...,    0    0    0]\n",
      " [1268 4298  265 ...,    0    0    0]\n",
      " [2082 2177   23 ...,    0    0    0]]\n",
      "113/200 [===============>..............] - ETA: 39s - loss: 1.5789 - acc: 0.8047[[  13   13   13 ...,    0    0    0]\n",
      " [2797 4842 2347 ...,    0    0    0]\n",
      " [   2 1809  405 ...,    0    0    0]\n",
      " ..., \n",
      " [ 606    7  232 ...,    0    0    0]\n",
      " [  89   27   20 ...,    0    0    0]\n",
      " [ 546  276  178 ...,    0    0    0]]\n",
      "114/200 [================>.............] - ETA: 39s - loss: 1.5789 - acc: 0.8047[[   1   13   91 ...,    0    0    0]\n",
      " [  15   14    1 ...,    0    0    0]\n",
      " [ 353   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [8129    7 3248 ...,    0    0    0]\n",
      " [ 353    8  603 ...,    0    0    0]\n",
      " [ 532    5  131 ...,    0    0    0]]\n",
      "115/200 [================>.............] - ETA: 38s - loss: 1.5787 - acc: 0.8048[[ 267  157    2 ...,    0    0    0]\n",
      " [3295    7   19 ...,    0    0    0]\n",
      " [  58   59    7 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 2248   63 ...,    0    0    0]\n",
      " [ 119  172    2 ...,    0    0    0]\n",
      " [   4    1 3064 ...,    0    0    0]]\n",
      "116/200 [================>.............] - ETA: 38s - loss: 1.5777 - acc: 0.8048[[ 868   13   13 ...,    0    0    0]\n",
      " [  13  119  157 ...,    0    0    0]\n",
      " [ 119   21 2208 ...,    0    0    0]\n",
      " ..., \n",
      " [  43  194 6631 ...,    0    0    0]\n",
      " [ 591 6515 3079 ...,    0    0    0]\n",
      " [ 280 1987    7 ...,    0    0    0]]\n",
      "117/200 [================>.............] - ETA: 37s - loss: 1.5747 - acc: 0.8051[[1742   11 3959 ...,    0    0    0]\n",
      " [   1  199 7911 ...,    0    0    0]\n",
      " [3989  604   13 ...,    0    0    0]\n",
      " ..., \n",
      " [2735 5332   83 ...,    0    0    0]\n",
      " [  13   11 1793 ...,    0    0    0]\n",
      " [4022 7272    8 ...,    0    0    0]]\n",
      "118/200 [================>.............] - ETA: 37s - loss: 1.5720 - acc: 0.8054[[   92   456   851 ...,     0     0     0]\n",
      " [11092  8523    11 ...,     0     0     0]\n",
      " [    1  2999    91 ...,     0     0     0]\n",
      " ..., \n",
      " [   16     1   602 ...,     0     0     0]\n",
      " [ 2525  5419  2506 ...,     0     0     0]\n",
      " [ 1653  4875  1136 ...,     0     0     0]]\n",
      "119/200 [================>.............] - ETA: 36s - loss: 1.5694 - acc: 0.8056[[   1  427 1856 ...,    0    0    0]\n",
      " [ 626 3961 3254 ...,    0    0    0]\n",
      " [   2 2024 2067 ...,    0    0    0]\n",
      " ..., \n",
      " [   2  485 3233 ...,    0    0    0]\n",
      " [ 226    7   13 ...,    0    0    0]\n",
      " [   2  440  405 ...,    0    0    0]]\n",
      "120/200 [=================>............] - ETA: 36s - loss: 1.5674 - acc: 0.8057[[   1 2503   56 ...,    0    0    0]\n",
      " [   1 2266  793 ...,    0    0    0]\n",
      " [  22 1423    4 ...,    0    0    0]\n",
      " ..., \n",
      " [2490  103   13 ...,    0    0    0]\n",
      " [  13 1804  128 ...,    0    0    0]\n",
      " [ 623  157    2 ...,    0    0    0]]\n",
      "121/200 [=================>............] - ETA: 36s - loss: 1.5662 - acc: 0.8058[[ 807 1855 4922 ...,    0    0    0]\n",
      " [ 654  145  103 ...,    0    0    0]\n",
      " [   1  785    9 ...,    0    0    0]\n",
      " ..., \n",
      " [2323 2339   13 ...,    0    0    0]\n",
      " [2698    7   13 ...,    0    0    0]\n",
      " [ 979   66  664 ...,    0    0    0]]\n",
      "122/200 [=================>............] - ETA: 35s - loss: 1.5647 - acc: 0.8059[[  109    26   106 ...,     0     0     0]\n",
      " [ 1500  7999   521 ...,     0     0     0]\n",
      " [    2    13   806 ...,     0     0     0]\n",
      " ..., \n",
      " [ 3022  6500   163 ...,     0     0     0]\n",
      " [    1 11634   245 ...,     0     0     0]\n",
      " [ 3909    69  2775 ...,     0     0     0]]\n",
      "123/200 [=================>............] - ETA: 35s - loss: 1.5645 - acc: 0.8059[[ 681 3499  887 ...,    0    0    0]\n",
      " [   2   13 2444 ...,    0    0    0]\n",
      " [  13   13   27 ...,    0    0    0]\n",
      " ..., \n",
      " [2033   90    2 ...,    0    0    0]\n",
      " [  15    9    2 ...,    0    0    0]\n",
      " [ 827 1400 1298 ...,    0    0    0]]\n",
      "124/200 [=================>............] - ETA: 34s - loss: 1.5658 - acc: 0.8058[[ 706 1296    5 ...,    0    0    0]\n",
      " [   1 9248    5 ...,    0    0    0]\n",
      " [ 531  163 1980 ...,    0    0    0]\n",
      " ..., \n",
      " [ 361 5218 1328 ...,    0    0    0]\n",
      " [  72   15    7 ...,    0    0    0]\n",
      " [  13   13   13 ...,    0    0    0]]\n",
      "125/200 [=================>............] - ETA: 34s - loss: 1.5669 - acc: 0.8057[[   4 1971    7 ...,    0    0    0]\n",
      " [ 630    7 1188 ...,    0    0    0]\n",
      " [ 264    9    2 ...,    0    0    0]\n",
      " ..., \n",
      " [ 137    2  417 ...,    0    0    0]\n",
      " [2434    7   74 ...,    0    0    0]\n",
      " [  57  125   13 ...,    0    0    0]]\n",
      "126/200 [=================>............] - ETA: 33s - loss: 1.5683 - acc: 0.8055[[   1 1130    9 ...,    0    0    0]\n",
      " [1433   76    1 ...,    0    0    0]\n",
      " [ 585 7398   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 630    7  512 ...,    0    0    0]\n",
      " [2481 2736   11 ...,    0    0    0]\n",
      " [   1 5535   13 ...,    0    0    0]]\n",
      "127/200 [==================>...........] - ETA: 33s - loss: 1.5696 - acc: 0.8054[[  15    7   45 ...,    0    0    0]\n",
      " [2861  103  887 ...,    0    0    0]\n",
      " [6448   13    7 ...,    0    0    0]\n",
      " ..., \n",
      " [ 234  290   96 ...,    0    0    0]\n",
      " [ 325  829   13 ...,    0    0    0]\n",
      " [ 879   13   30 ...,    0    0    0]]\n",
      "128/200 [==================>...........] - ETA: 32s - loss: 1.5693 - acc: 0.8054[[   10    63    13 ...,     0     0     0]\n",
      " [    1    13 11795 ...,     0     0     0]\n",
      " [    4    22  1829 ...,     0     0     0]\n",
      " ..., \n",
      " [  222  2013    21 ...,     0     0     0]\n",
      " [  233   670  3884 ...,     0     0     0]\n",
      " [   70    15   392 ...,     0     0     0]]\n",
      "129/200 [==================>...........] - ETA: 32s - loss: 1.5712 - acc: 0.8053[[  41  516    5 ...,    0    0    0]\n",
      " [  13   26  115 ...,    0    0    0]\n",
      " [4122 3172 2726 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  474  429 ...,    0    0    0]\n",
      " [  13  301  354 ...,    0    0    0]\n",
      " [   1  897 1175 ...,    0    0    0]]\n",
      "130/200 [==================>...........] - ETA: 31s - loss: 1.5722 - acc: 0.8051[[  18 1387    4 ...,    0    0    0]\n",
      " [7131   13    9 ...,    0    0    0]\n",
      " [ 108   89  320 ...,    0    0    0]\n",
      " ..., \n",
      " [3587   13  128 ...,    0    0    0]\n",
      " [  13 3861   14 ...,    0    0    0]\n",
      " [ 131 1003 2940 ...,    0    0    0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/200 [==================>...........] - ETA: 31s - loss: 1.5755 - acc: 0.8048[[   1 5576  467 ...,    0    0    0]\n",
      " [  13    3  809 ...,    0    0    0]\n",
      " [ 343 3183  384 ...,    0    0    0]\n",
      " ..., \n",
      " [  15    7  155 ...,    0    0    0]\n",
      " [   1   38   95 ...,    0    0    0]\n",
      " [ 228 3503  114 ...,    0    0    0]]\n",
      "132/200 [==================>...........] - ETA: 30s - loss: 1.5752 - acc: 0.8049[[ 108    1 6103 ...,    0    0    0]\n",
      " [5401   21  256 ...,    0    0    0]\n",
      " [   1 2393  294 ...,    0    0    0]\n",
      " ..., \n",
      " [ 242   38  271 ...,    0    0    0]\n",
      " [  13  695   14 ...,    0    0    0]\n",
      " [   4    1  274 ...,    0    0    0]]\n",
      "133/200 [==================>...........] - ETA: 30s - loss: 1.5759 - acc: 0.8048[[    6    33    13 ...,     0     0     0]\n",
      " [  234   290   144 ...,     0     0     0]\n",
      " [ 2270  1190    90 ...,     0     0     0]\n",
      " ..., \n",
      " [ 4686  8679 11273 ...,     0     0     0]\n",
      " [  108  1209  2508 ...,     0     0     0]\n",
      " [   34   400    77 ...,     0     0     0]]\n",
      "134/200 [===================>..........] - ETA: 30s - loss: 1.5773 - acc: 0.8047[[ 232  725  141 ...,    0    0    0]\n",
      " [ 276  178   13 ...,    0    0    0]\n",
      " [4359 4673  247 ...,    0    0    0]\n",
      " ..., \n",
      " [2792 1898   81 ...,    0    0    0]\n",
      " [6292   13    9 ...,    0    0    0]\n",
      " [  19  226    7 ...,    0    0    0]]\n",
      "135/200 [===================>..........] - ETA: 29s - loss: 1.5772 - acc: 0.8048[[1188    1 4704 ...,    0    0    0]\n",
      " [  13   15    7 ...,    0    0    0]\n",
      " [  93   67  190 ...,    0    0    0]\n",
      " ..., \n",
      " [ 406   13    1 ...,    0    0    0]\n",
      " [  68   21   41 ...,    0    0    0]\n",
      " [ 986 1865  105 ...,    0    0    0]]\n",
      "136/200 [===================>..........] - ETA: 29s - loss: 1.5761 - acc: 0.8049[[   2   37   32 ...,    0    0    0]\n",
      " [  22 2679   13 ...,    0    0    0]\n",
      " [2334    2 8471 ...,    0    0    0]\n",
      " ..., \n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]]\n",
      "137/200 [===================>..........] - ETA: 28s - loss: 1.5764 - acc: 0.8049[[4062   13    2 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [1434   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  868   91 ...,    0    0    0]\n",
      " [   1   19  274 ...,    0    0    0]\n",
      " [  55    7  655 ...,    0    0    0]]\n",
      "138/200 [===================>..........] - ETA: 28s - loss: 1.5763 - acc: 0.8049[[1357    8  797 ...,    0    0    0]\n",
      " [  18  194   18 ...,    0    0    0]\n",
      " [   1  220   91 ...,    0    0    0]\n",
      " ..., \n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [  55   11 4380 ...,    0    0    0]\n",
      " [  12  296   13 ...,    0    0    0]]\n",
      "139/200 [===================>..........] - ETA: 27s - loss: 1.5767 - acc: 0.8049[[2504 1870 3322 ...,    0    0    0]\n",
      " [ 140  609   73 ...,    0    0    0]\n",
      " [  13  808    5 ...,    0    0    0]\n",
      " ..., \n",
      " [  55    8  284 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [ 491   26  113 ...,    0    0    0]]\n",
      "140/200 [====================>.........] - ETA: 27s - loss: 1.5763 - acc: 0.8049[[ 481   66  115 ...,    0    0    0]\n",
      " [   1   13  140 ...,    0    0    0]\n",
      " [ 318    8  913 ...,    0    0    0]\n",
      " ..., \n",
      " [2157   27  487 ...,    0    0    0]\n",
      " [  54   13 2972 ...,    0    0    0]\n",
      " [3359   67  289 ...,    0    0    0]]\n",
      "141/200 [====================>.........] - ETA: 26s - loss: 1.5767 - acc: 0.8049[[  58   59   26 ...,    0    0    0]\n",
      " [ 167  187   65 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " ..., \n",
      " [  58   59    7 ...,    0    0    0]\n",
      " [  38  170 4160 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]]\n",
      "142/200 [====================>.........] - ETA: 26s - loss: 1.5767 - acc: 0.8049[[  58   59   26 ...,    0    0    0]\n",
      " [ 220   26   65 ...,    0    0    0]\n",
      " [  55    7   73 ...,    0    0    0]\n",
      " ..., \n",
      " [ 342  196    4 ...,    0    0    0]\n",
      " [ 342  196    4 ...,    0    0    0]\n",
      " [1757  154   66 ...,    0    0    0]]\n",
      "143/200 [====================>.........] - ETA: 25s - loss: 1.5768 - acc: 0.8049[[  1  78  13 ...,   0   0   0]\n",
      " [501   6  33 ...,   0   0   0]\n",
      " [ 38 825 433 ...,   0   0   0]\n",
      " ..., \n",
      " [501   6  24 ...,   0   0   0]\n",
      " [325 829 662 ...,   0   0   0]\n",
      " [824   6  28 ...,   0   0   0]]\n",
      "144/200 [====================>.........] - ETA: 25s - loss: 1.5770 - acc: 0.8049[[  70   15  392 ...,    0    0    0]\n",
      " [8464 2259   67 ...,    0    0    0]\n",
      " [   2 4067 2268 ...,    0    0    0]\n",
      " ..., \n",
      " [  99  255   73 ...,    0    0    0]\n",
      " [ 819   26   65 ...,    0    0    0]\n",
      " [  48  950    6 ...,    0    0    0]]\n",
      "145/200 [====================>.........] - ETA: 25s - loss: 1.5778 - acc: 0.8048[[1431  450   86 ...,    0    0    0]\n",
      " [  38   13   13 ...,    0    0    0]\n",
      " [   1  424   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 442  216   51 ...,    0    0    0]\n",
      " [ 159 1832   14 ...,    0    0    0]\n",
      " [  13  694  103 ...,    0    0    0]]\n",
      "146/200 [====================>.........] - ETA: 24s - loss: 1.5778 - acc: 0.8048[[   2 2444   14 ...,    0    0    0]\n",
      " [ 919   69 7067 ...,    0    0    0]\n",
      " [ 107   10 1555 ...,    0    0    0]\n",
      " ..., \n",
      " [ 433    7 2066 ...,    0    0    0]\n",
      " [1189  150   26 ...,    0    0    0]\n",
      " [1600   11  511 ...,    0    0    0]]\n",
      "147/200 [=====================>........] - ETA: 24s - loss: 1.5785 - acc: 0.8047[[   1   13   91 ...,    0    0    0]\n",
      " [ 422  755   11 ...,    0    0    0]\n",
      " [   2 2321 4020 ...,    0    0    0]\n",
      " ..., \n",
      " [2095  745 2520 ...,    0    0    0]\n",
      " [ 206   66  115 ...,    0    0    0]\n",
      " [3365 5674  850 ...,    0    0    0]]\n",
      "148/200 [=====================>........] - ETA: 23s - loss: 1.5762 - acc: 0.8049[[    1    13    91 ...,     0     0     0]\n",
      " [ 8738   139     7 ...,     0     0     0]\n",
      " [    1  2897   188 ...,     0     0     0]\n",
      " ..., \n",
      " [  644  8658     7 ...,     0     0     0]\n",
      " [   89    23    80 ...,     0     0     0]\n",
      " [11134  1064    13 ...,     0     0     0]]\n",
      "149/200 [=====================>........] - ETA: 23s - loss: 1.5735 - acc: 0.8052[[3833 2322   13 ...,    0    0    0]\n",
      " [ 284    7   13 ...,    0    0    0]\n",
      " [ 481  176  196 ...,    0    0    0]\n",
      " ..., \n",
      " [1701 4256 2968 ...,    0    0    0]\n",
      " [3313 1131   32 ...,    0    0    0]\n",
      " [  64   82  590 ...,    0    0    0]]\n",
      "150/200 [=====================>........] - ETA: 22s - loss: 1.5717 - acc: 0.8053[[1275  650  217 ...,    0    0    0]\n",
      " [ 986  721    5 ...,    0    0    0]\n",
      " [3318 9332  114 ...,    0    0    0]\n",
      " ..., \n",
      " [2555 2115  141 ...,    0    0    0]\n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [   2  146 1214 ...,    0    0    0]]\n",
      "151/200 [=====================>........] - ETA: 22s - loss: 1.5699 - acc: 0.8055[[ 119   21   13 ...,    0    0    0]\n",
      " [3135   13   13 ...,    0    0    0]\n",
      " [   1  221  230 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 1007  674 ...,    0    0    0]\n",
      " [3587 7061    7 ...,    0    0    0]\n",
      " [  15   14    2 ...,    0    0    0]]\n",
      "152/200 [=====================>........] - ETA: 21s - loss: 1.5682 - acc: 0.8056[[   2 1373   13 ...,    0    0    0]\n",
      " [ 154   66    4 ...,    0    0    0]\n",
      " [ 167    4   13 ...,    0    0    0]\n",
      " ..., \n",
      " [3689 3693    9 ...,    0    0    0]\n",
      " [4040  505   13 ...,    0    0    0]\n",
      " [  22 1738   13 ...,    0    0    0]]\n",
      "153/200 [=====================>........] - ETA: 21s - loss: 1.5663 - acc: 0.8057[[   2  221  230 ...,    0    0    0]\n",
      " [  19  344 1113 ...,    0    0    0]\n",
      " [2237 1642   13 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  132 2251 ...,    0    0    0]\n",
      " [  64 8144   82 ...,    0    0    0]\n",
      " [ 255  598   23 ...,    0    0    0]]\n",
      "154/200 [======================>.......] - ETA: 20s - loss: 1.5651 - acc: 0.8058[[  819    26   182 ...,     0     0     0]\n",
      " [ 1792    11  1048 ...,     0     0     0]\n",
      " [ 3054   130   131 ...,     0     0     0]\n",
      " ..., \n",
      " [ 1364 11506     9 ...,     0     0     0]\n",
      " [  413   558    11 ...,     0     0     0]\n",
      " [   34   188     7 ...,     0     0     0]]\n",
      "155/200 [======================>.......] - ETA: 20s - loss: 1.5659 - acc: 0.8057[[ 293    7 2445 ...,    0    0    0]\n",
      " [  18 2693   13 ...,    0    0    0]\n",
      " [3643 1207 2940 ...,    0    0    0]\n",
      " ..., \n",
      " [7456 9503   11 ...,    0    0    0]\n",
      " [ 280 1987  190 ...,    0    0    0]\n",
      " [8321 8845 8425 ...,    0    0    0]]\n",
      "156/200 [======================>.......] - ETA: 20s - loss: 1.5662 - acc: 0.8057[[    1    13   506 ...,     0     0     0]\n",
      " [  150  2173    13 ...,     0     0     0]\n",
      " [    2   538   123 ...,     0     0     0]\n",
      " ..., \n",
      " [ 1111   135   811 ...,     0     0     0]\n",
      " [  159  4081    81 ...,     0     0     0]\n",
      " [ 4482    13 11705 ...,     0     0     0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/200 [======================>.......] - ETA: 19s - loss: 1.5665 - acc: 0.8057[[ 873  374  289 ...,    0    0    0]\n",
      " [ 317   13   13 ...,    0    0    0]\n",
      " [2142  747 2705 ...,    0    0    0]\n",
      " ..., \n",
      " [  53    7  137 ...,    0    0    0]\n",
      " [   1   78  150 ...,    0    0    0]\n",
      " [ 633 1936   13 ...,    0    0    0]]\n",
      "158/200 [======================>.......] - ETA: 19s - loss: 1.5672 - acc: 0.8056[[   1 9492   38 ...,    0    0    0]\n",
      " [ 658    4   13 ...,    0    0    0]\n",
      " [  13   13   44 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 2039  361 ...,    0    0    0]\n",
      " [   1  459    7 ...,    0    0    0]\n",
      " [ 301   23  787 ...,    0    0    0]]\n",
      "159/200 [======================>.......] - ETA: 18s - loss: 1.5671 - acc: 0.8056[[  27 9816 3873 ...,    0    0    0]\n",
      " [ 865   13  301 ...,    0    0    0]\n",
      " [  10    2 3216 ...,    0    0    0]\n",
      " ..., \n",
      " [  10 2453 7036 ...,    0    0    0]\n",
      " [   4   40 4165 ...,    0    0    0]\n",
      " [  15    7   48 ...,    0    0    0]]\n",
      "160/200 [=======================>......] - ETA: 18s - loss: 1.5667 - acc: 0.8057[[ 184  810    1 ...,    0    0    0]\n",
      " [  13 1442   79 ...,    0    0    0]\n",
      " [1733   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 202    1 5659 ...,    0    0    0]\n",
      " [5691 1345    9 ...,    0    0    0]\n",
      " [   3 1428  116 ...,    0    0    0]]\n",
      "161/200 [=======================>......] - ETA: 17s - loss: 1.5686 - acc: 0.8055[[  943    13 11557 ...,     0     0     0]\n",
      " [   12     1   645 ...,     0     0     0]\n",
      " [ 3140    13  6136 ...,     0     0     0]\n",
      " ..., \n",
      " [   15     7   776 ...,     0     0     0]\n",
      " [ 1698     4     1 ...,     0     0     0]\n",
      " [   13  2336    21 ...,     0     0     0]]\n",
      "162/200 [=======================>......] - ETA: 17s - loss: 1.5702 - acc: 0.8053[[ 535  133   39 ...,    0    0    0]\n",
      " [ 873 2778 9301 ...,    0    0    0]\n",
      " [  13   13  802 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   49   13 ...,    0    0    0]\n",
      " [   1 7520   19 ...,    0    0    0]\n",
      " [ 161  426 1053 ...,    0    0    0]]\n",
      "163/200 [=======================>......] - ETA: 16s - loss: 1.5713 - acc: 0.8052[[ 108   68   13 ...,    0    0    0]\n",
      " [  13  104   21 ...,    0    0    0]\n",
      " [2365   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [  75  103  626 ...,    0    0    0]\n",
      " [ 276  178   13 ...,    0    0    0]\n",
      " [  10  383    2 ...,    0    0    0]]\n",
      "164/200 [=======================>......] - ETA: 16s - loss: 1.5741 - acc: 0.8049[[   13    26    67 ...,     0     0     0]\n",
      " [    1   179   161 ...,     0     0     0]\n",
      " [ 5206 10059     5 ...,     0     0     0]\n",
      " ..., \n",
      " [   90    99  1156 ...,     0     0     0]\n",
      " [    6     1   310 ...,     0     0     0]\n",
      " [ 1720    13     7 ...,     0     0     0]]\n",
      "165/200 [=======================>......] - ETA: 15s - loss: 1.5726 - acc: 0.8051[[    1   127    13 ...,     0     0     0]\n",
      " [    2   287     5 ...,     0     0     0]\n",
      " [   93    23   428 ...,     0     0     0]\n",
      " ..., \n",
      " [  606    13   606 ...,     0     0     0]\n",
      " [    1   794    11 ...,     0     0     0]\n",
      " [  584 10173  1345 ...,     0     0     0]]\n",
      "166/200 [=======================>......] - ETA: 15s - loss: 1.5740 - acc: 0.8049[[ 535    1 3629 ...,    0    0    0]\n",
      " [3685 6496   14 ...,    0    0    0]\n",
      " [ 276  178   13 ...,    0    0    0]\n",
      " ..., \n",
      " [5680   13  141 ...,    0    0    0]\n",
      " [2142  252  103 ...,    0    0    0]\n",
      " [6137   13 2621 ...,    0    0    0]]\n",
      "167/200 [========================>.....] - ETA: 15s - loss: 1.5746 - acc: 0.8049[[3485 8007   11 ...,    0    0    0]\n",
      " [  13   13  292 ...,    0    0    0]\n",
      " [  13   13    9 ...,    0    0    0]\n",
      " ..., \n",
      " [ 349    9   76 ...,    0    0    0]\n",
      " [  13   13   11 ...,    0    0    0]\n",
      " [  18 1530   13 ...,    0    0    0]]\n",
      "168/200 [========================>.....] - ETA: 14s - loss: 1.5744 - acc: 0.8049[[1768   13 1425 ...,    0    0    0]\n",
      " [3679    4 5243 ...,    0    0    0]\n",
      " [3138  105 1980 ...,    0    0    0]\n",
      " ..., \n",
      " [3022 2349 1585 ...,    0    0    0]\n",
      " [  15    7  229 ...,    0    0    0]\n",
      " [   1  221  230 ...,    0    0    0]]\n",
      "169/200 [========================>.....] - ETA: 14s - loss: 1.5737 - acc: 0.8050[[4791   13   27 ...,    0    0    0]\n",
      " [   6   25  151 ...,    0    0    0]\n",
      " [ 702  123  338 ...,    0    0    0]\n",
      " ..., \n",
      " [  15  265  107 ...,    0    0    0]\n",
      " [6796   63 1105 ...,    0    0    0]\n",
      " [  73   66 2451 ...,    0    0    0]]\n",
      "170/200 [========================>.....] - ETA: 13s - loss: 1.5744 - acc: 0.8050[[   4   13   13 ...,    0    0    0]\n",
      " [  13   13 5118 ...,    0    0    0]\n",
      " [  13  690 2463 ...,    0    0    0]\n",
      " ..., \n",
      " [1588   69   13 ...,    0    0    0]\n",
      " [ 219  970 2002 ...,    0    0    0]\n",
      " [   1  956   55 ...,    0    0    0]]\n",
      "171/200 [========================>.....] - ETA: 13s - loss: 1.5751 - acc: 0.8049[[   2 2487   32 ...,    0    0    0]\n",
      " [  13   69  297 ...,    0    0    0]\n",
      " [2181    7 1802 ...,    0    0    0]\n",
      " ..., \n",
      " [ 140  369    8 ...,    0    0    0]\n",
      " [ 491   26  113 ...,    0    0    0]\n",
      " [1396    6    2 ...,    0    0    0]]\n",
      "172/200 [========================>.....] - ETA: 12s - loss: 1.5750 - acc: 0.8049[[4946 2438 2101 ...,    0    0    0]\n",
      " [  19  352 1400 ...,    0    0    0]\n",
      " [4245   13    4 ...,    0    0    0]\n",
      " ..., \n",
      " [6465  172   12 ...,    0    0    0]\n",
      " [ 131  395  456 ...,    0    0    0]\n",
      " [   1   13 1847 ...,    0    0    0]]\n",
      "173/200 [========================>.....] - ETA: 12s - loss: 1.5751 - acc: 0.8049[[ 763 9690   21 ...,    0    0    0]\n",
      " [ 373  423   55 ...,    0    0    0]\n",
      " [   1   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 2893 2824 ...,    0    0    0]\n",
      " [  55    8 4432 ...,    0    0    0]\n",
      " [  13  792   86 ...,    0    0    0]]\n",
      "174/200 [=========================>....] - ETA: 11s - loss: 1.5751 - acc: 0.8049[[ 844    8 3029 ...,    0    0    0]\n",
      " [1910   55    7 ...,    0    0    0]\n",
      " [   1  220   73 ...,    0    0    0]\n",
      " ..., \n",
      " [ 937   13   13 ...,    0    0    0]\n",
      " [   1 1008 2973 ...,    0    0    0]\n",
      " [   1   13  191 ...,    0    0    0]]\n",
      "175/200 [=========================>....] - ETA: 11s - loss: 1.5753 - acc: 0.8049[[  58   59   26 ...,    0    0    0]\n",
      " [   1  740    5 ...,    0    0    0]\n",
      " [6094 7169  130 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  740    5 ...,    0    0    0]\n",
      " [  13 1056 6390 ...,    0    0    0]\n",
      " [ 154  635  143 ...,    0    0    0]]\n",
      "176/200 [=========================>....] - ETA: 10s - loss: 1.5748 - acc: 0.8050[[ 481   66   14 ...,    0    0    0]\n",
      " [  49   13  704 ...,    0    0    0]\n",
      " [ 167  187  106 ...,    0    0    0]\n",
      " ..., \n",
      " [1339 1553   11 ...,    0    0    0]\n",
      " [1635   13    9 ...,    0    0    0]\n",
      " [2589    5  220 ...,    0    0    0]]\n",
      "177/200 [=========================>....] - ETA: 10s - loss: 1.5750 - acc: 0.8050[[   1  132  509 ...,    0    0    0]\n",
      " [1896  187   65 ...,    0    0    0]\n",
      " [2395   13  100 ...,    0    0    0]\n",
      " ..., \n",
      " [ 185 1780   21 ...,    0    0    0]\n",
      " [ 255  154   66 ...,    0    0    0]\n",
      " [ 524   10   22 ...,    0    0    0]]\n",
      "178/200 [=========================>....] - ETA: 9s - loss: 1.5752 - acc: 0.8050 [[   16  5877 11689 ...,     0     0     0]\n",
      " [11630    13    13 ...,     0     0     0]\n",
      " [    1    13    13 ...,     0     0     0]\n",
      " ..., \n",
      " [   13    13   253 ...,     0     0     0]\n",
      " [    1    13  4128 ...,     0     0     0]\n",
      " [   15   448    29 ...,     0     0     0]]\n",
      "179/200 [=========================>....] - ETA: 9s - loss: 1.5756 - acc: 0.8050[[    1    13   879 ...,     0     0     0]\n",
      " [  364   375   411 ...,     0     0     0]\n",
      " [ 6528 11277  6082 ...,     0     0     0]\n",
      " ..., \n",
      " [10681 10044   253 ...,     0     0     0]\n",
      " [  481   176    66 ...,     0     0     0]\n",
      " [    1   919   736 ...,     0     0     0]]\n",
      "180/200 [==========================>...] - ETA: 9s - loss: 1.5757 - acc: 0.8050[[ 1360    13     9 ...,     0     0     0]\n",
      " [ 2196   418   335 ...,     0     0     0]\n",
      " [   15   247   234 ...,     0     0     0]\n",
      " ..., \n",
      " [10926     8    13 ...,     0     0     0]\n",
      " [   92  1755  3347 ...,     0     0     0]\n",
      " [  206    66    23 ...,     0     0     0]]\n",
      "181/200 [==========================>...] - ETA: 8s - loss: 1.5750 - acc: 0.8050[[   41     5     1 ...,     0     0     0]\n",
      " [10509 11024    83 ...,     0     0     0]\n",
      " [  131   248    85 ...,     0     0     0]\n",
      " ..., \n",
      " [   13    13     1 ...,     0     0     0]\n",
      " [ 1090  9071   461 ...,     0     0     0]\n",
      " [ 1491  2550  1950 ...,     0     0     0]]\n",
      "182/200 [==========================>...] - ETA: 8s - loss: 1.5732 - acc: 0.8052[[  70  152  139 ...,    0    0    0]\n",
      " [ 987    7  615 ...,    0    0    0]\n",
      " [2151   11    2 ...,    0    0    0]\n",
      " ..., \n",
      " [ 109   26  115 ...,    0    0    0]\n",
      " [1150   13   13 ...,    0    0    0]\n",
      " [   2 3865 1346 ...,    0    0    0]]\n",
      "183/200 [==========================>...] - ETA: 7s - loss: 1.5714 - acc: 0.8053[[   1 8252    5 ...,    0    0    0]\n",
      " [   1  474 1341 ...,    0    0    0]\n",
      " [ 500    7   19 ...,    0    0    0]\n",
      " ..., \n",
      " [ 962 6266    8 ...,    0    0    0]\n",
      " [   2  121 8811 ...,    0    0    0]\n",
      " [  56   13  397 ...,    0    0    0]]\n",
      "184/200 [==========================>...] - ETA: 7s - loss: 1.5697 - acc: 0.8055[[   4    1  117 ...,    0    0    0]\n",
      " [  13    7   13 ...,    0    0    0]\n",
      " [   1 4920    5 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  145  608 ...,    0    0    0]\n",
      " [   2   13  150 ...,    0    0    0]\n",
      " [1170  159  390 ...,    0    0    0]]\n",
      "185/200 [==========================>...] - ETA: 6s - loss: 1.5681 - acc: 0.8056[[2567 2560  217 ...,    0    0    0]\n",
      " [   2 1147   32 ...,    0    0    0]\n",
      " [  89   14 2631 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 5475    5 ...,    0    0    0]\n",
      " [ 955  814    5 ...,    0    0    0]\n",
      " [ 284    7   69 ...,    0    0    0]]\n",
      "186/200 [==========================>...] - ETA: 6s - loss: 1.5665 - acc: 0.8057[[3756   13    8 ...,    0    0    0]\n",
      " [2490    7  732 ...,    0    0    0]\n",
      " [  73   13    4 ...,    0    0    0]\n",
      " ..., \n",
      " [3236 2644   27 ...,    0    0    0]\n",
      " [1507   10 1061 ...,    0    0    0]\n",
      " [5489    7  390 ...,    0    0    0]]\n",
      "187/200 [===========================>..] - ETA: 5s - loss: 1.5651 - acc: 0.8058[[   2 1624 2642 ...,    0    0    0]\n",
      " [   2 1580 1048 ...,    0    0    0]\n",
      " [   1  261  401 ...,    0    0    0]\n",
      " ..., \n",
      " [   2  763  740 ...,    0    0    0]\n",
      " [  89  105   20 ...,    0    0    0]\n",
      " [1757 1483   27 ...,    0    0    0]]\n",
      "188/200 [===========================>..] - ETA: 5s - loss: 1.5641 - acc: 0.8059[[    2    74    56 ...,     0     0     0]\n",
      " [    1   528   142 ...,     0     0     0]\n",
      " [ 6686  8975  1850 ...,     0     0     0]\n",
      " ..., \n",
      " [    1   221   230 ...,     0     0     0]\n",
      " [ 1162  8454  2103 ...,     0     0     0]\n",
      " [11856  1993    11 ...,     0     0     0]]\n",
      "189/200 [===========================>..] - ETA: 4s - loss: 1.5636 - acc: 0.8060[[   1 3135  161 ...,    0    0    0]\n",
      " [3282 3426   11 ...,    0    0    0]\n",
      " [4182 2308   11 ...,    0    0    0]\n",
      " ..., \n",
      " [ 497   13   69 ...,    0    0    0]\n",
      " [ 280   13  100 ...,    0    0    0]\n",
      " [7546   13 1564 ...,    0    0    0]]\n",
      "190/200 [===========================>..] - ETA: 4s - loss: 1.5636 - acc: 0.8060[[   13    69   297 ...,     0     0     0]\n",
      " [ 2558  1063  8611 ...,     0     0     0]\n",
      " [ 3549   130   131 ...,     0     0     0]\n",
      " ..., \n",
      " [    1    91   106 ...,     0     0     0]\n",
      " [ 2461   900  3066 ...,     0     0     0]\n",
      " [11627   779    13 ...,     0     0     0]]\n",
      "191/200 [===========================>..] - ETA: 4s - loss: 1.5647 - acc: 0.8059[[  109    26    65 ...,     0     0     0]\n",
      " [  893   232 11645 ...,     0     0     0]\n",
      " [   89   684    20 ...,     0     0     0]\n",
      " ..., \n",
      " [    1   549     5 ...,     0     0     0]\n",
      " [  108  1350   543 ...,     0     0     0]\n",
      " [    5    79     1 ...,     0     0     0]]\n",
      "192/200 [===========================>..] - ETA: 3s - loss: 1.5649 - acc: 0.8058[[ 606    9 2477 ...,    0    0    0]\n",
      " [  89  684   20 ...,    0    0    0]\n",
      " [  13 2652 1558 ...,    0    0    0]\n",
      " ..., \n",
      " [1746 1574 6367 ...,    0    0    0]\n",
      " [ 508   15    1 ...,    0    0    0]\n",
      " [ 194    5    1 ...,    0    0    0]]\n",
      "193/200 [===========================>..] - ETA: 3s - loss: 1.5659 - acc: 0.8057[[    6     1  5556 ...,     0     0     0]\n",
      " [ 5526    13     1 ...,     0     0     0]\n",
      " [  108  4713    51 ...,     0     0     0]\n",
      " ..., \n",
      " [10537   558    30 ...,     0     0     0]\n",
      " [   13    13   430 ...,     0     0     0]\n",
      " [ 7029    13     9 ...,     0     0     0]]\n",
      "194/200 [============================>.] - ETA: 2s - loss: 1.5652 - acc: 0.8058[[   49    63   144 ...,     0     0     0]\n",
      " [11254    13    13 ...,     0     0     0]\n",
      " [ 1851     9  2938 ...,     0     0     0]\n",
      " ..., \n",
      " [   13    13   221 ...,     0     0     0]\n",
      " [  584     1  7157 ...,     0     0     0]\n",
      " [   13  8426  6054 ...,     0     0     0]]\n",
      "195/200 [============================>.] - ETA: 2s - loss: 1.5656 - acc: 0.8058[[   1 2324    5 ...,    0    0    0]\n",
      " [  13  104   21 ...,    0    0    0]\n",
      " [2543    1 1744 ...,    0    0    0]\n",
      " ..., \n",
      " [9196 5800    7 ...,    0    0    0]\n",
      " [  81   42 7503 ...,    0    0    0]\n",
      " [   1  166  371 ...,    0    0    0]]\n",
      "196/200 [============================>.] - ETA: 1s - loss: 1.5670 - acc: 0.8056[[1384   15   51 ...,    0    0    0]\n",
      " [  12   47  643 ...,    0    0    0]\n",
      " [  13    3 2537 ...,    0    0    0]\n",
      " ..., \n",
      " [  13 1432   10 ...,    0    0    0]\n",
      " [1386    7   73 ...,    0    0    0]\n",
      " [3954   13  192 ...,    0    0    0]]\n",
      "197/200 [============================>.] - ETA: 1s - loss: 1.5684 - acc: 0.8055[[   1 3955    9 ...,    0    0    0]\n",
      " [   1 2943  217 ...,    0    0    0]\n",
      " [ 278    1   63 ...,    0    0    0]\n",
      " ..., \n",
      " [ 439   90   34 ...,    0    0    0]\n",
      " [  32  155    6 ...,    0    0    0]\n",
      " [9404  375 8160 ...,    0    0    0]]\n",
      "198/200 [============================>.] - ETA: 0s - loss: 1.5699 - acc: 0.8053[[ 116  163  157 ...,    0    0    0]\n",
      " [ 220  324  209 ...,    0    0    0]\n",
      " [   1 1130   14 ...,    0    0    0]\n",
      " ..., \n",
      " [  13    1  681 ...,    0    0    0]\n",
      " [ 104  107 3647 ...,    0    0    0]\n",
      " [  12    1  908 ...,    0    0    0]]\n",
      "199/200 [============================>.] - ETA: 0s - loss: 1.5700 - acc: 0.8053[[1811    7   47 ...,    0    0    0]\n",
      " [  93   67   13 ...,    0    0    0]\n",
      " [3884  176  298 ...,    0    0    0]\n",
      " ..., \n",
      " [ 531   67  207 ...,    0    0    0]\n",
      " [  27 2828  247 ...,    0    0    0]\n",
      " [  13 2635   67 ...,    0    0    0]]\n",
      "200/200 [==============================] - 90s - loss: 1.5705 - acc: 0.8053    \n",
      "Epoch 5/10\n",
      "[[7069  123    7 ...,    0    0    0]\n",
      " [  13   13  200 ...,    0    0    0]\n",
      " [   1 1443   67 ...,    0    0    0]\n",
      " ..., \n",
      " [   4   22  408 ...,    0    0    0]\n",
      " [  10   63   13 ...,    0    0    0]\n",
      " [  18   22   13 ...,    0    0    0]]\n",
      "  1/200 [..............................] - ETA: 95s - loss: 1.7597 - acc: 0.7825[[  13    6    1 ...,    0    0    0]\n",
      " [  27 1415  128 ...,    0    0    0]\n",
      " [   1  831   99 ...,    0    0    0]\n",
      " ..., \n",
      " [ 116   13 9748 ...,    0    0    0]\n",
      " [5391   13   13 ...,    0    0    0]\n",
      " [   1 6447   13 ...,    0    0    0]]\n",
      "  2/200 [..............................] - ETA: 92s - loss: 1.6779 - acc: 0.7918[[   1 1769 2672 ...,    0    0    0]\n",
      " [ 557  733   13 ...,    0    0    0]\n",
      " [ 427   21 2318 ...,    0    0    0]\n",
      " ..., \n",
      " [ 108   93  959 ...,    0    0    0]\n",
      " [1304   23    2 ...,    0    0    0]\n",
      " [  12   34  692 ...,    0    0    0]]\n",
      "  3/200 [..............................] - ETA: 90s - loss: 1.6096 - acc: 0.8016[[  80   41  384 ...,    0    0    0]\n",
      " [   1  474  558 ...,    0    0    0]\n",
      " [  15   27  257 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   13   13 ...,    0    0    0]\n",
      " [  18    1  381 ...,    0    0    0]\n",
      " [ 958 5040  747 ...,    0    0    0]]\n",
      "  4/200 [..............................] - ETA: 88s - loss: 1.6020 - acc: 0.8034[[  10   34   13 ...,    0    0    0]\n",
      " [1853  135 2585 ...,    0    0    0]\n",
      " [  70   15  392 ...,    0    0    0]\n",
      " ..., \n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [ 109   26   65 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]]\n",
      "  5/200 [..............................] - ETA: 88s - loss: 1.6206 - acc: 0.8017[[4504 3102    1 ...,    0    0    0]\n",
      " [2504    8 1654 ...,    0    0    0]\n",
      " [   1  286    5 ...,    0    0    0]\n",
      " ..., \n",
      " [ 599  102    4 ...,    0    0    0]\n",
      " [1247   11  850 ...,    0    0    0]\n",
      " [5164   21  269 ...,    0    0    0]]\n",
      "  6/200 [..............................] - ETA: 87s - loss: 1.6049 - acc: 0.8032[[   1   47 2903 ...,    0    0    0]\n",
      " [   2   13 3238 ...,    0    0    0]\n",
      " [   1 2059 1158 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  214   23 ...,    0    0    0]\n",
      " [ 167 1865   13 ...,    0    0    0]\n",
      " [2017   67  694 ...,    0    0    0]]\n",
      "  7/200 [>.............................] - ETA: 87s - loss: 1.5985 - acc: 0.8037[[   1 3635    5 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " ..., \n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [2562   26  249 ...,    0    0    0]\n",
      " [  55   11 3290 ...,    0    0    0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8/200 [>.............................] - ETA: 86s - loss: 1.6010 - acc: 0.8035[[1267   26  113 ...,    0    0    0]\n",
      " [ 167  161  162 ...,    0    0    0]\n",
      " [ 234  435  167 ...,    0    0    0]\n",
      " ..., \n",
      " [1863   13   69 ...,    0    0    0]\n",
      " [  38  481  176 ...,    0    0    0]\n",
      " [   1 3317  310 ...,    0    0    0]]\n",
      "  9/200 [>.............................] - ETA: 86s - loss: 1.5901 - acc: 0.8049[[ 109   26  113 ...,    0    0    0]\n",
      " [  55  231   53 ...,    0    0    0]\n",
      " [1695  736 1528 ...,    0    0    0]\n",
      " ..., \n",
      " [  55   11 1220 ...,    0    0    0]\n",
      " [   1 1653 1614 ...,    0    0    0]\n",
      " [ 444 5769   40 ...,    0    0    0]]\n",
      " 10/200 [>.............................] - ETA: 85s - loss: 1.5924 - acc: 0.8050[[  19  352   30 ...,    0    0    0]\n",
      " [1757  119   27 ...,    0    0    0]\n",
      " [ 193   27  971 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  161  657 ...,    0    0    0]\n",
      " [   1  156 8704 ...,    0    0    0]\n",
      " [2198   69 8009 ...,    0    0    0]]\n",
      " 11/200 [>.............................] - ETA: 85s - loss: 1.5958 - acc: 0.8044[[  55   11 2025 ...,    0    0    0]\n",
      " [  58   59    7 ...,    0    0    0]\n",
      " [  49 1839    4 ...,    0    0    0]\n",
      " ..., \n",
      " [ 553  509   13 ...,    0    0    0]\n",
      " [ 342  196   66 ...,    0    0    0]\n",
      " [  32    2 2393 ...,    0    0    0]]\n",
      " 12/200 [>.............................] - ETA: 84s - loss: 1.5963 - acc: 0.8043[[1848  249   13 ...,    0    0    0]\n",
      " [   2   13 1373 ...,    0    0    0]\n",
      " [ 501  154   66 ...,    0    0    0]\n",
      " ..., \n",
      " [  55  100    1 ...,    0    0    0]\n",
      " [  55    7   13 ...,    0    0    0]\n",
      " [5591 5759    5 ...,    0    0    0]]\n",
      " 13/200 [>.............................] - ETA: 84s - loss: 1.5945 - acc: 0.8050[[ 131  179   69 ...,    0    0    0]\n",
      " [1745 3701    4 ...,    0    0    0]\n",
      " [1695  424  240 ...,    0    0    0]\n",
      " ..., \n",
      " [2323 2339  587 ...,    0    0    0]\n",
      " [1109    7  660 ...,    0    0    0]\n",
      " [   2 6148   74 ...,    0    0    0]]\n",
      " 14/200 [=>............................] - ETA: 83s - loss: 1.5908 - acc: 0.8054[[ 109   26  268 ...,    0    0    0]\n",
      " [ 447  200    9 ...,    0    0    0]\n",
      " [6526   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 514 2246   13 ...,    0    0    0]\n",
      " [ 108 6764   13 ...,    0    0    0]\n",
      " [  42   14 7660 ...,    0    0    0]]\n",
      " 15/200 [=>............................] - ETA: 83s - loss: 1.5804 - acc: 0.8058[[5230  558   83 ...,    0    0    0]\n",
      " [  13  800  390 ...,    0    0    0]\n",
      " [2535 6304   28 ...,    0    0    0]\n",
      " ..., \n",
      " [6992   11 1402 ...,    0    0    0]\n",
      " [ 299    5   19 ...,    0    0    0]\n",
      " [7181  721    7 ...,    0    0    0]]\n",
      " 16/200 [=>............................] - ETA: 82s - loss: 1.5586 - acc: 0.8070[[  55    7 4530 ...,    0    0    0]\n",
      " [   1  601    5 ...,    0    0    0]\n",
      " [   2  582  405 ...,    0    0    0]\n",
      " ..., \n",
      " [2002 4124 1060 ...,    0    0    0]\n",
      " [2000    5 3866 ...,    0    0    0]\n",
      " [  26   67   84 ...,    0    0    0]]\n",
      " 17/200 [=>............................] - ETA: 82s - loss: 1.5361 - acc: 0.8088[[  429  1887   484 ...,     0     0     0]\n",
      " [10146   971  9777 ...,     0     0     0]\n",
      " [  133    39  1899 ...,     0     0     0]\n",
      " ..., \n",
      " [ 9355 10993    11 ...,     0     0     0]\n",
      " [   22    13     9 ...,     0     0     0]\n",
      " [ 5353   963    13 ...,     0     0     0]]\n",
      " 18/200 [=>............................] - ETA: 82s - loss: 1.5206 - acc: 0.8100[[ 276  178   13 ...,    0    0    0]\n",
      " [1573 2461  450 ...,    0    0    0]\n",
      " [1727  812   13 ...,    0    0    0]\n",
      " ..., \n",
      " [1431  450    9 ...,    0    0    0]\n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [  26  113   88 ...,    0    0    0]]\n",
      " 19/200 [=>............................] - ETA: 81s - loss: 1.5056 - acc: 0.8109[[  15 1312   79 ...,    0    0    0]\n",
      " [1267  970 5527 ...,    0    0    0]\n",
      " [ 155  790 2047 ...,    0    0    0]\n",
      " ..., \n",
      " [5274 6861   11 ...,    0    0    0]\n",
      " [ 685  720 1150 ...,    0    0    0]\n",
      " [2371  532 1090 ...,    0    0    0]]\n",
      " 20/200 [==>...........................] - ETA: 81s - loss: 1.4947 - acc: 0.8117[[ 819   26   65 ...,    0    0    0]\n",
      " [  15   27   20 ...,    0    0    0]\n",
      " [1046  332 4746 ...,    0    0    0]\n",
      " ..., \n",
      " [   2   19  432 ...,    0    0    0]\n",
      " [ 131   69  309 ...,    0    0    0]\n",
      " [   1   13 3709 ...,    0    0    0]]\n",
      " 21/200 [==>...........................] - ETA: 81s - loss: 1.4835 - acc: 0.8126[[  22 1830   13 ...,    0    0    0]\n",
      " [1644 4243   13 ...,    0    0    0]\n",
      " [2160    2   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 706 3156   21 ...,    0    0    0]\n",
      " [  22  529 1376 ...,    0    0    0]\n",
      " [ 654  145    9 ...,    0    0    0]]\n",
      " 22/200 [==>...........................] - ETA: 80s - loss: 1.4737 - acc: 0.8131[[   2  440 3626 ...,    0    0    0]\n",
      " [ 150 4118 1345 ...,    0    0    0]\n",
      " [6629   27 3067 ...,    0    0    0]\n",
      " ..., \n",
      " [4526 2393 3885 ...,    0    0    0]\n",
      " [5829    7  732 ...,    0    0    0]\n",
      " [  13  761 6404 ...,    0    0    0]]\n",
      " 23/200 [==>...........................] - ETA: 80s - loss: 1.4674 - acc: 0.8137[[   2  676 2398 ...,    0    0    0]\n",
      " [ 792    7   13 ...,    0    0    0]\n",
      " [3408  157    2 ...,    0    0    0]\n",
      " ..., \n",
      " [3007    4  672 ...,    0    0    0]\n",
      " [ 226  752   13 ...,    0    0    0]\n",
      " [5933 5876 1425 ...,    0    0    0]]\n",
      " 24/200 [==>...........................] - ETA: 79s - loss: 1.4700 - acc: 0.8132[[ 226 1448  280 ...,    0    0    0]\n",
      " [   1  145  608 ...,    0    0    0]\n",
      " [ 807 4022   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 381  228  615 ...,    0    0    0]\n",
      " [   2 4374 9858 ...,    0    0    0]\n",
      " [  49 7088   21 ...,    0    0    0]]\n",
      " 25/200 [==>...........................] - ETA: 79s - loss: 1.4722 - acc: 0.8132[[ 676   19  352 ...,    0    0    0]\n",
      " [ 221  230  782 ...,    0    0    0]\n",
      " [5028   13  100 ...,    0    0    0]\n",
      " ..., \n",
      " [  15   14 1222 ...,    0    0    0]\n",
      " [  56  430    2 ...,    0    0    0]\n",
      " [   1   73  138 ...,    0    0    0]]\n",
      " 26/200 [==>...........................] - ETA: 79s - loss: 1.4850 - acc: 0.8119[[   1   13   91 ...,    0    0    0]\n",
      " [   1 3272 1040 ...,    0    0    0]\n",
      " [   1  330   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 219  324  209 ...,    0    0    0]\n",
      " [ 219  414  808 ...,    0    0    0]\n",
      " [ 697 1295  268 ...,    0    0    0]]\n",
      " 27/200 [===>..........................] - ETA: 78s - loss: 1.4872 - acc: 0.8117[[324 209  13 ...,   0   0   0]\n",
      " [745  11  39 ...,   0   0   0]\n",
      " [ 13   7 131 ...,   0   0   0]\n",
      " ..., \n",
      " [  4   1  38 ...,   0   0   0]\n",
      " [ 15   7   2 ...,   0   0   0]\n",
      " [ 43  41  13 ...,   0   0   0]]\n",
      " 28/200 [===>..........................] - ETA: 78s - loss: 1.4908 - acc: 0.8113[[  13 1578   15 ...,    0    0    0]\n",
      " [1578   13  105 ...,    0    0    0]\n",
      " [  70  159 1505 ...,    0    0    0]\n",
      " ..., \n",
      " [ 102  123 1944 ...,    0    0    0]\n",
      " [ 158  165    6 ...,    0    0    0]\n",
      " [   1   49   19 ...,    0    0    0]]\n",
      " 29/200 [===>..........................] - ETA: 77s - loss: 1.4965 - acc: 0.8108[[  41  237 1212 ...,    0    0    0]\n",
      " [2343   13    9 ...,    0    0    0]\n",
      " [   1   13  124 ...,    0    0    0]\n",
      " ..., \n",
      " [2265 3954    9 ...,    0    0    0]\n",
      " [ 104 1585   96 ...,    0    0    0]\n",
      " [   1   13 1459 ...,    0    0    0]]\n",
      " 30/200 [===>..........................] - ETA: 77s - loss: 1.4989 - acc: 0.8108[[  13   27 1181 ...,    0    0    0]\n",
      " [  13   15    7 ...,    0    0    0]\n",
      " [ 730   13 1067 ...,    0    0    0]\n",
      " ..., \n",
      " [  13  301 1384 ...,    0    0    0]\n",
      " [ 309  451   11 ...,    0    0    0]\n",
      " [   1 1017  182 ...,    0    0    0]]\n",
      " 31/200 [===>..........................] - ETA: 76s - loss: 1.5109 - acc: 0.8096[[ 463   27   20 ...,    0    0    0]\n",
      " [ 194  563  374 ...,    0    0    0]\n",
      " [  56   13   63 ...,    0    0    0]\n",
      " ..., \n",
      " [ 443  900    7 ...,    0    0    0]\n",
      " [3491   26  619 ...,    0    0    0]\n",
      " [1940  536   13 ...,    0    0    0]]\n",
      " 32/200 [===>..........................] - ETA: 76s - loss: 1.5199 - acc: 0.8087[[ 626    8 6161 ...,    0    0    0]\n",
      " [ 232   13 3343 ...,    0    0    0]\n",
      " [   1  751 2224 ...,    0    0    0]\n",
      " ..., \n",
      " [1014   13  381 ...,    0    0    0]\n",
      " [   2  259 2110 ...,    0    0    0]\n",
      " [3578  510   24 ...,    0    0    0]]\n",
      " 33/200 [===>..........................] - ETA: 75s - loss: 1.5262 - acc: 0.8081[[    1  4995    86 ...,     0     0     0]\n",
      " [   93  1163    13 ...,     0     0     0]\n",
      " [   15     7  2204 ...,     0     0     0]\n",
      " ..., \n",
      " [  458  3535     9 ...,     0     0     0]\n",
      " [  882   283    50 ...,     0     0     0]\n",
      " [   93 11772  1166 ...,     0     0     0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 34/200 [====>.........................] - ETA: 75s - loss: 1.5384 - acc: 0.8068[[    1  1086   123 ...,     0     0     0]\n",
      " [    1   730  3049 ...,     0     0     0]\n",
      " [    1  1559  2887 ...,     0     0     0]\n",
      " ..., \n",
      " [  564    13  1068 ...,     0     0     0]\n",
      " [  116   589 11609 ...,     0     0     0]\n",
      " [   10    92   888 ...,     0     0     0]]\n",
      " 35/200 [====>.........................] - ETA: 74s - loss: 1.5396 - acc: 0.8068[[ 232 3459   81 ...,    0    0    0]\n",
      " [ 379  177   13 ...,    0    0    0]\n",
      " [  19  120  105 ...,    0    0    0]\n",
      " ..., \n",
      " [  70    2 5322 ...,    0    0    0]\n",
      " [  13 1171   13 ...,    0    0    0]\n",
      " [ 599   63 1105 ...,    0    0    0]]\n",
      " 36/200 [====>.........................] - ETA: 74s - loss: 1.5422 - acc: 0.8066[[   3 1141    2 ...,    0    0    0]\n",
      " [  13  104 2467 ...,    0    0    0]\n",
      " [  15  105   21 ...,    0    0    0]\n",
      " ..., \n",
      " [   4  552  173 ...,    0    0    0]\n",
      " [5707  610   11 ...,    0    0    0]\n",
      " [   1 5269   23 ...,    0    0    0]]\n",
      " 37/200 [====>.........................] - ETA: 73s - loss: 1.5505 - acc: 0.8058[[  166   234    63 ...,     0     0     0]\n",
      " [   13     9   407 ...,     0     0     0]\n",
      " [    4    13  4290 ...,     0     0     0]\n",
      " ..., \n",
      " [   70   193 11373 ...,     0     0     0]\n",
      " [ 1760   898     1 ...,     0     0     0]\n",
      " [   15     7    54 ...,     0     0     0]]\n",
      " 38/200 [====>.........................] - ETA: 73s - loss: 1.5479 - acc: 0.8062[[  72   29    7 ...,    0    0    0]\n",
      " [ 108    1   13 ...,    0    0    0]\n",
      " [ 304 1173  695 ...,    0    0    0]\n",
      " ..., \n",
      " [  99  102 2728 ...,    0    0    0]\n",
      " [2203   13  260 ...,    0    0    0]\n",
      " [ 382    3 2264 ...,    0    0    0]]\n",
      " 39/200 [====>.........................] - ETA: 73s - loss: 1.5468 - acc: 0.8064[[   1  629    5 ...,    0    0    0]\n",
      " [ 221  230   13 ...,    0    0    0]\n",
      " [  15    7   18 ...,    0    0    0]\n",
      " ..., \n",
      " [  34    9    1 ...,    0    0    0]\n",
      " [   1  526 2248 ...,    0    0    0]\n",
      " [   1  431    5 ...,    0    0    0]]\n",
      " 40/200 [=====>........................] - ETA: 72s - loss: 1.5461 - acc: 0.8066[[  26 1533   24 ...,    0    0    0]\n",
      " [  13  137    7 ...,    0    0    0]\n",
      " [   2 5193  165 ...,    0    0    0]\n",
      " ..., \n",
      " [  13 4006 7600 ...,    0    0    0]\n",
      " [ 108 3929   13 ...,    0    0    0]\n",
      " [  42   13    1 ...,    0    0    0]]\n",
      " 41/200 [=====>........................] - ETA: 72s - loss: 1.5510 - acc: 0.8062[[ 229    2   13 ...,    0    0    0]\n",
      " [  68 1108  377 ...,    0    0    0]\n",
      " [  90  244 6505 ...,    0    0    0]\n",
      " ..., \n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [ 248   85  295 ...,    0    0    0]]\n",
      " 42/200 [=====>........................] - ETA: 71s - loss: 1.5524 - acc: 0.8061[[    1   545   191 ...,     0     0     0]\n",
      " [    1   701     5 ...,     0     0     0]\n",
      " [  561    75   329 ...,     0     0     0]\n",
      " ..., \n",
      " [  561     8  1386 ...,     0     0     0]\n",
      " [11855   252   205 ...,     0     0     0]\n",
      " [  727     6    57 ...,     0     0     0]]\n",
      " 43/200 [=====>........................] - ETA: 71s - loss: 1.5538 - acc: 0.8061[[  58   59   26 ...,    0    0    0]\n",
      " [   2  146   11 ...,    0    0    0]\n",
      " [ 109   26  619 ...,    0    0    0]\n",
      " ..., \n",
      " [  55    6   28 ...,    0    0    0]\n",
      " [ 109   26 1452 ...,    0    0    0]\n",
      " [  38  481  176 ...,    0    0    0]]\n",
      " 44/200 [=====>........................] - ETA: 70s - loss: 1.5535 - acc: 0.8062[[ 214   23    1 ...,    0    0    0]\n",
      " [ 214   23    1 ...,    0    0    0]\n",
      " [ 214   23    1 ...,    0    0    0]\n",
      " ..., \n",
      " [ 546    6   25 ...,    0    0    0]\n",
      " [1717   13    5 ...,    0    0    0]\n",
      " [  13    9  498 ...,    0    0    0]]\n",
      " 45/200 [=====>........................] - ETA: 70s - loss: 1.5536 - acc: 0.8063[[   1   13  736 ...,    0    0    0]\n",
      " [ 167  187  113 ...,    0    0    0]\n",
      " [1337    7 2059 ...,    0    0    0]\n",
      " ..., \n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [ 119    4  140 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]]\n",
      " 46/200 [=====>........................] - ETA: 69s - loss: 1.5552 - acc: 0.8062[[   1   13   91 ...,    0    0    0]\n",
      " [  26   12 2893 ...,    0    0    0]\n",
      " [ 454  205 2072 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 2011  283 ...,    0    0    0]\n",
      " [ 219   73  138 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]]\n",
      " 47/200 [======>.......................] - ETA: 69s - loss: 1.5555 - acc: 0.8063[[    1    19   352 ...,     0     0     0]\n",
      " [  284   550   940 ...,     0     0     0]\n",
      " [ 2593 10809   555 ...,     0     0     0]\n",
      " ..., \n",
      " [10034   398  4821 ...,     0     0     0]\n",
      " [    1    55  2892 ...,     0     0     0]\n",
      " [  547  3499    13 ...,     0     0     0]]\n",
      " 48/200 [======>.......................] - ETA: 68s - loss: 1.5561 - acc: 0.8063[[  884  4570     6 ...,     0     0     0]\n",
      " [    1   956   199 ...,     0     0     0]\n",
      " [   58    59   975 ...,     0     0     0]\n",
      " ..., \n",
      " [ 3213  4089     5 ...,     0     0     0]\n",
      " [11193   532  3291 ...,     0     0     0]\n",
      " [ 1525   398    13 ...,     0     0     0]]\n",
      " 49/200 [======>.......................] - ETA: 68s - loss: 1.5571 - acc: 0.8063[[1757  187   65 ...,    0    0    0]\n",
      " [ 444   36  921 ...,    0    0    0]\n",
      " [ 342  196   66 ...,    0    0    0]\n",
      " ..., \n",
      " [1896  187  182 ...,    0    0    0]\n",
      " [  13 2757  455 ...,    0    0    0]\n",
      " [   1 1669 3689 ...,    0    0    0]]\n",
      " 50/200 [======>.......................] - ETA: 67s - loss: 1.5585 - acc: 0.8062[[   1  881  509 ...,    0    0    0]\n",
      " [  12  296   49 ...,    0    0    0]\n",
      " [  15    7   61 ...,    0    0    0]\n",
      " ..., \n",
      " [ 119    4 1910 ...,    0    0    0]\n",
      " [1275  650  103 ...,    0    0    0]\n",
      " [  13   13    5 ...,    0    0    0]]\n",
      " 51/200 [======>.......................] - ETA: 67s - loss: 1.5591 - acc: 0.8062[[ 2387    93   281 ...,     0     0     0]\n",
      " [11592    13    27 ...,     0     0     0]\n",
      " [ 1236    34     3 ...,     0     0     0]\n",
      " ..., \n",
      " [   10   152   139 ...,     0     0     0]\n",
      " [   13   192    39 ...,     0     0     0]\n",
      " [   13  1844    13 ...,     0     0     0]]\n",
      " 52/200 [======>.......................] - ETA: 66s - loss: 1.5549 - acc: 0.8063[[  92   13 4159 ...,    0    0    0]\n",
      " [ 171  108   15 ...,    0    0    0]\n",
      " [2455  119 2005 ...,    0    0    0]\n",
      " ..., \n",
      " [ 309 4293    9 ...,    0    0    0]\n",
      " [2991 1171  100 ...,    0    0    0]\n",
      " [ 206   65   12 ...,    0    0    0]]\n",
      " 53/200 [======>.......................] - ETA: 66s - loss: 1.5468 - acc: 0.8070[[ 224    9  539 ...,    0    0    0]\n",
      " [   1   13  223 ...,    0    0    0]\n",
      " [ 978 4090   14 ...,    0    0    0]\n",
      " ..., \n",
      " [6373   11  694 ...,    0    0    0]\n",
      " [   1 3530  692 ...,    0    0    0]\n",
      " [ 131  573  478 ...,    0    0    0]]\n",
      " 54/200 [=======>......................] - ETA: 66s - loss: 1.5405 - acc: 0.8075[[ 391    5   17 ...,    0    0    0]\n",
      " [  17 1583   13 ...,    0    0    0]\n",
      " [   2 2442 1103 ...,    0    0    0]\n",
      " ..., \n",
      " [1248 3664 2995 ...,    0    0    0]\n",
      " [1862   27 2804 ...,    0    0    0]\n",
      " [3289  604 2206 ...,    0    0    0]]\n",
      " 55/200 [=======>......................] - ETA: 65s - loss: 1.5353 - acc: 0.8078[[    1   132   509 ...,     0     0     0]\n",
      " [    4   173   472 ...,     0     0     0]\n",
      " [   80   160    67 ...,     0     0     0]\n",
      " ..., \n",
      " [ 7394  6442    14 ...,     0     0     0]\n",
      " [ 3597  7808   715 ...,     0     0     0]\n",
      " [ 2966 10273    13 ...,     0     0     0]]\n",
      " 56/200 [=======>......................] - ETA: 65s - loss: 1.5299 - acc: 0.8081[[11032    13   289 ...,     0     0     0]\n",
      " [   15   247  4604 ...,     0     0     0]\n",
      " [    4     2   430 ...,     0     0     0]\n",
      " ..., \n",
      " [   13    13    27 ...,     0     0     0]\n",
      " [    1  1912  3553 ...,     0     0     0]\n",
      " [ 1339  1553    27 ...,     0     0     0]]\n",
      " 57/200 [=======>......................] - ETA: 64s - loss: 1.5267 - acc: 0.8083[[   1 4023   21 ...,    0    0    0]\n",
      " [   1  884 1054 ...,    0    0    0]\n",
      " [  55    7 1263 ...,    0    0    0]\n",
      " ..., \n",
      " [   2 1373   13 ...,    0    0    0]\n",
      " [   2  633  417 ...,    0    0    0]\n",
      " [   1  456  732 ...,    0    0    0]]\n",
      " 58/200 [=======>......................] - ETA: 64s - loss: 1.5232 - acc: 0.8086[[  55    7 4244 ...,    0    0    0]\n",
      " [  26   21  691 ...,    0    0    0]\n",
      " [ 425  217   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 626 2846    7 ...,    0    0    0]\n",
      " [ 127   19  661 ...,    0    0    0]\n",
      " [   1 1610    5 ...,    0    0    0]]\n",
      " 59/200 [=======>......................] - ETA: 63s - loss: 1.5197 - acc: 0.8088[[ 545 2882  267 ...,    0    0    0]\n",
      " [ 488   11  336 ...,    0    0    0]\n",
      " [1546 1415 1270 ...,    0    0    0]\n",
      " ..., \n",
      " [  49 2455 9170 ...,    0    0    0]\n",
      " [1337   30   33 ...,    0    0    0]\n",
      " [ 987    7  705 ...,    0    0    0]]\n",
      " 60/200 [========>.....................] - ETA: 63s - loss: 1.5167 - acc: 0.8089[[  38  499  295 ...,    0    0    0]\n",
      " [4384  130  880 ...,    0    0    0]\n",
      " [1935  295 7857 ...,    0    0    0]\n",
      " ..., \n",
      " [ 116 2700    8 ...,    0    0    0]\n",
      " [4358   13 7852 ...,    0    0    0]\n",
      " [1172  720   13 ...,    0    0    0]]\n",
      " 61/200 [========>.....................] - ETA: 62s - loss: 1.5164 - acc: 0.8088[[1075  280    8 ...,    0    0    0]\n",
      " [   1  214   23 ...,    0    0    0]\n",
      " [ 987    6   36 ...,    0    0    0]\n",
      " ..., \n",
      " [ 485   13   19 ...,    0    0    0]\n",
      " [1753  135 1266 ...,    0    0    0]\n",
      " [3062    8 1597 ...,    0    0    0]]\n",
      " 62/200 [========>.....................] - ETA: 62s - loss: 1.5189 - acc: 0.8086[[3733   13 3322 ...,    0    0    0]\n",
      " [  15    7   48 ...,    0    0    0]\n",
      " [3674 2252    4 ...,    0    0    0]\n",
      " ..., \n",
      " [ 844  329   24 ...,    0    0    0]\n",
      " [ 109   26   67 ...,    0    0    0]\n",
      " [ 107   70   15 ...,    0    0    0]]\n",
      " 63/200 [========>.....................] - ETA: 62s - loss: 1.5175 - acc: 0.8089[[ 930 9779   14 ...,    0    0    0]\n",
      " [ 109   26  106 ...,    0    0    0]\n",
      " [1405    7 1096 ...,    0    0    0]\n",
      " ..., \n",
      " [ 390 3380   11 ...,    0    0    0]\n",
      " [ 790 2047    9 ...,    0    0    0]\n",
      " [ 131  488  103 ...,    0    0    0]]\n",
      " 64/200 [========>.....................] - ETA: 61s - loss: 1.5209 - acc: 0.8085[[1339 1553    9 ...,    0    0    0]\n",
      " [3194   13  165 ...,    0    0    0]\n",
      " [  13   13    9 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13  568 ...,    0    0    0]\n",
      " [4368 5452  265 ...,    0    0    0]\n",
      " [ 109  154   66 ...,    0    0    0]]\n",
      " 65/200 [========>.....................] - ETA: 61s - loss: 1.5223 - acc: 0.8084[[1597  196 2573 ...,    0    0    0]\n",
      " [  15   14 1237 ...,    0    0    0]\n",
      " [   1 3982   13 ...,    0    0    0]\n",
      " ..., \n",
      " [  16   22  355 ...,    0    0    0]\n",
      " [   2 2041 1874 ...,    0    0    0]\n",
      " [ 280 9433 4699 ...,    0    0    0]]\n",
      " 66/200 [========>.....................] - ETA: 60s - loss: 1.5258 - acc: 0.8081[[10386     4    34 ...,     0     0     0]\n",
      " [ 9006  2116     9 ...,     0     0     0]\n",
      " [    1  9067     5 ...,     0     0     0]\n",
      " ..., \n",
      " [ 8231  3112    13 ...,     0     0     0]\n",
      " [ 3279    11   385 ...,     0     0     0]\n",
      " [   44    13   857 ...,     0     0     0]]\n",
      " 67/200 [=========>....................] - ETA: 60s - loss: 1.5250 - acc: 0.8082[[10745   112    36 ...,     0     0     0]\n",
      " [    1   542     9 ...,     0     0     0]\n",
      " [   93    67     1 ...,     0     0     0]\n",
      " ..., \n",
      " [ 7442  2021  1913 ...,     0     0     0]\n",
      " [  107    70     1 ...,     0     0     0]\n",
      " [    4    64    82 ...,     0     0     0]]\n",
      " 68/200 [=========>....................] - ETA: 59s - loss: 1.5262 - acc: 0.8081[[   10    99  1044 ...,     0     0     0]\n",
      " [   15     9    48 ...,     0     0     0]\n",
      " [10062  6003     4 ...,     0     0     0]\n",
      " ..., \n",
      " [  165   349   252 ...,     0     0     0]\n",
      " [  949     3     1 ...,     0     0     0]\n",
      " [   26  2920    60 ...,     0     0     0]]\n",
      " 69/200 [=========>....................] - ETA: 59s - loss: 1.5303 - acc: 0.8077[[   1   13  400 ...,    0    0    0]\n",
      " [ 474    1 1475 ...,    0    0    0]\n",
      " [ 931  309   13 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   13    1 ...,    0    0    0]\n",
      " [  80  110    4 ...,    0    0    0]\n",
      " [   2 1762  368 ...,    0    0    0]]\n",
      " 70/200 [=========>....................] - ETA: 58s - loss: 1.5351 - acc: 0.8072[[ 531   23  149 ...,    0    0    0]\n",
      " [   1 2923  253 ...,    0    0    0]\n",
      " [4685   54   13 ...,    0    0    0]\n",
      " ..., \n",
      " [2965   13    7 ...,    0    0    0]\n",
      " [ 276   13   15 ...,    0    0    0]\n",
      " [   4    1 1161 ...,    0    0    0]]\n",
      " 71/200 [=========>....................] - ETA: 58s - loss: 1.5401 - acc: 0.8067[[ 350   21 2683 ...,    0    0    0]\n",
      " [2379  627  247 ...,    0    0    0]\n",
      " [   1 1341   86 ...,    0    0    0]\n",
      " ..., \n",
      " [  43 1798    5 ...,    0    0    0]\n",
      " [  15  448   29 ...,    0    0    0]\n",
      " [ 937   13    8 ...,    0    0    0]]\n",
      " 72/200 [=========>....................] - ETA: 58s - loss: 1.5431 - acc: 0.8063[[   3 4041    2 ...,    0    0    0]\n",
      " [  95    1   63 ...,    0    0    0]\n",
      " [   4 1408   13 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 2192  757 ...,    0    0    0]\n",
      " [ 893 3353 1117 ...,    0    0    0]\n",
      " [  34 1226   96 ...,    0    0    0]]\n",
      " 73/200 [=========>....................] - ETA: 57s - loss: 1.5416 - acc: 0.8066[[  49    5    1 ...,    0    0    0]\n",
      " [1500   13 6988 ...,    0    0    0]\n",
      " [   1  873   13 ...,    0    0    0]\n",
      " ..., \n",
      " [   4   13   13 ...,    0    0    0]\n",
      " [ 108   68   23 ...,    0    0    0]\n",
      " [ 232  725   14 ...,    0    0    0]]\n",
      " 74/200 [==========>...................] - ETA: 57s - loss: 1.5427 - acc: 0.8065[[  74    5    1 ...,    0    0    0]\n",
      " [ 187    5   13 ...,    0    0    0]\n",
      " [ 264  105   20 ...,    0    0    0]\n",
      " ..., \n",
      " [   4    1   78 ...,    0    0    0]\n",
      " [9224 1119  993 ...,    0    0    0]\n",
      " [ 221  230   13 ...,    0    0    0]]\n",
      " 75/200 [==========>...................] - ETA: 56s - loss: 1.5465 - acc: 0.8061[[  16  166   49 ...,    0    0    0]\n",
      " [   2 1983  302 ...,    0    0    0]\n",
      " [  13 1287   13 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13 1211 ...,    0    0    0]\n",
      " [5470    8   13 ...,    0    0    0]\n",
      " [4315 4331   81 ...,    0    0    0]]\n",
      " 76/200 [==========>...................] - ETA: 56s - loss: 1.5466 - acc: 0.8062[[   13    13    13 ...,     0     0     0]\n",
      " [  137     2  5678 ...,     0     0     0]\n",
      " [  721    74    13 ...,     0     0     0]\n",
      " ..., \n",
      " [ 9513 11644  2385 ...,     0     0     0]\n",
      " [  104  1340    80 ...,     0     0     0]\n",
      " [   85     1  3845 ...,     0     0     0]]\n",
      " 77/200 [==========>...................] - ETA: 55s - loss: 1.5457 - acc: 0.8064[[ 812   13    9 ...,    0    0    0]\n",
      " [6382 6947    9 ...,    0    0    0]\n",
      " [ 153  729  574 ...,    0    0    0]\n",
      " ..., \n",
      " [  89   23  702 ...,    0    0    0]\n",
      " [  13   23 5447 ...,    0    0    0]\n",
      " [ 299    5  474 ...,    0    0    0]]\n",
      " 78/200 [==========>...................] - ETA: 55s - loss: 1.5450 - acc: 0.8066[[   1 1676 4129 ...,    0    0    0]\n",
      " [  12    1 5062 ...,    0    0    0]\n",
      " [ 242   69  263 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   27 3418 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]]\n",
      " 79/200 [==========>...................] - ETA: 55s - loss: 1.5462 - acc: 0.8065[[  22  905 1755 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [   1 2065 2164 ...,    0    0    0]\n",
      " ..., \n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [   1  191    5 ...,    0    0    0]]\n",
      " 80/200 [===========>..................] - ETA: 54s - loss: 1.5460 - acc: 0.8066[[  58   59   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [   1 1522  433 ...,    0    0    0]\n",
      " ..., \n",
      " [ 214   23    1 ...,    0    0    0]\n",
      " [2079   12    1 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]]\n",
      " 81/200 [===========>..................] - ETA: 54s - loss: 1.5465 - acc: 0.8066[[ 140  609   73 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [   1   13 2164 ...,    0    0    0]\n",
      " ..., \n",
      " [ 444    9  155 ...,    0    0    0]\n",
      " [ 127   76    5 ...,    0    0    0]\n",
      " [7042 2036   75 ...,    0    0    0]]\n",
      " 82/200 [===========>..................] - ETA: 53s - loss: 1.5460 - acc: 0.8067[[    2    13   701 ...,     0     0     0]\n",
      " [ 1189   224     7 ...,     0     0     0]\n",
      " [  200     7   176 ...,     0     0     0]\n",
      " ..., \n",
      " [    2    13 10143 ...,     0     0     0]\n",
      " [   13    26   182 ...,     0     0     0]\n",
      " [   42  1808    29 ...,     0     0     0]]\n",
      " 83/200 [===========>..................] - ETA: 53s - loss: 1.5463 - acc: 0.8068[[ 176   66  115 ...,    0    0    0]\n",
      " [   1  102    7 ...,    0    0    0]\n",
      " [ 167   69 3369 ...,    0    0    0]\n",
      " ..., \n",
      " [ 167   13   21 ...,    0    0    0]\n",
      " [4370 1038    8 ...,    0    0    0]\n",
      " [   2   13  167 ...,    0    0    0]]\n",
      " 84/200 [===========>..................] - ETA: 52s - loss: 1.5469 - acc: 0.8067[[ 131  226  398 ...,    0    0    0]\n",
      " [   1   13 1438 ...,    0    0    0]\n",
      " [   1   13   38 ...,    0    0    0]\n",
      " ..., \n",
      " [ 491   26  113 ...,    0    0    0]\n",
      " [ 727  292   13 ...,    0    0    0]\n",
      " [1221   13  941 ...,    0    0    0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 85/200 [===========>..................] - ETA: 52s - loss: 1.5473 - acc: 0.8067[[ 109   26  113 ...,    0    0    0]\n",
      " [ 546 8112  200 ...,    0    0    0]\n",
      " [ 632  528  142 ...,    0    0    0]\n",
      " ..., \n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [   1   13   58 ...,    0    0    0]\n",
      " [1355 2777   13 ...,    0    0    0]]\n",
      " 86/200 [===========>..................] - ETA: 51s - loss: 1.5475 - acc: 0.8068[[9786 2086   13 ...,    0    0    0]\n",
      " [  13    4  429 ...,    0    0    0]\n",
      " [ 884   26  115 ...,    0    0    0]\n",
      " ..., \n",
      " [ 383   13   46 ...,    0    0    0]\n",
      " [1827   25  308 ...,    0    0    0]\n",
      " [  13 3689 3693 ...,    0    0    0]]\n",
      " 87/200 [============>.................] - ETA: 51s - loss: 1.5481 - acc: 0.8067[[  55  292  728 ...,    0    0    0]\n",
      " [  19  352   26 ...,    0    0    0]\n",
      " [8676   13    5 ...,    0    0    0]\n",
      " ..., \n",
      " [ 444 5335    1 ...,    0    0    0]\n",
      " [ 154   66    4 ...,    0    0    0]\n",
      " [1827   36 2934 ...,    0    0    0]]\n",
      " 88/200 [============>.................] - ETA: 50s - loss: 1.5495 - acc: 0.8066[[    1    19   352 ...,     0     0     0]\n",
      " [11098  3659     9 ...,     0     0     0]\n",
      " [  501   154    66 ...,     0     0     0]\n",
      " ..., \n",
      " [    1   529   223 ...,     0     0     0]\n",
      " [ 1454   100     1 ...,     0     0     0]\n",
      " [ 2405  7209   700 ...,     0     0     0]]\n",
      " 89/200 [============>.................] - ETA: 50s - loss: 1.5498 - acc: 0.8066[[   1   13   13 ...,    0    0    0]\n",
      " [   2  440  842 ...,    0    0    0]\n",
      " [ 255   73  240 ...,    0    0    0]\n",
      " ..., \n",
      " [ 109   26  115 ...,    0    0    0]\n",
      " [   1 2930   86 ...,    0    0    0]\n",
      " [3830 1927 1531 ...,    0    0    0]]\n",
      " 90/200 [============>.................] - ETA: 49s - loss: 1.5454 - acc: 0.8068[[  66    6    1 ...,    0    0    0]\n",
      " [ 726 2576 4672 ...,    0    0    0]\n",
      " [   2   13   12 ...,    0    0    0]\n",
      " ..., \n",
      " [  22   13  704 ...,    0    0    0]\n",
      " [   1   19  120 ...,    0    0    0]\n",
      " [2346 4931 7102 ...,    0    0    0]]\n",
      " 91/200 [============>.................] - ETA: 49s - loss: 1.5424 - acc: 0.8070[[   1  260  438 ...,    0    0    0]\n",
      " [ 849  394 1610 ...,    0    0    0]\n",
      " [ 356  767  484 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 3525  294 ...,    0    0    0]\n",
      " [  13 3323    9 ...,    0    0    0]\n",
      " [  10    2   13 ...,    0    0    0]]\n",
      " 92/200 [============>.................] - ETA: 49s - loss: 1.5384 - acc: 0.8073[[ 654  145  398 ...,    0    0    0]\n",
      " [   1 2181    8 ...,    0    0    0]\n",
      " [  49   64 4137 ...,    0    0    0]\n",
      " ..., \n",
      " [1337  217    1 ...,    0    0    0]\n",
      " [  15  336   64 ...,    0    0    0]\n",
      " [1536 4331   13 ...,    0    0    0]]\n",
      " 93/200 [============>.................] - ETA: 48s - loss: 1.5355 - acc: 0.8075[[4424 4371  227 ...,    0    0    0]\n",
      " [ 119  267  157 ...,    0    0    0]\n",
      " [4139  398 2129 ...,    0    0    0]\n",
      " ..., \n",
      " [2536 2391  212 ...,    0    0    0]\n",
      " [1224   69 4841 ...,    0    0    0]\n",
      " [   1   13  241 ...,    0    0    0]]\n",
      " 94/200 [=============>................] - ETA: 48s - loss: 1.5328 - acc: 0.8077[[3492 4168  766 ...,    0    0    0]\n",
      " [   1   13   86 ...,    0    0    0]\n",
      " [ 790 2426   11 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   11 2586 ...,    0    0    0]\n",
      " [ 206   66   21 ...,    0    0    0]\n",
      " [1282    7  732 ...,    0    0    0]]\n",
      " 95/200 [=============>................] - ETA: 47s - loss: 1.5303 - acc: 0.8080[[6829 5421    9 ...,    0    0    0]\n",
      " [3153 1924    4 ...,    0    0    0]\n",
      " [  13   13  312 ...,    0    0    0]\n",
      " ..., \n",
      " [6292 9645   11 ...,    0    0    0]\n",
      " [1742    7 6252 ...,    0    0    0]\n",
      " [1331   11 1992 ...,    0    0    0]]\n",
      " 96/200 [=============>................] - ETA: 47s - loss: 1.5276 - acc: 0.8081[[  150  1697    13 ...,     0     0     0]\n",
      " [ 4458     8 11411 ...,     0     0     0]\n",
      " [  158   268     4 ...,     0     0     0]\n",
      " ..., \n",
      " [    1    13   680 ...,     0     0     0]\n",
      " [    1  2657   680 ...,     0     0     0]\n",
      " [ 6308   694  5350 ...,     0     0     0]]\n",
      " 97/200 [=============>................] - ETA: 46s - loss: 1.5256 - acc: 0.8083[[ 623  157   22 ...,    0    0    0]\n",
      " [  69  297   13 ...,    0    0    0]\n",
      " [ 344   83   15 ...,    0    0    0]\n",
      " ..., \n",
      " [   2   13  282 ...,    0    0    0]\n",
      " [  13   13    1 ...,    0    0    0]\n",
      " [  13   13 2385 ...,    0    0    0]]\n",
      " 98/200 [=============>................] - ETA: 46s - loss: 1.5236 - acc: 0.8084[[ 727   30   25 ...,    0    0    0]\n",
      " [ 119  462    8 ...,    0    0    0]\n",
      " [ 719  137    1 ...,    0    0    0]\n",
      " ..., \n",
      " [  13 8281 2278 ...,    0    0    0]\n",
      " [   2   13 1489 ...,    0    0    0]\n",
      " [ 708   82    2 ...,    0    0    0]]\n",
      " 99/200 [=============>................] - ETA: 45s - loss: 1.5225 - acc: 0.8085[[ 547 1206    2 ...,    0    0    0]\n",
      " [  19  120  662 ...,    0    0    0]\n",
      " [   2 1779  321 ...,    0    0    0]\n",
      " ..., \n",
      " [6404   27 5918 ...,    0    0    0]\n",
      " [1680   13  484 ...,    0    0    0]\n",
      " [   1  167  117 ...,    0    0    0]]\n",
      "100/200 [==============>...............] - ETA: 45s - loss: 1.5232 - acc: 0.8084[[1046   11  510 ...,    0    0    0]\n",
      " [  15    7  461 ...,    0    0    0]\n",
      " [  15 1272 1322 ...,    0    0    0]\n",
      " ..., \n",
      " [ 116    5    1 ...,    0    0    0]\n",
      " [5209   13   83 ...,    0    0    0]\n",
      " [   1 1547 1127 ...,    0    0    0]]\n",
      "101/200 [==============>...............] - ETA: 45s - loss: 1.5255 - acc: 0.8083[[  790  3805    11 ...,     0     0     0]\n",
      " [ 1635 10089    13 ...,     0     0     0]\n",
      " [ 1052     8  1465 ...,     0     0     0]\n",
      " ..., \n",
      " [  206   113    24 ...,     0     0     0]\n",
      " [  220    13    21 ...,     0     0     0]\n",
      " [   13    13     7 ...,     0     0     0]]\n",
      "102/200 [==============>...............] - ETA: 44s - loss: 1.5288 - acc: 0.8079[[4800 4919  247 ...,    0    0    0]\n",
      " [1696  729    8 ...,    0    0    0]\n",
      " [ 545 1007  674 ...,    0    0    0]\n",
      " ..., \n",
      " [7710   13   51 ...,    0    0    0]\n",
      " [ 108   68  410 ...,    0    0    0]\n",
      " [ 232 3054    9 ...,    0    0    0]]\n",
      "103/200 [==============>...............] - ETA: 44s - loss: 1.5303 - acc: 0.8078[[ 1332  9266    27 ...,     0     0     0]\n",
      " [    1   288 11255 ...,     0     0     0]\n",
      " [    1   580   473 ...,     0     0     0]\n",
      " ..., \n",
      " [  353  4319     7 ...,     0     0     0]\n",
      " [   70    15   283 ...,     0     0     0]\n",
      " [  353    13    14 ...,     0     0     0]]\n",
      "104/200 [==============>...............] - ETA: 43s - loss: 1.5316 - acc: 0.8077[[3252 3114   11 ...,    0    0    0]\n",
      " [   1  535  765 ...,    0    0    0]\n",
      " [1490 3312 1528 ...,    0    0    0]\n",
      " ..., \n",
      " [   2  131 4181 ...,    0    0    0]\n",
      " [   1 6409  360 ...,    0    0    0]\n",
      " [4181 2149   21 ...,    0    0    0]]\n",
      "105/200 [==============>...............] - ETA: 43s - loss: 1.5309 - acc: 0.8078[[ 1802    13    68 ...,     0     0     0]\n",
      " [   13 11267  8560 ...,     0     0     0]\n",
      " [  213    14  1099 ...,     0     0     0]\n",
      " ..., \n",
      " [   15     7    48 ...,     0     0     0]\n",
      " [  133    39   321 ...,     0     0     0]\n",
      " [    1  1942     5 ...,     0     0     0]]\n",
      "106/200 [==============>...............] - ETA: 42s - loss: 1.5305 - acc: 0.8079[[9231  112    5 ...,    0    0    0]\n",
      " [  13   13   44 ...,    0    0    0]\n",
      " [  68  114  321 ...,    0    0    0]\n",
      " ..., \n",
      " [  13  104   21 ...,    0    0    0]\n",
      " [  93  265  337 ...,    0    0    0]\n",
      " [ 171  108   13 ...,    0    0    0]]\n",
      "107/200 [===============>..............] - ETA: 42s - loss: 1.5325 - acc: 0.8077[[   1  166  371 ...,    0    0    0]\n",
      " [  13  572 3510 ...,    0    0    0]\n",
      " [   1 3776   10 ...,    0    0    0]\n",
      " ..., \n",
      " [  89   67    2 ...,    0    0    0]\n",
      " [ 137  336   18 ...,    0    0    0]\n",
      " [ 150  466  142 ...,    0    0    0]]\n",
      "108/200 [===============>..............] - ETA: 41s - loss: 1.5347 - acc: 0.8074[[   42   471    39 ...,     0     0     0]\n",
      " [    1   214     9 ...,     0     0     0]\n",
      " [    1    13    13 ...,     0     0     0]\n",
      " ..., \n",
      " [   41  2088  4006 ...,     0     0     0]\n",
      " [    1  2538  2476 ...,     0     0     0]\n",
      " [   13  1442 10169 ...,     0     0     0]]\n",
      "109/200 [===============>..............] - ETA: 41s - loss: 1.5374 - acc: 0.8071[[ 301 1351    3 ...,    0    0    0]\n",
      " [2860   13 1184 ...,    0    0    0]\n",
      " [ 719  577   10 ...,    0    0    0]\n",
      " ..., \n",
      " [ 156  213   27 ...,    0    0    0]\n",
      " [ 751 2527  532 ...,    0    0    0]\n",
      " [  80   41  805 ...,    0    0    0]]\n",
      "110/200 [===============>..............] - ETA: 40s - loss: 1.5406 - acc: 0.8068[[   1 1761    5 ...,    0    0    0]\n",
      " [ 194   63  144 ...,    0    0    0]\n",
      " [1054    9   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 280   13   13 ...,    0    0    0]\n",
      " [ 693    2  181 ...,    0    0    0]\n",
      " [ 474  572    7 ...,    0    0    0]]\n",
      "111/200 [===============>..............] - ETA: 40s - loss: 1.5406 - acc: 0.8068[[  89    7    2 ...,    0    0    0]\n",
      " [   1  662  934 ...,    0    0    0]\n",
      " [ 108   15   67 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   99 4777 ...,    0    0    0]\n",
      " [1232 3185   13 ...,    0    0    0]\n",
      " [1036   16  728 ...,    0    0    0]]\n",
      "112/200 [===============>..............] - ETA: 39s - loss: 1.5401 - acc: 0.8069[[   2  487    5 ...,    0    0    0]\n",
      " [   1   38  949 ...,    0    0    0]\n",
      " [5734   13   14 ...,    0    0    0]\n",
      " ..., \n",
      " [1000 2290    8 ...,    0    0    0]\n",
      " [   1   38   62 ...,    0    0    0]\n",
      " [ 250 1318  105 ...,    0    0    0]]\n",
      "113/200 [===============>..............] - ETA: 39s - loss: 1.5418 - acc: 0.8067[[ 194   63  144 ...,    0    0    0]\n",
      " [  10   92  888 ...,    0    0    0]\n",
      " [   1  467    5 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  170   29 ...,    0    0    0]\n",
      " [  80   41 1018 ...,    0    0    0]\n",
      " [  10   13  558 ...,    0    0    0]]\n",
      "114/200 [================>.............] - ETA: 39s - loss: 1.5425 - acc: 0.8067[[ 823   13    1 ...,    0    0    0]\n",
      " [ 341   13  104 ...,    0    0    0]\n",
      " [2308   13 6010 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13   13 ...,    0    0    0]\n",
      " [  56    2  497 ...,    0    0    0]\n",
      " [  13  458 7740 ...,    0    0    0]]\n",
      "115/200 [================>.............] - ETA: 38s - loss: 1.5425 - acc: 0.8067[[4496 3567  385 ...,    0    0    0]\n",
      " [  78   94   13 ...,    0    0    0]\n",
      " [3007  256    1 ...,    0    0    0]\n",
      " ..., \n",
      " [   4   17 3237 ...,    0    0    0]\n",
      " [  92   63  144 ...,    0    0    0]\n",
      " [  49   63  144 ...,    0    0    0]]\n",
      "116/200 [================>.............] - ETA: 38s - loss: 1.5419 - acc: 0.8069[[1753  676 6299 ...,    0    0    0]\n",
      " [   2 3272   74 ...,    0    0    0]\n",
      " [  13    7 4633 ...,    0    0    0]\n",
      " ..., \n",
      " [  13  104   21 ...,    0    0    0]\n",
      " [ 309 4211    9 ...,    0    0    0]\n",
      " [2071   11  147 ...,    0    0    0]]\n",
      "117/200 [================>.............] - ETA: 37s - loss: 1.5428 - acc: 0.8069[[ 379  177   13 ...,    0    0    0]\n",
      " [  99  177   13 ...,    0    0    0]\n",
      " [ 973   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [  18 1780   10 ...,    0    0    0]\n",
      " [  15  128   48 ...,    0    0    0]\n",
      " [  13   13   81 ...,    0    0    0]]\n",
      "118/200 [================>.............] - ETA: 37s - loss: 1.5432 - acc: 0.8069[[   1  885  981 ...,    0    0    0]\n",
      " [  13  133   68 ...,    0    0    0]\n",
      " [2318  133   92 ...,    0    0    0]\n",
      " ..., \n",
      " [  13 1186    4 ...,    0    0    0]\n",
      " [  89   23  155 ...,    0    0    0]\n",
      " [  55   27   13 ...,    0    0    0]]\n",
      "119/200 [================>.............] - ETA: 36s - loss: 1.5428 - acc: 0.8070[[  58   59   26 ...,    0    0    0]\n",
      " [ 454  883 2440 ...,    0    0    0]\n",
      " [   1   13  518 ...,    0    0    0]\n",
      " ..., \n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [5182   11  130 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]]\n",
      "120/200 [=================>............] - ETA: 36s - loss: 1.5429 - acc: 0.8071[[1267 7727 2130 ...,    0    0    0]\n",
      " [   1  220   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  187  635 ...,    0    0    0]\n",
      " [   2 1267 1547 ...,    0    0    0]\n",
      " [2239  720 2558 ...,    0    0    0]]\n",
      "121/200 [=================>............] - ETA: 35s - loss: 1.5440 - acc: 0.8070[[   58    59    26 ...,     0     0     0]\n",
      " [  681  1281    13 ...,     0     0     0]\n",
      " [  318     7    49 ...,     0     0     0]\n",
      " ..., \n",
      " [  844     8   284 ...,     0     0     0]\n",
      " [   58    59    26 ...,     0     0     0]\n",
      " [10907    46     5 ...,     0     0     0]]\n",
      "122/200 [=================>............] - ETA: 35s - loss: 1.5447 - acc: 0.8069[[ 318  329   10 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " ..., \n",
      " [   2  806    8 ...,    0    0    0]\n",
      " [  13   26  115 ...,    0    0    0]\n",
      " [   2 1135   13 ...,    0    0    0]]\n",
      "123/200 [=================>............] - ETA: 34s - loss: 1.5450 - acc: 0.8069[[1811 2457    1 ...,    0    0    0]\n",
      " [3730  326  209 ...,    0    0    0]\n",
      " [1282    7  732 ...,    0    0    0]\n",
      " ..., \n",
      " [4244  404   27 ...,    0    0    0]\n",
      " [ 481   66  106 ...,    0    0    0]\n",
      " [   1  214   23 ...,    0    0    0]]\n",
      "124/200 [=================>............] - ETA: 34s - loss: 1.5454 - acc: 0.8069[[ 167 2079  664 ...,    0    0    0]\n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [ 167 2004  336 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13 1997 ...,    0    0    0]\n",
      " [ 913    7 1014 ...,    0    0    0]\n",
      " [  55    7  536 ...,    0    0    0]]\n",
      "125/200 [=================>............] - ETA: 34s - loss: 1.5461 - acc: 0.8069[[    2    19  5809 ...,     0     0     0]\n",
      " [    1   884   223 ...,     0     0     0]\n",
      " [    2   258     5 ...,     0     0     0]\n",
      " ..., \n",
      " [    1  9295     5 ...,     0     0     0]\n",
      " [10274    13  1362 ...,     0     0     0]\n",
      " [    1   367  2161 ...,     0     0     0]]\n",
      "126/200 [=================>............] - ETA: 33s - loss: 1.5467 - acc: 0.8068[[   1   13 1333 ...,    0    0    0]\n",
      " [   1  367 2161 ...,    0    0    0]\n",
      " [ 481   66 1160 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   11   45 ...,    0    0    0]\n",
      " [4943   13   11 ...,    0    0    0]\n",
      " [  10    1  156 ...,    0    0    0]]\n",
      "127/200 [==================>...........] - ETA: 33s - loss: 1.5480 - acc: 0.8067[[  55  292  607 ...,    0    0    0]\n",
      " [  55   25  292 ...,    0    0    0]\n",
      " [ 116   13 3115 ...,    0    0    0]\n",
      " ..., \n",
      " [   2  712  778 ...,    0    0    0]\n",
      " [   1   91 3267 ...,    0    0    0]\n",
      " [  15    7  211 ...,    0    0    0]]\n",
      "128/200 [==================>...........] - ETA: 32s - loss: 1.5491 - acc: 0.8066[[1896  187   66 ...,    0    0    0]\n",
      " [   1  601    5 ...,    0    0    0]\n",
      " [ 342  196   66 ...,    0    0    0]\n",
      " ..., \n",
      " [  15 1272   29 ...,    0    0    0]\n",
      " [   1 1606 2590 ...,    0    0    0]\n",
      " [ 553 5541   23 ...,    0    0    0]]\n",
      "129/200 [==================>...........] - ETA: 32s - loss: 1.5489 - acc: 0.8066[[ 131  522 7535 ...,    0    0    0]\n",
      " [   2   94  144 ...,    0    0    0]\n",
      " [5180    8  717 ...,    0    0    0]\n",
      " ..., \n",
      " [  13  236  477 ...,    0    0    0]\n",
      " [   2  117    4 ...,    0    0    0]\n",
      " [3838    8 6077 ...,    0    0    0]]\n",
      "130/200 [==================>...........] - ETA: 31s - loss: 1.5464 - acc: 0.8067[[9096 8866    7 ...,    0    0    0]\n",
      " [   2   13 3220 ...,    0    0    0]\n",
      " [   1  145  218 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 3839  737 ...,    0    0    0]\n",
      " [ 119 4410    2 ...,    0    0    0]\n",
      " [3516 1053   33 ...,    0    0    0]]\n",
      "131/200 [==================>...........] - ETA: 31s - loss: 1.5441 - acc: 0.8069[[ 365    7  326 ...,    0    0    0]\n",
      " [  13  248   85 ...,    0    0    0]\n",
      " [ 116 2185   10 ...,    0    0    0]\n",
      " ..., \n",
      " [  13  811 1415 ...,    0    0    0]\n",
      " [2081    6   57 ...,    0    0    0]\n",
      " [3409   13  969 ...,    0    0    0]]\n",
      "132/200 [==================>...........] - ETA: 30s - loss: 1.5415 - acc: 0.8071[[   2   13 3238 ...,    0    0    0]\n",
      " [ 514 2246   13 ...,    0    0    0]\n",
      " [  22  282   83 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  161 7867 ...,    0    0    0]\n",
      " [ 603 5303    7 ...,    0    0    0]\n",
      " [ 119   30   28 ...,    0    0    0]]\n",
      "133/200 [==================>...........] - ETA: 30s - loss: 1.5397 - acc: 0.8073[[  89    7    2 ...,    0    0    0]\n",
      " [1600    8  444 ...,    0    0    0]\n",
      " [ 425    8 2535 ...,    0    0    0]\n",
      " ..., \n",
      " [ 187    4  109 ...,    0    0    0]\n",
      " [  13 8417   13 ...,    0    0    0]\n",
      " [3398 8587    7 ...,    0    0    0]]\n",
      "134/200 [===================>..........] - ETA: 29s - loss: 1.5371 - acc: 0.8075[[  607   816   878 ...,     0     0     0]\n",
      " [    2    13   905 ...,     0     0     0]\n",
      " [    2   877   172 ...,     0     0     0]\n",
      " ..., \n",
      " [  190  1455 11957 ...,     0     0     0]\n",
      " [ 1792   455     3 ...,     0     0     0]\n",
      " [  131   721   765 ...,     0     0     0]]\n",
      "135/200 [===================>..........] - ETA: 29s - loss: 1.5358 - acc: 0.8075[[  69 1710   13 ...,    0    0    0]\n",
      " [2486   13   13 ...,    0    0    0]\n",
      " [ 185  102   67 ...,    0    0    0]\n",
      " ..., \n",
      " [2523  398 4359 ...,    0    0    0]\n",
      " [1431  450   13 ...,    0    0    0]\n",
      " [  13  199 1448 ...,    0    0    0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/200 [===================>..........] - ETA: 29s - loss: 1.5333 - acc: 0.8077[[ 131 1194  295 ...,    0    0    0]\n",
      " [ 365    7  326 ...,    0    0    0]\n",
      " [2237 4702 1748 ...,    0    0    0]\n",
      " ..., \n",
      " [ 389  209 6340 ...,    0    0    0]\n",
      " [3207  128   20 ...,    0    0    0]\n",
      " [  13   13 1465 ...,    0    0    0]]\n",
      "137/200 [===================>..........] - ETA: 28s - loss: 1.5317 - acc: 0.8078[[ 425    7  169 ...,    0    0    0]\n",
      " [8008  565  444 ...,    0    0    0]\n",
      " [ 978 4090    7 ...,    0    0    0]\n",
      " ..., \n",
      " [ 905  162 2004 ...,    0    0    0]\n",
      " [5171   66 1869 ...,    0    0    0]\n",
      " [   2  943  258 ...,    0    0    0]]\n",
      "138/200 [===================>..........] - ETA: 28s - loss: 1.5303 - acc: 0.8079[[ 1848    11  1632 ...,     0     0     0]\n",
      " [ 1625   266    13 ...,     0     0     0]\n",
      " [   26    65  1709 ...,     0     0     0]\n",
      " ..., \n",
      " [  131  1194   295 ...,     0     0     0]\n",
      " [  893 10455  2073 ...,     0     0     0]\n",
      " [  154    66     6 ...,     0     0     0]]\n",
      "139/200 [===================>..........] - ETA: 27s - loss: 1.5293 - acc: 0.8080[[ 155   29    1 ...,    0    0    0]\n",
      " [  13   13    5 ...,    0    0    0]\n",
      " [  13 8751   23 ...,    0    0    0]\n",
      " ..., \n",
      " [9174 7457 3359 ...,    0    0    0]\n",
      " [1717   13  100 ...,    0    0    0]\n",
      " [1558  455    3 ...,    0    0    0]]\n",
      "140/200 [====================>.........] - ETA: 27s - loss: 1.5303 - acc: 0.8079[[  913     7  2134 ...,     0     0     0]\n",
      " [   13    68   871 ...,     0     0     0]\n",
      " [    1   221   230 ...,     0     0     0]\n",
      " ..., \n",
      " [   89     7     2 ...,     0     0     0]\n",
      " [   13  2459 10892 ...,     0     0     0]\n",
      " [  171    70    60 ...,     0     0     0]]\n",
      "141/200 [====================>.........] - ETA: 26s - loss: 1.5300 - acc: 0.8080[[5631 5868 1796 ...,    0    0    0]\n",
      " [ 131   69  263 ...,    0    0    0]\n",
      " [5040 1880  204 ...,    0    0    0]\n",
      " ..., \n",
      " [3400    8 6841 ...,    0    0    0]\n",
      " [  15   14   39 ...,    0    0    0]\n",
      " [ 119   30   36 ...,    0    0    0]]\n",
      "142/200 [====================>.........] - ETA: 26s - loss: 1.5313 - acc: 0.8078[[ 119  616  127 ...,    0    0    0]\n",
      " [   2 5523 3632 ...,    0    0    0]\n",
      " [   1  304 3255 ...,    0    0    0]\n",
      " ..., \n",
      " [ 140  150 4086 ...,    0    0    0]\n",
      " [   1 4874    5 ...,    0    0    0]\n",
      " [  13    9 2370 ...,    0    0    0]]\n",
      "143/200 [====================>.........] - ETA: 25s - loss: 1.5322 - acc: 0.8077[[ 444   83   40 ...,    0    0    0]\n",
      " [1634   13   13 ...,    0    0    0]\n",
      " [   1  248  252 ...,    0    0    0]\n",
      " ..., \n",
      " [ 291  126 1512 ...,    0    0    0]\n",
      " [   2 4493  167 ...,    0    0    0]\n",
      " [ 501  154   66 ...,    0    0    0]]\n",
      "144/200 [====================>.........] - ETA: 25s - loss: 1.5330 - acc: 0.8076[[  13  119   21 ...,    0    0    0]\n",
      " [   2  501 5214 ...,    0    0    0]\n",
      " [ 501    6   25 ...,    0    0    0]\n",
      " ..., \n",
      " [  15   14 1676 ...,    0    0    0]\n",
      " [2215  170   86 ...,    0    0    0]\n",
      " [9754 6508  276 ...,    0    0    0]]\n",
      "145/200 [====================>.........] - ETA: 24s - loss: 1.5340 - acc: 0.8076[[1115 3628   23 ...,    0    0    0]\n",
      " [  70   13   13 ...,    0    0    0]\n",
      " [  34    9    1 ...,    0    0    0]\n",
      " ..., \n",
      " [ 104   21  184 ...,    0    0    0]\n",
      " [  13  199    9 ...,    0    0    0]\n",
      " [ 137  336   18 ...,    0    0    0]]\n",
      "146/200 [====================>.........] - ETA: 24s - loss: 1.5337 - acc: 0.8076[[  13   13   14 ...,    0    0    0]\n",
      " [   1 1456  310 ...,    0    0    0]\n",
      " [   2  131  883 ...,    0    0    0]\n",
      " ..., \n",
      " [2603    6    1 ...,    0    0    0]\n",
      " [2565    1  482 ...,    0    0    0]\n",
      " [7079 1435    4 ...,    0    0    0]]\n",
      "147/200 [=====================>........] - ETA: 24s - loss: 1.5351 - acc: 0.8074[[    1    13 10332 ...,     0     0     0]\n",
      " [   42    14     1 ...,     0     0     0]\n",
      " [  149   495    13 ...,     0     0     0]\n",
      " ..., \n",
      " [   34   629    14 ...,     0     0     0]\n",
      " [   89     7     2 ...,     0     0     0]\n",
      " [    1  2013   312 ...,     0     0     0]]\n",
      "148/200 [=====================>........] - ETA: 23s - loss: 1.5365 - acc: 0.8073[[  245  2713    13 ...,     0     0     0]\n",
      " [   13  8595    14 ...,     0     0     0]\n",
      " [ 2731    34    77 ...,     0     0     0]\n",
      " ..., \n",
      " [   13   104  1108 ...,     0     0     0]\n",
      " [   13   159 10506 ...,     0     0     0]\n",
      " [ 1675  3294     9 ...,     0     0     0]]\n",
      "149/200 [=====================>........] - ETA: 23s - loss: 1.5388 - acc: 0.8071[[ 13 492  12 ...,   0   0   0]\n",
      " [ 48 194 629 ...,   0   0   0]\n",
      " [264   7  53 ...,   0   0   0]\n",
      " ..., \n",
      " [ 13  13  13 ...,   0   0   0]\n",
      " [108  68 253 ...,   0   0   0]\n",
      " [ 13  13 221 ...,   0   0   0]]\n",
      "150/200 [=====================>........] - ETA: 22s - loss: 1.5416 - acc: 0.8068[[ 1395  8395    14 ...,     0     0     0]\n",
      " [ 2333   610   249 ...,     0     0     0]\n",
      " [  116   350    21 ...,     0     0     0]\n",
      " ..., \n",
      " [ 3599    13   198 ...,     0     0     0]\n",
      " [    2 10742     5 ...,     0     0     0]\n",
      " [ 1332    13     9 ...,     0     0     0]]\n",
      "151/200 [=====================>........] - ETA: 22s - loss: 1.5418 - acc: 0.8068[[ 281  713   13 ...,    0    0    0]\n",
      " [6628   13    8 ...,    0    0    0]\n",
      " [  10  790 2047 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  177  676 ...,    0    0    0]\n",
      " [ 730   13    1 ...,    0    0    0]\n",
      " [  18  318    9 ...,    0    0    0]]\n",
      "152/200 [=====================>........] - ETA: 21s - loss: 1.5419 - acc: 0.8068[[   1  576 5200 ...,    0    0    0]\n",
      " [1066  912   23 ...,    0    0    0]\n",
      " [  89   11  184 ...,    0    0    0]\n",
      " ..., \n",
      " [ 234  402  144 ...,    0    0    0]\n",
      " [6839 1112   83 ...,    0    0    0]\n",
      " [ 159 3747    9 ...,    0    0    0]]\n",
      "153/200 [=====================>........] - ETA: 21s - loss: 1.5430 - acc: 0.8067[[ 746  117    8 ...,    0    0    0]\n",
      " [ 328   13   15 ...,    0    0    0]\n",
      " [  34   61   13 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   13 1846 ...,    0    0    0]\n",
      " [   2  999  144 ...,    0    0    0]\n",
      " [   4    1  204 ...,    0    0    0]]\n",
      "154/200 [======================>.......] - ETA: 20s - loss: 1.5438 - acc: 0.8066[[  13   26  106 ...,    0    0    0]\n",
      " [   1 2352   86 ...,    0    0    0]\n",
      " [1014   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [  18   69   13 ...,    0    0    0]\n",
      " [ 108   68 1632 ...,    0    0    0]\n",
      " [  89   23   39 ...,    0    0    0]]\n",
      "155/200 [======================>.......] - ETA: 20s - loss: 1.5438 - acc: 0.8066[[3599   13   13 ...,    0    0    0]\n",
      " [4956   13 1836 ...,    0    0    0]\n",
      " [   1   13 6850 ...,    0    0    0]\n",
      " ..., \n",
      " [ 415    6  210 ...,    0    0    0]\n",
      " [ 193    7   13 ...,    0    0    0]\n",
      " [   1  131  523 ...,    0    0    0]]\n",
      "156/200 [======================>.......] - ETA: 19s - loss: 1.5436 - acc: 0.8067[[   1 5684 9095 ...,    0    0    0]\n",
      " [2568 5828    9 ...,    0    0    0]\n",
      " [5543 1537 1471 ...,    0    0    0]\n",
      " ..., \n",
      " [   2  259  290 ...,    0    0    0]\n",
      " [  89   23 2497 ...,    0    0    0]\n",
      " [ 104 1629    1 ...,    0    0    0]]\n",
      "157/200 [======================>.......] - ETA: 19s - loss: 1.5446 - acc: 0.8067[[   1   13 1978 ...,    0    0    0]\n",
      " [ 697 2427  798 ...,    0    0    0]\n",
      " [ 333   13 1334 ...,    0    0    0]\n",
      " ..., \n",
      " [ 805   34   94 ...,    0    0    0]\n",
      " [  15    7   13 ...,    0    0    0]\n",
      " [6306 5860   13 ...,    0    0    0]]\n",
      "158/200 [======================>.......] - ETA: 19s - loss: 1.5450 - acc: 0.8067[[ 316  583 1622 ...,    0    0    0]\n",
      " [  34   94    7 ...,    0    0    0]\n",
      " [  78 1362   13 ...,    0    0    0]\n",
      " ..., \n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [5163 1765   29 ...,    0    0    0]]\n",
      "159/200 [======================>.......] - ETA: 18s - loss: 1.5454 - acc: 0.8067[[2574    7   19 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " ..., \n",
      " [6152   69 3226 ...,    0    0    0]\n",
      " [3222   13  163 ...,    0    0    0]\n",
      " [   1   13  191 ...,    0    0    0]]\n",
      "160/200 [=======================>......] - ETA: 18s - loss: 1.5458 - acc: 0.8066[[ 131  284 2368 ...,    0    0    0]\n",
      " [2065   69 5102 ...,    0    0    0]\n",
      " [ 167   13 3369 ...,    0    0    0]\n",
      " ..., \n",
      " [1324 1657   27 ...,    0    0    0]\n",
      " [ 284  100    1 ...,    0    0    0]\n",
      " [2808 2755  130 ...,    0    0    0]]\n",
      "161/200 [=======================>......] - ETA: 17s - loss: 1.5463 - acc: 0.8066[[6030   13   12 ...,    0    0    0]\n",
      " [4759   19  324 ...,    0    0    0]\n",
      " [   2   19 3634 ...,    0    0    0]\n",
      " ..., \n",
      " [1434   27 4474 ...,    0    0    0]\n",
      " [   2  852    3 ...,    0    0    0]\n",
      " [   1   19  352 ...,    0    0    0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/200 [=======================>......] - ETA: 17s - loss: 1.5467 - acc: 0.8066[[   1  143    5 ...,    0    0    0]\n",
      " [  55    8 1792 ...,    0    0    0]\n",
      " [   1  132  509 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13 1847 ...,    0    0    0]\n",
      " [   1  469    8 ...,    0    0    0]\n",
      " [ 140  553    8 ...,    0    0    0]]\n",
      "163/200 [=======================>......] - ETA: 16s - loss: 1.5473 - acc: 0.8065[[ 523 1898  925 ...,    0    0    0]\n",
      " [   2 1569 2114 ...,    0    0    0]\n",
      " [   1 6528  191 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [3050   55  100 ...,    0    0    0]\n",
      " [ 316   55    7 ...,    0    0    0]]\n",
      "164/200 [=======================>......] - ETA: 16s - loss: 1.5477 - acc: 0.8065[[3258    4 2081 ...,    0    0    0]\n",
      " [   1   47 6189 ...,    0    0    0]\n",
      " [1434    7  161 ...,    0    0    0]\n",
      " ..., \n",
      " [   2  145  608 ...,    0    0    0]\n",
      " [ 561 3076   36 ...,    0    0    0]\n",
      " [   1  220   73 ...,    0    0    0]]\n",
      "165/200 [=======================>......] - ETA: 15s - loss: 1.5479 - acc: 0.8065[[   1   13   11 ...,    0    0    0]\n",
      " [   2   58   59 ...,    0    0    0]\n",
      " [   1  220   91 ...,    0    0    0]\n",
      " ..., \n",
      " [ 366    6    1 ...,    0    0    0]\n",
      " [ 306 3262   13 ...,    0    0    0]\n",
      " [   1 1363  199 ...,    0    0    0]]\n",
      "166/200 [=======================>......] - ETA: 15s - loss: 1.5479 - acc: 0.8065[[   58    59    26 ...,     0     0     0]\n",
      " [   58    59    26 ...,     0     0     0]\n",
      " [   41     5  1056 ...,     0     0     0]\n",
      " ..., \n",
      " [   13    13    14 ...,     0     0     0]\n",
      " [ 1248 10206 10206 ...,     0     0     0]\n",
      " [   13     8  5949 ...,     0     0     0]]\n",
      "167/200 [========================>.....] - ETA: 15s - loss: 1.5481 - acc: 0.8065[[1224   27 3823 ...,    0    0    0]\n",
      " [  58   59  154 ...,    0    0    0]\n",
      " [ 501  154   66 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   13   13 ...,    0    0    0]\n",
      " [  12  296   13 ...,    0    0    0]\n",
      " [1491  102   67 ...,    0    0    0]]\n",
      "168/200 [========================>.....] - ETA: 14s - loss: 1.5482 - acc: 0.8066[[ 179 1315 4973 ...,    0    0    0]\n",
      " [ 234 4869  112 ...,    0    0    0]\n",
      " [   1  214   23 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  635    5 ...,    0    0    0]\n",
      " [ 342  196   66 ...,    0    0    0]\n",
      " [ 155   29  697 ...,    0    0    0]]\n",
      "169/200 [========================>.....] - ETA: 14s - loss: 1.5464 - acc: 0.8066[[ 958  998    7 ...,    0    0    0]\n",
      " [2490    9 2492 ...,    0    0    0]\n",
      " [   2 2602    4 ...,    0    0    0]\n",
      " ..., \n",
      " [  26   23  974 ...,    0    0    0]\n",
      " [  56   79    1 ...,    0    0    0]\n",
      " [ 561   11 1913 ...,    0    0    0]]\n",
      "170/200 [========================>.....] - ETA: 13s - loss: 1.5445 - acc: 0.8067[[ 478    2 1319 ...,    0    0    0]\n",
      " [1935  295 8426 ...,    0    0    0]\n",
      " [1525  326  267 ...,    0    0    0]\n",
      " ..., \n",
      " [ 108   13    9 ...,    0    0    0]\n",
      " [  26   23 7417 ...,    0    0    0]\n",
      " [ 579  217  226 ...,    0    0    0]]\n",
      "171/200 [========================>.....] - ETA: 13s - loss: 1.5428 - acc: 0.8069[[4458   21  933 ...,    0    0    0]\n",
      " [1248 2508   13 ...,    0    0    0]\n",
      " [  22  405   16 ...,    0    0    0]\n",
      " ..., \n",
      " [  22  405 2244 ...,    0    0    0]\n",
      " [ 166   41  970 ...,    0    0    0]\n",
      " [   1  751 2224 ...,    0    0    0]]\n",
      "172/200 [========================>.....] - ETA: 12s - loss: 1.5410 - acc: 0.8070[[ 131 2642   13 ...,    0    0    0]\n",
      " [  13   13  247 ...,    0    0    0]\n",
      " [   2  146   11 ...,    0    0    0]\n",
      " ..., \n",
      " [3689 3693   13 ...,    0    0    0]\n",
      " [ 500    7 1791 ...,    0    0    0]\n",
      " [ 374    5   13 ...,    0    0    0]]\n",
      "173/200 [========================>.....] - ETA: 12s - loss: 1.5395 - acc: 0.8071[[ 912    5    1 ...,    0    0    0]\n",
      " [2036  462  470 ...,    0    0    0]\n",
      " [1171 5423   13 ...,    0    0    0]\n",
      " ..., \n",
      " [8266  694  131 ...,    0    0    0]\n",
      " [   2   13 7637 ...,    0    0    0]\n",
      " [ 582 1927 1531 ...,    0    0    0]]\n",
      "174/200 [=========================>....] - ETA: 11s - loss: 1.5379 - acc: 0.8072[[3213 4089 1732 ...,    0    0    0]\n",
      " [ 390   13 8287 ...,    0    0    0]\n",
      " [ 246  190   10 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 1152 2403 ...,    0    0    0]\n",
      " [  87  632    9 ...,    0    0    0]\n",
      " [   1  474  429 ...,    0    0    0]]\n",
      "175/200 [=========================>....] - ETA: 11s - loss: 1.5366 - acc: 0.8073[[ 186   11   45 ...,    0    0    0]\n",
      " [  13 3488  521 ...,    0    0    0]\n",
      " [3396   13   49 ...,    0    0    0]\n",
      " ..., \n",
      " [  10  234 4098 ...,    0    0    0]\n",
      " [ 232  627    8 ...,    0    0    0]\n",
      " [3491  119  157 ...,    0    0    0]]\n",
      "176/200 [=========================>....] - ETA: 10s - loss: 1.5352 - acc: 0.8074[[   73   196   441 ...,     0     0     0]\n",
      " [11981  4113    27 ...,     0     0     0]\n",
      " [  380     7   322 ...,     0     0     0]\n",
      " ..., \n",
      " [ 5138  6683    83 ...,     0     0     0]\n",
      " [  185   854     5 ...,     0     0     0]\n",
      " [ 2746  7951  9616 ...,     0     0     0]]\n",
      "177/200 [=========================>....] - ETA: 10s - loss: 1.5339 - acc: 0.8075[[ 140  369 6301 ...,    0    0    0]\n",
      " [  42  471   39 ...,    0    0    0]\n",
      " [3007  157    2 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  580  473 ...,    0    0    0]\n",
      " [ 456  970 8511 ...,    0    0    0]\n",
      " [1046  217 2808 ...,    0    0    0]]\n",
      "178/200 [=========================>....] - ETA: 10s - loss: 1.5328 - acc: 0.8076[[   2  287 7391 ...,    0    0    0]\n",
      " [1446   13    9 ...,    0    0    0]\n",
      " [   2  146 1214 ...,    0    0    0]\n",
      " ..., \n",
      " [  10    2   61 ...,    0    0    0]\n",
      " [   1  717  117 ...,    0    0    0]\n",
      " [   4   13   13 ...,    0    0    0]]\n",
      "179/200 [=========================>....] - ETA: 9s - loss: 1.5320 - acc: 0.8076 [[ 131  381  228 ...,    0    0    0]\n",
      " [1562 4241   14 ...,    0    0    0]\n",
      " [  13   21   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 284    7  274 ...,    0    0    0]\n",
      " [   2  219  734 ...,    0    0    0]\n",
      " [ 623  631   24 ...,    0    0    0]]\n",
      "180/200 [==========================>...] - ETA: 9s - loss: 1.5326 - acc: 0.8076[[  108    68   410 ...,     0     0     0]\n",
      " [ 3928   600 11308 ...,     0     0     0]\n",
      " [  492    13     5 ...,     0     0     0]\n",
      " ..., \n",
      " [   19  1620     6 ...,     0     0     0]\n",
      " [ 8181    63    56 ...,     0     0     0]\n",
      " [10148 10148   231 ...,     0     0     0]]\n",
      "181/200 [==========================>...] - ETA: 8s - loss: 1.5327 - acc: 0.8076[[ 131 1767  332 ...,    0    0    0]\n",
      " [   6    1 2532 ...,    0    0    0]\n",
      " [1381  147  407 ...,    0    0    0]\n",
      " ..., \n",
      " [ 109    7 1276 ...,    0    0    0]\n",
      " [   2   13  613 ...,    0    0    0]\n",
      " [1230  951    4 ...,    0    0    0]]\n",
      "182/200 [==========================>...] - ETA: 8s - loss: 1.5339 - acc: 0.8074[[ 131  121 3113 ...,    0    0    0]\n",
      " [ 623   21 7905 ...,    0    0    0]\n",
      " [   1  785    9 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13  203 ...,    0    0    0]\n",
      " [   2  146 1129 ...,    0    0    0]\n",
      " [  10    2 1090 ...,    0    0    0]]\n",
      "183/200 [==========================>...] - ETA: 7s - loss: 1.5342 - acc: 0.8074[[   1   13   91 ...,    0    0    0]\n",
      " [   1  199 4208 ...,    0    0    0]\n",
      " [  58   59  187 ...,    0    0    0]\n",
      " ..., \n",
      " [ 495   32    2 ...,    0    0    0]\n",
      " [   2   13  734 ...,    0    0    0]\n",
      " [1573 6341 5974 ...,    0    0    0]]\n",
      "184/200 [==========================>...] - ETA: 7s - loss: 1.5352 - acc: 0.8073[[   1  998 3979 ...,    0    0    0]\n",
      " [ 263  267   13 ...,    0    0    0]\n",
      " [1247    7   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 650   13  365 ...,    0    0    0]\n",
      " [  34    1   61 ...,    0    0    0]\n",
      " [3819    7  780 ...,    0    0    0]]\n",
      "185/200 [==========================>...] - ETA: 6s - loss: 1.5364 - acc: 0.8072[[   2  551  861 ...,    0    0    0]\n",
      " [1675   13  192 ...,    0    0    0]\n",
      " [ 293 1222 2501 ...,    0    0    0]\n",
      " ..., \n",
      " [ 344  117   13 ...,    0    0    0]\n",
      " [1004  421 2149 ...,    0    0    0]\n",
      " [1761   23  210 ...,    0    0    0]]\n",
      "186/200 [==========================>...] - ETA: 6s - loss: 1.5363 - acc: 0.8072[[ 300   23  400 ...,    0    0    0]\n",
      " [  15    9 6069 ...,    0    0    0]\n",
      " [3978  157    1 ...,    0    0    0]\n",
      " ..., \n",
      " [3100   15    9 ...,    0    0    0]\n",
      " [ 348 2320 5144 ...,    0    0    0]\n",
      " [  13   13 3164 ...,    0    0    0]]\n",
      "187/200 [===========================>..] - ETA: 5s - loss: 1.5369 - acc: 0.8071[[   49   164   816 ...,     0     0     0]\n",
      " [  301   934  8133 ...,     0     0     0]\n",
      " [11585   112     5 ...,     0     0     0]\n",
      " ..., \n",
      " [    1    19    13 ...,     0     0     0]\n",
      " [   13     6  3737 ...,     0     0     0]\n",
      " [11163    13  1243 ...,     0     0     0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/200 [===========================>..] - ETA: 5s - loss: 1.5382 - acc: 0.8070[[  15   11   45 ...,    0    0    0]\n",
      " [ 184  810   29 ...,    0    0    0]\n",
      " [  89    7   22 ...,    0    0    0]\n",
      " ..., \n",
      " [1925 1207 2354 ...,    0    0    0]\n",
      " [  10    1  345 ...,    0    0    0]\n",
      " [ 108   68  410 ...,    0    0    0]]\n",
      "189/200 [===========================>..] - ETA: 5s - loss: 1.5403 - acc: 0.8068[[2206   13 2298 ...,    0    0    0]\n",
      " [  10  383    2 ...,    0    0    0]\n",
      " [9208   67 9798 ...,    0    0    0]\n",
      " ..., \n",
      " [  68   21    3 ...,    0    0    0]\n",
      " [  13  744    3 ...,    0    0    0]\n",
      " [  89   27  317 ...,    0    0    0]]\n",
      "190/200 [===========================>..] - ETA: 4s - loss: 1.5412 - acc: 0.8067[[1892 7168    4 ...,    0    0    0]\n",
      " [3006 2446   14 ...,    0    0    0]\n",
      " [1170 2169 2080 ...,    0    0    0]\n",
      " ..., \n",
      " [ 726    7  191 ...,    0    0    0]\n",
      " [1231   70   68 ...,    0    0    0]\n",
      " [   2  293 1244 ...,    0    0    0]]\n",
      "191/200 [===========================>..] - ETA: 4s - loss: 1.5431 - acc: 0.8065[[   13 10823     7 ...,     0     0     0]\n",
      " [   13   435  7769 ...,     0     0     0]\n",
      " [   13    13     9 ...,     0     0     0]\n",
      " ..., \n",
      " [    2  1745  3196 ...,     0     0     0]\n",
      " [ 8017  1395     9 ...,     0     0     0]\n",
      " [    2    13   796 ...,     0     0     0]]\n",
      "192/200 [===========================>..] - ETA: 3s - loss: 1.5440 - acc: 0.8064[[   19   352     8 ...,     0     0     0]\n",
      " [  187     5  4712 ...,     0     0     0]\n",
      " [ 3222  7637    13 ...,     0     0     0]\n",
      " ..., \n",
      " [  500     7 10824 ...,     0     0     0]\n",
      " [   69   297    13 ...,     0     0     0]\n",
      " [ 1152  4028   252 ...,     0     0     0]]\n",
      "193/200 [===========================>..] - ETA: 3s - loss: 1.5433 - acc: 0.8065[[8602    9 2859 ...,    0    0    0]\n",
      " [   2 6397    3 ...,    0    0    0]\n",
      " [3252   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 325 1063 1998 ...,    0    0    0]\n",
      " [   1  126 2437 ...,    0    0    0]\n",
      " [  13   13   14 ...,    0    0    0]]\n",
      "194/200 [============================>.] - ETA: 2s - loss: 1.5449 - acc: 0.8063[[   1   99 4711 ...,    0    0    0]\n",
      " [ 154   66    6 ...,    0    0    0]\n",
      " [ 154   66    6 ...,    0    0    0]\n",
      " ..., \n",
      " [2288   13  105 ...,    0    0    0]\n",
      " [  15  748   90 ...,    0    0    0]\n",
      " [ 356  767  811 ...,    0    0    0]]\n",
      "195/200 [============================>.] - ETA: 2s - loss: 1.5455 - acc: 0.8063[[    2   222 10613 ...,     0     0     0]\n",
      " [   10    63    13 ...,     0     0     0]\n",
      " [    1    13    32 ...,     0     0     0]\n",
      " ..., \n",
      " [   13    13   298 ...,     0     0     0]\n",
      " [   19   120   438 ...,     0     0     0]\n",
      " [   34    61  6449 ...,     0     0     0]]\n",
      "196/200 [============================>.] - ETA: 1s - loss: 1.5456 - acc: 0.8062[[  304  3255   103 ...,     0     0     0]\n",
      " [ 2379  7422     8 ...,     0     0     0]\n",
      " [10485 10333   100 ...,     0     0     0]\n",
      " ..., \n",
      " [    4    13   816 ...,     0     0     0]\n",
      " [   13     9    48 ...,     0     0     0]\n",
      " [  890  2211   114 ...,     0     0     0]]\n",
      "197/200 [============================>.] - ETA: 1s - loss: 1.5455 - acc: 0.8063[[5267 2367   14 ...,    0    0    0]\n",
      " [ 108  104 2357 ...,    0    0    0]\n",
      " [   4    1  894 ...,    0    0    0]\n",
      " ..., \n",
      " [ 155  301  338 ...,    0    0    0]\n",
      " [ 377 4559   13 ...,    0    0    0]\n",
      " [   4  432   68 ...,    0    0    0]]\n",
      "198/200 [============================>.] - ETA: 0s - loss: 1.5458 - acc: 0.8063[[  18    1 1558 ...,    0    0    0]\n",
      " [ 986 5031  703 ...,    0    0    0]\n",
      " [3001 6530 5388 ...,    0    0    0]\n",
      " ..., \n",
      " [1289   13    2 ...,    0    0    0]\n",
      " [ 406   13 8740 ...,    0    0    0]\n",
      " [   1  387 3348 ...,    0    0    0]]\n",
      "199/200 [============================>.] - ETA: 0s - loss: 1.5462 - acc: 0.8063[[ 3470    13   626 ...,     0     0     0]\n",
      " [ 7322     9  1842 ...,     0     0     0]\n",
      " [  483  4428    10 ...,     0     0     0]\n",
      " ..., \n",
      " [   13   391     5 ...,     0     0     0]\n",
      " [ 7029  2222    81 ...,     0     0     0]\n",
      " [10683  9535    11 ...,     0     0     0]]\n",
      "200/200 [==============================] - 91s - loss: 1.5473 - acc: 0.8062    \n",
      "Epoch 6/10\n",
      "[[3822 3881    3 ...,    0    0    0]\n",
      " [ 103  280   13 ...,    0    0    0]\n",
      " [ 280 4960   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 670  559  114 ...,    0    0    0]\n",
      " [  47 1401 3981 ...,    0    0    0]\n",
      " [  34   74   13 ...,    0    0    0]]\n",
      "  1/200 [..............................] - ETA: 91s - loss: 1.5953 - acc: 0.8061[[   22  2086   255 ...,     0     0     0]\n",
      " [ 1360   585    13 ...,     0     0     0]\n",
      " [  514  2246    11 ...,     0     0     0]\n",
      " ..., \n",
      " [10878    13   219 ...,     0     0     0]\n",
      " [   12   366    13 ...,     0     0     0]\n",
      " [  535    15     7 ...,     0     0     0]]\n",
      "  2/200 [..............................] - ETA: 90s - loss: 1.6371 - acc: 0.8010[[5707   13  141 ...,    0    0    0]\n",
      " [  70 1807   13 ...,    0    0    0]\n",
      " [  13   13  114 ...,    0    0    0]\n",
      " ..., \n",
      " [1577   13   11 ...,    0    0    0]\n",
      " [1562   13 1191 ...,    0    0    0]\n",
      " [6551   11   81 ...,    0    0    0]]\n",
      "  3/200 [..............................] - ETA: 90s - loss: 1.6819 - acc: 0.7930[[   4   13 2514 ...,    0    0    0]\n",
      " [  34   61   13 ...,    0    0    0]\n",
      " [  69  263    9 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 1033   67 ...,    0    0    0]\n",
      " [  32  348    1 ...,    0    0    0]\n",
      " [  68  128   39 ...,    0    0    0]]\n",
      "  4/200 [..............................] - ETA: 89s - loss: 1.7110 - acc: 0.7912[[ 558    5 2055 ...,    0    0    0]\n",
      " [  10   13    8 ...,    0    0    0]\n",
      " [  15  448   29 ...,    0    0    0]\n",
      " ..., \n",
      " [6422   13  192 ...,    0    0    0]\n",
      " [2495    5   13 ...,    0    0    0]\n",
      " [   1 2407    5 ...,    0    0    0]]\n",
      "  5/200 [..............................] - ETA: 89s - loss: 1.7396 - acc: 0.7869[[ 297   13  263 ...,    0    0    0]\n",
      " [  13  104   14 ...,    0    0    0]\n",
      " [  13  448    3 ...,    0    0    0]\n",
      " ..., \n",
      " [  15    7   48 ...,    0    0    0]\n",
      " [  89   23  177 ...,    0    0    0]\n",
      " [   2 1099   13 ...,    0    0    0]]\n",
      "  6/200 [..............................] - ETA: 89s - loss: 1.7242 - acc: 0.7888[[ 347  110 7274 ...,    0    0    0]\n",
      " [ 432   13   13 ...,    0    0    0]\n",
      " [  80 2742 2468 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  679  527 ...,    0    0    0]\n",
      " [  15    7  282 ...,    0    0    0]\n",
      " [  13   26  106 ...,    0    0    0]]\n",
      "  7/200 [>.............................] - ETA: 89s - loss: 1.7296 - acc: 0.7888[[1563   13 1393 ...,    0    0    0]\n",
      " [ 104  898   99 ...,    0    0    0]\n",
      " [3432  605   13 ...,    0    0    0]\n",
      " ..., \n",
      " [6448   13   14 ...,    0    0    0]\n",
      " [   1 6322    5 ...,    0    0    0]\n",
      " [ 341   13  245 ...,    0    0    0]]\n",
      "  8/200 [>.............................] - ETA: 89s - loss: 1.7135 - acc: 0.7909[[ 380    7 4121 ...,    0    0    0]\n",
      " [ 140  609   26 ...,    0    0    0]\n",
      " [ 127  179  851 ...,    0    0    0]\n",
      " ..., \n",
      " [ 140  609   26 ...,    0    0    0]\n",
      " [ 355 4849   11 ...,    0    0    0]\n",
      " [7486   13    5 ...,    0    0    0]]\n",
      "  9/200 [>.............................] - ETA: 88s - loss: 1.6940 - acc: 0.7933[[   2 1261 2099 ...,    0    0    0]\n",
      " [   2  121 1421 ...,    0    0    0]\n",
      " [ 726  217  255 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [ 176   66 2512 ...,    0    0    0]\n",
      " [   1  468 2949 ...,    0    0    0]]\n",
      " 10/200 [>.............................] - ETA: 88s - loss: 1.6903 - acc: 0.7936[[ 38 481 176 ...,   0   0   0]\n",
      " [ 13  26 441 ...,   0   0   0]\n",
      " [187  66   6 ...,   0   0   0]\n",
      " ..., \n",
      " [284   7  26 ...,   0   0   0]\n",
      " [  1  13  91 ...,   0   0   0]\n",
      " [  1  13  91 ...,   0   0   0]]\n",
      " 11/200 [>.............................] - ETA: 87s - loss: 1.6869 - acc: 0.7942[[   1   13   91 ...,    0    0    0]\n",
      " [ 140  609   26 ...,    0    0    0]\n",
      " [   1  220   73 ...,    0    0    0]\n",
      " ..., \n",
      " [ 154   66 1215 ...,    0    0    0]\n",
      " [   2  179  680 ...,    0    0    0]\n",
      " [ 390   13   11 ...,    0    0    0]]\n",
      " 12/200 [>.............................] - ETA: 86s - loss: 1.6728 - acc: 0.7959[[  456  1542   662 ...,     0     0     0]\n",
      " [  131   547  1438 ...,     0     0     0]\n",
      " [ 2351    10     1 ...,     0     0     0]\n",
      " ..., \n",
      " [    1    13  3217 ...,     0     0     0]\n",
      " [   15    14 11683 ...,     0     0     0]\n",
      " [    1  1356     5 ...,     0     0     0]]\n",
      " 13/200 [>.............................] - ETA: 86s - loss: 1.6638 - acc: 0.7966[[  13   13   13 ...,    0    0    0]\n",
      " [ 751  103 4071 ...,    0    0    0]\n",
      " [  10 2939 3751 ...,    0    0    0]\n",
      " ..., \n",
      " [ 488    7  324 ...,    0    0    0]\n",
      " [  64   82   13 ...,    0    0    0]\n",
      " [   1  412 1011 ...,    0    0    0]]\n",
      " 14/200 [=>............................] - ETA: 85s - loss: 1.6565 - acc: 0.7977[[   1 1660 2134 ...,    0    0    0]\n",
      " [  13  956 4275 ...,    0    0    0]\n",
      " [ 111    4    1 ...,    0    0    0]\n",
      " ..., \n",
      " [3289   30   24 ...,    0    0    0]\n",
      " [2095  745 2520 ...,    0    0    0]\n",
      " [5171   66  115 ...,    0    0    0]]\n",
      " 15/200 [=>............................] - ETA: 85s - loss: 1.6502 - acc: 0.7986[[    1   736  1616 ...,     0     0     0]\n",
      " [ 4701 10213     9 ...,     0     0     0]\n",
      " [    2   866  3775 ...,     0     0     0]\n",
      " ..., \n",
      " [   55     6    57 ...,     0     0     0]\n",
      " [    2  1649  1715 ...,     0     0     0]\n",
      " [   19   120    13 ...,     0     0     0]]\n",
      " 16/200 [=>............................] - ETA: 84s - loss: 1.6488 - acc: 0.7989[[ 585 9701 6296 ...,    0    0    0]\n",
      " [3626 2067   13 ...,    0    0    0]\n",
      " [   1   91  106 ...,    0    0    0]\n",
      " ..., \n",
      " [  66    6    1 ...,    0    0    0]\n",
      " [5527 5689    9 ...,    0    0    0]\n",
      " [   1   47   49 ...,    0    0    0]]\n",
      " 17/200 [=>............................] - ETA: 84s - loss: 1.6425 - acc: 0.7996[[ 1635 11261     8 ...,     0     0     0]\n",
      " [    1  3005  1719 ...,     0     0     0]\n",
      " [  109    26   115 ...,     0     0     0]\n",
      " ..., \n",
      " [  109    26   113 ...,     0     0     0]\n",
      " [   90   194  1044 ...,     0     0     0]\n",
      " [ 1287    13    81 ...,     0     0     0]]\n",
      " 18/200 [=>............................] - ETA: 83s - loss: 1.6375 - acc: 0.7999[[2425    8   55 ...,    0    0    0]\n",
      " [2309 3927   11 ...,    0    0    0]\n",
      " [ 173 4190   10 ...,    0    0    0]\n",
      " ..., \n",
      " [1822   13    9 ...,    0    0    0]\n",
      " [3061   13   13 ...,    0    0    0]\n",
      " [   1  261   13 ...,    0    0    0]]\n",
      " 19/200 [=>............................] - ETA: 83s - loss: 1.6173 - acc: 0.8017[[   2  904  405 ...,    0    0    0]\n",
      " [3062  196 9581 ...,    0    0    0]\n",
      " [  13   13   27 ...,    0    0    0]\n",
      " ..., \n",
      " [ 681  187  399 ...,    0    0    0]\n",
      " [   1  126  198 ...,    0    0    0]\n",
      " [ 131  456 1127 ...,    0    0    0]]\n",
      " 20/200 [==>...........................] - ETA: 82s - loss: 1.5985 - acc: 0.8032[[ 276  178   13 ...,    0    0    0]\n",
      " [ 154   66   67 ...,    0    0    0]\n",
      " [  13    1 3430 ...,    0    0    0]\n",
      " ..., \n",
      " [6341 5974    7 ...,    0    0    0]\n",
      " [   1  263 1691 ...,    0    0    0]\n",
      " [   2   37  144 ...,    0    0    0]]\n",
      " 21/200 [==>...........................] - ETA: 81s - loss: 1.5793 - acc: 0.8047[[  15    7  166 ...,    0    0    0]\n",
      " [1811  217  514 ...,    0    0    0]\n",
      " [ 267  157   92 ...,    0    0    0]\n",
      " ..., \n",
      " [3718   29  337 ...,    0    0    0]\n",
      " [   4    2  188 ...,    0    0    0]\n",
      " [  54    2   94 ...,    0    0    0]]\n",
      " 22/200 [==>...........................] - ETA: 81s - loss: 1.5673 - acc: 0.8056[[   2 8865  819 ...,    0    0    0]\n",
      " [  18   15 3368 ...,    0    0    0]\n",
      " [ 302   11  319 ...,    0    0    0]\n",
      " ..., \n",
      " [   4    2   13 ...,    0    0    0]\n",
      " [  13 9772   13 ...,    0    0    0]\n",
      " [ 592 8142    1 ...,    0    0    0]]\n",
      " 23/200 [==>...........................] - ETA: 80s - loss: 1.5648 - acc: 0.8058[[  13   13   68 ...,    0    0    0]\n",
      " [  10  888   13 ...,    0    0    0]\n",
      " [9482  486  240 ...,    0    0    0]\n",
      " ..., \n",
      " [ 108  210 1468 ...,    0    0    0]\n",
      " [2797 4459    9 ...,    0    0    0]\n",
      " [1068 4127  247 ...,    0    0    0]]\n",
      " 24/200 [==>...........................] - ETA: 80s - loss: 1.5739 - acc: 0.8050[[8163 8613 5159 ...,    0    0    0]\n",
      " [3484  610   86 ...,    0    0    0]\n",
      " [  18    2  153 ...,    0    0    0]\n",
      " ..., \n",
      " [  10    2 3037 ...,    0    0    0]\n",
      " [1068 9485  192 ...,    0    0    0]\n",
      " [3079 3363    9 ...,    0    0    0]]\n",
      " 25/200 [==>...........................] - ETA: 79s - loss: 1.5754 - acc: 0.8047[[ 535 1398   13 ...,    0    0    0]\n",
      " [ 300   21    1 ...,    0    0    0]\n",
      " [ 108   68   23 ...,    0    0    0]\n",
      " ..., \n",
      " [   8  155   10 ...,    0    0    0]\n",
      " [ 535    1 3423 ...,    0    0    0]\n",
      " [4571 2417  703 ...,    0    0    0]]\n",
      " 26/200 [==>...........................] - ETA: 79s - loss: 1.5751 - acc: 0.8048[[ 1740  1635    13 ...,     0     0     0]\n",
      " [ 1019   747 10354 ...,     0     0     0]\n",
      " [   89    27    20 ...,     0     0     0]\n",
      " ..., \n",
      " [   80  2199    13 ...,     0     0     0]\n",
      " [    1  3089    23 ...,     0     0     0]\n",
      " [    4     1   264 ...,     0     0     0]]\n",
      " 27/200 [===>..........................] - ETA: 78s - loss: 1.5770 - acc: 0.8046[[  93  724   90 ...,    0    0    0]\n",
      " [2309 3927  684 ...,    0    0    0]\n",
      " [   2 2437    5 ...,    0    0    0]\n",
      " ..., \n",
      " [ 174  446   13 ...,    0    0    0]\n",
      " [5338 4002    7 ...,    0    0    0]\n",
      " [   1   25 3212 ...,    0    0    0]]\n",
      " 28/200 [===>..........................] - ETA: 78s - loss: 1.5839 - acc: 0.8036[[  13 8440  523 ...,    0    0    0]\n",
      " [ 763 6237 1934 ...,    0    0    0]\n",
      " [ 203 1646   79 ...,    0    0    0]\n",
      " ..., \n",
      " [  12   13   13 ...,    0    0    0]\n",
      " [ 730   13 1846 ...,    0    0    0]\n",
      " [ 104  114   48 ...,    0    0    0]]\n",
      " 29/200 [===>..........................] - ETA: 77s - loss: 1.5928 - acc: 0.8026[[  89    7   22 ...,    0    0    0]\n",
      " [  15    7   48 ...,    0    0    0]\n",
      " [  13   26  115 ...,    0    0    0]\n",
      " ..., \n",
      " [ 406    7 1265 ...,    0    0    0]\n",
      " [ 770  299    5 ...,    0    0    0]\n",
      " [  78   94   13 ...,    0    0    0]]\n",
      " 30/200 [===>..........................] - ETA: 77s - loss: 1.5864 - acc: 0.8034[[  13   63  144 ...,    0    0    0]\n",
      " [  15    9   80 ...,    0    0    0]\n",
      " [   1  167  191 ...,    0    0    0]\n",
      " ..., \n",
      " [   3   20 1560 ...,    0    0    0]\n",
      " [   1 1274  276 ...,    0    0    0]\n",
      " [  13  114  155 ...,    0    0    0]]\n",
      " 31/200 [===>..........................] - ETA: 77s - loss: 1.5926 - acc: 0.8028[[   70    13 11859 ...,     0     0     0]\n",
      " [   80    41    14 ...,     0     0     0]\n",
      " [  232  3054   384 ...,     0     0     0]\n",
      " ..., \n",
      " [ 1931  1772    29 ...,     0     0     0]\n",
      " [ 1382  1963    11 ...,     0     0     0]\n",
      " [  698  5800  1429 ...,     0     0     0]]\n",
      " 32/200 [===>..........................] - ETA: 76s - loss: 1.5916 - acc: 0.8030[[   1  177   70 ...,    0    0    0]\n",
      " [  41  330  674 ...,    0    0    0]\n",
      " [ 104   14  233 ...,    0    0    0]\n",
      " ..., \n",
      " [ 194   63  144 ...,    0    0    0]\n",
      " [  13  104 1619 ...,    0    0    0]\n",
      " [ 245 1225   13 ...,    0    0    0]]\n",
      " 33/200 [===>..........................] - ETA: 75s - loss: 1.5874 - acc: 0.8037[[1226   97   13 ...,    0    0    0]\n",
      " [1233 3058   25 ...,    0    0    0]\n",
      " [  10  402   13 ...,    0    0    0]\n",
      " ..., \n",
      " [  15   14    2 ...,    0    0    0]\n",
      " [1401 8027   81 ...,    0    0    0]\n",
      " [  13 1049   13 ...,    0    0    0]]\n",
      " 34/200 [====>.........................] - ETA: 75s - loss: 1.5883 - acc: 0.8037[[ 503    9  305 ...,    0    0    0]\n",
      " [1629    1 1798 ...,    0    0    0]\n",
      " [ 565    1  189 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [ 547   69 4400 ...,    0    0    0]\n",
      " [   1 1276 3182 ...,    0    0    0]]\n",
      " 35/200 [====>.........................] - ETA: 75s - loss: 1.5892 - acc: 0.8036[[3158  217 1453 ...,    0    0    0]\n",
      " [   1  261 2012 ...,    0    0    0]\n",
      " [  13  167  523 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [ 167 6286 4386 ...,    0    0    0]\n",
      " [   1   13 3414 ...,    0    0    0]]\n",
      " 36/200 [====>.........................] - ETA: 74s - loss: 1.5861 - acc: 0.8039[[   1 2230  199 ...,    0    0    0]\n",
      " [   1  220   73 ...,    0    0    0]\n",
      " [2553  594  205 ...,    0    0    0]\n",
      " ..., \n",
      " [  55   27 2904 ...,    0    0    0]\n",
      " [ 274   55    7 ...,    0    0    0]\n",
      " [   1   13   91 ...,    0    0    0]]\n",
      " 37/200 [====>.........................] - ETA: 74s - loss: 1.5845 - acc: 0.8041[[   1   13   91 ...,    0    0    0]\n",
      " [ 481   66  106 ...,    0    0    0]\n",
      " [ 456  121   26 ...,    0    0    0]\n",
      " ..., \n",
      " [  13    3 7124 ...,    0    0    0]\n",
      " [ 599 1780   23 ...,    0    0    0]\n",
      " [ 422  755  312 ...,    0    0    0]]\n",
      " 38/200 [====>.........................] - ETA: 73s - loss: 1.5831 - acc: 0.8043[[2032  610  168 ...,    0    0    0]\n",
      " [ 232 1991    4 ...,    0    0    0]\n",
      " [  49  102  112 ...,    0    0    0]\n",
      " ..., \n",
      " [ 150 2695  947 ...,    0    0    0]\n",
      " [   2 3709   13 ...,    0    0    0]\n",
      " [  92 2036  462 ...,    0    0    0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 39/200 [====>.........................] - ETA: 73s - loss: 1.5832 - acc: 0.8043[[5401 3039   13 ...,    0    0    0]\n",
      " [  34    9   41 ...,    0    0    0]\n",
      " [1082  295  353 ...,    0    0    0]\n",
      " ..., \n",
      " [4748 2617  141 ...,    0    0    0]\n",
      " [  10  697 1295 ...,    0    0    0]\n",
      " [   1  547 6865 ...,    0    0    0]]\n",
      " 40/200 [=====>........................] - ETA: 72s - loss: 1.5835 - acc: 0.8043[[  37   56   37 ...,    0    0    0]\n",
      " [ 880  903   92 ...,    0    0    0]\n",
      " [4008   43 3511 ...,    0    0    0]\n",
      " ..., \n",
      " [ 347   61    2 ...,    0    0    0]\n",
      " [ 654  145   11 ...,    0    0    0]\n",
      " [ 456  119   21 ...,    0    0    0]]\n",
      " 41/200 [=====>........................] - ETA: 72s - loss: 1.5848 - acc: 0.8042[[   4    1 3064 ...,    0    0    0]\n",
      " [  12 5230   13 ...,    0    0    0]\n",
      " [ 246   11 4044 ...,    0    0    0]\n",
      " ..., \n",
      " [  13    4 1453 ...,    0    0    0]\n",
      " [1109  332 8047 ...,    0    0    0]\n",
      " [  13 9504 5172 ...,    0    0    0]]\n",
      " 42/200 [=====>........................] - ETA: 71s - loss: 1.5839 - acc: 0.8044[[ 685   38   62 ...,    0    0    0]\n",
      " [ 913    7 3013 ...,    0    0    0]\n",
      " [ 224    7 4494 ...,    0    0    0]\n",
      " ..., \n",
      " [ 416   13    1 ...,    0    0    0]\n",
      " [3350 2858    9 ...,    0    0    0]\n",
      " [   1  682  189 ...,    0    0    0]]\n",
      " 43/200 [=====>........................] - ETA: 71s - loss: 1.5841 - acc: 0.8045[[ 1149  5222  1429 ...,     0     0     0]\n",
      " [   99   881  2396 ...,     0     0     0]\n",
      " [  726   419     3 ...,     0     0     0]\n",
      " ..., \n",
      " [    2  2011    16 ...,     0     0     0]\n",
      " [  967   130  3006 ...,     0     0     0]\n",
      " [10699    11   130 ...,     0     0     0]]\n",
      " 44/200 [=====>........................] - ETA: 70s - loss: 1.5841 - acc: 0.8045[[   2   13  405 ...,    0    0    0]\n",
      " [   1  221  230 ...,    0    0    0]\n",
      " [3847 8196    3 ...,    0    0    0]\n",
      " ..., \n",
      " [   2  361    5 ...,    0    0    0]\n",
      " [  48  171    1 ...,    0    0    0]\n",
      " [  10  116  203 ...,    0    0    0]]\n",
      " 45/200 [=====>........................] - ETA: 70s - loss: 1.5786 - acc: 0.8050[[ 150 8632  390 ...,    0    0    0]\n",
      " [1469  995    8 ...,    0    0    0]\n",
      " [  19  120  117 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  916  336 ...,    0    0    0]\n",
      " [   1 1797  610 ...,    0    0    0]\n",
      " [ 321   10  343 ...,    0    0    0]]\n",
      " 46/200 [=====>........................] - ETA: 69s - loss: 1.5715 - acc: 0.8056[[1062   11   45 ...,    0    0    0]\n",
      " [  18   42 1535 ...,    0    0    0]\n",
      " [   2   19 1811 ...,    0    0    0]\n",
      " ..., \n",
      " [ 665  473   13 ...,    0    0    0]\n",
      " [4488   13 3072 ...,    0    0    0]\n",
      " [   1   78  360 ...,    0    0    0]]\n",
      " 47/200 [======>.......................] - ETA: 69s - loss: 1.5641 - acc: 0.8062[[   2   13   14 ...,    0    0    0]\n",
      " [2909  168   41 ...,    0    0    0]\n",
      " [ 257   15   32 ...,    0    0    0]\n",
      " ..., \n",
      " [5409   11 1048 ...,    0    0    0]\n",
      " [ 246  604 5651 ...,    0    0    0]\n",
      " [ 248  604 5651 ...,    0    0    0]]\n",
      " 48/200 [======>.......................] - ETA: 68s - loss: 1.5598 - acc: 0.8066[[   13 11979     9 ...,     0     0     0]\n",
      " [  978   967     7 ...,     0     0     0]\n",
      " [    2  1346  2405 ...,     0     0     0]\n",
      " ..., \n",
      " [   89     7   586 ...,     0     0     0]\n",
      " [  232    13  3269 ...,     0     0     0]\n",
      " [  347   259    63 ...,     0     0     0]]\n",
      " 49/200 [======>.......................] - ETA: 68s - loss: 1.5594 - acc: 0.8066[[ 2894 11190    13 ...,     0     0     0]\n",
      " [    1  4282     8 ...,     0     0     0]\n",
      " [ 2900    13     7 ...,     0     0     0]\n",
      " ..., \n",
      " [   18     2  1884 ...,     0     0     0]\n",
      " [   15     7     1 ...,     0     0     0]\n",
      " [    1  2233    29 ...,     0     0     0]]\n",
      " 50/200 [======>.......................] - ETA: 67s - loss: 1.5604 - acc: 0.8065[[7006 1123   13 ...,    0    0    0]\n",
      " [4209  971    9 ...,    0    0    0]\n",
      " [  70 2215  231 ...,    0    0    0]\n",
      " ..., \n",
      " [  13 2230   13 ...,    0    0    0]\n",
      " [  23   13  136 ...,    0    0    0]\n",
      " [ 730   13  108 ...,    0    0    0]]\n",
      " 51/200 [======>.......................] - ETA: 67s - loss: 1.5640 - acc: 0.8061[[10549    13    11 ...,     0     0     0]\n",
      " [ 2820  6055   530 ...,     0     0     0]\n",
      " [  523  5302    13 ...,     0     0     0]\n",
      " ..., \n",
      " [  202    71     7 ...,     0     0     0]\n",
      " [   32     1    47 ...,     0     0     0]\n",
      " [    1  1238   336 ...,     0     0     0]]\n",
      " 52/200 [======>.......................] - ETA: 66s - loss: 1.5653 - acc: 0.8059[[   34     9     1 ...,     0     0     0]\n",
      " [    1  6327     7 ...,     0     0     0]\n",
      " [   89     9     2 ...,     0     0     0]\n",
      " ..., \n",
      " [   13 10095    44 ...,     0     0     0]\n",
      " [  406    13  7620 ...,     0     0     0]\n",
      " [    1   845   770 ...,     0     0     0]]\n",
      " 53/200 [======>.......................] - ETA: 66s - loss: 1.5640 - acc: 0.8061[[ 379   23 3609 ...,    0    0    0]\n",
      " [  10 1196   13 ...,    0    0    0]\n",
      " [ 166    2  259 ...,    0    0    0]\n",
      " ..., \n",
      " [ 133   39 1165 ...,    0    0    0]\n",
      " [   1 3703   11 ...,    0    0    0]\n",
      " [   1  823 5216 ...,    0    0    0]]\n",
      " 54/200 [=======>......................] - ETA: 65s - loss: 1.5678 - acc: 0.8056[[ 244 2381  123 ...,    0    0    0]\n",
      " [ 409  192    2 ...,    0    0    0]\n",
      " [  13 1825    9 ...,    0    0    0]\n",
      " ..., \n",
      " [1892 7257    9 ...,    0    0    0]\n",
      " [1328   13   83 ...,    0    0    0]\n",
      " [   1  175 5681 ...,    0    0    0]]\n",
      " 55/200 [=======>......................] - ETA: 65s - loss: 1.5710 - acc: 0.8053[[  54  234   63 ...,    0    0    0]\n",
      " [   1 1341   21 ...,    0    0    0]\n",
      " [  15  448   29 ...,    0    0    0]\n",
      " ..., \n",
      " [   4    1  645 ...,    0    0    0]\n",
      " [5542 2931   14 ...,    0    0    0]\n",
      " [ 586    9   18 ...,    0    0    0]]\n",
      " 56/200 [=======>......................] - ETA: 64s - loss: 1.5775 - acc: 0.8046[[1265    3 2312 ...,    0    0    0]\n",
      " [   1 2456 2248 ...,    0    0    0]\n",
      " [  13  301   23 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 4946   21 ...,    0    0    0]\n",
      " [1209   13  574 ...,    0    0    0]\n",
      " [  69  451   83 ...,    0    0    0]]\n",
      " 57/200 [=======>......................] - ETA: 64s - loss: 1.5776 - acc: 0.8047[[   4 1097   13 ...,    0    0    0]\n",
      " [1070 2004   23 ...,    0    0    0]\n",
      " [5232  247 1268 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   13    9 ...,    0    0    0]\n",
      " [ 171   43 7345 ...,    0    0    0]\n",
      " [ 137    2 7421 ...,    0    0    0]]\n",
      " 58/200 [=======>......................] - ETA: 64s - loss: 1.5806 - acc: 0.8043[[   13    13  3647 ...,     0     0     0]\n",
      " [   13 11605     9 ...,     0     0     0]\n",
      " [  181    13   105 ...,     0     0     0]\n",
      " ..., \n",
      " [ 4851    13 10762 ...,     0     0     0]\n",
      " [ 9718     5     2 ...,     0     0     0]\n",
      " [   89     9   693 ...,     0     0     0]]\n",
      " 59/200 [=======>......................] - ETA: 63s - loss: 1.5782 - acc: 0.8047[[  13 1442   13 ...,    0    0    0]\n",
      " [2461   13    9 ...,    0    0    0]\n",
      " [  13 1442   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 951    2 1118 ...,    0    0    0]\n",
      " [   1   13   98 ...,    0    0    0]\n",
      " [  17  431   14 ...,    0    0    0]]\n",
      " 60/200 [========>.....................] - ETA: 63s - loss: 1.5763 - acc: 0.8050[[   4   22 2404 ...,    0    0    0]\n",
      " [1925   11 1243 ...,    0    0    0]\n",
      " [1287   13 5519 ...,    0    0    0]\n",
      " ..., \n",
      " [ 318    9 2492 ...,    0    0    0]\n",
      " [   2   13 1300 ...,    0    0    0]\n",
      " [   1   13   38 ...,    0    0    0]]\n",
      " 61/200 [========>.....................] - ETA: 62s - loss: 1.5778 - acc: 0.8048[[6214  172   41 ...,    0    0    0]\n",
      " [4280  292   40 ...,    0    0    0]\n",
      " [2192   55    7 ...,    0    0    0]\n",
      " ..., \n",
      " [ 226  217  140 ...,    0    0    0]\n",
      " [3608  119   13 ...,    0    0    0]\n",
      " [ 373  423   55 ...,    0    0    0]]\n",
      " 62/200 [========>.....................] - ETA: 62s - loss: 1.5785 - acc: 0.8048[[ 318    7   49 ...,    0    0    0]\n",
      " [  13   26  922 ...,    0    0    0]\n",
      " [  55   11   13 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  220  527 ...,    0    0    0]\n",
      " [   1  422 2108 ...,    0    0    0]\n",
      " [  55    7  682 ...,    0    0    0]]\n",
      " 63/200 [========>.....................] - ETA: 61s - loss: 1.5789 - acc: 0.8047[[  456   307   867 ...,     0     0     0]\n",
      " [   73   240     4 ...,     0     0     0]\n",
      " [ 3906    69 11375 ...,     0     0     0]\n",
      " ..., \n",
      " [    1    13    91 ...,     0     0     0]\n",
      " [    1   547   732 ...,     0     0     0]\n",
      " [   13   275    99 ...,     0     0     0]]\n",
      " 64/200 [========>.....................] - ETA: 61s - loss: 1.5797 - acc: 0.8046[[ 632   47  867 ...,    0    0    0]\n",
      " [1005   11 1492 ...,    0    0    0]\n",
      " [   2 4390   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 140  583  100 ...,    0    0    0]\n",
      " [  19  352  187 ...,    0    0    0]\n",
      " [   1   19  352 ...,    0    0    0]]\n",
      " 65/200 [========>.....................] - ETA: 60s - loss: 1.5791 - acc: 0.8047[[ 884    8  491 ...,    0    0    0]\n",
      " [ 176   66  106 ...,    0    0    0]\n",
      " [  13   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  823 1876 ...,    0    0    0]\n",
      " [   1  180    7 ...,    0    0    0]\n",
      " [2176 3115   23 ...,    0    0    0]]\n",
      " 66/200 [========>.....................] - ETA: 60s - loss: 1.5803 - acc: 0.8046[[   3 1428  159 ...,    0    0    0]\n",
      " [  15    7 7374 ...,    0    0    0]\n",
      " [ 717 3637  256 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13 1438 ...,    0    0    0]\n",
      " [1390 2704 3787 ...,    0    0    0]\n",
      " [1219   17 2281 ...,    0    0    0]]\n",
      " 67/200 [=========>....................] - ETA: 60s - loss: 1.5791 - acc: 0.8048[[ 585 3731 1002 ...,    0    0    0]\n",
      " [   1   38 6760 ...,    0    0    0]\n",
      " [   1 5327  499 ...,    0    0    0]\n",
      " ..., \n",
      " [  89    7   80 ...,    0    0    0]\n",
      " [   2 3717  146 ...,    0    0    0]\n",
      " [   2 4572 1129 ...,    0    0    0]]\n",
      " 68/200 [=========>....................] - ETA: 59s - loss: 1.5796 - acc: 0.8047[[  66    6    1 ...,    0    0    0]\n",
      " [1446   13   23 ...,    0    0    0]\n",
      " [  22  405   16 ...,    0    0    0]\n",
      " ..., \n",
      " [1577 2630   14 ...,    0    0    0]\n",
      " [ 221  230  659 ...,    0    0    0]\n",
      " [ 132   73  240 ...,    0    0    0]]\n",
      " 69/200 [=========>....................] - ETA: 59s - loss: 1.5803 - acc: 0.8046[[   1 3845   11 ...,    0    0    0]\n",
      " [   1 1753 1634 ...,    0    0    0]\n",
      " [  26  115    4 ...,    0    0    0]\n",
      " ..., \n",
      " [ 545   69 5333 ...,    0    0    0]\n",
      " [ 300  133    1 ...,    0    0    0]\n",
      " [2461 8349    9 ...,    0    0    0]]\n",
      " 70/200 [=========>....................] - ETA: 58s - loss: 1.5793 - acc: 0.8048[[ 350  289  129 ...,    0    0    0]\n",
      " [   1 1015    5 ...,    0    0    0]\n",
      " [ 170 1599   32 ...,    0    0    0]\n",
      " ..., \n",
      " [1822   13    7 ...,    0    0    0]\n",
      " [ 108   15   14 ...,    0    0    0]\n",
      " [ 280 1987   14 ...,    0    0    0]]\n",
      " 71/200 [=========>....................] - ETA: 58s - loss: 1.5765 - acc: 0.8050[[9077   50  173 ...,    0    0    0]\n",
      " [1961 2587   11 ...,    0    0    0]\n",
      " [3697  119  157 ...,    0    0    0]\n",
      " ..., \n",
      " [1486  299    5 ...,    0    0    0]\n",
      " [7828   13   11 ...,    0    0    0]\n",
      " [ 496   11 1220 ...,    0    0    0]]\n",
      " 72/200 [=========>....................] - ETA: 57s - loss: 1.5721 - acc: 0.8054[[ 355   13   11 ...,    0    0    0]\n",
      " [ 284  941 1465 ...,    0    0    0]\n",
      " [   1 1054    6 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   11 3565 ...,    0    0    0]\n",
      " [  17   13   83 ...,    0    0    0]\n",
      " [ 126  264    7 ...,    0    0    0]]\n",
      " 73/200 [=========>....................] - ETA: 57s - loss: 1.5677 - acc: 0.8058[[    1   567   522 ...,     0     0     0]\n",
      " [    2    19   352 ...,     0     0     0]\n",
      " [  166    13    13 ...,     0     0     0]\n",
      " ..., \n",
      " [  812  1064 10285 ...,     0     0     0]\n",
      " [   13  1512    11 ...,     0     0     0]\n",
      " [ 1911  5863    11 ...,     0     0     0]]\n",
      " 74/200 [==========>...................] - ETA: 56s - loss: 1.5638 - acc: 0.8061[[   13  2060  8660 ...,     0     0     0]\n",
      " [   13  3523  5816 ...,     0     0     0]\n",
      " [   13  1149 11626 ...,     0     0     0]\n",
      " ..., \n",
      " [  443    13    81 ...,     0     0     0]\n",
      " [    1  2791    27 ...,     0     0     0]\n",
      " [  978   967   604 ...,     0     0     0]]\n",
      " 75/200 [==========>...................] - ETA: 56s - loss: 1.5609 - acc: 0.8064[[    4   347   793 ...,     0     0     0]\n",
      " [ 8530    13    27 ...,     0     0     0]\n",
      " [  599    13   112 ...,     0     0     0]\n",
      " ..., \n",
      " [   32 10814     3 ...,     0     0     0]\n",
      " [ 2704  6929     7 ...,     0     0     0]\n",
      " [  348     2   846 ...,     0     0     0]]\n",
      " 76/200 [==========>...................] - ETA: 55s - loss: 1.5605 - acc: 0.8064[[ 108 4250    9 ...,    0    0    0]\n",
      " [ 301 8908 7838 ...,    0    0    0]\n",
      " [6110  222 2838 ...,    0    0    0]\n",
      " ..., \n",
      " [ 276  178   13 ...,    0    0    0]\n",
      " [ 102 7048   29 ...,    0    0    0]\n",
      " [3012    8 9083 ...,    0    0    0]]\n",
      " 77/200 [==========>...................] - ETA: 55s - loss: 1.5624 - acc: 0.8062[[   68   471    39 ...,     0     0     0]\n",
      " [11204    11   269 ...,     0     0     0]\n",
      " [ 7859  1562    13 ...,     0     0     0]\n",
      " ..., \n",
      " [   15    11    45 ...,     0     0     0]\n",
      " [   75    13  4214 ...,     0     0     0]\n",
      " [   13     1   801 ...,     0     0     0]]\n",
      " 78/200 [==========>...................] - ETA: 55s - loss: 1.5631 - acc: 0.8061[[    4    13    13 ...,     0     0     0]\n",
      " [11258    13    13 ...,     0     0     0]\n",
      " [ 3664    13    11 ...,     0     0     0]\n",
      " ..., \n",
      " [   80  1327    29 ...,     0     0     0]\n",
      " [  108    68  1573 ...,     0     0     0]\n",
      " [   10   116     5 ...,     0     0     0]]\n",
      " 79/200 [==========>...................] - ETA: 54s - loss: 1.5641 - acc: 0.8060[[   2 7796    3 ...,    0    0    0]\n",
      " [ 301   79   21 ...,    0    0    0]\n",
      " [1720   13 3192 ...,    0    0    0]\n",
      " ..., \n",
      " [  70  291 1018 ...,    0    0    0]\n",
      " [  10   63   13 ...,    0    0    0]\n",
      " [3604   13   14 ...,    0    0    0]]\n",
      " 80/200 [===========>..................] - ETA: 54s - loss: 1.5639 - acc: 0.8060[[  34    9    2 ...,    0    0    0]\n",
      " [3309   13   10 ...,    0    0    0]\n",
      " [3138  192   39 ...,    0    0    0]\n",
      " ..., \n",
      " [9776  744    3 ...,    0    0    0]\n",
      " [  32    1  908 ...,    0    0    0]\n",
      " [  33   13 1218 ...,    0    0    0]]\n",
      " 81/200 [===========>..................] - ETA: 53s - loss: 1.5668 - acc: 0.8057[[   1 9590  397 ...,    0    0    0]\n",
      " [ 803 3021  103 ...,    0    0    0]\n",
      " [ 564   13  297 ...,    0    0    0]\n",
      " ..., \n",
      " [ 558    5 2142 ...,    0    0    0]\n",
      " [ 171   70  644 ...,    0    0    0]\n",
      " [  70   15  392 ...,    0    0    0]]\n",
      " 82/200 [===========>..................] - ETA: 53s - loss: 1.5688 - acc: 0.8054[[  18    1   13 ...,    0    0    0]\n",
      " [  15    9 7198 ...,    0    0    0]\n",
      " [  15   11   45 ...,    0    0    0]\n",
      " ..., \n",
      " [1381 9770    3 ...,    0    0    0]\n",
      " [6832   13 1864 ...,    0    0    0]\n",
      " [1621  546    9 ...,    0    0    0]]\n",
      " 83/200 [===========>..................] - ETA: 52s - loss: 1.5730 - acc: 0.8050[[  15   11  147 ...,    0    0    0]\n",
      " [  70   15 1648 ...,    0    0    0]\n",
      " [1635   13  265 ...,    0    0    0]\n",
      " ..., \n",
      " [2069    7 1818 ...,    0    0    0]\n",
      " [  68  114 1523 ...,    0    0    0]\n",
      " [   1 1996    5 ...,    0    0    0]]\n",
      " 84/200 [===========>..................] - ETA: 52s - loss: 1.5726 - acc: 0.8051[[    1  1825     5 ...,     0     0     0]\n",
      " [   16    41   826 ...,     0     0     0]\n",
      " [ 1066  2530     8 ...,     0     0     0]\n",
      " ..., \n",
      " [   13  3328    44 ...,     0     0     0]\n",
      " [   32    79 11010 ...,     0     0     0]\n",
      " [  730    13   227 ...,     0     0     0]]\n",
      " 85/200 [===========>..................] - ETA: 51s - loss: 1.5748 - acc: 0.8048[[   15     7     2 ...,     0     0     0]\n",
      " [  108    68    21 ...,     0     0     0]\n",
      " [ 3903   105   505 ...,     0     0     0]\n",
      " ..., \n",
      " [    2   188   144 ...,     0     0     0]\n",
      " [    1   493  2588 ...,     0     0     0]\n",
      " [11730   303   102 ...,     0     0     0]]\n",
      " 86/200 [===========>..................] - ETA: 51s - loss: 1.5752 - acc: 0.8047[[  13   68  574 ...,    0    0    0]\n",
      " [ 159   13  336 ...,    0    0    0]\n",
      " [  53    9    1 ...,    0    0    0]\n",
      " ..., \n",
      " [1236    3    1 ...,    0    0    0]\n",
      " [  13  141   39 ...,    0    0    0]\n",
      " [ 443 1112    7 ...,    0    0    0]]\n",
      " 87/200 [============>.................] - ETA: 51s - loss: 1.5745 - acc: 0.8049[[ 2905    51  1765 ...,     0     0     0]\n",
      " [ 7920    13    11 ...,     0     0     0]\n",
      " [11831   695     6 ...,     0     0     0]\n",
      " ..., \n",
      " [  109    26    65 ...,     0     0     0]\n",
      " [    2   426  2162 ...,     0     0     0]\n",
      " [ 6620  6804   100 ...,     0     0     0]]\n",
      " 88/200 [============>.................] - ETA: 50s - loss: 1.5755 - acc: 0.8048[[ 154   66    6 ...,    0    0    0]\n",
      " [  58   59 2805 ...,    0    0    0]\n",
      " [   1  785  115 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 1896  119 ...,    0    0    0]\n",
      " [  78   37   13 ...,    0    0    0]\n",
      " [   2   13    5 ...,    0    0    0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 89/200 [============>.................] - ETA: 50s - loss: 1.5753 - acc: 0.8048[[   2  258    5 ...,    0    0    0]\n",
      " [  13   26  441 ...,    0    0    0]\n",
      " [  55    7 2803 ...,    0    0    0]\n",
      " ..., \n",
      " [ 219   26  441 ...,    0    0    0]\n",
      " [2928 2633    6 ...,    0    0    0]\n",
      " [ 116  191   13 ...,    0    0    0]]\n",
      " 90/200 [============>.................] - ETA: 49s - loss: 1.5750 - acc: 0.8049[[   1 1276 3182 ...,    0    0    0]\n",
      " [  38  176   66 ...,    0    0    0]\n",
      " [   1 1276 3182 ...,    0    0    0]\n",
      " ..., \n",
      " [  13 4441    5 ...,    0    0    0]\n",
      " [2253  808  514 ...,    0    0    0]\n",
      " [  13   26  113 ...,    0    0    0]]\n",
      " 91/200 [============>.................] - ETA: 49s - loss: 1.5745 - acc: 0.8049[[ 131 2788 2973 ...,    0    0    0]\n",
      " [ 109   26  101 ...,    0    0    0]\n",
      " [   2   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [1390 2704 3787 ...,    0    0    0]\n",
      " [1827 1582   10 ...,    0    0    0]\n",
      " [   1  236  477 ...,    0    0    0]]\n",
      " 92/200 [============>.................] - ETA: 48s - loss: 1.5745 - acc: 0.8049[[   2  582  405 ...,    0    0    0]\n",
      " [ 884  154   66 ...,    0    0    0]\n",
      " [ 654  117  332 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [1986    8 1431 ...,    0    0    0]\n",
      " [5682    9    4 ...,    0    0    0]]\n",
      " 93/200 [============>.................] - ETA: 48s - loss: 1.5755 - acc: 0.8048[[ 3013  9457  1060 ...,     0     0     0]\n",
      " [  109    26  1481 ...,     0     0     0]\n",
      " [10316    13    13 ...,     0     0     0]\n",
      " ..., \n",
      " [   38    62    13 ...,     0     0     0]\n",
      " [  623   157    13 ...,     0     0     0]\n",
      " [   10    13    13 ...,     0     0     0]]\n",
      " 94/200 [=============>................] - ETA: 47s - loss: 1.5758 - acc: 0.8048[[1846   13   11 ...,    0    0    0]\n",
      " [3319 1708  205 ...,    0    0    0]\n",
      " [  22 8203  310 ...,    0    0    0]\n",
      " ..., \n",
      " [2425   27 1059 ...,    0    0    0]\n",
      " [ 844  217 1679 ...,    0    0    0]\n",
      " [5387  969   11 ...,    0    0    0]]\n",
      " 95/200 [=============>................] - ETA: 47s - loss: 1.5754 - acc: 0.8049[[ 3377    11  4318 ...,     0     0     0]\n",
      " [10997   128    39 ...,     0     0     0]\n",
      " [   10  1461     5 ...,     0     0     0]\n",
      " ..., \n",
      " [  137     7     1 ...,     0     0     0]\n",
      " [    1  2195   236 ...,     0     0     0]\n",
      " [ 1405   100   566 ...,     0     0     0]]\n",
      " 96/200 [=============>................] - ETA: 46s - loss: 1.5755 - acc: 0.8049[[  15    7 6030 ...,    0    0    0]\n",
      " [  79  121  255 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " ..., \n",
      " [ 150  199  287 ...,    0    0    0]\n",
      " [ 751   11  399 ...,    0    0    0]\n",
      " [1742    9  155 ...,    0    0    0]]\n",
      " 97/200 [=============>................] - ETA: 46s - loss: 1.5758 - acc: 0.8049[[ 579    7 1010 ...,    0    0    0]\n",
      " [ 665 1252    9 ...,    0    0    0]\n",
      " [  80  199 6663 ...,    0    0    0]\n",
      " ..., \n",
      " [1385  968 1360 ...,    0    0    0]\n",
      " [8877   13   14 ...,    0    0    0]\n",
      " [   1 2097  152 ...,    0    0    0]]\n",
      " 98/200 [=============>................] - ETA: 46s - loss: 1.5742 - acc: 0.8050[[ 3010   430   590 ...,     0     0     0]\n",
      " [   13  6010    11 ...,     0     0     0]\n",
      " [ 3571     9  5456 ...,     0     0     0]\n",
      " ..., \n",
      " [11295    83    15 ...,     0     0     0]\n",
      " [  219   119   157 ...,     0     0     0]\n",
      " [   22  9314  5292 ...,     0     0     0]]\n",
      " 99/200 [=============>................] - ETA: 45s - loss: 1.5711 - acc: 0.8053[[ 267  157   22 ...,    0    0    0]\n",
      " [7723 1091  941 ...,    0    0    0]\n",
      " [1549  455    3 ...,    0    0    0]\n",
      " ..., \n",
      " [   2   13  394 ...,    0    0    0]\n",
      " [   2   19  545 ...,    0    0    0]\n",
      " [4883   13    5 ...,    0    0    0]]\n",
      "100/200 [==============>...............] - ETA: 45s - loss: 1.5677 - acc: 0.8056[[  13 3137  600 ...,    0    0    0]\n",
      " [7760   13   27 ...,    0    0    0]\n",
      " [3079 3363   11 ...,    0    0    0]\n",
      " ..., \n",
      " [1381    8 2084 ...,    0    0    0]\n",
      " [   1  214   23 ...,    0    0    0]\n",
      " [ 109   26 1317 ...,    0    0    0]]\n",
      "101/200 [==============>...............] - ETA: 44s - loss: 1.5652 - acc: 0.8058[[   13    13    13 ...,     0     0     0]\n",
      " [   13  2435 11097 ...,     0     0     0]\n",
      " [    1   191     6 ...,     0     0     0]\n",
      " ..., \n",
      " [    1   214  1301 ...,     0     0     0]\n",
      " [   34    14    48 ...,     0     0     0]\n",
      " [    1   406  5815 ...,     0     0     0]]\n",
      "102/200 [==============>...............] - ETA: 44s - loss: 1.5630 - acc: 0.8059[[    1  9836    23 ...,     0     0     0]\n",
      " [  154    66     6 ...,     0     0     0]\n",
      " [ 2541   748     3 ...,     0     0     0]\n",
      " ..., \n",
      " [  195    15    13 ...,     0     0     0]\n",
      " [    1 11532    14 ...,     0     0     0]\n",
      " [   56  4391     6 ...,     0     0     0]]\n",
      "103/200 [==============>...............] - ETA: 43s - loss: 1.5625 - acc: 0.8060[[   1 1693 3514 ...,    0    0    0]\n",
      " [3827 4729   25 ...,    0    0    0]\n",
      " [4034 5683   10 ...,    0    0    0]\n",
      " ..., \n",
      " [ 221  230   13 ...,    0    0    0]\n",
      " [  70   15  392 ...,    0    0    0]\n",
      " [ 335    9    2 ...,    0    0    0]]\n",
      "104/200 [==============>...............] - ETA: 43s - loss: 1.5621 - acc: 0.8061[[  15  748   90 ...,    0    0    0]\n",
      " [   1 1217  231 ...,    0    0    0]\n",
      " [ 152  139   11 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13   13 ...,    0    0    0]\n",
      " [   1 9395   23 ...,    0    0    0]\n",
      " [  15 1272 1558 ...,    0    0    0]]\n",
      "105/200 [==============>...............] - ETA: 42s - loss: 1.5639 - acc: 0.8059[[  34  592   13 ...,    0    0    0]\n",
      " [  18   22 5726 ...,    0    0    0]\n",
      " [7167   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   13   44 ...,    0    0    0]\n",
      " [9077   50   13 ...,    0    0    0]\n",
      " [   4  189  343 ...,    0    0    0]]\n",
      "106/200 [==============>...............] - ETA: 42s - loss: 1.5645 - acc: 0.8059[[  15    9    2 ...,    0    0    0]\n",
      " [  89    7   80 ...,    0    0    0]\n",
      " [  15   14   41 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  611   86 ...,    0    0    0]\n",
      " [   1  485 1456 ...,    0    0    0]\n",
      " [  15  744   90 ...,    0    0    0]]\n",
      "107/200 [===============>..............] - ETA: 41s - loss: 1.5649 - acc: 0.8058[[  56  290    5 ...,    0    0    0]\n",
      " [ 108 1971    9 ...,    0    0    0]\n",
      " [1460 1503   89 ...,    0    0    0]\n",
      " ..., \n",
      " [  78   77 9528 ...,    0    0    0]\n",
      " [ 127   63  144 ...,    0    0    0]\n",
      " [4802   76   43 ...,    0    0    0]]\n",
      "108/200 [===============>..............] - ETA: 41s - loss: 1.5649 - acc: 0.8058[[ 245  431    9 ...,    0    0    0]\n",
      " [   1   73  138 ...,    0    0    0]\n",
      " [  56  706  290 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 1540  737 ...,    0    0    0]\n",
      " [  12 2850   13 ...,    0    0    0]\n",
      " [3194  102   67 ...,    0    0    0]]\n",
      "109/200 [===============>..............] - ETA: 41s - loss: 1.5676 - acc: 0.8056[[ 202    1 2814 ...,    0    0    0]\n",
      " [   1  847   16 ...,    0    0    0]\n",
      " [2346   13   81 ...,    0    0    0]\n",
      " ..., \n",
      " [  13 1645  568 ...,    0    0    0]\n",
      " [ 535    1 3643 ...,    0    0    0]\n",
      " [5119 1903    9 ...,    0    0    0]]\n",
      "110/200 [===============>..............] - ETA: 40s - loss: 1.5695 - acc: 0.8054[[  64  598   82 ...,    0    0    0]\n",
      " [5095 1115 1312 ...,    0    0    0]\n",
      " [ 739  396   13 ...,    0    0    0]\n",
      " ..., \n",
      " [8251 4061   86 ...,    0    0    0]\n",
      " [  56   63    4 ...,    0    0    0]\n",
      " [   1 1011 1463 ...,    0    0    0]]\n",
      "111/200 [===============>..............] - ETA: 40s - loss: 1.5741 - acc: 0.8049[[  69  263   30 ...,    0    0    0]\n",
      " [ 159   13  141 ...,    0    0    0]\n",
      " [ 116   67    1 ...,    0    0    0]\n",
      " ..., \n",
      " [  89   67 5801 ...,    0    0    0]\n",
      " [   1 1033   86 ...,    0    0    0]\n",
      " [  32   13   13 ...,    0    0    0]]\n",
      "112/200 [===============>..............] - ETA: 39s - loss: 1.5723 - acc: 0.8051[[  10  885 1705 ...,    0    0    0]\n",
      " [  13 1442  947 ...,    0    0    0]\n",
      " [  34  592  630 ...,    0    0    0]\n",
      " ..., \n",
      " [7813 2029    9 ...,    0    0    0]\n",
      " [4534   43 4534 ...,    0    0    0]\n",
      " [  72 7076   83 ...,    0    0    0]]\n",
      "113/200 [===============>..............] - ETA: 39s - loss: 1.5742 - acc: 0.8049[[  13  817   17 ...,    0    0    0]\n",
      " [  10  888   13 ...,    0    0    0]\n",
      " [ 133   39   20 ...,    0    0    0]\n",
      " ..., \n",
      " [   2  223 1745 ...,    0    0    0]\n",
      " [   1  463   13 ...,    0    0    0]\n",
      " [ 194  102  504 ...,    0    0    0]]\n",
      "114/200 [================>.............] - ETA: 38s - loss: 1.5753 - acc: 0.8048[[ 550 8168   13 ...,    0    0    0]\n",
      " [ 245   13   13 ...,    0    0    0]\n",
      " [  18    1 7564 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 6402  462 ...,    0    0    0]\n",
      " [1742  455    3 ...,    0    0    0]\n",
      " [ 104 1340   48 ...,    0    0    0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/200 [================>.............] - ETA: 38s - loss: 1.5746 - acc: 0.8050[[  658    14   276 ...,     0     0     0]\n",
      " [    4   116  1595 ...,     0     0     0]\n",
      " [    1   416   381 ...,     0     0     0]\n",
      " ..., \n",
      " [  127  4833    63 ...,     0     0     0]\n",
      " [    1   282   339 ...,     0     0     0]\n",
      " [11976     9   111 ...,     0     0     0]]\n",
      "116/200 [================>.............] - ETA: 37s - loss: 1.5741 - acc: 0.8050[[  93 1629   60 ...,    0    0    0]\n",
      " [1357    8 6176 ...,    0    0    0]\n",
      " [ 150 1718  133 ...,    0    0    0]\n",
      " ..., \n",
      " [ 884   73   66 ...,    0    0    0]\n",
      " [  55 9128 1070 ...,    0    0    0]\n",
      " [  13   26  182 ...,    0    0    0]]\n",
      "117/200 [================>.............] - ETA: 37s - loss: 1.5745 - acc: 0.8050[[    1    13    91 ...,     0     0     0]\n",
      " [ 5582   217 11411 ...,     0     0     0]\n",
      " [  109    26   113 ...,     0     0     0]\n",
      " ..., \n",
      " [    1  8532   169 ...,     0     0     0]\n",
      " [  248  3499   280 ...,     0     0     0]\n",
      " [ 1695   623     6 ...,     0     0     0]]\n",
      "118/200 [================>.............] - ETA: 36s - loss: 1.5749 - acc: 0.8050[[   1 1896  191 ...,    0    0    0]\n",
      " [  58   59 1032 ...,    0    0    0]\n",
      " [   1  884  191 ...,    0    0    0]\n",
      " ..., \n",
      " [  73 1479    4 ...,    0    0    0]\n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [1430  811   13 ...,    0    0    0]]\n",
      "119/200 [================>.............] - ETA: 36s - loss: 1.5745 - acc: 0.8050[[  19  120 2442 ...,    0    0    0]\n",
      " [1379    1  126 ...,    0    0    0]\n",
      " [5183    4  367 ...,    0    0    0]\n",
      " ..., \n",
      " [2191    8  880 ...,    0    0    0]\n",
      " [ 546  510    6 ...,    0    0    0]\n",
      " [  13 2639 9459 ...,    0    0    0]]\n",
      "120/200 [=================>............] - ETA: 36s - loss: 1.5748 - acc: 0.8050[[   13    26   441 ...,     0     0     0]\n",
      " [   58    59   187 ...,     0     0     0]\n",
      " [    1  1508  1687 ...,     0     0     0]\n",
      " ..., \n",
      " [  255   160  1938 ...,     0     0     0]\n",
      " [ 7406 10480  1673 ...,     0     0     0]\n",
      " [   19   352   154 ...,     0     0     0]]\n",
      "121/200 [=================>............] - ETA: 35s - loss: 1.5741 - acc: 0.8051[[ 711  168   53 ...,    0    0    0]\n",
      " [   2  179  734 ...,    0    0    0]\n",
      " [1757  187  115 ...,    0    0    0]\n",
      " ..., \n",
      " [  22  864    8 ...,    0    0    0]\n",
      " [  47  867   13 ...,    0    0    0]\n",
      " [ 234 9748  289 ...,    0    0    0]]\n",
      "122/200 [=================>............] - ETA: 35s - loss: 1.5753 - acc: 0.8050[[ 166 7677   27 ...,    0    0    0]\n",
      " [ 654  145   11 ...,    0    0    0]\n",
      " [ 131  429 1187 ...,    0    0    0]\n",
      " ..., \n",
      " [  13 8443   11 ...,    0    0    0]\n",
      " [2084 2581 1392 ...,    0    0    0]\n",
      " [ 236  477  246 ...,    0    0    0]]\n",
      "123/200 [=================>............] - ETA: 34s - loss: 1.5755 - acc: 0.8050[[    2   412    12 ...,     0     0     0]\n",
      " [ 3909   267    23 ...,     0     0     0]\n",
      " [    1  6447    13 ...,     0     0     0]\n",
      " ..., \n",
      " [ 1497     8   148 ...,     0     0     0]\n",
      " [   22  4477 10665 ...,     0     0     0]\n",
      " [ 2965    13    30 ...,     0     0     0]]\n",
      "124/200 [=================>............] - ETA: 34s - loss: 1.5760 - acc: 0.8049[[   1  406 5815 ...,    0    0    0]\n",
      " [  13  505  105 ...,    0    0    0]\n",
      " [  22  150   13 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 4705 8115 ...,    0    0    0]\n",
      " [2453   13   13 ...,    0    0    0]\n",
      " [ 566    1 2604 ...,    0    0    0]]\n",
      "125/200 [=================>............] - ETA: 33s - loss: 1.5763 - acc: 0.8049[[  93   23   13 ...,    0    0    0]\n",
      " [ 147  202   13 ...,    0    0    0]\n",
      " [1693 3716 1232 ...,    0    0    0]\n",
      " ..., \n",
      " [ 119   21  616 ...,    0    0    0]\n",
      " [ 377    5   15 ...,    0    0    0]\n",
      " [3827   67 5652 ...,    0    0    0]]\n",
      "126/200 [=================>............] - ETA: 33s - loss: 1.5759 - acc: 0.8050[[ 1819     8  5136 ...,     0     0     0]\n",
      " [ 1770     5 11027 ...,     0     0     0]\n",
      " [    2  1355    13 ...,     0     0     0]\n",
      " ..., \n",
      " [  987    83    41 ...,     0     0     0]\n",
      " [   10  1334   123 ...,     0     0     0]\n",
      " [   15    14     1 ...,     0     0     0]]\n",
      "127/200 [==================>...........] - ETA: 32s - loss: 1.5733 - acc: 0.8052[[  47 1907 1911 ...,    0    0    0]\n",
      " [   1   19  120 ...,    0    0    0]\n",
      " [1668   13  925 ...,    0    0    0]\n",
      " ..., \n",
      " [  15 1893   90 ...,    0    0    0]\n",
      " [   1 2757   11 ...,    0    0    0]\n",
      " [ 973 6406   11 ...,    0    0    0]]\n",
      "128/200 [==================>...........] - ETA: 32s - loss: 1.5712 - acc: 0.8054[[  173     5    69 ...,     0     0     0]\n",
      " [11368     5  3219 ...,     0     0     0]\n",
      " [ 4915   941 11116 ...,     0     0     0]\n",
      " ..., \n",
      " [  108    68   595 ...,     0     0     0]\n",
      " [ 1224  1890    13 ...,     0     0     0]\n",
      " [ 3054   130  1046 ...,     0     0     0]]\n",
      "129/200 [==================>...........] - ETA: 31s - loss: 1.5689 - acc: 0.8055[[  13 2097   11 ...,    0    0    0]\n",
      " [ 849 1211   10 ...,    0    0    0]\n",
      " [9739 1535    4 ...,    0    0    0]\n",
      " ..., \n",
      " [5617 3345 1822 ...,    0    0    0]\n",
      " [ 633 3324   23 ...,    0    0    0]\n",
      " [3125 1254   11 ...,    0    0    0]]\n",
      "130/200 [==================>...........] - ETA: 31s - loss: 1.5668 - acc: 0.8057[[    1  5180 10336 ...,     0     0     0]\n",
      " [  519  5445  2648 ...,     0     0     0]\n",
      " [    1  2400    13 ...,     0     0     0]\n",
      " ..., \n",
      " [ 1369  3750   192 ...,     0     0     0]\n",
      " [ 3327     9    48 ...,     0     0     0]\n",
      " [    1    13  3351 ...,     0     0     0]]\n",
      "131/200 [==================>...........] - ETA: 31s - loss: 1.5661 - acc: 0.8057[[   1 2510    5 ...,    0    0    0]\n",
      " [ 824    9   76 ...,    0    0    0]\n",
      " [3393 7762    8 ...,    0    0    0]\n",
      " ..., \n",
      " [ 132   26   65 ...,    0    0    0]\n",
      " [4911 2964    8 ...,    0    0    0]\n",
      " [ 930   13   14 ...,    0    0    0]]\n",
      "132/200 [==================>...........] - ETA: 30s - loss: 1.5666 - acc: 0.8057[[ 159 5589   11 ...,    0    0    0]\n",
      " [1067  314   13 ...,    0    0    0]\n",
      " [   1 1289 3073 ...,    0    0    0]\n",
      " ..., \n",
      " [  17 4581   11 ...,    0    0    0]\n",
      " [  10    1   47 ...,    0    0    0]\n",
      " [ 155   68  718 ...,    0    0    0]]\n",
      "133/200 [==================>...........] - ETA: 30s - loss: 1.5675 - acc: 0.8056[[ 102  123  442 ...,    0    0    0]\n",
      " [ 145  757    9 ...,    0    0    0]\n",
      " [   1 1115  291 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 7219   38 ...,    0    0    0]\n",
      " [  99 5343 2628 ...,    0    0    0]\n",
      " [7155   81    2 ...,    0    0    0]]\n",
      "134/200 [===================>..........] - ETA: 29s - loss: 1.5677 - acc: 0.8056[[  79    5  600 ...,    0    0    0]\n",
      " [  13 1751  541 ...,    0    0    0]\n",
      " [1346 2013  163 ...,    0    0    0]\n",
      " ..., \n",
      " [1694 2380  247 ...,    0    0    0]\n",
      " [  19 1848 4197 ...,    0    0    0]\n",
      " [  70   13   13 ...,    0    0    0]]\n",
      "135/200 [===================>..........] - ETA: 29s - loss: 1.5691 - acc: 0.8054[[  41    5    1 ...,    0    0    0]\n",
      " [  42    7  111 ...,    0    0    0]\n",
      " [   1 3532    4 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  680   13 ...,    0    0    0]\n",
      " [ 293 5775   23 ...,    0    0    0]\n",
      " [   6 4325   86 ...,    0    0    0]]\n",
      "136/200 [===================>..........] - ETA: 28s - loss: 1.5679 - acc: 0.8055[[  12   47 4618 ...,    0    0    0]\n",
      " [  32   61    3 ...,    0    0    0]\n",
      " [   1   47  872 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   13    9 ...,    0    0    0]\n",
      " [  13 1226  876 ...,    0    0    0]\n",
      " [ 730   13  995 ...,    0    0    0]]\n",
      "137/200 [===================>..........] - ETA: 28s - loss: 1.5686 - acc: 0.8054[[6290   23   48 ...,    0    0    0]\n",
      " [  70 2860 4117 ...,    0    0    0]\n",
      " [ 639   37   13 ...,    0    0    0]\n",
      " ..., \n",
      " [   2   19  563 ...,    0    0    0]\n",
      " [   1  747   14 ...,    0    0    0]\n",
      " [  15    7 6004 ...,    0    0    0]]\n",
      "138/200 [===================>..........] - ETA: 27s - loss: 1.5712 - acc: 0.8052[[ 302   13  154 ...,    0    0    0]\n",
      " [  15  105   21 ...,    0    0    0]\n",
      " [5814   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [  15  871   20 ...,    0    0    0]\n",
      " [2410 9350    9 ...,    0    0    0]\n",
      " [ 644   13   81 ...,    0    0    0]]\n",
      "139/200 [===================>..........] - ETA: 27s - loss: 1.5754 - acc: 0.8047[[   1   69    7 ...,    0    0    0]\n",
      " [ 108   68  410 ...,    0    0    0]\n",
      " [  15    7   48 ...,    0    0    0]\n",
      " ..., \n",
      " [  13  104   21 ...,    0    0    0]\n",
      " [  12  393   13 ...,    0    0    0]\n",
      " [2113    9   39 ...,    0    0    0]]\n",
      "140/200 [====================>.........] - ETA: 27s - loss: 1.5763 - acc: 0.8046[[   1   13    5 ...,    0    0    0]\n",
      " [ 483    1  474 ...,    0    0    0]\n",
      " [ 104   13   97 ...,    0    0    0]\n",
      " ..., \n",
      " [1360 3930   11 ...,    0    0    0]\n",
      " [  43  383  244 ...,    0    0    0]\n",
      " [  15  530    3 ...,    0    0    0]]\n",
      "141/200 [====================>.........] - ETA: 26s - loss: 1.5758 - acc: 0.8047[[  301  3343 11699 ...,     0     0     0]\n",
      " [ 9173  7862    81 ...,     0     0     0]\n",
      " [   13    13  5463 ...,     0     0     0]\n",
      " ..., \n",
      " [    4     2  1307 ...,     0     0     0]\n",
      " [   13 11062     1 ...,     0     0     0]\n",
      " [   13    13   385 ...,     0     0     0]]\n",
      "142/200 [====================>.........] - ETA: 26s - loss: 1.5773 - acc: 0.8045[[  962   450   283 ...,     0     0     0]\n",
      " [    1   659 10774 ...,     0     0     0]\n",
      " [    2  1045   910 ...,     0     0     0]\n",
      " ..., \n",
      " [    5   738    13 ...,     0     0     0]\n",
      " [    1    13    13 ...,     0     0     0]\n",
      " [ 3056   355  1433 ...,     0     0     0]]\n",
      "143/200 [====================>.........] - ETA: 25s - loss: 1.5768 - acc: 0.8046[[    1  1876    81 ...,     0     0     0]\n",
      " [   13    13    13 ...,     0     0     0]\n",
      " [   13  7673  2325 ...,     0     0     0]\n",
      " ..., \n",
      " [   13     1    13 ...,     0     0     0]\n",
      " [    1    13  5660 ...,     0     0     0]\n",
      " [ 4094    13 10706 ...,     0     0     0]]\n",
      "144/200 [====================>.........] - ETA: 25s - loss: 1.5759 - acc: 0.8047[[   13    13     4 ...,     0     0     0]\n",
      " [   41   264  1023 ...,     0     0     0]\n",
      " [ 1092    13   264 ...,     0     0     0]\n",
      " ..., \n",
      " [ 1038  5235    10 ...,     0     0     0]\n",
      " [    1  1124    27 ...,     0     0     0]\n",
      " [11578  7361     4 ...,     0     0     0]]\n",
      "145/200 [====================>.........] - ETA: 24s - loss: 1.5765 - acc: 0.8047[[  58   59  154 ...,    0    0    0]\n",
      " [1056 1719  267 ...,    0    0    0]\n",
      " [  13   69 2399 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [   2   13  405 ...,    0    0    0]]\n",
      "146/200 [====================>.........] - ETA: 24s - loss: 1.5764 - acc: 0.8047[[ 109   26  106 ...,    0    0    0]\n",
      " [   1 1202    5 ...,    0    0    0]\n",
      " [   1 1276 3182 ...,    0    0    0]\n",
      " ..., \n",
      " [2990  674  308 ...,    0    0    0]\n",
      " [ 491   26  113 ...,    0    0    0]\n",
      " [ 152  139  106 ...,    0    0    0]]\n",
      "147/200 [=====================>........] - ETA: 23s - loss: 1.5765 - acc: 0.8047[[ 1189   224     7 ...,     0     0     0]\n",
      " [    1    13    91 ...,     0     0     0]\n",
      " [ 2574    30    36 ...,     0     0     0]\n",
      " ..., \n",
      " [    1   551    13 ...,     0     0     0]\n",
      " [   13   104   945 ...,     0     0     0]\n",
      " [  306    27 11880 ...,     0     0     0]]\n",
      "148/200 [=====================>........] - ETA: 23s - loss: 1.5762 - acc: 0.8048[[   1   13   91 ...,    0    0    0]\n",
      " [   1  306  119 ...,    0    0    0]\n",
      " [   1   13   91 ...,    0    0    0]\n",
      " ..., \n",
      " [ 456  187 1924 ...,    0    0    0]\n",
      " [ 234  102   67 ...,    0    0    0]\n",
      " [ 456 4785   32 ...,    0    0    0]]\n",
      "149/200 [=====================>........] - ETA: 22s - loss: 1.5765 - acc: 0.8047[[ 456  187 1924 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [   1 6434  384 ...,    0    0    0]\n",
      " ..., \n",
      " [1195 1916   11 ...,    0    0    0]\n",
      " [ 372   11  269 ...,    0    0    0]\n",
      " [ 318    8   92 ...,    0    0    0]]\n",
      "150/200 [=====================>........] - ETA: 22s - loss: 1.5767 - acc: 0.8047[[ 342  196    4 ...,    0    0    0]\n",
      " [ 661   10    1 ...,    0    0    0]\n",
      " [ 342  196    4 ...,    0    0    0]\n",
      " ..., \n",
      " [ 390 3598   27 ...,    0    0    0]\n",
      " [  16 4647 1418 ...,    0    0    0]\n",
      " [ 171  108 1150 ...,    0    0    0]]\n",
      "151/200 [=====================>........] - ETA: 22s - loss: 1.5769 - acc: 0.8047[[  109    26   115 ...,     0     0     0]\n",
      " [    1    19   120 ...,     0     0     0]\n",
      " [  203   295  1943 ...,     0     0     0]\n",
      " ..., \n",
      " [ 1961  3177    14 ...,     0     0     0]\n",
      " [    1  5396     4 ...,     0     0     0]\n",
      " [   13 11404    61 ...,     0     0     0]]\n",
      "152/200 [=====================>........] - ETA: 21s - loss: 1.5775 - acc: 0.8047[[   2   13 7793 ...,    0    0    0]\n",
      " [2932   13   13 ...,    0    0    0]\n",
      " [   1  132  732 ...,    0    0    0]\n",
      " ..., \n",
      " [  70   15  392 ...,    0    0    0]\n",
      " [2350   11  631 ...,    0    0    0]\n",
      " [  60  110   11 ...,    0    0    0]]\n",
      "153/200 [=====================>........] - ETA: 21s - loss: 1.5776 - acc: 0.8046[[10963  3063    83 ...,     0     0     0]\n",
      " [  987    83   318 ...,     0     0     0]\n",
      " [  193    14    13 ...,     0     0     0]\n",
      " ..., \n",
      " [   99   255    73 ...,     0     0     0]\n",
      " [    2    19   545 ...,     0     0     0]\n",
      " [  119     6    36 ...,     0     0     0]]\n",
      "154/200 [======================>.......] - ETA: 20s - loss: 1.5776 - acc: 0.8047[[    1   339  1897 ...,     0     0     0]\n",
      " [   68   337     3 ...,     0     0     0]\n",
      " [   49    38    62 ...,     0     0     0]\n",
      " ..., \n",
      " [ 1397     1    13 ...,     0     0     0]\n",
      " [   13 11624     8 ...,     0     0     0]\n",
      " [   70  5936  6089 ...,     0     0     0]]\n",
      "155/200 [======================>.......] - ETA: 20s - loss: 1.5772 - acc: 0.8047[[   1  785  283 ...,    0    0    0]\n",
      " [1170  159  390 ...,    0    0    0]\n",
      " [   1   13   91 ...,    0    0    0]\n",
      " ..., \n",
      " [  55    7  191 ...,    0    0    0]\n",
      " [  49 4490 7088 ...,    0    0    0]\n",
      " [   1   13  343 ...,    0    0    0]]\n",
      "156/200 [======================>.......] - ETA: 19s - loss: 1.5752 - acc: 0.8049[[  69  418  335 ...,    0    0    0]\n",
      " [1961 8415   11 ...,    0    0    0]\n",
      " [5175  694  103 ...,    0    0    0]\n",
      " ..., \n",
      " [ 309 4632 5172 ...,    0    0    0]\n",
      " [3402 2029    7 ...,    0    0    0]\n",
      " [  13  816  276 ...,    0    0    0]]\n",
      "157/200 [======================>.......] - ETA: 19s - loss: 1.5737 - acc: 0.8050[[  797 11533   186 ...,     0     0     0]\n",
      " [ 1801  2135   451 ...,     0     0     0]\n",
      " [ 2406    13   903 ...,     0     0     0]\n",
      " ..., \n",
      " [ 1050    13   647 ...,     0     0     0]\n",
      " [  866  4106    21 ...,     0     0     0]\n",
      " [   70     1  9107 ...,     0     0     0]]\n",
      "158/200 [======================>.......] - ETA: 18s - loss: 1.5715 - acc: 0.8051[[6389 2097  694 ...,    0    0    0]\n",
      " [   1   13   13 ...,    0    0    0]\n",
      " [ 363 3764 1205 ...,    0    0    0]\n",
      " ..., \n",
      " [2015   11 2025 ...,    0    0    0]\n",
      " [  13   26   23 ...,    0    0    0]\n",
      " [ 761  621   13 ...,    0    0    0]]\n",
      "159/200 [======================>.......] - ETA: 18s - loss: 1.5699 - acc: 0.8053[[  13   13  807 ...,    0    0    0]\n",
      " [ 491  187  182 ...,    0    0    0]\n",
      " [ 365    7   13 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  883 2440 ...,    0    0    0]\n",
      " [  13 1248 1710 ...,    0    0    0]\n",
      " [2613  141   39 ...,    0    0    0]]\n",
      "160/200 [=======================>......] - ETA: 18s - loss: 1.5686 - acc: 0.8054[[  16   13    5 ...,    0    0    0]\n",
      " [5945 2617  168 ...,    0    0    0]\n",
      " [  49  177  144 ...,    0    0    0]\n",
      " ..., \n",
      " [5517 2123 6731 ...,    0    0    0]\n",
      " [   1  221  230 ...,    0    0    0]\n",
      " [ 140  553  697 ...,    0    0    0]]\n",
      "161/200 [=======================>......] - ETA: 17s - loss: 1.5680 - acc: 0.8054[[5490    5    1 ...,    0    0    0]\n",
      " [  13   13   13 ...,    0    0    0]\n",
      " [  89    7   80 ...,    0    0    0]\n",
      " ..., \n",
      " [  93   23    1 ...,    0    0    0]\n",
      " [  12   13  161 ...,    0    0    0]\n",
      " [1770    5   13 ...,    0    0    0]]\n",
      "162/200 [=======================>......] - ETA: 17s - loss: 1.5677 - acc: 0.8055[[  70   68  377 ...,    0    0    0]\n",
      " [   1 1556 6068 ...,    0    0    0]\n",
      " [ 194 1156  853 ...,    0    0    0]\n",
      " ..., \n",
      " [ 137    9   15 ...,    0    0    0]\n",
      " [  13   13   44 ...,    0    0    0]\n",
      " [3711  210   13 ...,    0    0    0]]\n",
      "163/200 [=======================>......] - ETA: 16s - loss: 1.5683 - acc: 0.8054[[ 137    7   19 ...,    0    0    0]\n",
      " [   1  214   23 ...,    0    0    0]\n",
      " [ 599 2846 1433 ...,    0    0    0]\n",
      " ..., \n",
      " [1150 1900    9 ...,    0    0    0]\n",
      " [  15   11   45 ...,    0    0    0]\n",
      " [ 245 1192    8 ...,    0    0    0]]\n",
      "164/200 [=======================>......] - ETA: 16s - loss: 1.5689 - acc: 0.8053[[  13   13    4 ...,    0    0    0]\n",
      " [1742    7 2878 ...,    0    0    0]\n",
      " [  13   13  141 ...,    0    0    0]\n",
      " ..., \n",
      " [ 644  435 5264 ...,    0    0    0]\n",
      " [   2   13  146 ...,    0    0    0]\n",
      " [   1 6418   13 ...,    0    0    0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/200 [=======================>......] - ETA: 15s - loss: 1.5692 - acc: 0.8053[[ 630  164   13 ...,    0    0    0]\n",
      " [   4   60 9835 ...,    0    0    0]\n",
      " [ 103 1075  779 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 1274    5 ...,    0    0    0]\n",
      " [  89   23  693 ...,    0    0    0]\n",
      " [   4    2   37 ...,    0    0    0]]\n",
      "166/200 [=======================>......] - ETA: 15s - loss: 1.5689 - acc: 0.8053[[  13   13   86 ...,    0    0    0]\n",
      " [3550    9  254 ...,    0    0    0]\n",
      " [ 605 2648   23 ...,    0    0    0]\n",
      " ..., \n",
      " [6382 6947   30 ...,    0    0    0]\n",
      " [  13  418  335 ...,    0    0    0]\n",
      " [  13 4125 5709 ...,    0    0    0]]\n",
      "167/200 [========================>.....] - ETA: 14s - loss: 1.5705 - acc: 0.8052[[   1 1927    5 ...,    0    0    0]\n",
      " [  13   13   67 ...,    0    0    0]\n",
      " [  29 5307   13 ...,    0    0    0]\n",
      " ..., \n",
      " [6482 6781   13 ...,    0    0    0]\n",
      " [2139  210 3422 ...,    0    0    0]\n",
      " [   1 7826  218 ...,    0    0    0]]\n",
      "168/200 [========================>.....] - ETA: 14s - loss: 1.5714 - acc: 0.8051[[ 171    4  318 ...,    0    0    0]\n",
      " [   4   22 4218 ...,    0    0    0]\n",
      " [  89    7  439 ...,    0    0    0]\n",
      " ..., \n",
      " [ 486  537   57 ...,    0    0    0]\n",
      " [  13   13   51 ...,    0    0    0]\n",
      " [4511 4278   41 ...,    0    0    0]]\n",
      "169/200 [========================>.....] - ETA: 13s - loss: 1.5735 - acc: 0.8048[[  42   11   45 ...,    0    0    0]\n",
      " [ 586    9  939 ...,    0    0    0]\n",
      " [ 751   13  171 ...,    0    0    0]\n",
      " ..., \n",
      " [   2 9906 1477 ...,    0    0    0]\n",
      " [  13  104 1619 ...,    0    0    0]\n",
      " [   1   19  120 ...,    0    0    0]]\n",
      "170/200 [========================>.....] - ETA: 13s - loss: 1.5731 - acc: 0.8049[[ 1546  4893    81 ...,     0     0     0]\n",
      " [  443   900    11 ...,     0     0     0]\n",
      " [   22  1241     9 ...,     0     0     0]\n",
      " ..., \n",
      " [    1  1238 11900 ...,     0     0     0]\n",
      " [ 1675  1415    11 ...,     0     0     0]\n",
      " [   13    13   292 ...,     0     0     0]]\n",
      "171/200 [========================>.....] - ETA: 13s - loss: 1.5742 - acc: 0.8048[[  49   63  144 ...,    0    0    0]\n",
      " [   1  751 2224 ...,    0    0    0]\n",
      " [ 173  831   32 ...,    0    0    0]\n",
      " ..., \n",
      " [  13  321  285 ...,    0    0    0]\n",
      " [  34  400   77 ...,    0    0    0]\n",
      " [   2 7121    3 ...,    0    0    0]]\n",
      "172/200 [========================>.....] - ETA: 12s - loss: 1.5749 - acc: 0.8048[[   1  156   61 ...,    0    0    0]\n",
      " [  64   82   13 ...,    0    0    0]\n",
      " [  15    7   45 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 7812    5 ...,    0    0    0]\n",
      " [ 535   13   34 ...,    0    0    0]\n",
      " [   1  541   10 ...,    0    0    0]]\n",
      "173/200 [========================>.....] - ETA: 12s - loss: 1.5743 - acc: 0.8048[[3798  160  265 ...,    0    0    0]\n",
      " [  43   99 3083 ...,    0    0    0]\n",
      " [  22   13  736 ...,    0    0    0]\n",
      " ..., \n",
      " [1164   13    1 ...,    0    0    0]\n",
      " [  92 1800   67 ...,    0    0    0]\n",
      " [   1 4878    4 ...,    0    0    0]]\n",
      "174/200 [=========================>....] - ETA: 11s - loss: 1.5739 - acc: 0.8049[[   17   431 11930 ...,     0     0     0]\n",
      " [ 1019  3939   103 ...,     0     0     0]\n",
      " [ 1164     1    13 ...,     0     0     0]\n",
      " ..., \n",
      " [  367    27   269 ...,     0     0     0]\n",
      " [  219    26   441 ...,     0     0     0]\n",
      " [ 1905   809  7684 ...,     0     0     0]]\n",
      "175/200 [=========================>....] - ETA: 11s - loss: 1.5741 - acc: 0.8049[[   1 2105  941 ...,    0    0    0]\n",
      " [1324 4909   69 ...,    0    0    0]\n",
      " [   2  397 5043 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   69  297 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [6741 2232   23 ...,    0    0    0]]\n",
      "176/200 [=========================>....] - ETA: 10s - loss: 1.5741 - acc: 0.8049[[ 214   23    1 ...,    0    0    0]\n",
      " [  13  301  155 ...,    0    0    0]\n",
      " [ 373  423   55 ...,    0    0    0]\n",
      " ..., \n",
      " [1005    9 7106 ...,    0    0    0]\n",
      " [5992   69 3226 ...,    0    0    0]\n",
      " [ 373  423   55 ...,    0    0    0]]\n",
      "177/200 [=========================>....] - ETA: 10s - loss: 1.5737 - acc: 0.8050[[5937 1321 5794 ...,    0    0    0]\n",
      " [   1   13 3967 ...,    0    0    0]\n",
      " [  49  919 7088 ...,    0    0    0]\n",
      " ..., \n",
      " [1137 3695    4 ...,    0    0    0]\n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [   1   13   91 ...,    0    0    0]]\n",
      "178/200 [=========================>....] - ETA: 9s - loss: 1.5735 - acc: 0.8051 [[  89   14   39 ...,    0    0    0]\n",
      " [ 481   66 1215 ...,    0    0    0]\n",
      " [   1  868   26 ...,    0    0    0]\n",
      " ..., \n",
      " [ 179  946  677 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [3491  680   13 ...,    0    0    0]]\n",
      "179/200 [=========================>....] - ETA: 9s - loss: 1.5740 - acc: 0.8050[[ 108   68   23 ...,    0    0    0]\n",
      " [   2   19  417 ...,    0    0    0]\n",
      " [  55    7 2921 ...,    0    0    0]\n",
      " ..., \n",
      " [ 456  187  687 ...,    0    0    0]\n",
      " [ 241    7 8494 ...,    0    0    0]\n",
      " [  13 4086 3289 ...,    0    0    0]]\n",
      "180/200 [==========================>...] - ETA: 9s - loss: 1.5743 - acc: 0.8050[[  47   15   14 ...,    0    0    0]\n",
      " [2012    5  142 ...,    0    0    0]\n",
      " [4418   11 2389 ...,    0    0    0]\n",
      " ..., \n",
      " [1449 1148   13 ...,    0    0    0]\n",
      " [   1 3494  161 ...,    0    0    0]\n",
      " [  13 2654    4 ...,    0    0    0]]\n",
      "181/200 [==========================>...] - ETA: 8s - loss: 1.5744 - acc: 0.8050[[  64   82  107 ...,    0    0    0]\n",
      " [ 276  178   13 ...,    0    0    0]\n",
      " [ 488    8    1 ...,    0    0    0]\n",
      " ..., \n",
      " [  34   61   98 ...,    0    0    0]\n",
      " [2022 2923  205 ...,    0    0    0]\n",
      " [ 109   26   65 ...,    0    0    0]]\n",
      "182/200 [==========================>...] - ETA: 8s - loss: 1.5743 - acc: 0.8050[[   1   91   14 ...,    0    0    0]\n",
      " [ 325  829  662 ...,    0    0    0]\n",
      " [   3  356  767 ...,    0    0    0]\n",
      " ..., \n",
      " [ 390 3686    9 ...,    0    0    0]\n",
      " [ 226   13  284 ...,    0    0    0]\n",
      " [   1 1228  808 ...,    0    0    0]]\n",
      "183/200 [==========================>...] - ETA: 7s - loss: 1.5744 - acc: 0.8050[[ 749   12    2 ...,    0    0    0]\n",
      " [   1   13 1666 ...,    0    0    0]\n",
      " [1536   13  385 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   13   13 ...,    0    0    0]\n",
      " [ 500  455    3 ...,    0    0    0]\n",
      " [  13 3939 4822 ...,    0    0    0]]\n",
      "184/200 [==========================>...] - ETA: 7s - loss: 1.5744 - acc: 0.8050[[  647    13   462 ...,     0     0     0]\n",
      " [    1  1343    76 ...,     0     0     0]\n",
      " [   13  9175    14 ...,     0     0     0]\n",
      " ..., \n",
      " [ 5592 10575     5 ...,     0     0     0]\n",
      " [  241    13    18 ...,     0     0     0]\n",
      " [  967  1533     3 ...,     0     0     0]]\n",
      "185/200 [==========================>...] - ETA: 6s - loss: 1.5737 - acc: 0.8050[[2455  424 1301 ...,    0    0    0]\n",
      " [ 380    7   13 ...,    0    0    0]\n",
      " [   1   38   62 ...,    0    0    0]\n",
      " ..., \n",
      " [ 316  583 1628 ...,    0    0    0]\n",
      " [ 304 3255 1010 ...,    0    0    0]\n",
      " [ 149  186   10 ...,    0    0    0]]\n",
      "186/200 [==========================>...] - ETA: 6s - loss: 1.5723 - acc: 0.8052[[  795    13   363 ...,     0     0     0]\n",
      " [    1  1693  3716 ...,     0     0     0]\n",
      " [   13    13    13 ...,     0     0     0]\n",
      " ..., \n",
      " [ 3696    13  4556 ...,     0     0     0]\n",
      " [ 9945    13    86 ...,     0     0     0]\n",
      " [    1  1208 11348 ...,     0     0     0]]\n",
      "187/200 [===========================>..] - ETA: 5s - loss: 1.5707 - acc: 0.8053[[3292   13    5 ...,    0    0    0]\n",
      " [   2 8614 1737 ...,    0    0    0]\n",
      " [2939   13   14 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   13    7 ...,    0    0    0]\n",
      " [   4    1  145 ...,    0    0    0]\n",
      " [5850   13  128 ...,    0    0    0]]\n",
      "188/200 [===========================>..] - ETA: 5s - loss: 1.5692 - acc: 0.8054[[    2    13   146 ...,     0     0     0]\n",
      " [ 2525  5419 11672 ...,     0     0     0]\n",
      " [  491  2381    13 ...,     0     0     0]\n",
      " ..., \n",
      " [   49    13   851 ...,     0     0     0]\n",
      " [ 4385    13    14 ...,     0     0     0]\n",
      " [ 3791  1634   761 ...,     0     0     0]]\n",
      "189/200 [===========================>..] - ETA: 4s - loss: 1.5679 - acc: 0.8055[[ 2002  4124     9 ...,     0     0     0]\n",
      " [  280  1987     7 ...,     0     0     0]\n",
      " [ 4404    27 11508 ...,     0     0     0]\n",
      " ..., \n",
      " [ 2883  5521  4566 ...,     0     0     0]\n",
      " [  226     7   212 ...,     0     0     0]\n",
      " [   10   430    13 ...,     0     0     0]]\n",
      "190/200 [===========================>..] - ETA: 4s - loss: 1.5665 - acc: 0.8056[[ 131  491  522 ...,    0    0    0]\n",
      " [1862   30   24 ...,    0    0    0]\n",
      " [ 749   80  678 ...,    0    0    0]\n",
      " ..., \n",
      " [ 433  471   39 ...,    0    0    0]\n",
      " [ 345 3419 1044 ...,    0    0    0]\n",
      " [1550 1366    7 ...,    0    0    0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/200 [===========================>..] - ETA: 4s - loss: 1.5655 - acc: 0.8057[[5746 6464  253 ...,    0    0    0]\n",
      " [   4  444   13 ...,    0    0    0]\n",
      " [ 425   27  174 ...,    0    0    0]\n",
      " ..., \n",
      " [5814   13   14 ...,    0    0    0]\n",
      " [2642 2297   40 ...,    0    0    0]\n",
      " [   2  146 1129 ...,    0    0    0]]\n",
      "192/200 [===========================>..] - ETA: 3s - loss: 1.5654 - acc: 0.8058[[   1 5049 9636 ...,    0    0    0]\n",
      " [  55 1574    6 ...,    0    0    0]\n",
      " [2700    8 1429 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  429 1887 ...,    0    0    0]\n",
      " [   1 1245 1136 ...,    0    0    0]\n",
      " [   1   49   19 ...,    0    0    0]]\n",
      "193/200 [===========================>..] - ETA: 3s - loss: 1.5657 - acc: 0.8057[[ 108   68   67 ...,    0    0    0]\n",
      " [ 930   13  415 ...,    0    0    0]\n",
      " [ 621 1404 1184 ...,    0    0    0]\n",
      " ..., \n",
      " [   2  153 3973 ...,    0    0    0]\n",
      " [  80   41   14 ...,    0    0    0]\n",
      " [1761   23   13 ...,    0    0    0]]\n",
      "194/200 [============================>.] - ETA: 2s - loss: 1.5663 - acc: 0.8056[[ 149   53    7 ...,    0    0    0]\n",
      " [  18 1167  513 ...,    0    0    0]\n",
      " [ 337    3  338 ...,    0    0    0]\n",
      " ..., \n",
      " [  15    7    1 ...,    0    0    0]\n",
      " [  72  155    1 ...,    0    0    0]\n",
      " [   3 2748    1 ...,    0    0    0]]\n",
      "195/200 [============================>.] - ETA: 2s - loss: 1.5669 - acc: 0.8056[[ 105    9  385 ...,    0    0    0]\n",
      " [   6    1   13 ...,    0    0    0]\n",
      " [1696 7717   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 626   13   13 ...,    0    0    0]\n",
      " [2459 7832 1904 ...,    0    0    0]\n",
      " [  15  530    3 ...,    0    0    0]]\n",
      "196/200 [============================>.] - ETA: 1s - loss: 1.5674 - acc: 0.8055[[ 416 2716    8 ...,    0    0    0]\n",
      " [ 245 1192    8 ...,    0    0    0]\n",
      " [ 137   13    1 ...,    0    0    0]\n",
      " ..., \n",
      " [ 317   34  525 ...,    0    0    0]\n",
      " [   1  181  170 ...,    0    0    0]\n",
      " [ 618   13    5 ...,    0    0    0]]\n",
      "197/200 [============================>.] - ETA: 1s - loss: 1.5673 - acc: 0.8055[[  13 1163   12 ...,    0    0    0]\n",
      " [ 582 1211   10 ...,    0    0    0]\n",
      " [1063 6802 3370 ...,    0    0    0]\n",
      " ..., \n",
      " [ 137    7    4 ...,    0    0    0]\n",
      " [  10   63   13 ...,    0    0    0]\n",
      " [ 644   13  521 ...,    0    0    0]]\n",
      "198/200 [============================>.] - ETA: 0s - loss: 1.5688 - acc: 0.8054[[  13 9256    7 ...,    0    0    0]\n",
      " [6629   13   30 ...,    0    0    0]\n",
      " [  60 2510    5 ...,    0    0    0]\n",
      " ..., \n",
      " [  18   68  265 ...,    0    0    0]\n",
      " [  56   13   63 ...,    0    0    0]\n",
      " [1952 1630   13 ...,    0    0    0]]\n",
      "199/200 [============================>.] - ETA: 0s - loss: 1.5694 - acc: 0.8053[[ 535   41   37 ...,    0    0    0]\n",
      " [  93 1671   32 ...,    0    0    0]\n",
      " [  19  120    1 ...,    0    0    0]\n",
      " ..., \n",
      " [7200   13   11 ...,    0    0    0]\n",
      " [  10    2  146 ...,    0    0    0]\n",
      " [1246   13  816 ...,    0    0    0]]\n",
      "200/200 [==============================] - 90s - loss: 1.5713 - acc: 0.8051    \n",
      "Epoch 7/10\n",
      "[[ 3470    13   626 ...,     0     0     0]\n",
      " [ 9663 10549    11 ...,     0     0     0]\n",
      " [ 6526    13   898 ...,     0     0     0]\n",
      " ..., \n",
      " [  250    98     1 ...,     0     0     0]\n",
      " [  947    13   684 ...,     0     0     0]\n",
      " [ 3362   105    21 ...,     0     0     0]]\n",
      "  1/200 [..............................] - ETA: 91s - loss: 1.5723 - acc: 0.8097[[2697   50  105 ...,    0    0    0]\n",
      " [1344 3402 6866 ...,    0    0    0]\n",
      " [  10  276   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 202    1  463 ...,    0    0    0]\n",
      " [  15   27 1087 ...,    0    0    0]\n",
      " [  13  390 1415 ...,    0    0    0]]\n",
      "  2/200 [..............................] - ETA: 89s - loss: 1.6219 - acc: 0.8021[[  260    13     7 ...,     0     0     0]\n",
      " [11288  2473  8019 ...,     0     0     0]\n",
      " [ 1524     2    74 ...,     0     0     0]\n",
      " ..., \n",
      " [ 2765    23   207 ...,     0     0     0]\n",
      " [  438    13  1232 ...,     0     0     0]\n",
      " [    1  2131    23 ...,     0     0     0]]\n",
      "  3/200 [..............................] - ETA: 89s - loss: 1.6421 - acc: 0.8011[[  344     7    73 ...,     0     0     0]\n",
      " [  194 10634    34 ...,     0     0     0]\n",
      " [    1    78   177 ...,     0     0     0]\n",
      " ..., \n",
      " [   13  3645  3446 ...,     0     0     0]\n",
      " [    1    13  1442 ...,     0     0     0]\n",
      " [   15    11    45 ...,     0     0     0]]\n",
      "  4/200 [..............................] - ETA: 88s - loss: 1.5998 - acc: 0.8058[[1153    1   13 ...,    0    0    0]\n",
      " [ 149   13  333 ...,    0    0    0]\n",
      " [ 233  358  222 ...,    0    0    0]\n",
      " ..., \n",
      " [ 341   13    6 ...,    0    0    0]\n",
      " [  70    1  611 ...,    0    0    0]\n",
      " [6586 6960    9 ...,    0    0    0]]\n",
      "  5/200 [..............................] - ETA: 87s - loss: 1.5783 - acc: 0.8091[[  80  678    9 ...,    0    0    0]\n",
      " [ 746  117 4585 ...,    0    0    0]\n",
      " [   1  685  135 ...,    0    0    0]\n",
      " ..., \n",
      " [ 491   26  113 ...,    0    0    0]\n",
      " [ 579   11 1749 ...,    0    0    0]\n",
      " [   2  179 2444 ...,    0    0    0]]\n",
      "  6/200 [..............................] - ETA: 87s - loss: 1.5872 - acc: 0.8077[[ 154   66    6 ...,    0    0    0]\n",
      " [  55    7 1937 ...,    0    0    0]\n",
      " [   2 1413 1260 ...,    0    0    0]\n",
      " ..., \n",
      " [1472    7   13 ...,    0    0    0]\n",
      " [   1   47  287 ...,    0    0    0]\n",
      " [   1 9181  199 ...,    0    0    0]]\n",
      "  7/200 [>.............................] - ETA: 86s - loss: 1.5768 - acc: 0.8092[[ 496   27 1663 ...,    0    0    0]\n",
      " [3491  389  209 ...,    0    0    0]\n",
      " [   1  931    5 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13  169 ...,    0    0    0]\n",
      " [ 496  217   55 ...,    0    0    0]\n",
      " [2562   26  113 ...,    0    0    0]]\n",
      "  8/200 [>.............................] - ETA: 86s - loss: 1.5715 - acc: 0.8099[[ 373  423   55 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " ..., \n",
      " [ 496  941 3279 ...,    0    0    0]\n",
      " [   1   13   10 ...,    0    0    0]\n",
      " [   2  845  282 ...,    0    0    0]]\n",
      "  9/200 [>.............................] - ETA: 86s - loss: 1.5781 - acc: 0.8089[[  456  1494   692 ...,     0     0     0]\n",
      " [    1    13    91 ...,     0     0     0]\n",
      " [ 1382  1963   231 ...,     0     0     0]\n",
      " ..., \n",
      " [    1 11353   191 ...,     0     0     0]\n",
      " [    1    47  3229 ...,     0     0     0]\n",
      " [  248  2193   209 ...,     0     0     0]]\n",
      " 10/200 [>.............................] - ETA: 85s - loss: 1.5751 - acc: 0.8093[[  58   59   26 ...,    0    0    0]\n",
      " [   1  156   55 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " ..., \n",
      " [1454    7   13 ...,    0    0    0]\n",
      " [ 503  960    3 ...,    0    0    0]\n",
      " [ 248  800 1733 ...,    0    0    0]]\n",
      " 11/200 [>.............................] - ETA: 85s - loss: 1.5789 - acc: 0.8086[[ 5687     9    39 ...,     0     0     0]\n",
      " [    1  2182   191 ...,     0     0     0]\n",
      " [  127   102   112 ...,     0     0     0]\n",
      " ..., \n",
      " [   15    14    13 ...,     0     0     0]\n",
      " [10926    11   130 ...,     0     0     0]\n",
      " [    1  4595     5 ...,     0     0     0]]\n",
      " 12/200 [>.............................] - ETA: 85s - loss: 1.5846 - acc: 0.8076[[3236 2644   11 ...,    0    0    0]\n",
      " [  10    1   19 ...,    0    0    0]\n",
      " [   1   19   37 ...,    0    0    0]\n",
      " ..., \n",
      " [ 746  117 2526 ...,    0    0    0]\n",
      " [1268 4298  265 ...,    0    0    0]\n",
      " [2082 2177   23 ...,    0    0    0]]\n",
      " 13/200 [>.............................] - ETA: 84s - loss: 1.5870 - acc: 0.8071[[  13   13   13 ...,    0    0    0]\n",
      " [2797 4842 2347 ...,    0    0    0]\n",
      " [   2 1809  405 ...,    0    0    0]\n",
      " ..., \n",
      " [ 606    7  232 ...,    0    0    0]\n",
      " [  89   27   20 ...,    0    0    0]\n",
      " [ 546  276  178 ...,    0    0    0]]\n",
      " 14/200 [=>............................] - ETA: 84s - loss: 1.5864 - acc: 0.8070[[   1   13   91 ...,    0    0    0]\n",
      " [  15   14    1 ...,    0    0    0]\n",
      " [ 353   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [8129    7 3248 ...,    0    0    0]\n",
      " [ 353    8  603 ...,    0    0    0]\n",
      " [ 532    5  131 ...,    0    0    0]]\n",
      " 15/200 [=>............................] - ETA: 83s - loss: 1.5842 - acc: 0.8073[[ 267  157    2 ...,    0    0    0]\n",
      " [3295    7   19 ...,    0    0    0]\n",
      " [  58   59    7 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 2248   63 ...,    0    0    0]\n",
      " [ 119  172    2 ...,    0    0    0]\n",
      " [   4    1 3064 ...,    0    0    0]]\n",
      " 16/200 [=>............................] - ETA: 83s - loss: 1.5771 - acc: 0.8077[[ 868   13   13 ...,    0    0    0]\n",
      " [  13  119  157 ...,    0    0    0]\n",
      " [ 119   21 2208 ...,    0    0    0]\n",
      " ..., \n",
      " [  43  194 6631 ...,    0    0    0]\n",
      " [ 591 6515 3079 ...,    0    0    0]\n",
      " [ 280 1987    7 ...,    0    0    0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 17/200 [=>............................] - ETA: 83s - loss: 1.5562 - acc: 0.8096[[1742   11 3959 ...,    0    0    0]\n",
      " [   1  199 7911 ...,    0    0    0]\n",
      " [3989  604   13 ...,    0    0    0]\n",
      " ..., \n",
      " [2735 5332   83 ...,    0    0    0]\n",
      " [  13   11 1793 ...,    0    0    0]\n",
      " [4022 7272    8 ...,    0    0    0]]\n",
      " 18/200 [=>............................] - ETA: 82s - loss: 1.5389 - acc: 0.8110[[   92   456   851 ...,     0     0     0]\n",
      " [11092  8523    11 ...,     0     0     0]\n",
      " [    1  2999    91 ...,     0     0     0]\n",
      " ..., \n",
      " [   16     1   602 ...,     0     0     0]\n",
      " [ 2525  5419  2506 ...,     0     0     0]\n",
      " [ 1653  4875  1136 ...,     0     0     0]]\n",
      " 19/200 [=>............................] - ETA: 82s - loss: 1.5248 - acc: 0.8118[[   1  427 1856 ...,    0    0    0]\n",
      " [ 626 3961 3254 ...,    0    0    0]\n",
      " [   2 2024 2067 ...,    0    0    0]\n",
      " ..., \n",
      " [   2  485 3233 ...,    0    0    0]\n",
      " [ 226    7   13 ...,    0    0    0]\n",
      " [   2  440  405 ...,    0    0    0]]\n",
      " 20/200 [==>...........................] - ETA: 81s - loss: 1.5146 - acc: 0.8125[[   1 2503   56 ...,    0    0    0]\n",
      " [   1 2266  793 ...,    0    0    0]\n",
      " [  22 1423    4 ...,    0    0    0]\n",
      " ..., \n",
      " [2490  103   13 ...,    0    0    0]\n",
      " [  13 1804  128 ...,    0    0    0]\n",
      " [ 623  157    2 ...,    0    0    0]]\n",
      " 21/200 [==>...........................] - ETA: 81s - loss: 1.5099 - acc: 0.8126[[ 807 1855 4922 ...,    0    0    0]\n",
      " [ 654  145  103 ...,    0    0    0]\n",
      " [   1  785    9 ...,    0    0    0]\n",
      " ..., \n",
      " [2323 2339   13 ...,    0    0    0]\n",
      " [2698    7   13 ...,    0    0    0]\n",
      " [ 979   66  664 ...,    0    0    0]]\n",
      " 22/200 [==>...........................] - ETA: 80s - loss: 1.5044 - acc: 0.8130[[  109    26   106 ...,     0     0     0]\n",
      " [ 1500  7999   521 ...,     0     0     0]\n",
      " [    2    13   806 ...,     0     0     0]\n",
      " ..., \n",
      " [ 3022  6500   163 ...,     0     0     0]\n",
      " [    1 11634   245 ...,     0     0     0]\n",
      " [ 3909    69  2775 ...,     0     0     0]]\n",
      " 23/200 [==>...........................] - ETA: 80s - loss: 1.5059 - acc: 0.8127[[ 681 3499  887 ...,    0    0    0]\n",
      " [   2   13 2444 ...,    0    0    0]\n",
      " [  13   13   27 ...,    0    0    0]\n",
      " ..., \n",
      " [2033   90    2 ...,    0    0    0]\n",
      " [  15    9    2 ...,    0    0    0]\n",
      " [ 827 1400 1298 ...,    0    0    0]]\n",
      " 24/200 [==>...........................] - ETA: 80s - loss: 1.5148 - acc: 0.8115[[ 706 1296    5 ...,    0    0    0]\n",
      " [   1 9248    5 ...,    0    0    0]\n",
      " [ 531  163 1980 ...,    0    0    0]\n",
      " ..., \n",
      " [ 361 5218 1328 ...,    0    0    0]\n",
      " [  72   15    7 ...,    0    0    0]\n",
      " [  13   13   13 ...,    0    0    0]]\n",
      " 25/200 [==>...........................] - ETA: 79s - loss: 1.5221 - acc: 0.8108[[   4 1971    7 ...,    0    0    0]\n",
      " [ 630    7 1188 ...,    0    0    0]\n",
      " [ 264    9    2 ...,    0    0    0]\n",
      " ..., \n",
      " [ 137    2  417 ...,    0    0    0]\n",
      " [2434    7   74 ...,    0    0    0]\n",
      " [  57  125   13 ...,    0    0    0]]\n",
      " 26/200 [==>...........................] - ETA: 79s - loss: 1.5303 - acc: 0.8097[[   1 1130    9 ...,    0    0    0]\n",
      " [1433   76    1 ...,    0    0    0]\n",
      " [ 585 7398   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 630    7  512 ...,    0    0    0]\n",
      " [2481 2736   11 ...,    0    0    0]\n",
      " [   1 5535   13 ...,    0    0    0]]\n",
      " 27/200 [===>..........................] - ETA: 78s - loss: 1.5378 - acc: 0.8090[[  15    7   45 ...,    0    0    0]\n",
      " [2861  103  887 ...,    0    0    0]\n",
      " [6448   13    7 ...,    0    0    0]\n",
      " ..., \n",
      " [ 234  290   96 ...,    0    0    0]\n",
      " [ 325  829   13 ...,    0    0    0]\n",
      " [ 879   13   30 ...,    0    0    0]]\n",
      " 28/200 [===>..........................] - ETA: 78s - loss: 1.5375 - acc: 0.8091[[   10    63    13 ...,     0     0     0]\n",
      " [    1    13 11795 ...,     0     0     0]\n",
      " [    4    22  1829 ...,     0     0     0]\n",
      " ..., \n",
      " [  222  2013    21 ...,     0     0     0]\n",
      " [  233   670  3884 ...,     0     0     0]\n",
      " [   70    15   392 ...,     0     0     0]]\n",
      " 29/200 [===>..........................] - ETA: 77s - loss: 1.5472 - acc: 0.8083[[  41  516    5 ...,    0    0    0]\n",
      " [  13   26  115 ...,    0    0    0]\n",
      " [4122 3172 2726 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  474  429 ...,    0    0    0]\n",
      " [  13  301  354 ...,    0    0    0]\n",
      " [   1  897 1175 ...,    0    0    0]]\n",
      " 30/200 [===>..........................] - ETA: 77s - loss: 1.5521 - acc: 0.8077[[  18 1387    4 ...,    0    0    0]\n",
      " [7131   13    9 ...,    0    0    0]\n",
      " [ 108   89  320 ...,    0    0    0]\n",
      " ..., \n",
      " [3587   13  128 ...,    0    0    0]\n",
      " [  13 3861   14 ...,    0    0    0]\n",
      " [ 131 1003 2940 ...,    0    0    0]]\n",
      " 31/200 [===>..........................] - ETA: 77s - loss: 1.5667 - acc: 0.8061[[   1 5576  467 ...,    0    0    0]\n",
      " [  13    3  809 ...,    0    0    0]\n",
      " [ 343 3183  384 ...,    0    0    0]\n",
      " ..., \n",
      " [  15    7  155 ...,    0    0    0]\n",
      " [   1   38   95 ...,    0    0    0]\n",
      " [ 228 3503  114 ...,    0    0    0]]\n",
      " 32/200 [===>..........................] - ETA: 76s - loss: 1.5656 - acc: 0.8064[[ 108    1 6103 ...,    0    0    0]\n",
      " [5401   21  256 ...,    0    0    0]\n",
      " [   1 2393  294 ...,    0    0    0]\n",
      " ..., \n",
      " [ 242   38  271 ...,    0    0    0]\n",
      " [  13  695   14 ...,    0    0    0]\n",
      " [   4    1  274 ...,    0    0    0]]\n",
      " 33/200 [===>..........................] - ETA: 76s - loss: 1.5688 - acc: 0.8063[[    6    33    13 ...,     0     0     0]\n",
      " [  234   290   144 ...,     0     0     0]\n",
      " [ 2270  1190    90 ...,     0     0     0]\n",
      " ..., \n",
      " [ 4686  8679 11273 ...,     0     0     0]\n",
      " [  108  1209  2508 ...,     0     0     0]\n",
      " [   34   400    77 ...,     0     0     0]]\n",
      " 34/200 [====>.........................] - ETA: 75s - loss: 1.5742 - acc: 0.8057[[ 232  725  141 ...,    0    0    0]\n",
      " [ 276  178   13 ...,    0    0    0]\n",
      " [4359 4673  247 ...,    0    0    0]\n",
      " ..., \n",
      " [2792 1898   81 ...,    0    0    0]\n",
      " [6292   13    9 ...,    0    0    0]\n",
      " [  19  226    7 ...,    0    0    0]]\n",
      " 35/200 [====>.........................] - ETA: 75s - loss: 1.5738 - acc: 0.8058[[1188    1 4704 ...,    0    0    0]\n",
      " [  13   15    7 ...,    0    0    0]\n",
      " [  93   67  190 ...,    0    0    0]\n",
      " ..., \n",
      " [ 406   13    1 ...,    0    0    0]\n",
      " [  68   21   41 ...,    0    0    0]\n",
      " [ 986 1865  105 ...,    0    0    0]]\n",
      " 36/200 [====>.........................] - ETA: 74s - loss: 1.5699 - acc: 0.8064[[   2   37   32 ...,    0    0    0]\n",
      " [  22 2679   13 ...,    0    0    0]\n",
      " [2334    2 8471 ...,    0    0    0]\n",
      " ..., \n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]]\n",
      " 37/200 [====>.........................] - ETA: 74s - loss: 1.5710 - acc: 0.8063[[4062   13    2 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [1434   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  868   91 ...,    0    0    0]\n",
      " [   1   19  274 ...,    0    0    0]\n",
      " [  55    7  655 ...,    0    0    0]]\n",
      " 38/200 [====>.........................] - ETA: 73s - loss: 1.5709 - acc: 0.8063[[1357    8  797 ...,    0    0    0]\n",
      " [  18  194   18 ...,    0    0    0]\n",
      " [   1  220   91 ...,    0    0    0]\n",
      " ..., \n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [  55   11 4380 ...,    0    0    0]\n",
      " [  12  296   13 ...,    0    0    0]]\n",
      " 39/200 [====>.........................] - ETA: 73s - loss: 1.5724 - acc: 0.8061[[2504 1870 3322 ...,    0    0    0]\n",
      " [ 140  609   73 ...,    0    0    0]\n",
      " [  13  808    5 ...,    0    0    0]\n",
      " ..., \n",
      " [  55    8  284 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [ 491   26  113 ...,    0    0    0]]\n",
      " 40/200 [=====>........................] - ETA: 72s - loss: 1.5711 - acc: 0.8063[[ 481   66  115 ...,    0    0    0]\n",
      " [   1   13  140 ...,    0    0    0]\n",
      " [ 318    8  913 ...,    0    0    0]\n",
      " ..., \n",
      " [2157   27  487 ...,    0    0    0]\n",
      " [  54   13 2972 ...,    0    0    0]\n",
      " [3359   67  289 ...,    0    0    0]]\n",
      " 41/200 [=====>........................] - ETA: 72s - loss: 1.5724 - acc: 0.8061[[  58   59   26 ...,    0    0    0]\n",
      " [ 167  187   65 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " ..., \n",
      " [  58   59    7 ...,    0    0    0]\n",
      " [  38  170 4160 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]]\n",
      " 42/200 [=====>........................] - ETA: 71s - loss: 1.5725 - acc: 0.8061[[  58   59   26 ...,    0    0    0]\n",
      " [ 220   26   65 ...,    0    0    0]\n",
      " [  55    7   73 ...,    0    0    0]\n",
      " ..., \n",
      " [ 342  196    4 ...,    0    0    0]\n",
      " [ 342  196    4 ...,    0    0    0]\n",
      " [1757  154   66 ...,    0    0    0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 43/200 [=====>........................] - ETA: 71s - loss: 1.5729 - acc: 0.8061[[  1  78  13 ...,   0   0   0]\n",
      " [501   6  33 ...,   0   0   0]\n",
      " [ 38 825 433 ...,   0   0   0]\n",
      " ..., \n",
      " [501   6  24 ...,   0   0   0]\n",
      " [325 829 662 ...,   0   0   0]\n",
      " [824   6  28 ...,   0   0   0]]\n",
      " 44/200 [=====>........................] - ETA: 70s - loss: 1.5737 - acc: 0.8060[[  70   15  392 ...,    0    0    0]\n",
      " [8464 2259   67 ...,    0    0    0]\n",
      " [   2 4067 2268 ...,    0    0    0]\n",
      " ..., \n",
      " [  99  255   73 ...,    0    0    0]\n",
      " [ 819   26   65 ...,    0    0    0]\n",
      " [  48  950    6 ...,    0    0    0]]\n",
      " 45/200 [=====>........................] - ETA: 70s - loss: 1.5764 - acc: 0.8057[[1431  450   86 ...,    0    0    0]\n",
      " [  38   13   13 ...,    0    0    0]\n",
      " [   1  424   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 442  216   51 ...,    0    0    0]\n",
      " [ 159 1832   14 ...,    0    0    0]\n",
      " [  13  694  103 ...,    0    0    0]]\n",
      " 46/200 [=====>........................] - ETA: 69s - loss: 1.5764 - acc: 0.8058[[   2 2444   14 ...,    0    0    0]\n",
      " [ 919   69 7067 ...,    0    0    0]\n",
      " [ 107   10 1555 ...,    0    0    0]\n",
      " ..., \n",
      " [ 433    7 2066 ...,    0    0    0]\n",
      " [1189  150   26 ...,    0    0    0]\n",
      " [1600   11  511 ...,    0    0    0]]\n",
      " 47/200 [======>.......................] - ETA: 69s - loss: 1.5786 - acc: 0.8054[[   1   13   91 ...,    0    0    0]\n",
      " [ 422  755   11 ...,    0    0    0]\n",
      " [   2 2321 4020 ...,    0    0    0]\n",
      " ..., \n",
      " [2095  745 2520 ...,    0    0    0]\n",
      " [ 206   66  115 ...,    0    0    0]\n",
      " [3365 5674  850 ...,    0    0    0]]\n",
      " 48/200 [======>.......................] - ETA: 69s - loss: 1.5712 - acc: 0.8061[[    1    13    91 ...,     0     0     0]\n",
      " [ 8738   139     7 ...,     0     0     0]\n",
      " [    1  2897   188 ...,     0     0     0]\n",
      " ..., \n",
      " [  644  8658     7 ...,     0     0     0]\n",
      " [   89    23    80 ...,     0     0     0]\n",
      " [11134  1064    13 ...,     0     0     0]]\n",
      " 49/200 [======>.......................] - ETA: 68s - loss: 1.5632 - acc: 0.8068[[3833 2322   13 ...,    0    0    0]\n",
      " [ 284    7   13 ...,    0    0    0]\n",
      " [ 481  176  196 ...,    0    0    0]\n",
      " ..., \n",
      " [1701 4256 2968 ...,    0    0    0]\n",
      " [3313 1131   32 ...,    0    0    0]\n",
      " [  64   82  590 ...,    0    0    0]]\n",
      " 50/200 [======>.......................] - ETA: 68s - loss: 1.5578 - acc: 0.8072[[1275  650  217 ...,    0    0    0]\n",
      " [ 986  721    5 ...,    0    0    0]\n",
      " [3318 9332  114 ...,    0    0    0]\n",
      " ..., \n",
      " [2555 2115  141 ...,    0    0    0]\n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [   2  146 1214 ...,    0    0    0]]\n",
      " 51/200 [======>.......................] - ETA: 67s - loss: 1.5528 - acc: 0.8076[[ 119   21   13 ...,    0    0    0]\n",
      " [3135   13   13 ...,    0    0    0]\n",
      " [   1  221  230 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 1007  674 ...,    0    0    0]\n",
      " [3587 7061    7 ...,    0    0    0]\n",
      " [  15   14    2 ...,    0    0    0]]\n",
      " 52/200 [======>.......................] - ETA: 67s - loss: 1.5480 - acc: 0.8079[[   2 1373   13 ...,    0    0    0]\n",
      " [ 154   66    4 ...,    0    0    0]\n",
      " [ 167    4   13 ...,    0    0    0]\n",
      " ..., \n",
      " [3689 3693    9 ...,    0    0    0]\n",
      " [4040  505   13 ...,    0    0    0]\n",
      " [  22 1738   13 ...,    0    0    0]]\n",
      " 53/200 [======>.......................] - ETA: 66s - loss: 1.5427 - acc: 0.8082[[   2  221  230 ...,    0    0    0]\n",
      " [  19  344 1113 ...,    0    0    0]\n",
      " [2237 1642   13 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  132 2251 ...,    0    0    0]\n",
      " [  64 8144   82 ...,    0    0    0]\n",
      " [ 255  598   23 ...,    0    0    0]]\n",
      " 54/200 [=======>......................] - ETA: 66s - loss: 1.5397 - acc: 0.8085[[  819    26   182 ...,     0     0     0]\n",
      " [ 1792    11  1048 ...,     0     0     0]\n",
      " [ 3054   130   131 ...,     0     0     0]\n",
      " ..., \n",
      " [ 1364 11506     9 ...,     0     0     0]\n",
      " [  413   558    11 ...,     0     0     0]\n",
      " [   34   188     7 ...,     0     0     0]]\n",
      " 55/200 [=======>......................] - ETA: 65s - loss: 1.5424 - acc: 0.8082[[ 293    7 2445 ...,    0    0    0]\n",
      " [  18 2693   13 ...,    0    0    0]\n",
      " [3643 1207 2940 ...,    0    0    0]\n",
      " ..., \n",
      " [7456 9503   11 ...,    0    0    0]\n",
      " [ 280 1987  190 ...,    0    0    0]\n",
      " [8321 8845 8425 ...,    0    0    0]]\n",
      " 56/200 [=======>......................] - ETA: 65s - loss: 1.5436 - acc: 0.8081[[    1    13   506 ...,     0     0     0]\n",
      " [  150  2173    13 ...,     0     0     0]\n",
      " [    2   538   123 ...,     0     0     0]\n",
      " ..., \n",
      " [ 1111   135   811 ...,     0     0     0]\n",
      " [  159  4081    81 ...,     0     0     0]\n",
      " [ 4482    13 11705 ...,     0     0     0]]\n",
      " 57/200 [=======>......................] - ETA: 64s - loss: 1.5449 - acc: 0.8080[[ 873  374  289 ...,    0    0    0]\n",
      " [ 317   13   13 ...,    0    0    0]\n",
      " [2142  747 2705 ...,    0    0    0]\n",
      " ..., \n",
      " [  53    7  137 ...,    0    0    0]\n",
      " [   1   78  150 ...,    0    0    0]\n",
      " [ 633 1936   13 ...,    0    0    0]]\n",
      " 58/200 [=======>......................] - ETA: 64s - loss: 1.5471 - acc: 0.8077[[   1 9492   38 ...,    0    0    0]\n",
      " [ 658    4   13 ...,    0    0    0]\n",
      " [  13   13   44 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 2039  361 ...,    0    0    0]\n",
      " [   1  459    7 ...,    0    0    0]\n",
      " [ 301   23  787 ...,    0    0    0]]\n",
      " 59/200 [=======>......................] - ETA: 63s - loss: 1.5472 - acc: 0.8077[[  27 9816 3873 ...,    0    0    0]\n",
      " [ 865   13  301 ...,    0    0    0]\n",
      " [  10    2 3216 ...,    0    0    0]\n",
      " ..., \n",
      " [  10 2453 7036 ...,    0    0    0]\n",
      " [   4   40 4165 ...,    0    0    0]\n",
      " [  15    7   48 ...,    0    0    0]]\n",
      " 60/200 [========>.....................] - ETA: 63s - loss: 1.5463 - acc: 0.8078[[ 184  810    1 ...,    0    0    0]\n",
      " [  13 1442   79 ...,    0    0    0]\n",
      " [1733   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 202    1 5659 ...,    0    0    0]\n",
      " [5691 1345    9 ...,    0    0    0]\n",
      " [   3 1428  116 ...,    0    0    0]]\n",
      " 61/200 [========>.....................] - ETA: 63s - loss: 1.5515 - acc: 0.8073[[  943    13 11557 ...,     0     0     0]\n",
      " [   12     1   645 ...,     0     0     0]\n",
      " [ 3140    13  6136 ...,     0     0     0]\n",
      " ..., \n",
      " [   15     7   776 ...,     0     0     0]\n",
      " [ 1698     4     1 ...,     0     0     0]\n",
      " [   13  2336    21 ...,     0     0     0]]\n",
      " 62/200 [========>.....................] - ETA: 62s - loss: 1.5559 - acc: 0.8068[[ 535  133   39 ...,    0    0    0]\n",
      " [ 873 2778 9301 ...,    0    0    0]\n",
      " [  13   13  802 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   49   13 ...,    0    0    0]\n",
      " [   1 7520   19 ...,    0    0    0]\n",
      " [ 161  426 1053 ...,    0    0    0]]\n",
      " 63/200 [========>.....................] - ETA: 62s - loss: 1.5589 - acc: 0.8064[[ 108   68   13 ...,    0    0    0]\n",
      " [  13  104   21 ...,    0    0    0]\n",
      " [2365   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [  75  103  626 ...,    0    0    0]\n",
      " [ 276  178   13 ...,    0    0    0]\n",
      " [  10  383    2 ...,    0    0    0]]\n",
      " 64/200 [========>.....................] - ETA: 61s - loss: 1.5664 - acc: 0.8056[[   13    26    67 ...,     0     0     0]\n",
      " [    1   179   161 ...,     0     0     0]\n",
      " [ 5206 10059     5 ...,     0     0     0]\n",
      " ..., \n",
      " [   90    99  1156 ...,     0     0     0]\n",
      " [    6     1   310 ...,     0     0     0]\n",
      " [ 1720    13     7 ...,     0     0     0]]\n",
      " 65/200 [========>.....................] - ETA: 61s - loss: 1.5627 - acc: 0.8061[[    1   127    13 ...,     0     0     0]\n",
      " [    2   287     5 ...,     0     0     0]\n",
      " [   93    23   428 ...,     0     0     0]\n",
      " ..., \n",
      " [  606    13   606 ...,     0     0     0]\n",
      " [    1   794    11 ...,     0     0     0]\n",
      " [  584 10173  1345 ...,     0     0     0]]\n",
      " 66/200 [========>.....................] - ETA: 60s - loss: 1.5662 - acc: 0.8057[[ 535    1 3629 ...,    0    0    0]\n",
      " [3685 6496   14 ...,    0    0    0]\n",
      " [ 276  178   13 ...,    0    0    0]\n",
      " ..., \n",
      " [5680   13  141 ...,    0    0    0]\n",
      " [2142  252  103 ...,    0    0    0]\n",
      " [6137   13 2621 ...,    0    0    0]]\n",
      " 67/200 [=========>....................] - ETA: 60s - loss: 1.5677 - acc: 0.8056[[3485 8007   11 ...,    0    0    0]\n",
      " [  13   13  292 ...,    0    0    0]\n",
      " [  13   13    9 ...,    0    0    0]\n",
      " ..., \n",
      " [ 349    9   76 ...,    0    0    0]\n",
      " [  13   13   11 ...,    0    0    0]\n",
      " [  18 1530   13 ...,    0    0    0]]\n",
      " 68/200 [=========>....................] - ETA: 59s - loss: 1.5675 - acc: 0.8057[[1768   13 1425 ...,    0    0    0]\n",
      " [3679    4 5243 ...,    0    0    0]\n",
      " [3138  105 1980 ...,    0    0    0]\n",
      " ..., \n",
      " [3022 2349 1585 ...,    0    0    0]\n",
      " [  15    7  229 ...,    0    0    0]\n",
      " [   1  221  230 ...,    0    0    0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 69/200 [=========>....................] - ETA: 59s - loss: 1.5659 - acc: 0.8060[[4791   13   27 ...,    0    0    0]\n",
      " [   6   25  151 ...,    0    0    0]\n",
      " [ 702  123  338 ...,    0    0    0]\n",
      " ..., \n",
      " [  15  265  107 ...,    0    0    0]\n",
      " [6796   63 1105 ...,    0    0    0]\n",
      " [  73   66 2451 ...,    0    0    0]]\n",
      " 70/200 [=========>....................] - ETA: 58s - loss: 1.5676 - acc: 0.8058[[   4   13   13 ...,    0    0    0]\n",
      " [  13   13 5118 ...,    0    0    0]\n",
      " [  13  690 2463 ...,    0    0    0]\n",
      " ..., \n",
      " [1588   69   13 ...,    0    0    0]\n",
      " [ 219  970 2002 ...,    0    0    0]\n",
      " [   1  956   55 ...,    0    0    0]]\n",
      " 71/200 [=========>....................] - ETA: 58s - loss: 1.5695 - acc: 0.8057[[   2 2487   32 ...,    0    0    0]\n",
      " [  13   69  297 ...,    0    0    0]\n",
      " [2181    7 1802 ...,    0    0    0]\n",
      " ..., \n",
      " [ 140  369    8 ...,    0    0    0]\n",
      " [ 491   26  113 ...,    0    0    0]\n",
      " [1396    6    2 ...,    0    0    0]]\n",
      " 72/200 [=========>....................] - ETA: 57s - loss: 1.5693 - acc: 0.8057[[4946 2438 2101 ...,    0    0    0]\n",
      " [  19  352 1400 ...,    0    0    0]\n",
      " [4245   13    4 ...,    0    0    0]\n",
      " ..., \n",
      " [6465  172   12 ...,    0    0    0]\n",
      " [ 131  395  456 ...,    0    0    0]\n",
      " [   1   13 1847 ...,    0    0    0]]\n",
      " 73/200 [=========>....................] - ETA: 57s - loss: 1.5695 - acc: 0.8057[[ 763 9690   21 ...,    0    0    0]\n",
      " [ 373  423   55 ...,    0    0    0]\n",
      " [   1   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 2893 2824 ...,    0    0    0]\n",
      " [  55    8 4432 ...,    0    0    0]\n",
      " [  13  792   86 ...,    0    0    0]]\n",
      " 74/200 [==========>...................] - ETA: 57s - loss: 1.5694 - acc: 0.8057[[ 844    8 3029 ...,    0    0    0]\n",
      " [1910   55    7 ...,    0    0    0]\n",
      " [   1  220   73 ...,    0    0    0]\n",
      " ..., \n",
      " [ 937   13   13 ...,    0    0    0]\n",
      " [   1 1008 2973 ...,    0    0    0]\n",
      " [   1   13  191 ...,    0    0    0]]\n",
      " 75/200 [==========>...................] - ETA: 56s - loss: 1.5699 - acc: 0.8057[[  58   59   26 ...,    0    0    0]\n",
      " [   1  740    5 ...,    0    0    0]\n",
      " [6094 7169  130 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  740    5 ...,    0    0    0]\n",
      " [  13 1056 6390 ...,    0    0    0]\n",
      " [ 154  635  143 ...,    0    0    0]]\n",
      " 76/200 [==========>...................] - ETA: 56s - loss: 1.5690 - acc: 0.8059[[ 481   66   14 ...,    0    0    0]\n",
      " [  49   13  704 ...,    0    0    0]\n",
      " [ 167  187  106 ...,    0    0    0]\n",
      " ..., \n",
      " [1339 1553   11 ...,    0    0    0]\n",
      " [1635   13    9 ...,    0    0    0]\n",
      " [2589    5  220 ...,    0    0    0]]\n",
      " 77/200 [==========>...................] - ETA: 55s - loss: 1.5693 - acc: 0.8059[[   1  132  509 ...,    0    0    0]\n",
      " [1896  187   65 ...,    0    0    0]\n",
      " [2395   13  100 ...,    0    0    0]\n",
      " ..., \n",
      " [ 185 1780   21 ...,    0    0    0]\n",
      " [ 255  154   66 ...,    0    0    0]\n",
      " [ 524   10   22 ...,    0    0    0]]\n",
      " 78/200 [==========>...................] - ETA: 55s - loss: 1.5699 - acc: 0.8059[[   16  5877 11689 ...,     0     0     0]\n",
      " [11630    13    13 ...,     0     0     0]\n",
      " [    1    13    13 ...,     0     0     0]\n",
      " ..., \n",
      " [   13    13   253 ...,     0     0     0]\n",
      " [    1    13  4128 ...,     0     0     0]\n",
      " [   15   448    29 ...,     0     0     0]]\n",
      " 79/200 [==========>...................] - ETA: 54s - loss: 1.5709 - acc: 0.8058[[    1    13   879 ...,     0     0     0]\n",
      " [  364   375   411 ...,     0     0     0]\n",
      " [ 6528 11277  6082 ...,     0     0     0]\n",
      " ..., \n",
      " [10681 10044   253 ...,     0     0     0]\n",
      " [  481   176    66 ...,     0     0     0]\n",
      " [    1   919   736 ...,     0     0     0]]\n",
      " 80/200 [===========>..................] - ETA: 54s - loss: 1.5711 - acc: 0.8058[[ 1360    13     9 ...,     0     0     0]\n",
      " [ 2196   418   335 ...,     0     0     0]\n",
      " [   15   247   234 ...,     0     0     0]\n",
      " ..., \n",
      " [10926     8    13 ...,     0     0     0]\n",
      " [   92  1755  3347 ...,     0     0     0]\n",
      " [  206    66    23 ...,     0     0     0]]\n",
      " 81/200 [===========>..................] - ETA: 53s - loss: 1.5695 - acc: 0.8059[[   41     5     1 ...,     0     0     0]\n",
      " [10509 11024    83 ...,     0     0     0]\n",
      " [  131   248    85 ...,     0     0     0]\n",
      " ..., \n",
      " [   13    13     1 ...,     0     0     0]\n",
      " [ 1090  9071   461 ...,     0     0     0]\n",
      " [ 1491  2550  1950 ...,     0     0     0]]\n",
      " 82/200 [===========>..................] - ETA: 53s - loss: 1.5656 - acc: 0.8061[[  70  152  139 ...,    0    0    0]\n",
      " [ 987    7  615 ...,    0    0    0]\n",
      " [2151   11    2 ...,    0    0    0]\n",
      " ..., \n",
      " [ 109   26  115 ...,    0    0    0]\n",
      " [1150   13   13 ...,    0    0    0]\n",
      " [   2 3865 1346 ...,    0    0    0]]\n",
      " 83/200 [===========>..................] - ETA: 53s - loss: 1.5616 - acc: 0.8065[[   1 8252    5 ...,    0    0    0]\n",
      " [   1  474 1341 ...,    0    0    0]\n",
      " [ 500    7   19 ...,    0    0    0]\n",
      " ..., \n",
      " [ 962 6266    8 ...,    0    0    0]\n",
      " [   2  121 8811 ...,    0    0    0]\n",
      " [  56   13  397 ...,    0    0    0]]\n",
      " 84/200 [===========>..................] - ETA: 52s - loss: 1.5580 - acc: 0.8068[[   4    1  117 ...,    0    0    0]\n",
      " [  13    7   13 ...,    0    0    0]\n",
      " [   1 4920    5 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  145  608 ...,    0    0    0]\n",
      " [   2   13  150 ...,    0    0    0]\n",
      " [1170  159  390 ...,    0    0    0]]\n",
      " 85/200 [===========>..................] - ETA: 52s - loss: 1.5546 - acc: 0.8070[[2567 2560  217 ...,    0    0    0]\n",
      " [   2 1147   32 ...,    0    0    0]\n",
      " [  89   14 2631 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 5475    5 ...,    0    0    0]\n",
      " [ 955  814    5 ...,    0    0    0]\n",
      " [ 284    7   69 ...,    0    0    0]]\n",
      " 86/200 [===========>..................] - ETA: 51s - loss: 1.5512 - acc: 0.8073[[3756   13    8 ...,    0    0    0]\n",
      " [2490    7  732 ...,    0    0    0]\n",
      " [  73   13    4 ...,    0    0    0]\n",
      " ..., \n",
      " [3236 2644   27 ...,    0    0    0]\n",
      " [1507   10 1061 ...,    0    0    0]\n",
      " [5489    7  390 ...,    0    0    0]]\n",
      " 87/200 [============>.................] - ETA: 51s - loss: 1.5484 - acc: 0.8075[[   2 1624 2642 ...,    0    0    0]\n",
      " [   2 1580 1048 ...,    0    0    0]\n",
      " [   1  261  401 ...,    0    0    0]\n",
      " ..., \n",
      " [   2  763  740 ...,    0    0    0]\n",
      " [  89  105   20 ...,    0    0    0]\n",
      " [1757 1483   27 ...,    0    0    0]]\n",
      " 88/200 [============>.................] - ETA: 50s - loss: 1.5464 - acc: 0.8077[[    2    74    56 ...,     0     0     0]\n",
      " [    1   528   142 ...,     0     0     0]\n",
      " [ 6686  8975  1850 ...,     0     0     0]\n",
      " ..., \n",
      " [    1   221   230 ...,     0     0     0]\n",
      " [ 1162  8454  2103 ...,     0     0     0]\n",
      " [11856  1993    11 ...,     0     0     0]]\n",
      " 89/200 [============>.................] - ETA: 50s - loss: 1.5457 - acc: 0.8078[[   1 3135  161 ...,    0    0    0]\n",
      " [3282 3426   11 ...,    0    0    0]\n",
      " [4182 2308   11 ...,    0    0    0]\n",
      " ..., \n",
      " [ 497   13   69 ...,    0    0    0]\n",
      " [ 280   13  100 ...,    0    0    0]\n",
      " [7546   13 1564 ...,    0    0    0]]\n",
      " 90/200 [============>.................] - ETA: 49s - loss: 1.5458 - acc: 0.8078[[   13    69   297 ...,     0     0     0]\n",
      " [ 2558  1063  8611 ...,     0     0     0]\n",
      " [ 3549   130   131 ...,     0     0     0]\n",
      " ..., \n",
      " [    1    91   106 ...,     0     0     0]\n",
      " [ 2461   900  3066 ...,     0     0     0]\n",
      " [11627   779    13 ...,     0     0     0]]\n",
      " 91/200 [============>.................] - ETA: 49s - loss: 1.5481 - acc: 0.8076[[  109    26    65 ...,     0     0     0]\n",
      " [  893   232 11645 ...,     0     0     0]\n",
      " [   89   684    20 ...,     0     0     0]\n",
      " ..., \n",
      " [    1   549     5 ...,     0     0     0]\n",
      " [  108  1350   543 ...,     0     0     0]\n",
      " [    5    79     1 ...,     0     0     0]]\n",
      " 92/200 [============>.................] - ETA: 49s - loss: 1.5487 - acc: 0.8075[[ 606    9 2477 ...,    0    0    0]\n",
      " [  89  684   20 ...,    0    0    0]\n",
      " [  13 2652 1558 ...,    0    0    0]\n",
      " ..., \n",
      " [1746 1574 6367 ...,    0    0    0]\n",
      " [ 508   15    1 ...,    0    0    0]\n",
      " [ 194    5    1 ...,    0    0    0]]\n",
      " 93/200 [============>.................] - ETA: 48s - loss: 1.5510 - acc: 0.8072[[    6     1  5556 ...,     0     0     0]\n",
      " [ 5526    13     1 ...,     0     0     0]\n",
      " [  108  4713    51 ...,     0     0     0]\n",
      " ..., \n",
      " [10537   558    30 ...,     0     0     0]\n",
      " [   13    13   430 ...,     0     0     0]\n",
      " [ 7029    13     9 ...,     0     0     0]]\n",
      " 94/200 [=============>................] - ETA: 48s - loss: 1.5498 - acc: 0.8074[[   49    63   144 ...,     0     0     0]\n",
      " [11254    13    13 ...,     0     0     0]\n",
      " [ 1851     9  2938 ...,     0     0     0]\n",
      " ..., \n",
      " [   13    13   221 ...,     0     0     0]\n",
      " [  584     1  7157 ...,     0     0     0]\n",
      " [   13  8426  6054 ...,     0     0     0]]\n",
      " 95/200 [=============>................] - ETA: 47s - loss: 1.5507 - acc: 0.8073[[   1 2324    5 ...,    0    0    0]\n",
      " [  13  104   21 ...,    0    0    0]\n",
      " [2543    1 1744 ...,    0    0    0]\n",
      " ..., \n",
      " [9196 5800    7 ...,    0    0    0]\n",
      " [  81   42 7503 ...,    0    0    0]\n",
      " [   1  166  371 ...,    0    0    0]]\n",
      " 96/200 [=============>................] - ETA: 47s - loss: 1.5537 - acc: 0.8070[[1384   15   51 ...,    0    0    0]\n",
      " [  12   47  643 ...,    0    0    0]\n",
      " [  13    3 2537 ...,    0    0    0]\n",
      " ..., \n",
      " [  13 1432   10 ...,    0    0    0]\n",
      " [1386    7   73 ...,    0    0    0]\n",
      " [3954   13  192 ...,    0    0    0]]\n",
      " 97/200 [=============>................] - ETA: 46s - loss: 1.5566 - acc: 0.8066[[   1 3955    9 ...,    0    0    0]\n",
      " [   1 2943  217 ...,    0    0    0]\n",
      " [ 278    1   63 ...,    0    0    0]\n",
      " ..., \n",
      " [ 439   90   34 ...,    0    0    0]\n",
      " [  32  155    6 ...,    0    0    0]\n",
      " [9404  375 8160 ...,    0    0    0]]\n",
      " 98/200 [=============>................] - ETA: 46s - loss: 1.5598 - acc: 0.8063[[ 116  163  157 ...,    0    0    0]\n",
      " [ 220  324  209 ...,    0    0    0]\n",
      " [   1 1130   14 ...,    0    0    0]\n",
      " ..., \n",
      " [  13    1  681 ...,    0    0    0]\n",
      " [ 104  107 3647 ...,    0    0    0]\n",
      " [  12    1  908 ...,    0    0    0]]\n",
      " 99/200 [=============>................] - ETA: 45s - loss: 1.5600 - acc: 0.8063[[1811    7   47 ...,    0    0    0]\n",
      " [  93   67   13 ...,    0    0    0]\n",
      " [3884  176  298 ...,    0    0    0]\n",
      " ..., \n",
      " [ 531   67  207 ...,    0    0    0]\n",
      " [  27 2828  247 ...,    0    0    0]\n",
      " [  13 2635   67 ...,    0    0    0]]\n",
      "100/200 [==============>...............] - ETA: 45s - loss: 1.5611 - acc: 0.8062[[7069  123    7 ...,    0    0    0]\n",
      " [  13   13  200 ...,    0    0    0]\n",
      " [   1 1443   67 ...,    0    0    0]\n",
      " ..., \n",
      " [   4   22  408 ...,    0    0    0]\n",
      " [  10   63   13 ...,    0    0    0]\n",
      " [  18   22   13 ...,    0    0    0]]\n",
      "101/200 [==============>...............] - ETA: 44s - loss: 1.5630 - acc: 0.8060[[  13    6    1 ...,    0    0    0]\n",
      " [  27 1415  128 ...,    0    0    0]\n",
      " [   1  831   99 ...,    0    0    0]\n",
      " ..., \n",
      " [ 116   13 9748 ...,    0    0    0]\n",
      " [5391   13   13 ...,    0    0    0]\n",
      " [   1 6447   13 ...,    0    0    0]]\n",
      "102/200 [==============>...............] - ETA: 44s - loss: 1.5633 - acc: 0.8059[[   1 1769 2672 ...,    0    0    0]\n",
      " [ 557  733   13 ...,    0    0    0]\n",
      " [ 427   21 2318 ...,    0    0    0]\n",
      " ..., \n",
      " [ 108   93  959 ...,    0    0    0]\n",
      " [1304   23    2 ...,    0    0    0]\n",
      " [  12   34  692 ...,    0    0    0]]\n",
      "103/200 [==============>...............] - ETA: 44s - loss: 1.5624 - acc: 0.8061[[  80   41  384 ...,    0    0    0]\n",
      " [   1  474  558 ...,    0    0    0]\n",
      " [  15   27  257 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   13   13 ...,    0    0    0]\n",
      " [  18    1  381 ...,    0    0    0]\n",
      " [ 958 5040  747 ...,    0    0    0]]\n",
      "104/200 [==============>...............] - ETA: 43s - loss: 1.5626 - acc: 0.8061[[  10   34   13 ...,    0    0    0]\n",
      " [1853  135 2585 ...,    0    0    0]\n",
      " [  70   15  392 ...,    0    0    0]\n",
      " ..., \n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [ 109   26   65 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]]\n",
      "105/200 [==============>...............] - ETA: 43s - loss: 1.5638 - acc: 0.8060[[4504 3102    1 ...,    0    0    0]\n",
      " [2504    8 1654 ...,    0    0    0]\n",
      " [   1  286    5 ...,    0    0    0]\n",
      " ..., \n",
      " [ 599  102    4 ...,    0    0    0]\n",
      " [1247   11  850 ...,    0    0    0]\n",
      " [5164   21  269 ...,    0    0    0]]\n",
      "106/200 [==============>...............] - ETA: 42s - loss: 1.5634 - acc: 0.8060[[   1   47 2903 ...,    0    0    0]\n",
      " [   2   13 3238 ...,    0    0    0]\n",
      " [   1 2059 1158 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  214   23 ...,    0    0    0]\n",
      " [ 167 1865   13 ...,    0    0    0]\n",
      " [2017   67  694 ...,    0    0    0]]\n",
      "107/200 [===============>..............] - ETA: 42s - loss: 1.5634 - acc: 0.8060[[   1 3635    5 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " ..., \n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [2562   26  249 ...,    0    0    0]\n",
      " [  55   11 3290 ...,    0    0    0]]\n",
      "108/200 [===============>..............] - ETA: 41s - loss: 1.5639 - acc: 0.8060[[1267   26  113 ...,    0    0    0]\n",
      " [ 167  161  162 ...,    0    0    0]\n",
      " [ 234  435  167 ...,    0    0    0]\n",
      " ..., \n",
      " [1863   13   69 ...,    0    0    0]\n",
      " [  38  481  176 ...,    0    0    0]\n",
      " [   1 3317  310 ...,    0    0    0]]\n",
      "109/200 [===============>..............] - ETA: 41s - loss: 1.5633 - acc: 0.8061[[ 109   26  113 ...,    0    0    0]\n",
      " [  55  231   53 ...,    0    0    0]\n",
      " [1695  736 1528 ...,    0    0    0]\n",
      " ..., \n",
      " [  55   11 1220 ...,    0    0    0]\n",
      " [   1 1653 1614 ...,    0    0    0]\n",
      " [ 444 5769   40 ...,    0    0    0]]\n",
      "110/200 [===============>..............] - ETA: 40s - loss: 1.5638 - acc: 0.8061[[  19  352   30 ...,    0    0    0]\n",
      " [1757  119   27 ...,    0    0    0]\n",
      " [ 193   27  971 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  161  657 ...,    0    0    0]\n",
      " [   1  156 8704 ...,    0    0    0]\n",
      " [2198   69 8009 ...,    0    0    0]]\n",
      "111/200 [===============>..............] - ETA: 40s - loss: 1.5644 - acc: 0.8060[[  55   11 2025 ...,    0    0    0]\n",
      " [  58   59    7 ...,    0    0    0]\n",
      " [  49 1839    4 ...,    0    0    0]\n",
      " ..., \n",
      " [ 553  509   13 ...,    0    0    0]\n",
      " [ 342  196   66 ...,    0    0    0]\n",
      " [  32    2 2393 ...,    0    0    0]]\n",
      "112/200 [===============>..............] - ETA: 39s - loss: 1.5647 - acc: 0.8060[[1848  249   13 ...,    0    0    0]\n",
      " [   2   13 1373 ...,    0    0    0]\n",
      " [ 501  154   66 ...,    0    0    0]\n",
      " ..., \n",
      " [  55  100    1 ...,    0    0    0]\n",
      " [  55    7   13 ...,    0    0    0]\n",
      " [5591 5759    5 ...,    0    0    0]]\n",
      "113/200 [===============>..............] - ETA: 39s - loss: 1.5648 - acc: 0.8061[[ 131  179   69 ...,    0    0    0]\n",
      " [1745 3701    4 ...,    0    0    0]\n",
      " [1695  424  240 ...,    0    0    0]\n",
      " ..., \n",
      " [2323 2339  587 ...,    0    0    0]\n",
      " [1109    7  660 ...,    0    0    0]\n",
      " [   2 6148   74 ...,    0    0    0]]\n",
      "114/200 [================>.............] - ETA: 39s - loss: 1.5646 - acc: 0.8061[[ 109   26  268 ...,    0    0    0]\n",
      " [ 447  200    9 ...,    0    0    0]\n",
      " [6526   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 514 2246   13 ...,    0    0    0]\n",
      " [ 108 6764   13 ...,    0    0    0]\n",
      " [  42   14 7660 ...,    0    0    0]]\n",
      "115/200 [================>.............] - ETA: 38s - loss: 1.5634 - acc: 0.8062[[5230  558   83 ...,    0    0    0]\n",
      " [  13  800  390 ...,    0    0    0]\n",
      " [2535 6304   28 ...,    0    0    0]\n",
      " ..., \n",
      " [6992   11 1402 ...,    0    0    0]\n",
      " [ 299    5   19 ...,    0    0    0]\n",
      " [7181  721    7 ...,    0    0    0]]\n",
      "116/200 [================>.............] - ETA: 38s - loss: 1.5605 - acc: 0.8063[[  55    7 4530 ...,    0    0    0]\n",
      " [   1  601    5 ...,    0    0    0]\n",
      " [   2  582  405 ...,    0    0    0]\n",
      " ..., \n",
      " [2002 4124 1060 ...,    0    0    0]\n",
      " [2000    5 3866 ...,    0    0    0]\n",
      " [  26   67   84 ...,    0    0    0]]\n",
      "117/200 [================>.............] - ETA: 37s - loss: 1.5572 - acc: 0.8066[[  429  1887   484 ...,     0     0     0]\n",
      " [10146   971  9777 ...,     0     0     0]\n",
      " [  133    39  1899 ...,     0     0     0]\n",
      " ..., \n",
      " [ 9355 10993    11 ...,     0     0     0]\n",
      " [   22    13     9 ...,     0     0     0]\n",
      " [ 5353   963    13 ...,     0     0     0]]\n",
      "118/200 [================>.............] - ETA: 37s - loss: 1.5546 - acc: 0.8068[[ 276  178   13 ...,    0    0    0]\n",
      " [1573 2461  450 ...,    0    0    0]\n",
      " [1727  812   13 ...,    0    0    0]\n",
      " ..., \n",
      " [1431  450    9 ...,    0    0    0]\n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [  26  113   88 ...,    0    0    0]]\n",
      "119/200 [================>.............] - ETA: 36s - loss: 1.5519 - acc: 0.8070[[  15 1312   79 ...,    0    0    0]\n",
      " [1267  970 5527 ...,    0    0    0]\n",
      " [ 155  790 2047 ...,    0    0    0]\n",
      " ..., \n",
      " [5274 6861   11 ...,    0    0    0]\n",
      " [ 685  720 1150 ...,    0    0    0]\n",
      " [2371  532 1090 ...,    0    0    0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/200 [=================>............] - ETA: 36s - loss: 1.5497 - acc: 0.8071[[ 819   26   65 ...,    0    0    0]\n",
      " [  15   27   20 ...,    0    0    0]\n",
      " [1046  332 4746 ...,    0    0    0]\n",
      " ..., \n",
      " [   2   19  432 ...,    0    0    0]\n",
      " [ 131   69  309 ...,    0    0    0]\n",
      " [   1   13 3709 ...,    0    0    0]]\n",
      "121/200 [=================>............] - ETA: 35s - loss: 1.5472 - acc: 0.8073[[  22 1830   13 ...,    0    0    0]\n",
      " [1644 4243   13 ...,    0    0    0]\n",
      " [2160    2   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 706 3156   21 ...,    0    0    0]\n",
      " [  22  529 1376 ...,    0    0    0]\n",
      " [ 654  145    9 ...,    0    0    0]]\n",
      "122/200 [=================>............] - ETA: 35s - loss: 1.5449 - acc: 0.8075[[   2  440 3626 ...,    0    0    0]\n",
      " [ 150 4118 1345 ...,    0    0    0]\n",
      " [6629   27 3067 ...,    0    0    0]\n",
      " ..., \n",
      " [4526 2393 3885 ...,    0    0    0]\n",
      " [5829    7  732 ...,    0    0    0]\n",
      " [  13  761 6404 ...,    0    0    0]]\n",
      "123/200 [=================>............] - ETA: 34s - loss: 1.5431 - acc: 0.8076[[   2  676 2398 ...,    0    0    0]\n",
      " [ 792    7   13 ...,    0    0    0]\n",
      " [3408  157    2 ...,    0    0    0]\n",
      " ..., \n",
      " [3007    4  672 ...,    0    0    0]\n",
      " [ 226  752   13 ...,    0    0    0]\n",
      " [5933 5876 1425 ...,    0    0    0]]\n",
      "124/200 [=================>............] - ETA: 34s - loss: 1.5430 - acc: 0.8076[[ 226 1448  280 ...,    0    0    0]\n",
      " [   1  145  608 ...,    0    0    0]\n",
      " [ 807 4022   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 381  228  615 ...,    0    0    0]\n",
      " [   2 4374 9858 ...,    0    0    0]\n",
      " [  49 7088   21 ...,    0    0    0]]\n",
      "125/200 [=================>............] - ETA: 34s - loss: 1.5428 - acc: 0.8076[[ 676   19  352 ...,    0    0    0]\n",
      " [ 221  230  782 ...,    0    0    0]\n",
      " [5028   13  100 ...,    0    0    0]\n",
      " ..., \n",
      " [  15   14 1222 ...,    0    0    0]\n",
      " [  56  430    2 ...,    0    0    0]\n",
      " [   1   73  138 ...,    0    0    0]]\n",
      "126/200 [=================>............] - ETA: 33s - loss: 1.5449 - acc: 0.8074[[   1   13   91 ...,    0    0    0]\n",
      " [   1 3272 1040 ...,    0    0    0]\n",
      " [   1  330   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 219  324  209 ...,    0    0    0]\n",
      " [ 219  414  808 ...,    0    0    0]\n",
      " [ 697 1295  268 ...,    0    0    0]]\n",
      "127/200 [==================>...........] - ETA: 33s - loss: 1.5449 - acc: 0.8074[[324 209  13 ...,   0   0   0]\n",
      " [745  11  39 ...,   0   0   0]\n",
      " [ 13   7 131 ...,   0   0   0]\n",
      " ..., \n",
      " [  4   1  38 ...,   0   0   0]\n",
      " [ 15   7   2 ...,   0   0   0]\n",
      " [ 43  41  13 ...,   0   0   0]]\n",
      "128/200 [==================>...........] - ETA: 32s - loss: 1.5452 - acc: 0.8074[[  13 1578   15 ...,    0    0    0]\n",
      " [1578   13  105 ...,    0    0    0]\n",
      " [  70  159 1505 ...,    0    0    0]\n",
      " ..., \n",
      " [ 102  123 1944 ...,    0    0    0]\n",
      " [ 158  165    6 ...,    0    0    0]\n",
      " [   1   49   19 ...,    0    0    0]]\n",
      "129/200 [==================>...........] - ETA: 32s - loss: 1.5460 - acc: 0.8073[[  41  237 1212 ...,    0    0    0]\n",
      " [2343   13    9 ...,    0    0    0]\n",
      " [   1   13  124 ...,    0    0    0]\n",
      " ..., \n",
      " [2265 3954    9 ...,    0    0    0]\n",
      " [ 104 1585   96 ...,    0    0    0]\n",
      " [   1   13 1459 ...,    0    0    0]]\n",
      "130/200 [==================>...........] - ETA: 31s - loss: 1.5461 - acc: 0.8073[[  13   27 1181 ...,    0    0    0]\n",
      " [  13   15    7 ...,    0    0    0]\n",
      " [ 730   13 1067 ...,    0    0    0]\n",
      " ..., \n",
      " [  13  301 1384 ...,    0    0    0]\n",
      " [ 309  451   11 ...,    0    0    0]\n",
      " [   1 1017  182 ...,    0    0    0]]\n",
      "131/200 [==================>...........] - ETA: 31s - loss: 1.5486 - acc: 0.8070[[ 463   27   20 ...,    0    0    0]\n",
      " [ 194  563  374 ...,    0    0    0]\n",
      " [  56   13   63 ...,    0    0    0]\n",
      " ..., \n",
      " [ 443  900    7 ...,    0    0    0]\n",
      " [3491   26  619 ...,    0    0    0]\n",
      " [1940  536   13 ...,    0    0    0]]\n",
      "132/200 [==================>...........] - ETA: 30s - loss: 1.5505 - acc: 0.8068[[ 626    8 6161 ...,    0    0    0]\n",
      " [ 232   13 3343 ...,    0    0    0]\n",
      " [   1  751 2224 ...,    0    0    0]\n",
      " ..., \n",
      " [1014   13  381 ...,    0    0    0]\n",
      " [   2  259 2110 ...,    0    0    0]\n",
      " [3578  510   24 ...,    0    0    0]]\n",
      "133/200 [==================>...........] - ETA: 30s - loss: 1.5518 - acc: 0.8067[[    1  4995    86 ...,     0     0     0]\n",
      " [   93  1163    13 ...,     0     0     0]\n",
      " [   15     7  2204 ...,     0     0     0]\n",
      " ..., \n",
      " [  458  3535     9 ...,     0     0     0]\n",
      " [  882   283    50 ...,     0     0     0]\n",
      " [   93 11772  1166 ...,     0     0     0]]\n",
      "134/200 [===================>..........] - ETA: 29s - loss: 1.5546 - acc: 0.8064[[    1  1086   123 ...,     0     0     0]\n",
      " [    1   730  3049 ...,     0     0     0]\n",
      " [    1  1559  2887 ...,     0     0     0]\n",
      " ..., \n",
      " [  564    13  1068 ...,     0     0     0]\n",
      " [  116   589 11609 ...,     0     0     0]\n",
      " [   10    92   888 ...,     0     0     0]]\n",
      "135/200 [===================>..........] - ETA: 29s - loss: 1.5548 - acc: 0.8064[[ 232 3459   81 ...,    0    0    0]\n",
      " [ 379  177   13 ...,    0    0    0]\n",
      " [  19  120  105 ...,    0    0    0]\n",
      " ..., \n",
      " [  70    2 5322 ...,    0    0    0]\n",
      " [  13 1171   13 ...,    0    0    0]\n",
      " [ 599   63 1105 ...,    0    0    0]]\n",
      "136/200 [===================>..........] - ETA: 29s - loss: 1.5554 - acc: 0.8064[[   3 1141    2 ...,    0    0    0]\n",
      " [  13  104 2467 ...,    0    0    0]\n",
      " [  15  105   21 ...,    0    0    0]\n",
      " ..., \n",
      " [   4  552  173 ...,    0    0    0]\n",
      " [5707  610   11 ...,    0    0    0]\n",
      " [   1 5269   23 ...,    0    0    0]]\n",
      "137/200 [===================>..........] - ETA: 28s - loss: 1.5575 - acc: 0.8061[[  166   234    63 ...,     0     0     0]\n",
      " [   13     9   407 ...,     0     0     0]\n",
      " [    4    13  4290 ...,     0     0     0]\n",
      " ..., \n",
      " [   70   193 11373 ...,     0     0     0]\n",
      " [ 1760   898     1 ...,     0     0     0]\n",
      " [   15     7    54 ...,     0     0     0]]\n",
      "138/200 [===================>..........] - ETA: 28s - loss: 1.5567 - acc: 0.8062[[  72   29    7 ...,    0    0    0]\n",
      " [ 108    1   13 ...,    0    0    0]\n",
      " [ 304 1173  695 ...,    0    0    0]\n",
      " ..., \n",
      " [  99  102 2728 ...,    0    0    0]\n",
      " [2203   13  260 ...,    0    0    0]\n",
      " [ 382    3 2264 ...,    0    0    0]]\n",
      "139/200 [===================>..........] - ETA: 27s - loss: 1.5563 - acc: 0.8063[[   1  629    5 ...,    0    0    0]\n",
      " [ 221  230   13 ...,    0    0    0]\n",
      " [  15    7   18 ...,    0    0    0]\n",
      " ..., \n",
      " [  34    9    1 ...,    0    0    0]\n",
      " [   1  526 2248 ...,    0    0    0]\n",
      " [   1  431    5 ...,    0    0    0]]\n",
      "140/200 [====================>.........] - ETA: 27s - loss: 1.5561 - acc: 0.8064[[  26 1533   24 ...,    0    0    0]\n",
      " [  13  137    7 ...,    0    0    0]\n",
      " [   2 5193  165 ...,    0    0    0]\n",
      " ..., \n",
      " [  13 4006 7600 ...,    0    0    0]\n",
      " [ 108 3929   13 ...,    0    0    0]\n",
      " [  42   13    1 ...,    0    0    0]]\n",
      "141/200 [====================>.........] - ETA: 26s - loss: 1.5574 - acc: 0.8062[[ 229    2   13 ...,    0    0    0]\n",
      " [  68 1108  377 ...,    0    0    0]\n",
      " [  90  244 6505 ...,    0    0    0]\n",
      " ..., \n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [ 248   85  295 ...,    0    0    0]]\n",
      "142/200 [====================>.........] - ETA: 26s - loss: 1.5578 - acc: 0.8062[[    1   545   191 ...,     0     0     0]\n",
      " [    1   701     5 ...,     0     0     0]\n",
      " [  561    75   329 ...,     0     0     0]\n",
      " ..., \n",
      " [  561     8  1386 ...,     0     0     0]\n",
      " [11855   252   205 ...,     0     0     0]\n",
      " [  727     6    57 ...,     0     0     0]]\n",
      "143/200 [====================>.........] - ETA: 25s - loss: 1.5582 - acc: 0.8062[[  58   59   26 ...,    0    0    0]\n",
      " [   2  146   11 ...,    0    0    0]\n",
      " [ 109   26  619 ...,    0    0    0]\n",
      " ..., \n",
      " [  55    6   28 ...,    0    0    0]\n",
      " [ 109   26 1452 ...,    0    0    0]\n",
      " [  38  481  176 ...,    0    0    0]]\n",
      "144/200 [====================>.........] - ETA: 25s - loss: 1.5580 - acc: 0.8062[[ 214   23    1 ...,    0    0    0]\n",
      " [ 214   23    1 ...,    0    0    0]\n",
      " [ 214   23    1 ...,    0    0    0]\n",
      " ..., \n",
      " [ 546    6   25 ...,    0    0    0]\n",
      " [1717   13    5 ...,    0    0    0]\n",
      " [  13    9  498 ...,    0    0    0]]\n",
      "145/200 [====================>.........] - ETA: 24s - loss: 1.5580 - acc: 0.8063[[   1   13  736 ...,    0    0    0]\n",
      " [ 167  187  113 ...,    0    0    0]\n",
      " [1337    7 2059 ...,    0    0    0]\n",
      " ..., \n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [ 119    4  140 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/200 [====================>.........] - ETA: 24s - loss: 1.5584 - acc: 0.8063[[   1   13   91 ...,    0    0    0]\n",
      " [  26   12 2893 ...,    0    0    0]\n",
      " [ 454  205 2072 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 2011  283 ...,    0    0    0]\n",
      " [ 219   73  138 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]]\n",
      "147/200 [=====================>........] - ETA: 24s - loss: 1.5585 - acc: 0.8063[[    1    19   352 ...,     0     0     0]\n",
      " [  284   550   940 ...,     0     0     0]\n",
      " [ 2593 10809   555 ...,     0     0     0]\n",
      " ..., \n",
      " [10034   398  4821 ...,     0     0     0]\n",
      " [    1    55  2892 ...,     0     0     0]\n",
      " [  547  3499    13 ...,     0     0     0]]\n",
      "148/200 [=====================>........] - ETA: 23s - loss: 1.5587 - acc: 0.8063[[  884  4570     6 ...,     0     0     0]\n",
      " [    1   956   199 ...,     0     0     0]\n",
      " [   58    59   975 ...,     0     0     0]\n",
      " ..., \n",
      " [ 3213  4089     5 ...,     0     0     0]\n",
      " [11193   532  3291 ...,     0     0     0]\n",
      " [ 1525   398    13 ...,     0     0     0]]\n",
      "149/200 [=====================>........] - ETA: 23s - loss: 1.5590 - acc: 0.8063[[1757  187   65 ...,    0    0    0]\n",
      " [ 444   36  921 ...,    0    0    0]\n",
      " [ 342  196   66 ...,    0    0    0]\n",
      " ..., \n",
      " [1896  187  182 ...,    0    0    0]\n",
      " [  13 2757  455 ...,    0    0    0]\n",
      " [   1 1669 3689 ...,    0    0    0]]\n",
      "150/200 [=====================>........] - ETA: 22s - loss: 1.5594 - acc: 0.8062[[   1  881  509 ...,    0    0    0]\n",
      " [  12  296   49 ...,    0    0    0]\n",
      " [  15    7   61 ...,    0    0    0]\n",
      " ..., \n",
      " [ 119    4 1910 ...,    0    0    0]\n",
      " [1275  650  103 ...,    0    0    0]\n",
      " [  13   13    5 ...,    0    0    0]]\n",
      "151/200 [=====================>........] - ETA: 22s - loss: 1.5596 - acc: 0.8062[[ 2387    93   281 ...,     0     0     0]\n",
      " [11592    13    27 ...,     0     0     0]\n",
      " [ 1236    34     3 ...,     0     0     0]\n",
      " ..., \n",
      " [   10   152   139 ...,     0     0     0]\n",
      " [   13   192    39 ...,     0     0     0]\n",
      " [   13  1844    13 ...,     0     0     0]]\n",
      "152/200 [=====================>........] - ETA: 21s - loss: 1.5581 - acc: 0.8063[[  92   13 4159 ...,    0    0    0]\n",
      " [ 171  108   15 ...,    0    0    0]\n",
      " [2455  119 2005 ...,    0    0    0]\n",
      " ..., \n",
      " [ 309 4293    9 ...,    0    0    0]\n",
      " [2991 1171  100 ...,    0    0    0]\n",
      " [ 206   65   12 ...,    0    0    0]]\n",
      "153/200 [=====================>........] - ETA: 21s - loss: 1.5553 - acc: 0.8065[[ 224    9  539 ...,    0    0    0]\n",
      " [   1   13  223 ...,    0    0    0]\n",
      " [ 978 4090   14 ...,    0    0    0]\n",
      " ..., \n",
      " [6373   11  694 ...,    0    0    0]\n",
      " [   1 3530  692 ...,    0    0    0]\n",
      " [ 131  573  478 ...,    0    0    0]]\n",
      "154/200 [======================>.......] - ETA: 20s - loss: 1.5530 - acc: 0.8067[[ 391    5   17 ...,    0    0    0]\n",
      " [  17 1583   13 ...,    0    0    0]\n",
      " [   2 2442 1103 ...,    0    0    0]\n",
      " ..., \n",
      " [1248 3664 2995 ...,    0    0    0]\n",
      " [1862   27 2804 ...,    0    0    0]\n",
      " [3289  604 2206 ...,    0    0    0]]\n",
      "155/200 [======================>.......] - ETA: 20s - loss: 1.5510 - acc: 0.8068[[    1   132   509 ...,     0     0     0]\n",
      " [    4   173   472 ...,     0     0     0]\n",
      " [   80   160    67 ...,     0     0     0]\n",
      " ..., \n",
      " [ 7394  6442    14 ...,     0     0     0]\n",
      " [ 3597  7808   715 ...,     0     0     0]\n",
      " [ 2966 10273    13 ...,     0     0     0]]\n",
      "156/200 [======================>.......] - ETA: 19s - loss: 1.5489 - acc: 0.8069[[11032    13   289 ...,     0     0     0]\n",
      " [   15   247  4604 ...,     0     0     0]\n",
      " [    4     2   430 ...,     0     0     0]\n",
      " ..., \n",
      " [   13    13    27 ...,     0     0     0]\n",
      " [    1  1912  3553 ...,     0     0     0]\n",
      " [ 1339  1553    27 ...,     0     0     0]]\n",
      "157/200 [======================>.......] - ETA: 19s - loss: 1.5476 - acc: 0.8070[[   1 4023   21 ...,    0    0    0]\n",
      " [   1  884 1054 ...,    0    0    0]\n",
      " [  55    7 1263 ...,    0    0    0]\n",
      " ..., \n",
      " [   2 1373   13 ...,    0    0    0]\n",
      " [   2  633  417 ...,    0    0    0]\n",
      " [   1  456  732 ...,    0    0    0]]\n",
      "158/200 [======================>.......] - ETA: 19s - loss: 1.5462 - acc: 0.8071[[  55    7 4244 ...,    0    0    0]\n",
      " [  26   21  691 ...,    0    0    0]\n",
      " [ 425  217   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 626 2846    7 ...,    0    0    0]\n",
      " [ 127   19  661 ...,    0    0    0]\n",
      " [   1 1610    5 ...,    0    0    0]]\n",
      "159/200 [======================>.......] - ETA: 18s - loss: 1.5448 - acc: 0.8072[[ 545 2882  267 ...,    0    0    0]\n",
      " [ 488   11  336 ...,    0    0    0]\n",
      " [1546 1415 1270 ...,    0    0    0]\n",
      " ..., \n",
      " [  49 2455 9170 ...,    0    0    0]\n",
      " [1337   30   33 ...,    0    0    0]\n",
      " [ 987    7  705 ...,    0    0    0]]\n",
      "160/200 [=======================>......] - ETA: 18s - loss: 1.5435 - acc: 0.8073[[  38  499  295 ...,    0    0    0]\n",
      " [4384  130  880 ...,    0    0    0]\n",
      " [1935  295 7857 ...,    0    0    0]\n",
      " ..., \n",
      " [ 116 2700    8 ...,    0    0    0]\n",
      " [4358   13 7852 ...,    0    0    0]\n",
      " [1172  720   13 ...,    0    0    0]]\n",
      "161/200 [=======================>......] - ETA: 17s - loss: 1.5431 - acc: 0.8072[[1075  280    8 ...,    0    0    0]\n",
      " [   1  214   23 ...,    0    0    0]\n",
      " [ 987    6   36 ...,    0    0    0]\n",
      " ..., \n",
      " [ 485   13   19 ...,    0    0    0]\n",
      " [1753  135 1266 ...,    0    0    0]\n",
      " [3062    8 1597 ...,    0    0    0]]\n",
      "162/200 [=======================>......] - ETA: 17s - loss: 1.5439 - acc: 0.8072[[3733   13 3322 ...,    0    0    0]\n",
      " [  15    7   48 ...,    0    0    0]\n",
      " [3674 2252    4 ...,    0    0    0]\n",
      " ..., \n",
      " [ 844  329   24 ...,    0    0    0]\n",
      " [ 109   26   67 ...,    0    0    0]\n",
      " [ 107   70   15 ...,    0    0    0]]\n",
      "163/200 [=======================>......] - ETA: 16s - loss: 1.5432 - acc: 0.8073[[ 930 9779   14 ...,    0    0    0]\n",
      " [ 109   26  106 ...,    0    0    0]\n",
      " [1405    7 1096 ...,    0    0    0]\n",
      " ..., \n",
      " [ 390 3380   11 ...,    0    0    0]\n",
      " [ 790 2047    9 ...,    0    0    0]\n",
      " [ 131  488  103 ...,    0    0    0]]\n",
      "164/200 [=======================>......] - ETA: 16s - loss: 1.5444 - acc: 0.8072[[1339 1553    9 ...,    0    0    0]\n",
      " [3194   13  165 ...,    0    0    0]\n",
      " [  13   13    9 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13  568 ...,    0    0    0]\n",
      " [4368 5452  265 ...,    0    0    0]\n",
      " [ 109  154   66 ...,    0    0    0]]\n",
      "165/200 [=======================>......] - ETA: 15s - loss: 1.5448 - acc: 0.8071[[1597  196 2573 ...,    0    0    0]\n",
      " [  15   14 1237 ...,    0    0    0]\n",
      " [   1 3982   13 ...,    0    0    0]\n",
      " ..., \n",
      " [  16   22  355 ...,    0    0    0]\n",
      " [   2 2041 1874 ...,    0    0    0]\n",
      " [ 280 9433 4699 ...,    0    0    0]]\n",
      "166/200 [=======================>......] - ETA: 15s - loss: 1.5460 - acc: 0.8070[[10386     4    34 ...,     0     0     0]\n",
      " [ 9006  2116     9 ...,     0     0     0]\n",
      " [    1  9067     5 ...,     0     0     0]\n",
      " ..., \n",
      " [ 8231  3112    13 ...,     0     0     0]\n",
      " [ 3279    11   385 ...,     0     0     0]\n",
      " [   44    13   857 ...,     0     0     0]]\n",
      "167/200 [========================>.....] - ETA: 14s - loss: 1.5456 - acc: 0.8071[[10745   112    36 ...,     0     0     0]\n",
      " [    1   542     9 ...,     0     0     0]\n",
      " [   93    67     1 ...,     0     0     0]\n",
      " ..., \n",
      " [ 7442  2021  1913 ...,     0     0     0]\n",
      " [  107    70     1 ...,     0     0     0]\n",
      " [    4    64    82 ...,     0     0     0]]\n",
      "168/200 [========================>.....] - ETA: 14s - loss: 1.5459 - acc: 0.8070[[   10    99  1044 ...,     0     0     0]\n",
      " [   15     9    48 ...,     0     0     0]\n",
      " [10062  6003     4 ...,     0     0     0]\n",
      " ..., \n",
      " [  165   349   252 ...,     0     0     0]\n",
      " [  949     3     1 ...,     0     0     0]\n",
      " [   26  2920    60 ...,     0     0     0]]\n",
      "169/200 [========================>.....] - ETA: 14s - loss: 1.5474 - acc: 0.8069[[   1   13  400 ...,    0    0    0]\n",
      " [ 474    1 1475 ...,    0    0    0]\n",
      " [ 931  309   13 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   13    1 ...,    0    0    0]\n",
      " [  80  110    4 ...,    0    0    0]\n",
      " [   2 1762  368 ...,    0    0    0]]\n",
      "170/200 [========================>.....] - ETA: 13s - loss: 1.5493 - acc: 0.8067[[ 531   23  149 ...,    0    0    0]\n",
      " [   1 2923  253 ...,    0    0    0]\n",
      " [4685   54   13 ...,    0    0    0]\n",
      " ..., \n",
      " [2965   13    7 ...,    0    0    0]\n",
      " [ 276   13   15 ...,    0    0    0]\n",
      " [   4    1 1161 ...,    0    0    0]]\n",
      "171/200 [========================>.....] - ETA: 13s - loss: 1.5513 - acc: 0.8065[[ 350   21 2683 ...,    0    0    0]\n",
      " [2379  627  247 ...,    0    0    0]\n",
      " [   1 1341   86 ...,    0    0    0]\n",
      " ..., \n",
      " [  43 1798    5 ...,    0    0    0]\n",
      " [  15  448   29 ...,    0    0    0]\n",
      " [ 937   13    8 ...,    0    0    0]]\n",
      "172/200 [========================>.....] - ETA: 12s - loss: 1.5525 - acc: 0.8063[[   3 4041    2 ...,    0    0    0]\n",
      " [  95    1   63 ...,    0    0    0]\n",
      " [   4 1408   13 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 2192  757 ...,    0    0    0]\n",
      " [ 893 3353 1117 ...,    0    0    0]\n",
      " [  34 1226   96 ...,    0    0    0]]\n",
      "173/200 [========================>.....] - ETA: 12s - loss: 1.5518 - acc: 0.8064[[  49    5    1 ...,    0    0    0]\n",
      " [1500   13 6988 ...,    0    0    0]\n",
      " [   1  873   13 ...,    0    0    0]\n",
      " ..., \n",
      " [   4   13   13 ...,    0    0    0]\n",
      " [ 108   68   23 ...,    0    0    0]\n",
      " [ 232  725   14 ...,    0    0    0]]\n",
      "174/200 [=========================>....] - ETA: 11s - loss: 1.5521 - acc: 0.8064[[  74    5    1 ...,    0    0    0]\n",
      " [ 187    5   13 ...,    0    0    0]\n",
      " [ 264  105   20 ...,    0    0    0]\n",
      " ..., \n",
      " [   4    1   78 ...,    0    0    0]\n",
      " [9224 1119  993 ...,    0    0    0]\n",
      " [ 221  230   13 ...,    0    0    0]]\n",
      "175/200 [=========================>....] - ETA: 11s - loss: 1.5537 - acc: 0.8062[[  16  166   49 ...,    0    0    0]\n",
      " [   2 1983  302 ...,    0    0    0]\n",
      " [  13 1287   13 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13 1211 ...,    0    0    0]\n",
      " [5470    8   13 ...,    0    0    0]\n",
      " [4315 4331   81 ...,    0    0    0]]\n",
      "176/200 [=========================>....] - ETA: 10s - loss: 1.5537 - acc: 0.8063[[   13    13    13 ...,     0     0     0]\n",
      " [  137     2  5678 ...,     0     0     0]\n",
      " [  721    74    13 ...,     0     0     0]\n",
      " ..., \n",
      " [ 9513 11644  2385 ...,     0     0     0]\n",
      " [  104  1340    80 ...,     0     0     0]\n",
      " [   85     1  3845 ...,     0     0     0]]\n",
      "177/200 [=========================>....] - ETA: 10s - loss: 1.5533 - acc: 0.8063[[ 812   13    9 ...,    0    0    0]\n",
      " [6382 6947    9 ...,    0    0    0]\n",
      " [ 153  729  574 ...,    0    0    0]\n",
      " ..., \n",
      " [  89   23  702 ...,    0    0    0]\n",
      " [  13   23 5447 ...,    0    0    0]\n",
      " [ 299    5  474 ...,    0    0    0]]\n",
      "178/200 [=========================>....] - ETA: 9s - loss: 1.5529 - acc: 0.8064 [[   1 1676 4129 ...,    0    0    0]\n",
      " [  12    1 5062 ...,    0    0    0]\n",
      " [ 242   69  263 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   27 3418 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]]\n",
      "179/200 [=========================>....] - ETA: 9s - loss: 1.5534 - acc: 0.8064[[  22  905 1755 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [   1 2065 2164 ...,    0    0    0]\n",
      " ..., \n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [   1  191    5 ...,    0    0    0]]\n",
      "180/200 [==========================>...] - ETA: 9s - loss: 1.5533 - acc: 0.8064[[  58   59   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [   1 1522  433 ...,    0    0    0]\n",
      " ..., \n",
      " [ 214   23    1 ...,    0    0    0]\n",
      " [2079   12    1 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]]\n",
      "181/200 [==========================>...] - ETA: 8s - loss: 1.5534 - acc: 0.8064[[ 140  609   73 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [   1   13 2164 ...,    0    0    0]\n",
      " ..., \n",
      " [ 444    9  155 ...,    0    0    0]\n",
      " [ 127   76    5 ...,    0    0    0]\n",
      " [7042 2036   75 ...,    0    0    0]]\n",
      "182/200 [==========================>...] - ETA: 8s - loss: 1.5531 - acc: 0.8065[[    2    13   701 ...,     0     0     0]\n",
      " [ 1189   224     7 ...,     0     0     0]\n",
      " [  200     7   176 ...,     0     0     0]\n",
      " ..., \n",
      " [    2    13 10143 ...,     0     0     0]\n",
      " [   13    26   182 ...,     0     0     0]\n",
      " [   42  1808    29 ...,     0     0     0]]\n",
      "183/200 [==========================>...] - ETA: 7s - loss: 1.5532 - acc: 0.8065[[ 176   66  115 ...,    0    0    0]\n",
      " [   1  102    7 ...,    0    0    0]\n",
      " [ 167   69 3369 ...,    0    0    0]\n",
      " ..., \n",
      " [ 167   13   21 ...,    0    0    0]\n",
      " [4370 1038    8 ...,    0    0    0]\n",
      " [   2   13  167 ...,    0    0    0]]\n",
      "184/200 [==========================>...] - ETA: 7s - loss: 1.5535 - acc: 0.8065[[ 131  226  398 ...,    0    0    0]\n",
      " [   1   13 1438 ...,    0    0    0]\n",
      " [   1   13   38 ...,    0    0    0]\n",
      " ..., \n",
      " [ 491   26  113 ...,    0    0    0]\n",
      " [ 727  292   13 ...,    0    0    0]\n",
      " [1221   13  941 ...,    0    0    0]]\n",
      "185/200 [==========================>...] - ETA: 6s - loss: 1.5536 - acc: 0.8065[[ 109   26  113 ...,    0    0    0]\n",
      " [ 546 8112  200 ...,    0    0    0]\n",
      " [ 632  528  142 ...,    0    0    0]\n",
      " ..., \n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [   1   13   58 ...,    0    0    0]\n",
      " [1355 2777   13 ...,    0    0    0]]\n",
      "186/200 [==========================>...] - ETA: 6s - loss: 1.5536 - acc: 0.8065[[9786 2086   13 ...,    0    0    0]\n",
      " [  13    4  429 ...,    0    0    0]\n",
      " [ 884   26  115 ...,    0    0    0]\n",
      " ..., \n",
      " [ 383   13   46 ...,    0    0    0]\n",
      " [1827   25  308 ...,    0    0    0]\n",
      " [  13 3689 3693 ...,    0    0    0]]\n",
      "187/200 [===========================>..] - ETA: 5s - loss: 1.5539 - acc: 0.8065[[  55  292  728 ...,    0    0    0]\n",
      " [  19  352   26 ...,    0    0    0]\n",
      " [8676   13    5 ...,    0    0    0]\n",
      " ..., \n",
      " [ 444 5335    1 ...,    0    0    0]\n",
      " [ 154   66    4 ...,    0    0    0]\n",
      " [1827   36 2934 ...,    0    0    0]]\n",
      "188/200 [===========================>..] - ETA: 5s - loss: 1.5545 - acc: 0.8065[[    1    19   352 ...,     0     0     0]\n",
      " [11098  3659     9 ...,     0     0     0]\n",
      " [  501   154    66 ...,     0     0     0]\n",
      " ..., \n",
      " [    1   529   223 ...,     0     0     0]\n",
      " [ 1454   100     1 ...,     0     0     0]\n",
      " [ 2405  7209   700 ...,     0     0     0]]\n",
      "189/200 [===========================>..] - ETA: 4s - loss: 1.5546 - acc: 0.8065[[   1   13   13 ...,    0    0    0]\n",
      " [   2  440  842 ...,    0    0    0]\n",
      " [ 255   73  240 ...,    0    0    0]\n",
      " ..., \n",
      " [ 109   26  115 ...,    0    0    0]\n",
      " [   1 2930   86 ...,    0    0    0]\n",
      " [3830 1927 1531 ...,    0    0    0]]\n",
      "190/200 [===========================>..] - ETA: 4s - loss: 1.5525 - acc: 0.8065[[  66    6    1 ...,    0    0    0]\n",
      " [ 726 2576 4672 ...,    0    0    0]\n",
      " [   2   13   12 ...,    0    0    0]\n",
      " ..., \n",
      " [  22   13  704 ...,    0    0    0]\n",
      " [   1   19  120 ...,    0    0    0]\n",
      " [2346 4931 7102 ...,    0    0    0]]\n",
      "191/200 [===========================>..] - ETA: 4s - loss: 1.5510 - acc: 0.8066[[   1  260  438 ...,    0    0    0]\n",
      " [ 849  394 1610 ...,    0    0    0]\n",
      " [ 356  767  484 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 3525  294 ...,    0    0    0]\n",
      " [  13 3323    9 ...,    0    0    0]\n",
      " [  10    2   13 ...,    0    0    0]]\n",
      "192/200 [===========================>..] - ETA: 3s - loss: 1.5490 - acc: 0.8068[[ 654  145  398 ...,    0    0    0]\n",
      " [   1 2181    8 ...,    0    0    0]\n",
      " [  49   64 4137 ...,    0    0    0]\n",
      " ..., \n",
      " [1337  217    1 ...,    0    0    0]\n",
      " [  15  336   64 ...,    0    0    0]\n",
      " [1536 4331   13 ...,    0    0    0]]\n",
      "193/200 [===========================>..] - ETA: 3s - loss: 1.5476 - acc: 0.8069[[4424 4371  227 ...,    0    0    0]\n",
      " [ 119  267  157 ...,    0    0    0]\n",
      " [4139  398 2129 ...,    0    0    0]\n",
      " ..., \n",
      " [2536 2391  212 ...,    0    0    0]\n",
      " [1224   69 4841 ...,    0    0    0]\n",
      " [   1   13  241 ...,    0    0    0]]\n",
      "194/200 [============================>.] - ETA: 2s - loss: 1.5462 - acc: 0.8070[[3492 4168  766 ...,    0    0    0]\n",
      " [   1   13   86 ...,    0    0    0]\n",
      " [ 790 2426   11 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   11 2586 ...,    0    0    0]\n",
      " [ 206   66   21 ...,    0    0    0]\n",
      " [1282    7  732 ...,    0    0    0]]\n",
      "195/200 [============================>.] - ETA: 2s - loss: 1.5448 - acc: 0.8071[[6829 5421    9 ...,    0    0    0]\n",
      " [3153 1924    4 ...,    0    0    0]\n",
      " [  13   13  312 ...,    0    0    0]\n",
      " ..., \n",
      " [6292 9645   11 ...,    0    0    0]\n",
      " [1742    7 6252 ...,    0    0    0]\n",
      " [1331   11 1992 ...,    0    0    0]]\n",
      "196/200 [============================>.] - ETA: 1s - loss: 1.5435 - acc: 0.8072[[  150  1697    13 ...,     0     0     0]\n",
      " [ 4458     8 11411 ...,     0     0     0]\n",
      " [  158   268     4 ...,     0     0     0]\n",
      " ..., \n",
      " [    1    13   680 ...,     0     0     0]\n",
      " [    1  2657   680 ...,     0     0     0]\n",
      " [ 6308   694  5350 ...,     0     0     0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197/200 [============================>.] - ETA: 1s - loss: 1.5424 - acc: 0.8073[[ 623  157   22 ...,    0    0    0]\n",
      " [  69  297   13 ...,    0    0    0]\n",
      " [ 344   83   15 ...,    0    0    0]\n",
      " ..., \n",
      " [   2   13  282 ...,    0    0    0]\n",
      " [  13   13    1 ...,    0    0    0]\n",
      " [  13   13 2385 ...,    0    0    0]]\n",
      "198/200 [============================>.] - ETA: 0s - loss: 1.5413 - acc: 0.8074[[ 727   30   25 ...,    0    0    0]\n",
      " [ 119  462    8 ...,    0    0    0]\n",
      " [ 719  137    1 ...,    0    0    0]\n",
      " ..., \n",
      " [  13 8281 2278 ...,    0    0    0]\n",
      " [   2   13 1489 ...,    0    0    0]\n",
      " [ 708   82    2 ...,    0    0    0]]\n",
      "199/200 [============================>.] - ETA: 0s - loss: 1.5406 - acc: 0.8074[[ 547 1206    2 ...,    0    0    0]\n",
      " [  19  120  662 ...,    0    0    0]\n",
      " [   2 1779  321 ...,    0    0    0]\n",
      " ..., \n",
      " [6404   27 5918 ...,    0    0    0]\n",
      " [1680   13  484 ...,    0    0    0]\n",
      " [   1  167  117 ...,    0    0    0]]\n",
      "200/200 [==============================] - 90s - loss: 1.5409 - acc: 0.8074    \n",
      "Epoch 8/10\n",
      "[[1046   11  510 ...,    0    0    0]\n",
      " [  15    7  461 ...,    0    0    0]\n",
      " [  15 1272 1322 ...,    0    0    0]\n",
      " ..., \n",
      " [ 116    5    1 ...,    0    0    0]\n",
      " [5209   13   83 ...,    0    0    0]\n",
      " [   1 1547 1127 ...,    0    0    0]]\n",
      "  1/200 [..............................] - ETA: 93s - loss: 1.7478 - acc: 0.7933[[  790  3805    11 ...,     0     0     0]\n",
      " [ 1635 10089    13 ...,     0     0     0]\n",
      " [ 1052     8  1465 ...,     0     0     0]\n",
      " ..., \n",
      " [  206   113    24 ...,     0     0     0]\n",
      " [  220    13    21 ...,     0     0     0]\n",
      " [   13    13     7 ...,     0     0     0]]\n",
      "  2/200 [..............................] - ETA: 93s - loss: 1.8028 - acc: 0.7839[[4800 4919  247 ...,    0    0    0]\n",
      " [1696  729    8 ...,    0    0    0]\n",
      " [ 545 1007  674 ...,    0    0    0]\n",
      " ..., \n",
      " [7710   13   51 ...,    0    0    0]\n",
      " [ 108   68  410 ...,    0    0    0]\n",
      " [ 232 3054    9 ...,    0    0    0]]\n",
      "  3/200 [..............................] - ETA: 92s - loss: 1.7623 - acc: 0.7871[[ 1332  9266    27 ...,     0     0     0]\n",
      " [    1   288 11255 ...,     0     0     0]\n",
      " [    1   580   473 ...,     0     0     0]\n",
      " ..., \n",
      " [  353  4319     7 ...,     0     0     0]\n",
      " [   70    15   283 ...,     0     0     0]\n",
      " [  353    13    14 ...,     0     0     0]]\n",
      "  4/200 [..............................] - ETA: 90s - loss: 1.7375 - acc: 0.7894[[3252 3114   11 ...,    0    0    0]\n",
      " [   1  535  765 ...,    0    0    0]\n",
      " [1490 3312 1528 ...,    0    0    0]\n",
      " ..., \n",
      " [   2  131 4181 ...,    0    0    0]\n",
      " [   1 6409  360 ...,    0    0    0]\n",
      " [4181 2149   21 ...,    0    0    0]]\n",
      "  5/200 [..............................] - ETA: 89s - loss: 1.6814 - acc: 0.7958[[ 1802    13    68 ...,     0     0     0]\n",
      " [   13 11267  8560 ...,     0     0     0]\n",
      " [  213    14  1099 ...,     0     0     0]\n",
      " ..., \n",
      " [   15     7    48 ...,     0     0     0]\n",
      " [  133    39   321 ...,     0     0     0]\n",
      " [    1  1942     5 ...,     0     0     0]]\n",
      "  6/200 [..............................] - ETA: 88s - loss: 1.6492 - acc: 0.7988[[9231  112    5 ...,    0    0    0]\n",
      " [  13   13   44 ...,    0    0    0]\n",
      " [  68  114  321 ...,    0    0    0]\n",
      " ..., \n",
      " [  13  104   21 ...,    0    0    0]\n",
      " [  93  265  337 ...,    0    0    0]\n",
      " [ 171  108   13 ...,    0    0    0]]\n",
      "  7/200 [>.............................] - ETA: 88s - loss: 1.6623 - acc: 0.7968[[   1  166  371 ...,    0    0    0]\n",
      " [  13  572 3510 ...,    0    0    0]\n",
      " [   1 3776   10 ...,    0    0    0]\n",
      " ..., \n",
      " [  89   67    2 ...,    0    0    0]\n",
      " [ 137  336   18 ...,    0    0    0]\n",
      " [ 150  466  142 ...,    0    0    0]]\n",
      "  8/200 [>.............................] - ETA: 87s - loss: 1.6754 - acc: 0.7951[[   42   471    39 ...,     0     0     0]\n",
      " [    1   214     9 ...,     0     0     0]\n",
      " [    1    13    13 ...,     0     0     0]\n",
      " ..., \n",
      " [   41  2088  4006 ...,     0     0     0]\n",
      " [    1  2538  2476 ...,     0     0     0]\n",
      " [   13  1442 10169 ...,     0     0     0]]\n",
      "  9/200 [>.............................] - ETA: 87s - loss: 1.6929 - acc: 0.7929[[ 301 1351    3 ...,    0    0    0]\n",
      " [2860   13 1184 ...,    0    0    0]\n",
      " [ 719  577   10 ...,    0    0    0]\n",
      " ..., \n",
      " [ 156  213   27 ...,    0    0    0]\n",
      " [ 751 2527  532 ...,    0    0    0]\n",
      " [  80   41  805 ...,    0    0    0]]\n",
      " 10/200 [>.............................] - ETA: 87s - loss: 1.7117 - acc: 0.7905[[   1 1761    5 ...,    0    0    0]\n",
      " [ 194   63  144 ...,    0    0    0]\n",
      " [1054    9   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 280   13   13 ...,    0    0    0]\n",
      " [ 693    2  181 ...,    0    0    0]\n",
      " [ 474  572    7 ...,    0    0    0]]\n",
      " 11/200 [>.............................] - ETA: 87s - loss: 1.6964 - acc: 0.7923[[  89    7    2 ...,    0    0    0]\n",
      " [   1  662  934 ...,    0    0    0]\n",
      " [ 108   15   67 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   99 4777 ...,    0    0    0]\n",
      " [1232 3185   13 ...,    0    0    0]\n",
      " [1036   16  728 ...,    0    0    0]]\n",
      " 12/200 [>.............................] - ETA: 86s - loss: 1.6780 - acc: 0.7947[[   2  487    5 ...,    0    0    0]\n",
      " [   1   38  949 ...,    0    0    0]\n",
      " [5734   13   14 ...,    0    0    0]\n",
      " ..., \n",
      " [1000 2290    8 ...,    0    0    0]\n",
      " [   1   38   62 ...,    0    0    0]\n",
      " [ 250 1318  105 ...,    0    0    0]]\n",
      " 13/200 [>.............................] - ETA: 86s - loss: 1.6820 - acc: 0.7937[[ 194   63  144 ...,    0    0    0]\n",
      " [  10   92  888 ...,    0    0    0]\n",
      " [   1  467    5 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  170   29 ...,    0    0    0]\n",
      " [  80   41 1018 ...,    0    0    0]\n",
      " [  10   13  558 ...,    0    0    0]]\n",
      " 14/200 [=>............................] - ETA: 85s - loss: 1.6780 - acc: 0.7943[[ 823   13    1 ...,    0    0    0]\n",
      " [ 341   13  104 ...,    0    0    0]\n",
      " [2308   13 6010 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13   13 ...,    0    0    0]\n",
      " [  56    2  497 ...,    0    0    0]\n",
      " [  13  458 7740 ...,    0    0    0]]\n",
      " 15/200 [=>............................] - ETA: 85s - loss: 1.6684 - acc: 0.7955[[4496 3567  385 ...,    0    0    0]\n",
      " [  78   94   13 ...,    0    0    0]\n",
      " [3007  256    1 ...,    0    0    0]\n",
      " ..., \n",
      " [   4   17 3237 ...,    0    0    0]\n",
      " [  92   63  144 ...,    0    0    0]\n",
      " [  49   63  144 ...,    0    0    0]]\n",
      " 16/200 [=>............................] - ETA: 85s - loss: 1.6566 - acc: 0.7973[[1753  676 6299 ...,    0    0    0]\n",
      " [   2 3272   74 ...,    0    0    0]\n",
      " [  13    7 4633 ...,    0    0    0]\n",
      " ..., \n",
      " [  13  104   21 ...,    0    0    0]\n",
      " [ 309 4211    9 ...,    0    0    0]\n",
      " [2071   11  147 ...,    0    0    0]]\n",
      " 17/200 [=>............................] - ETA: 84s - loss: 1.6555 - acc: 0.7979[[ 379  177   13 ...,    0    0    0]\n",
      " [  99  177   13 ...,    0    0    0]\n",
      " [ 973   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [  18 1780   10 ...,    0    0    0]\n",
      " [  15  128   48 ...,    0    0    0]\n",
      " [  13   13   81 ...,    0    0    0]]\n",
      " 18/200 [=>............................] - ETA: 83s - loss: 1.6522 - acc: 0.7985[[   1  885  981 ...,    0    0    0]\n",
      " [  13  133   68 ...,    0    0    0]\n",
      " [2318  133   92 ...,    0    0    0]\n",
      " ..., \n",
      " [  13 1186    4 ...,    0    0    0]\n",
      " [  89   23  155 ...,    0    0    0]\n",
      " [  55   27   13 ...,    0    0    0]]\n",
      " 19/200 [=>............................] - ETA: 83s - loss: 1.6435 - acc: 0.7998[[  58   59   26 ...,    0    0    0]\n",
      " [ 454  883 2440 ...,    0    0    0]\n",
      " [   1   13  518 ...,    0    0    0]\n",
      " ..., \n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [5182   11  130 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]]\n",
      " 20/200 [==>...........................] - ETA: 83s - loss: 1.6392 - acc: 0.8003[[1267 7727 2130 ...,    0    0    0]\n",
      " [   1  220   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  187  635 ...,    0    0    0]\n",
      " [   2 1267 1547 ...,    0    0    0]\n",
      " [2239  720 2558 ...,    0    0    0]]\n",
      " 21/200 [==>...........................] - ETA: 82s - loss: 1.6410 - acc: 0.8001[[   58    59    26 ...,     0     0     0]\n",
      " [  681  1281    13 ...,     0     0     0]\n",
      " [  318     7    49 ...,     0     0     0]\n",
      " ..., \n",
      " [  844     8   284 ...,     0     0     0]\n",
      " [   58    59    26 ...,     0     0     0]\n",
      " [10907    46     5 ...,     0     0     0]]\n",
      " 22/200 [==>...........................] - ETA: 82s - loss: 1.6403 - acc: 0.8001[[ 318  329   10 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " ..., \n",
      " [   2  806    8 ...,    0    0    0]\n",
      " [  13   26  115 ...,    0    0    0]\n",
      " [   2 1135   13 ...,    0    0    0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 23/200 [==>...........................] - ETA: 81s - loss: 1.6376 - acc: 0.8004[[1811 2457    1 ...,    0    0    0]\n",
      " [3730  326  209 ...,    0    0    0]\n",
      " [1282    7  732 ...,    0    0    0]\n",
      " ..., \n",
      " [4244  404   27 ...,    0    0    0]\n",
      " [ 481   66  106 ...,    0    0    0]\n",
      " [   1  214   23 ...,    0    0    0]]\n",
      " 24/200 [==>...........................] - ETA: 81s - loss: 1.6360 - acc: 0.8006[[ 167 2079  664 ...,    0    0    0]\n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [ 167 2004  336 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13 1997 ...,    0    0    0]\n",
      " [ 913    7 1014 ...,    0    0    0]\n",
      " [  55    7  536 ...,    0    0    0]]\n",
      " 25/200 [==>...........................] - ETA: 80s - loss: 1.6354 - acc: 0.8006[[    2    19  5809 ...,     0     0     0]\n",
      " [    1   884   223 ...,     0     0     0]\n",
      " [    2   258     5 ...,     0     0     0]\n",
      " ..., \n",
      " [    1  9295     5 ...,     0     0     0]\n",
      " [10274    13  1362 ...,     0     0     0]\n",
      " [    1   367  2161 ...,     0     0     0]]\n",
      " 26/200 [==>...........................] - ETA: 80s - loss: 1.6348 - acc: 0.8006[[   1   13 1333 ...,    0    0    0]\n",
      " [   1  367 2161 ...,    0    0    0]\n",
      " [ 481   66 1160 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   11   45 ...,    0    0    0]\n",
      " [4943   13   11 ...,    0    0    0]\n",
      " [  10    1  156 ...,    0    0    0]]\n",
      " 27/200 [===>..........................] - ETA: 79s - loss: 1.6375 - acc: 0.8001[[  55  292  607 ...,    0    0    0]\n",
      " [  55   25  292 ...,    0    0    0]\n",
      " [ 116   13 3115 ...,    0    0    0]\n",
      " ..., \n",
      " [   2  712  778 ...,    0    0    0]\n",
      " [   1   91 3267 ...,    0    0    0]\n",
      " [  15    7  211 ...,    0    0    0]]\n",
      " 28/200 [===>..........................] - ETA: 79s - loss: 1.6394 - acc: 0.8000[[1896  187   66 ...,    0    0    0]\n",
      " [   1  601    5 ...,    0    0    0]\n",
      " [ 342  196   66 ...,    0    0    0]\n",
      " ..., \n",
      " [  15 1272   29 ...,    0    0    0]\n",
      " [   1 1606 2590 ...,    0    0    0]\n",
      " [ 553 5541   23 ...,    0    0    0]]\n",
      " 29/200 [===>..........................] - ETA: 78s - loss: 1.6355 - acc: 0.8004[[ 131  522 7535 ...,    0    0    0]\n",
      " [   2   94  144 ...,    0    0    0]\n",
      " [5180    8  717 ...,    0    0    0]\n",
      " ..., \n",
      " [  13  236  477 ...,    0    0    0]\n",
      " [   2  117    4 ...,    0    0    0]\n",
      " [3838    8 6077 ...,    0    0    0]]\n",
      " 30/200 [===>..........................] - ETA: 78s - loss: 1.6214 - acc: 0.8012[[9096 8866    7 ...,    0    0    0]\n",
      " [   2   13 3220 ...,    0    0    0]\n",
      " [   1  145  218 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 3839  737 ...,    0    0    0]\n",
      " [ 119 4410    2 ...,    0    0    0]\n",
      " [3516 1053   33 ...,    0    0    0]]\n",
      " 31/200 [===>..........................] - ETA: 78s - loss: 1.6094 - acc: 0.8021[[ 365    7  326 ...,    0    0    0]\n",
      " [  13  248   85 ...,    0    0    0]\n",
      " [ 116 2185   10 ...,    0    0    0]\n",
      " ..., \n",
      " [  13  811 1415 ...,    0    0    0]\n",
      " [2081    6   57 ...,    0    0    0]\n",
      " [3409   13  969 ...,    0    0    0]]\n",
      " 32/200 [===>..........................] - ETA: 77s - loss: 1.5967 - acc: 0.8030[[   2   13 3238 ...,    0    0    0]\n",
      " [ 514 2246   13 ...,    0    0    0]\n",
      " [  22  282   83 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  161 7867 ...,    0    0    0]\n",
      " [ 603 5303    7 ...,    0    0    0]\n",
      " [ 119   30   28 ...,    0    0    0]]\n",
      " 33/200 [===>..........................] - ETA: 77s - loss: 1.5875 - acc: 0.8037[[  89    7    2 ...,    0    0    0]\n",
      " [1600    8  444 ...,    0    0    0]\n",
      " [ 425    8 2535 ...,    0    0    0]\n",
      " ..., \n",
      " [ 187    4  109 ...,    0    0    0]\n",
      " [  13 8417   13 ...,    0    0    0]\n",
      " [3398 8587    7 ...,    0    0    0]]\n",
      " 34/200 [====>.........................] - ETA: 76s - loss: 1.5758 - acc: 0.8047[[  607   816   878 ...,     0     0     0]\n",
      " [    2    13   905 ...,     0     0     0]\n",
      " [    2   877   172 ...,     0     0     0]\n",
      " ..., \n",
      " [  190  1455 11957 ...,     0     0     0]\n",
      " [ 1792   455     3 ...,     0     0     0]\n",
      " [  131   721   765 ...,     0     0     0]]\n",
      " 35/200 [====>.........................] - ETA: 76s - loss: 1.5697 - acc: 0.8050[[  69 1710   13 ...,    0    0    0]\n",
      " [2486   13   13 ...,    0    0    0]\n",
      " [ 185  102   67 ...,    0    0    0]\n",
      " ..., \n",
      " [2523  398 4359 ...,    0    0    0]\n",
      " [1431  450   13 ...,    0    0    0]\n",
      " [  13  199 1448 ...,    0    0    0]]\n",
      " 36/200 [====>.........................] - ETA: 75s - loss: 1.5590 - acc: 0.8058[[ 131 1194  295 ...,    0    0    0]\n",
      " [ 365    7  326 ...,    0    0    0]\n",
      " [2237 4702 1748 ...,    0    0    0]\n",
      " ..., \n",
      " [ 389  209 6340 ...,    0    0    0]\n",
      " [3207  128   20 ...,    0    0    0]\n",
      " [  13   13 1465 ...,    0    0    0]]\n",
      " 37/200 [====>.........................] - ETA: 75s - loss: 1.5523 - acc: 0.8063[[ 425    7  169 ...,    0    0    0]\n",
      " [8008  565  444 ...,    0    0    0]\n",
      " [ 978 4090    7 ...,    0    0    0]\n",
      " ..., \n",
      " [ 905  162 2004 ...,    0    0    0]\n",
      " [5171   66 1869 ...,    0    0    0]\n",
      " [   2  943  258 ...,    0    0    0]]\n",
      " 38/200 [====>.........................] - ETA: 74s - loss: 1.5465 - acc: 0.8066[[ 1848    11  1632 ...,     0     0     0]\n",
      " [ 1625   266    13 ...,     0     0     0]\n",
      " [   26    65  1709 ...,     0     0     0]\n",
      " ..., \n",
      " [  131  1194   295 ...,     0     0     0]\n",
      " [  893 10455  2073 ...,     0     0     0]\n",
      " [  154    66     6 ...,     0     0     0]]\n",
      " 39/200 [====>.........................] - ETA: 74s - loss: 1.5427 - acc: 0.8068[[ 155   29    1 ...,    0    0    0]\n",
      " [  13   13    5 ...,    0    0    0]\n",
      " [  13 8751   23 ...,    0    0    0]\n",
      " ..., \n",
      " [9174 7457 3359 ...,    0    0    0]\n",
      " [1717   13  100 ...,    0    0    0]\n",
      " [1558  455    3 ...,    0    0    0]]\n",
      " 40/200 [=====>........................] - ETA: 73s - loss: 1.5458 - acc: 0.8065[[  913     7  2134 ...,     0     0     0]\n",
      " [   13    68   871 ...,     0     0     0]\n",
      " [    1   221   230 ...,     0     0     0]\n",
      " ..., \n",
      " [   89     7     2 ...,     0     0     0]\n",
      " [   13  2459 10892 ...,     0     0     0]\n",
      " [  171    70    60 ...,     0     0     0]]\n",
      " 41/200 [=====>........................] - ETA: 73s - loss: 1.5443 - acc: 0.8069[[5631 5868 1796 ...,    0    0    0]\n",
      " [ 131   69  263 ...,    0    0    0]\n",
      " [5040 1880  204 ...,    0    0    0]\n",
      " ..., \n",
      " [3400    8 6841 ...,    0    0    0]\n",
      " [  15   14   39 ...,    0    0    0]\n",
      " [ 119   30   36 ...,    0    0    0]]\n",
      " 42/200 [=====>........................] - ETA: 72s - loss: 1.5481 - acc: 0.8064[[ 119  616  127 ...,    0    0    0]\n",
      " [   2 5523 3632 ...,    0    0    0]\n",
      " [   1  304 3255 ...,    0    0    0]\n",
      " ..., \n",
      " [ 140  150 4086 ...,    0    0    0]\n",
      " [   1 4874    5 ...,    0    0    0]\n",
      " [  13    9 2370 ...,    0    0    0]]\n",
      " 43/200 [=====>........................] - ETA: 72s - loss: 1.5509 - acc: 0.8061[[ 444   83   40 ...,    0    0    0]\n",
      " [1634   13   13 ...,    0    0    0]\n",
      " [   1  248  252 ...,    0    0    0]\n",
      " ..., \n",
      " [ 291  126 1512 ...,    0    0    0]\n",
      " [   2 4493  167 ...,    0    0    0]\n",
      " [ 501  154   66 ...,    0    0    0]]\n",
      " 44/200 [=====>........................] - ETA: 71s - loss: 1.5530 - acc: 0.8059[[  13  119   21 ...,    0    0    0]\n",
      " [   2  501 5214 ...,    0    0    0]\n",
      " [ 501    6   25 ...,    0    0    0]\n",
      " ..., \n",
      " [  15   14 1676 ...,    0    0    0]\n",
      " [2215  170   86 ...,    0    0    0]\n",
      " [9754 6508  276 ...,    0    0    0]]\n",
      " 45/200 [=====>........................] - ETA: 71s - loss: 1.5556 - acc: 0.8056[[1115 3628   23 ...,    0    0    0]\n",
      " [  70   13   13 ...,    0    0    0]\n",
      " [  34    9    1 ...,    0    0    0]\n",
      " ..., \n",
      " [ 104   21  184 ...,    0    0    0]\n",
      " [  13  199    9 ...,    0    0    0]\n",
      " [ 137  336   18 ...,    0    0    0]]\n",
      " 46/200 [=====>........................] - ETA: 70s - loss: 1.5543 - acc: 0.8058[[  13   13   14 ...,    0    0    0]\n",
      " [   1 1456  310 ...,    0    0    0]\n",
      " [   2  131  883 ...,    0    0    0]\n",
      " ..., \n",
      " [2603    6    1 ...,    0    0    0]\n",
      " [2565    1  482 ...,    0    0    0]\n",
      " [7079 1435    4 ...,    0    0    0]]\n",
      " 47/200 [======>.......................] - ETA: 70s - loss: 1.5582 - acc: 0.8054[[    1    13 10332 ...,     0     0     0]\n",
      " [   42    14     1 ...,     0     0     0]\n",
      " [  149   495    13 ...,     0     0     0]\n",
      " ..., \n",
      " [   34   629    14 ...,     0     0     0]\n",
      " [   89     7     2 ...,     0     0     0]\n",
      " [    1  2013   312 ...,     0     0     0]]\n",
      " 48/200 [======>.......................] - ETA: 70s - loss: 1.5619 - acc: 0.8050[[  245  2713    13 ...,     0     0     0]\n",
      " [   13  8595    14 ...,     0     0     0]\n",
      " [ 2731    34    77 ...,     0     0     0]\n",
      " ..., \n",
      " [   13   104  1108 ...,     0     0     0]\n",
      " [   13   159 10506 ...,     0     0     0]\n",
      " [ 1675  3294     9 ...,     0     0     0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 49/200 [======>.......................] - ETA: 69s - loss: 1.5686 - acc: 0.8043[[ 13 492  12 ...,   0   0   0]\n",
      " [ 48 194 629 ...,   0   0   0]\n",
      " [264   7  53 ...,   0   0   0]\n",
      " ..., \n",
      " [ 13  13  13 ...,   0   0   0]\n",
      " [108  68 253 ...,   0   0   0]\n",
      " [ 13  13 221 ...,   0   0   0]]\n",
      " 50/200 [======>.......................] - ETA: 69s - loss: 1.5762 - acc: 0.8036[[ 1395  8395    14 ...,     0     0     0]\n",
      " [ 2333   610   249 ...,     0     0     0]\n",
      " [  116   350    21 ...,     0     0     0]\n",
      " ..., \n",
      " [ 3599    13   198 ...,     0     0     0]\n",
      " [    2 10742     5 ...,     0     0     0]\n",
      " [ 1332    13     9 ...,     0     0     0]]\n",
      " 51/200 [======>.......................] - ETA: 68s - loss: 1.5761 - acc: 0.8036[[ 281  713   13 ...,    0    0    0]\n",
      " [6628   13    8 ...,    0    0    0]\n",
      " [  10  790 2047 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  177  676 ...,    0    0    0]\n",
      " [ 730   13    1 ...,    0    0    0]\n",
      " [  18  318    9 ...,    0    0    0]]\n",
      " 52/200 [======>.......................] - ETA: 68s - loss: 1.5757 - acc: 0.8038[[   1  576 5200 ...,    0    0    0]\n",
      " [1066  912   23 ...,    0    0    0]\n",
      " [  89   11  184 ...,    0    0    0]\n",
      " ..., \n",
      " [ 234  402  144 ...,    0    0    0]\n",
      " [6839 1112   83 ...,    0    0    0]\n",
      " [ 159 3747    9 ...,    0    0    0]]\n",
      " 53/200 [======>.......................] - ETA: 67s - loss: 1.5784 - acc: 0.8034[[ 746  117    8 ...,    0    0    0]\n",
      " [ 328   13   15 ...,    0    0    0]\n",
      " [  34   61   13 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   13 1846 ...,    0    0    0]\n",
      " [   2  999  144 ...,    0    0    0]\n",
      " [   4    1  204 ...,    0    0    0]]\n",
      " 54/200 [=======>......................] - ETA: 67s - loss: 1.5800 - acc: 0.8032[[  13   26  106 ...,    0    0    0]\n",
      " [   1 2352   86 ...,    0    0    0]\n",
      " [1014   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [  18   69   13 ...,    0    0    0]\n",
      " [ 108   68 1632 ...,    0    0    0]\n",
      " [  89   23   39 ...,    0    0    0]]\n",
      " 55/200 [=======>......................] - ETA: 66s - loss: 1.5791 - acc: 0.8034[[3599   13   13 ...,    0    0    0]\n",
      " [4956   13 1836 ...,    0    0    0]\n",
      " [   1   13 6850 ...,    0    0    0]\n",
      " ..., \n",
      " [ 415    6  210 ...,    0    0    0]\n",
      " [ 193    7   13 ...,    0    0    0]\n",
      " [   1  131  523 ...,    0    0    0]]\n",
      " 56/200 [=======>......................] - ETA: 66s - loss: 1.5779 - acc: 0.8037[[   1 5684 9095 ...,    0    0    0]\n",
      " [2568 5828    9 ...,    0    0    0]\n",
      " [5543 1537 1471 ...,    0    0    0]\n",
      " ..., \n",
      " [   2  259  290 ...,    0    0    0]\n",
      " [  89   23 2497 ...,    0    0    0]\n",
      " [ 104 1629    1 ...,    0    0    0]]\n",
      " 57/200 [=======>......................] - ETA: 65s - loss: 1.5799 - acc: 0.8036[[   1   13 1978 ...,    0    0    0]\n",
      " [ 697 2427  798 ...,    0    0    0]\n",
      " [ 333   13 1334 ...,    0    0    0]\n",
      " ..., \n",
      " [ 805   34   94 ...,    0    0    0]\n",
      " [  15    7   13 ...,    0    0    0]\n",
      " [6306 5860   13 ...,    0    0    0]]\n",
      " 58/200 [=======>......................] - ETA: 65s - loss: 1.5803 - acc: 0.8037[[ 316  583 1622 ...,    0    0    0]\n",
      " [  34   94    7 ...,    0    0    0]\n",
      " [  78 1362   13 ...,    0    0    0]\n",
      " ..., \n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [5163 1765   29 ...,    0    0    0]]\n",
      " 59/200 [=======>......................] - ETA: 64s - loss: 1.5809 - acc: 0.8037[[2574    7   19 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " ..., \n",
      " [6152   69 3226 ...,    0    0    0]\n",
      " [3222   13  163 ...,    0    0    0]\n",
      " [   1   13  191 ...,    0    0    0]]\n",
      " 60/200 [========>.....................] - ETA: 64s - loss: 1.5813 - acc: 0.8037[[ 131  284 2368 ...,    0    0    0]\n",
      " [2065   69 5102 ...,    0    0    0]\n",
      " [ 167   13 3369 ...,    0    0    0]\n",
      " ..., \n",
      " [1324 1657   27 ...,    0    0    0]\n",
      " [ 284  100    1 ...,    0    0    0]\n",
      " [2808 2755  130 ...,    0    0    0]]\n",
      " 61/200 [========>.....................] - ETA: 64s - loss: 1.5820 - acc: 0.8037[[6030   13   12 ...,    0    0    0]\n",
      " [4759   19  324 ...,    0    0    0]\n",
      " [   2   19 3634 ...,    0    0    0]\n",
      " ..., \n",
      " [1434   27 4474 ...,    0    0    0]\n",
      " [   2  852    3 ...,    0    0    0]\n",
      " [   1   19  352 ...,    0    0    0]]\n",
      " 62/200 [========>.....................] - ETA: 63s - loss: 1.5825 - acc: 0.8036[[   1  143    5 ...,    0    0    0]\n",
      " [  55    8 1792 ...,    0    0    0]\n",
      " [   1  132  509 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13 1847 ...,    0    0    0]\n",
      " [   1  469    8 ...,    0    0    0]\n",
      " [ 140  553    8 ...,    0    0    0]]\n",
      " 63/200 [========>.....................] - ETA: 63s - loss: 1.5835 - acc: 0.8035[[ 523 1898  925 ...,    0    0    0]\n",
      " [   2 1569 2114 ...,    0    0    0]\n",
      " [   1 6528  191 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [3050   55  100 ...,    0    0    0]\n",
      " [ 316   55    7 ...,    0    0    0]]\n",
      " 64/200 [========>.....................] - ETA: 62s - loss: 1.5839 - acc: 0.8035[[3258    4 2081 ...,    0    0    0]\n",
      " [   1   47 6189 ...,    0    0    0]\n",
      " [1434    7  161 ...,    0    0    0]\n",
      " ..., \n",
      " [   2  145  608 ...,    0    0    0]\n",
      " [ 561 3076   36 ...,    0    0    0]\n",
      " [   1  220   73 ...,    0    0    0]]\n",
      " 65/200 [========>.....................] - ETA: 62s - loss: 1.5839 - acc: 0.8036[[   1   13   11 ...,    0    0    0]\n",
      " [   2   58   59 ...,    0    0    0]\n",
      " [   1  220   91 ...,    0    0    0]\n",
      " ..., \n",
      " [ 366    6    1 ...,    0    0    0]\n",
      " [ 306 3262   13 ...,    0    0    0]\n",
      " [   1 1363  199 ...,    0    0    0]]\n",
      " 66/200 [========>.....................] - ETA: 61s - loss: 1.5831 - acc: 0.8037[[   58    59    26 ...,     0     0     0]\n",
      " [   58    59    26 ...,     0     0     0]\n",
      " [   41     5  1056 ...,     0     0     0]\n",
      " ..., \n",
      " [   13    13    14 ...,     0     0     0]\n",
      " [ 1248 10206 10206 ...,     0     0     0]\n",
      " [   13     8  5949 ...,     0     0     0]]\n",
      " 67/200 [=========>....................] - ETA: 61s - loss: 1.5833 - acc: 0.8037[[1224   27 3823 ...,    0    0    0]\n",
      " [  58   59  154 ...,    0    0    0]\n",
      " [ 501  154   66 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   13   13 ...,    0    0    0]\n",
      " [  12  296   13 ...,    0    0    0]\n",
      " [1491  102   67 ...,    0    0    0]]\n",
      " 68/200 [=========>....................] - ETA: 60s - loss: 1.5829 - acc: 0.8038[[ 179 1315 4973 ...,    0    0    0]\n",
      " [ 234 4869  112 ...,    0    0    0]\n",
      " [   1  214   23 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  635    5 ...,    0    0    0]\n",
      " [ 342  196   66 ...,    0    0    0]\n",
      " [ 155   29  697 ...,    0    0    0]]\n",
      " 69/200 [=========>....................] - ETA: 60s - loss: 1.5780 - acc: 0.8040[[ 958  998    7 ...,    0    0    0]\n",
      " [2490    9 2492 ...,    0    0    0]\n",
      " [   2 2602    4 ...,    0    0    0]\n",
      " ..., \n",
      " [  26   23  974 ...,    0    0    0]\n",
      " [  56   79    1 ...,    0    0    0]\n",
      " [ 561   11 1913 ...,    0    0    0]]\n",
      " 70/200 [=========>....................] - ETA: 59s - loss: 1.5728 - acc: 0.8043[[ 478    2 1319 ...,    0    0    0]\n",
      " [1935  295 8426 ...,    0    0    0]\n",
      " [1525  326  267 ...,    0    0    0]\n",
      " ..., \n",
      " [ 108   13    9 ...,    0    0    0]\n",
      " [  26   23 7417 ...,    0    0    0]\n",
      " [ 579  217  226 ...,    0    0    0]]\n",
      " 71/200 [=========>....................] - ETA: 59s - loss: 1.5683 - acc: 0.8047[[4458   21  933 ...,    0    0    0]\n",
      " [1248 2508   13 ...,    0    0    0]\n",
      " [  22  405   16 ...,    0    0    0]\n",
      " ..., \n",
      " [  22  405 2244 ...,    0    0    0]\n",
      " [ 166   41  970 ...,    0    0    0]\n",
      " [   1  751 2224 ...,    0    0    0]]\n",
      " 72/200 [=========>....................] - ETA: 59s - loss: 1.5635 - acc: 0.8050[[ 131 2642   13 ...,    0    0    0]\n",
      " [  13   13  247 ...,    0    0    0]\n",
      " [   2  146   11 ...,    0    0    0]\n",
      " ..., \n",
      " [3689 3693   13 ...,    0    0    0]\n",
      " [ 500    7 1791 ...,    0    0    0]\n",
      " [ 374    5   13 ...,    0    0    0]]\n",
      " 73/200 [=========>....................] - ETA: 58s - loss: 1.5598 - acc: 0.8054[[ 912    5    1 ...,    0    0    0]\n",
      " [2036  462  470 ...,    0    0    0]\n",
      " [1171 5423   13 ...,    0    0    0]\n",
      " ..., \n",
      " [8266  694  131 ...,    0    0    0]\n",
      " [   2   13 7637 ...,    0    0    0]\n",
      " [ 582 1927 1531 ...,    0    0    0]]\n",
      " 74/200 [==========>...................] - ETA: 58s - loss: 1.5555 - acc: 0.8056[[3213 4089 1732 ...,    0    0    0]\n",
      " [ 390   13 8287 ...,    0    0    0]\n",
      " [ 246  190   10 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 1152 2403 ...,    0    0    0]\n",
      " [  87  632    9 ...,    0    0    0]\n",
      " [   1  474  429 ...,    0    0    0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 75/200 [==========>...................] - ETA: 57s - loss: 1.5523 - acc: 0.8059[[ 186   11   45 ...,    0    0    0]\n",
      " [  13 3488  521 ...,    0    0    0]\n",
      " [3396   13   49 ...,    0    0    0]\n",
      " ..., \n",
      " [  10  234 4098 ...,    0    0    0]\n",
      " [ 232  627    8 ...,    0    0    0]\n",
      " [3491  119  157 ...,    0    0    0]]\n",
      " 76/200 [==========>...................] - ETA: 57s - loss: 1.5488 - acc: 0.8062[[   73   196   441 ...,     0     0     0]\n",
      " [11981  4113    27 ...,     0     0     0]\n",
      " [  380     7   322 ...,     0     0     0]\n",
      " ..., \n",
      " [ 5138  6683    83 ...,     0     0     0]\n",
      " [  185   854     5 ...,     0     0     0]\n",
      " [ 2746  7951  9616 ...,     0     0     0]]\n",
      " 77/200 [==========>...................] - ETA: 56s - loss: 1.5455 - acc: 0.8063[[ 140  369 6301 ...,    0    0    0]\n",
      " [  42  471   39 ...,    0    0    0]\n",
      " [3007  157    2 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  580  473 ...,    0    0    0]\n",
      " [ 456  970 8511 ...,    0    0    0]\n",
      " [1046  217 2808 ...,    0    0    0]]\n",
      " 78/200 [==========>...................] - ETA: 56s - loss: 1.5429 - acc: 0.8065[[   2  287 7391 ...,    0    0    0]\n",
      " [1446   13    9 ...,    0    0    0]\n",
      " [   2  146 1214 ...,    0    0    0]\n",
      " ..., \n",
      " [  10    2   61 ...,    0    0    0]\n",
      " [   1  717  117 ...,    0    0    0]\n",
      " [   4   13   13 ...,    0    0    0]]\n",
      " 79/200 [==========>...................] - ETA: 55s - loss: 1.5409 - acc: 0.8066[[ 131  381  228 ...,    0    0    0]\n",
      " [1562 4241   14 ...,    0    0    0]\n",
      " [  13   21   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 284    7  274 ...,    0    0    0]\n",
      " [   2  219  734 ...,    0    0    0]\n",
      " [ 623  631   24 ...,    0    0    0]]\n",
      " 80/200 [===========>..................] - ETA: 55s - loss: 1.5420 - acc: 0.8065[[  108    68   410 ...,     0     0     0]\n",
      " [ 3928   600 11308 ...,     0     0     0]\n",
      " [  492    13     5 ...,     0     0     0]\n",
      " ..., \n",
      " [   19  1620     6 ...,     0     0     0]\n",
      " [ 8181    63    56 ...,     0     0     0]\n",
      " [10148 10148   231 ...,     0     0     0]]\n",
      " 81/200 [===========>..................] - ETA: 54s - loss: 1.5423 - acc: 0.8066[[ 131 1767  332 ...,    0    0    0]\n",
      " [   6    1 2532 ...,    0    0    0]\n",
      " [1381  147  407 ...,    0    0    0]\n",
      " ..., \n",
      " [ 109    7 1276 ...,    0    0    0]\n",
      " [   2   13  613 ...,    0    0    0]\n",
      " [1230  951    4 ...,    0    0    0]]\n",
      " 82/200 [===========>..................] - ETA: 54s - loss: 1.5447 - acc: 0.8063[[ 131  121 3113 ...,    0    0    0]\n",
      " [ 623   21 7905 ...,    0    0    0]\n",
      " [   1  785    9 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13  203 ...,    0    0    0]\n",
      " [   2  146 1129 ...,    0    0    0]\n",
      " [  10    2 1090 ...,    0    0    0]]\n",
      " 83/200 [===========>..................] - ETA: 53s - loss: 1.5452 - acc: 0.8063[[   1   13   91 ...,    0    0    0]\n",
      " [   1  199 4208 ...,    0    0    0]\n",
      " [  58   59  187 ...,    0    0    0]\n",
      " ..., \n",
      " [ 495   32    2 ...,    0    0    0]\n",
      " [   2   13  734 ...,    0    0    0]\n",
      " [1573 6341 5974 ...,    0    0    0]]\n",
      " 84/200 [===========>..................] - ETA: 53s - loss: 1.5473 - acc: 0.8060[[   1  998 3979 ...,    0    0    0]\n",
      " [ 263  267   13 ...,    0    0    0]\n",
      " [1247    7   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 650   13  365 ...,    0    0    0]\n",
      " [  34    1   61 ...,    0    0    0]\n",
      " [3819    7  780 ...,    0    0    0]]\n",
      " 85/200 [===========>..................] - ETA: 52s - loss: 1.5497 - acc: 0.8058[[   2  551  861 ...,    0    0    0]\n",
      " [1675   13  192 ...,    0    0    0]\n",
      " [ 293 1222 2501 ...,    0    0    0]\n",
      " ..., \n",
      " [ 344  117   13 ...,    0    0    0]\n",
      " [1004  421 2149 ...,    0    0    0]\n",
      " [1761   23  210 ...,    0    0    0]]\n",
      " 86/200 [===========>..................] - ETA: 52s - loss: 1.5493 - acc: 0.8059[[ 300   23  400 ...,    0    0    0]\n",
      " [  15    9 6069 ...,    0    0    0]\n",
      " [3978  157    1 ...,    0    0    0]\n",
      " ..., \n",
      " [3100   15    9 ...,    0    0    0]\n",
      " [ 348 2320 5144 ...,    0    0    0]\n",
      " [  13   13 3164 ...,    0    0    0]]\n",
      " 87/200 [============>.................] - ETA: 51s - loss: 1.5505 - acc: 0.8057[[   49   164   816 ...,     0     0     0]\n",
      " [  301   934  8133 ...,     0     0     0]\n",
      " [11585   112     5 ...,     0     0     0]\n",
      " ..., \n",
      " [    1    19    13 ...,     0     0     0]\n",
      " [   13     6  3737 ...,     0     0     0]\n",
      " [11163    13  1243 ...,     0     0     0]]\n",
      " 88/200 [============>.................] - ETA: 51s - loss: 1.5531 - acc: 0.8055[[  15   11   45 ...,    0    0    0]\n",
      " [ 184  810   29 ...,    0    0    0]\n",
      " [  89    7   22 ...,    0    0    0]\n",
      " ..., \n",
      " [1925 1207 2354 ...,    0    0    0]\n",
      " [  10    1  345 ...,    0    0    0]\n",
      " [ 108   68  410 ...,    0    0    0]]\n",
      " 89/200 [============>.................] - ETA: 50s - loss: 1.5572 - acc: 0.8050[[2206   13 2298 ...,    0    0    0]\n",
      " [  10  383    2 ...,    0    0    0]\n",
      " [9208   67 9798 ...,    0    0    0]\n",
      " ..., \n",
      " [  68   21    3 ...,    0    0    0]\n",
      " [  13  744    3 ...,    0    0    0]\n",
      " [  89   27  317 ...,    0    0    0]]\n",
      " 90/200 [============>.................] - ETA: 50s - loss: 1.5590 - acc: 0.8048[[1892 7168    4 ...,    0    0    0]\n",
      " [3006 2446   14 ...,    0    0    0]\n",
      " [1170 2169 2080 ...,    0    0    0]\n",
      " ..., \n",
      " [ 726    7  191 ...,    0    0    0]\n",
      " [1231   70   68 ...,    0    0    0]\n",
      " [   2  293 1244 ...,    0    0    0]]\n",
      " 91/200 [============>.................] - ETA: 49s - loss: 1.5627 - acc: 0.8044[[   13 10823     7 ...,     0     0     0]\n",
      " [   13   435  7769 ...,     0     0     0]\n",
      " [   13    13     9 ...,     0     0     0]\n",
      " ..., \n",
      " [    2  1745  3196 ...,     0     0     0]\n",
      " [ 8017  1395     9 ...,     0     0     0]\n",
      " [    2    13   796 ...,     0     0     0]]\n",
      " 92/200 [============>.................] - ETA: 49s - loss: 1.5645 - acc: 0.8042[[   19   352     8 ...,     0     0     0]\n",
      " [  187     5  4712 ...,     0     0     0]\n",
      " [ 3222  7637    13 ...,     0     0     0]\n",
      " ..., \n",
      " [  500     7 10824 ...,     0     0     0]\n",
      " [   69   297    13 ...,     0     0     0]\n",
      " [ 1152  4028   252 ...,     0     0     0]]\n",
      " 93/200 [============>.................] - ETA: 49s - loss: 1.5628 - acc: 0.8045[[8602    9 2859 ...,    0    0    0]\n",
      " [   2 6397    3 ...,    0    0    0]\n",
      " [3252   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 325 1063 1998 ...,    0    0    0]\n",
      " [   1  126 2437 ...,    0    0    0]\n",
      " [  13   13   14 ...,    0    0    0]]\n",
      " 94/200 [=============>................] - ETA: 48s - loss: 1.5657 - acc: 0.8042[[   1   99 4711 ...,    0    0    0]\n",
      " [ 154   66    6 ...,    0    0    0]\n",
      " [ 154   66    6 ...,    0    0    0]\n",
      " ..., \n",
      " [2288   13  105 ...,    0    0    0]\n",
      " [  15  748   90 ...,    0    0    0]\n",
      " [ 356  767  811 ...,    0    0    0]]\n",
      " 95/200 [=============>................] - ETA: 48s - loss: 1.5667 - acc: 0.8041[[    2   222 10613 ...,     0     0     0]\n",
      " [   10    63    13 ...,     0     0     0]\n",
      " [    1    13    32 ...,     0     0     0]\n",
      " ..., \n",
      " [   13    13   298 ...,     0     0     0]\n",
      " [   19   120   438 ...,     0     0     0]\n",
      " [   34    61  6449 ...,     0     0     0]]\n",
      " 96/200 [=============>................] - ETA: 47s - loss: 1.5667 - acc: 0.8041[[  304  3255   103 ...,     0     0     0]\n",
      " [ 2379  7422     8 ...,     0     0     0]\n",
      " [10485 10333   100 ...,     0     0     0]\n",
      " ..., \n",
      " [    4    13   816 ...,     0     0     0]\n",
      " [   13     9    48 ...,     0     0     0]\n",
      " [  890  2211   114 ...,     0     0     0]]\n",
      " 97/200 [=============>................] - ETA: 47s - loss: 1.5663 - acc: 0.8042[[5267 2367   14 ...,    0    0    0]\n",
      " [ 108  104 2357 ...,    0    0    0]\n",
      " [   4    1  894 ...,    0    0    0]\n",
      " ..., \n",
      " [ 155  301  338 ...,    0    0    0]\n",
      " [ 377 4559   13 ...,    0    0    0]\n",
      " [   4  432   68 ...,    0    0    0]]\n",
      " 98/200 [=============>................] - ETA: 46s - loss: 1.5667 - acc: 0.8042[[  18    1 1558 ...,    0    0    0]\n",
      " [ 986 5031  703 ...,    0    0    0]\n",
      " [3001 6530 5388 ...,    0    0    0]\n",
      " ..., \n",
      " [1289   13    2 ...,    0    0    0]\n",
      " [ 406   13 8740 ...,    0    0    0]\n",
      " [   1  387 3348 ...,    0    0    0]]\n",
      " 99/200 [=============>................] - ETA: 46s - loss: 1.5672 - acc: 0.8042[[ 3470    13   626 ...,     0     0     0]\n",
      " [ 7322     9  1842 ...,     0     0     0]\n",
      " [  483  4428    10 ...,     0     0     0]\n",
      " ..., \n",
      " [   13   391     5 ...,     0     0     0]\n",
      " [ 7029  2222    81 ...,     0     0     0]\n",
      " [10683  9535    11 ...,     0     0     0]]\n",
      "100/200 [==============>...............] - ETA: 45s - loss: 1.5691 - acc: 0.8040[[3822 3881    3 ...,    0    0    0]\n",
      " [ 103  280   13 ...,    0    0    0]\n",
      " [ 280 4960   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 670  559  114 ...,    0    0    0]\n",
      " [  47 1401 3981 ...,    0    0    0]\n",
      " [  34   74   13 ...,    0    0    0]]\n",
      "101/200 [==============>...............] - ETA: 45s - loss: 1.5693 - acc: 0.8040[[   22  2086   255 ...,     0     0     0]\n",
      " [ 1360   585    13 ...,     0     0     0]\n",
      " [  514  2246    11 ...,     0     0     0]\n",
      " ..., \n",
      " [10878    13   219 ...,     0     0     0]\n",
      " [   12   366    13 ...,     0     0     0]\n",
      " [  535    15     7 ...,     0     0     0]]\n",
      "102/200 [==============>...............] - ETA: 44s - loss: 1.5704 - acc: 0.8040[[5707   13  141 ...,    0    0    0]\n",
      " [  70 1807   13 ...,    0    0    0]\n",
      " [  13   13  114 ...,    0    0    0]\n",
      " ..., \n",
      " [1577   13   11 ...,    0    0    0]\n",
      " [1562   13 1191 ...,    0    0    0]\n",
      " [6551   11   81 ...,    0    0    0]]\n",
      "103/200 [==============>...............] - ETA: 44s - loss: 1.5723 - acc: 0.8037[[   4   13 2514 ...,    0    0    0]\n",
      " [  34   61   13 ...,    0    0    0]\n",
      " [  69  263    9 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 1033   67 ...,    0    0    0]\n",
      " [  32  348    1 ...,    0    0    0]\n",
      " [  68  128   39 ...,    0    0    0]]\n",
      "104/200 [==============>...............] - ETA: 43s - loss: 1.5745 - acc: 0.8035[[ 558    5 2055 ...,    0    0    0]\n",
      " [  10   13    8 ...,    0    0    0]\n",
      " [  15  448   29 ...,    0    0    0]\n",
      " ..., \n",
      " [6422   13  192 ...,    0    0    0]\n",
      " [2495    5   13 ...,    0    0    0]\n",
      " [   1 2407    5 ...,    0    0    0]]\n",
      "105/200 [==============>...............] - ETA: 43s - loss: 1.5771 - acc: 0.8032[[ 297   13  263 ...,    0    0    0]\n",
      " [  13  104   14 ...,    0    0    0]\n",
      " [  13  448    3 ...,    0    0    0]\n",
      " ..., \n",
      " [  15    7   48 ...,    0    0    0]\n",
      " [  89   23  177 ...,    0    0    0]\n",
      " [   2 1099   13 ...,    0    0    0]]\n",
      "106/200 [==============>...............] - ETA: 43s - loss: 1.5777 - acc: 0.8032[[ 347  110 7274 ...,    0    0    0]\n",
      " [ 432   13   13 ...,    0    0    0]\n",
      " [  80 2742 2468 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  679  527 ...,    0    0    0]\n",
      " [  15    7  282 ...,    0    0    0]\n",
      " [  13   26  106 ...,    0    0    0]]\n",
      "107/200 [===============>..............] - ETA: 42s - loss: 1.5794 - acc: 0.8030[[1563   13 1393 ...,    0    0    0]\n",
      " [ 104  898   99 ...,    0    0    0]\n",
      " [3432  605   13 ...,    0    0    0]\n",
      " ..., \n",
      " [6448   13   14 ...,    0    0    0]\n",
      " [   1 6322    5 ...,    0    0    0]\n",
      " [ 341   13  245 ...,    0    0    0]]\n",
      "108/200 [===============>..............] - ETA: 42s - loss: 1.5796 - acc: 0.8030[[ 380    7 4121 ...,    0    0    0]\n",
      " [ 140  609   26 ...,    0    0    0]\n",
      " [ 127  179  851 ...,    0    0    0]\n",
      " ..., \n",
      " [ 140  609   26 ...,    0    0    0]\n",
      " [ 355 4849   11 ...,    0    0    0]\n",
      " [7486   13    5 ...,    0    0    0]]\n",
      "109/200 [===============>..............] - ETA: 41s - loss: 1.5792 - acc: 0.8031[[   2 1261 2099 ...,    0    0    0]\n",
      " [   2  121 1421 ...,    0    0    0]\n",
      " [ 726  217  255 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [ 176   66 2512 ...,    0    0    0]\n",
      " [   1  468 2949 ...,    0    0    0]]\n",
      "110/200 [===============>..............] - ETA: 41s - loss: 1.5799 - acc: 0.8031[[ 38 481 176 ...,   0   0   0]\n",
      " [ 13  26 441 ...,   0   0   0]\n",
      " [187  66   6 ...,   0   0   0]\n",
      " ..., \n",
      " [284   7  26 ...,   0   0   0]\n",
      " [  1  13  91 ...,   0   0   0]\n",
      " [  1  13  91 ...,   0   0   0]]\n",
      "111/200 [===============>..............] - ETA: 40s - loss: 1.5806 - acc: 0.8030[[   1   13   91 ...,    0    0    0]\n",
      " [ 140  609   26 ...,    0    0    0]\n",
      " [   1  220   73 ...,    0    0    0]\n",
      " ..., \n",
      " [ 154   66 1215 ...,    0    0    0]\n",
      " [   2  179  680 ...,    0    0    0]\n",
      " [ 390   13   11 ...,    0    0    0]]\n",
      "112/200 [===============>..............] - ETA: 40s - loss: 1.5800 - acc: 0.8031[[  456  1542   662 ...,     0     0     0]\n",
      " [  131   547  1438 ...,     0     0     0]\n",
      " [ 2351    10     1 ...,     0     0     0]\n",
      " ..., \n",
      " [    1    13  3217 ...,     0     0     0]\n",
      " [   15    14 11683 ...,     0     0     0]\n",
      " [    1  1356     5 ...,     0     0     0]]\n",
      "113/200 [===============>..............] - ETA: 39s - loss: 1.5798 - acc: 0.8032[[  13   13   13 ...,    0    0    0]\n",
      " [ 751  103 4071 ...,    0    0    0]\n",
      " [  10 2939 3751 ...,    0    0    0]\n",
      " ..., \n",
      " [ 488    7  324 ...,    0    0    0]\n",
      " [  64   82   13 ...,    0    0    0]\n",
      " [   1  412 1011 ...,    0    0    0]]\n",
      "114/200 [================>.............] - ETA: 39s - loss: 1.5796 - acc: 0.8032[[   1 1660 2134 ...,    0    0    0]\n",
      " [  13  956 4275 ...,    0    0    0]\n",
      " [ 111    4    1 ...,    0    0    0]\n",
      " ..., \n",
      " [3289   30   24 ...,    0    0    0]\n",
      " [2095  745 2520 ...,    0    0    0]\n",
      " [5171   66  115 ...,    0    0    0]]\n",
      "115/200 [================>.............] - ETA: 38s - loss: 1.5794 - acc: 0.8033[[    1   736  1616 ...,     0     0     0]\n",
      " [ 4701 10213     9 ...,     0     0     0]\n",
      " [    2   866  3775 ...,     0     0     0]\n",
      " ..., \n",
      " [   55     6    57 ...,     0     0     0]\n",
      " [    2  1649  1715 ...,     0     0     0]\n",
      " [   19   120    13 ...,     0     0     0]]\n",
      "116/200 [================>.............] - ETA: 38s - loss: 1.5798 - acc: 0.8033[[ 585 9701 6296 ...,    0    0    0]\n",
      " [3626 2067   13 ...,    0    0    0]\n",
      " [   1   91  106 ...,    0    0    0]\n",
      " ..., \n",
      " [  66    6    1 ...,    0    0    0]\n",
      " [5527 5689    9 ...,    0    0    0]\n",
      " [   1   47   49 ...,    0    0    0]]\n",
      "117/200 [================>.............] - ETA: 37s - loss: 1.5795 - acc: 0.8034[[ 1635 11261     8 ...,     0     0     0]\n",
      " [    1  3005  1719 ...,     0     0     0]\n",
      " [  109    26   115 ...,     0     0     0]\n",
      " ..., \n",
      " [  109    26   113 ...,     0     0     0]\n",
      " [   90   194  1044 ...,     0     0     0]\n",
      " [ 1287    13    81 ...,     0     0     0]]\n",
      "118/200 [================>.............] - ETA: 37s - loss: 1.5793 - acc: 0.8034[[2425    8   55 ...,    0    0    0]\n",
      " [2309 3927   11 ...,    0    0    0]\n",
      " [ 173 4190   10 ...,    0    0    0]\n",
      " ..., \n",
      " [1822   13    9 ...,    0    0    0]\n",
      " [3061   13   13 ...,    0    0    0]\n",
      " [   1  261   13 ...,    0    0    0]]\n",
      "119/200 [================>.............] - ETA: 37s - loss: 1.5765 - acc: 0.8037[[   2  904  405 ...,    0    0    0]\n",
      " [3062  196 9581 ...,    0    0    0]\n",
      " [  13   13   27 ...,    0    0    0]\n",
      " ..., \n",
      " [ 681  187  399 ...,    0    0    0]\n",
      " [   1  126  198 ...,    0    0    0]\n",
      " [ 131  456 1127 ...,    0    0    0]]\n",
      "120/200 [=================>............] - ETA: 36s - loss: 1.5737 - acc: 0.8039[[ 276  178   13 ...,    0    0    0]\n",
      " [ 154   66   67 ...,    0    0    0]\n",
      " [  13    1 3430 ...,    0    0    0]\n",
      " ..., \n",
      " [6341 5974    7 ...,    0    0    0]\n",
      " [   1  263 1691 ...,    0    0    0]\n",
      " [   2   37  144 ...,    0    0    0]]\n",
      "121/200 [=================>............] - ETA: 36s - loss: 1.5705 - acc: 0.8041[[  15    7  166 ...,    0    0    0]\n",
      " [1811  217  514 ...,    0    0    0]\n",
      " [ 267  157   92 ...,    0    0    0]\n",
      " ..., \n",
      " [3718   29  337 ...,    0    0    0]\n",
      " [   4    2  188 ...,    0    0    0]\n",
      " [  54    2   94 ...,    0    0    0]]\n",
      "122/200 [=================>............] - ETA: 35s - loss: 1.5684 - acc: 0.8043[[   2 8865  819 ...,    0    0    0]\n",
      " [  18   15 3368 ...,    0    0    0]\n",
      " [ 302   11  319 ...,    0    0    0]\n",
      " ..., \n",
      " [   4    2   13 ...,    0    0    0]\n",
      " [  13 9772   13 ...,    0    0    0]\n",
      " [ 592 8142    1 ...,    0    0    0]]\n",
      "123/200 [=================>............] - ETA: 35s - loss: 1.5679 - acc: 0.8044[[  13   13   68 ...,    0    0    0]\n",
      " [  10  888   13 ...,    0    0    0]\n",
      " [9482  486  240 ...,    0    0    0]\n",
      " ..., \n",
      " [ 108  210 1468 ...,    0    0    0]\n",
      " [2797 4459    9 ...,    0    0    0]\n",
      " [1068 4127  247 ...,    0    0    0]]\n",
      "124/200 [=================>............] - ETA: 34s - loss: 1.5696 - acc: 0.8042[[8163 8613 5159 ...,    0    0    0]\n",
      " [3484  610   86 ...,    0    0    0]\n",
      " [  18    2  153 ...,    0    0    0]\n",
      " ..., \n",
      " [  10    2 3037 ...,    0    0    0]\n",
      " [1068 9485  192 ...,    0    0    0]\n",
      " [3079 3363    9 ...,    0    0    0]]\n",
      "125/200 [=================>............] - ETA: 34s - loss: 1.5699 - acc: 0.8042[[ 535 1398   13 ...,    0    0    0]\n",
      " [ 300   21    1 ...,    0    0    0]\n",
      " [ 108   68   23 ...,    0    0    0]\n",
      " ..., \n",
      " [   8  155   10 ...,    0    0    0]\n",
      " [ 535    1 3423 ...,    0    0    0]\n",
      " [4571 2417  703 ...,    0    0    0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/200 [=================>............] - ETA: 33s - loss: 1.5699 - acc: 0.8042[[ 1740  1635    13 ...,     0     0     0]\n",
      " [ 1019   747 10354 ...,     0     0     0]\n",
      " [   89    27    20 ...,     0     0     0]\n",
      " ..., \n",
      " [   80  2199    13 ...,     0     0     0]\n",
      " [    1  3089    23 ...,     0     0     0]\n",
      " [    4     1   264 ...,     0     0     0]]\n",
      "127/200 [==================>...........] - ETA: 33s - loss: 1.5703 - acc: 0.8041[[  93  724   90 ...,    0    0    0]\n",
      " [2309 3927  684 ...,    0    0    0]\n",
      " [   2 2437    5 ...,    0    0    0]\n",
      " ..., \n",
      " [ 174  446   13 ...,    0    0    0]\n",
      " [5338 4002    7 ...,    0    0    0]\n",
      " [   1   25 3212 ...,    0    0    0]]\n",
      "128/200 [==================>...........] - ETA: 32s - loss: 1.5719 - acc: 0.8039[[  13 8440  523 ...,    0    0    0]\n",
      " [ 763 6237 1934 ...,    0    0    0]\n",
      " [ 203 1646   79 ...,    0    0    0]\n",
      " ..., \n",
      " [  12   13   13 ...,    0    0    0]\n",
      " [ 730   13 1846 ...,    0    0    0]\n",
      " [ 104  114   48 ...,    0    0    0]]\n",
      "129/200 [==================>...........] - ETA: 32s - loss: 1.5739 - acc: 0.8037[[  89    7   22 ...,    0    0    0]\n",
      " [  15    7   48 ...,    0    0    0]\n",
      " [  13   26  115 ...,    0    0    0]\n",
      " ..., \n",
      " [ 406    7 1265 ...,    0    0    0]\n",
      " [ 770  299    5 ...,    0    0    0]\n",
      " [  78   94   13 ...,    0    0    0]]\n",
      "130/200 [==================>...........] - ETA: 32s - loss: 1.5726 - acc: 0.8039[[  13   63  144 ...,    0    0    0]\n",
      " [  15    9   80 ...,    0    0    0]\n",
      " [   1  167  191 ...,    0    0    0]\n",
      " ..., \n",
      " [   3   20 1560 ...,    0    0    0]\n",
      " [   1 1274  276 ...,    0    0    0]\n",
      " [  13  114  155 ...,    0    0    0]]\n",
      "131/200 [==================>...........] - ETA: 31s - loss: 1.5742 - acc: 0.8037[[   70    13 11859 ...,     0     0     0]\n",
      " [   80    41    14 ...,     0     0     0]\n",
      " [  232  3054   384 ...,     0     0     0]\n",
      " ..., \n",
      " [ 1931  1772    29 ...,     0     0     0]\n",
      " [ 1382  1963    11 ...,     0     0     0]\n",
      " [  698  5800  1429 ...,     0     0     0]]\n",
      "132/200 [==================>...........] - ETA: 31s - loss: 1.5740 - acc: 0.8038[[   1  177   70 ...,    0    0    0]\n",
      " [  41  330  674 ...,    0    0    0]\n",
      " [ 104   14  233 ...,    0    0    0]\n",
      " ..., \n",
      " [ 194   63  144 ...,    0    0    0]\n",
      " [  13  104 1619 ...,    0    0    0]\n",
      " [ 245 1225   13 ...,    0    0    0]]\n",
      "133/200 [==================>...........] - ETA: 30s - loss: 1.5731 - acc: 0.8039[[1226   97   13 ...,    0    0    0]\n",
      " [1233 3058   25 ...,    0    0    0]\n",
      " [  10  402   13 ...,    0    0    0]\n",
      " ..., \n",
      " [  15   14    2 ...,    0    0    0]\n",
      " [1401 8027   81 ...,    0    0    0]\n",
      " [  13 1049   13 ...,    0    0    0]]\n",
      "134/200 [===================>..........] - ETA: 30s - loss: 1.5734 - acc: 0.8039[[ 503    9  305 ...,    0    0    0]\n",
      " [1629    1 1798 ...,    0    0    0]\n",
      " [ 565    1  189 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [ 547   69 4400 ...,    0    0    0]\n",
      " [   1 1276 3182 ...,    0    0    0]]\n",
      "135/200 [===================>..........] - ETA: 29s - loss: 1.5738 - acc: 0.8039[[3158  217 1453 ...,    0    0    0]\n",
      " [   1  261 2012 ...,    0    0    0]\n",
      " [  13  167  523 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [ 167 6286 4386 ...,    0    0    0]\n",
      " [   1   13 3414 ...,    0    0    0]]\n",
      "136/200 [===================>..........] - ETA: 29s - loss: 1.5731 - acc: 0.8040[[   1 2230  199 ...,    0    0    0]\n",
      " [   1  220   73 ...,    0    0    0]\n",
      " [2553  594  205 ...,    0    0    0]\n",
      " ..., \n",
      " [  55   27 2904 ...,    0    0    0]\n",
      " [ 274   55    7 ...,    0    0    0]\n",
      " [   1   13   91 ...,    0    0    0]]\n",
      "137/200 [===================>..........] - ETA: 28s - loss: 1.5727 - acc: 0.8041[[   1   13   91 ...,    0    0    0]\n",
      " [ 481   66  106 ...,    0    0    0]\n",
      " [ 456  121   26 ...,    0    0    0]\n",
      " ..., \n",
      " [  13    3 7124 ...,    0    0    0]\n",
      " [ 599 1780   23 ...,    0    0    0]\n",
      " [ 422  755  312 ...,    0    0    0]]\n",
      "138/200 [===================>..........] - ETA: 28s - loss: 1.5724 - acc: 0.8041[[2032  610  168 ...,    0    0    0]\n",
      " [ 232 1991    4 ...,    0    0    0]\n",
      " [  49  102  112 ...,    0    0    0]\n",
      " ..., \n",
      " [ 150 2695  947 ...,    0    0    0]\n",
      " [   2 3709   13 ...,    0    0    0]\n",
      " [  92 2036  462 ...,    0    0    0]]\n",
      "139/200 [===================>..........] - ETA: 27s - loss: 1.5725 - acc: 0.8041[[5401 3039   13 ...,    0    0    0]\n",
      " [  34    9   41 ...,    0    0    0]\n",
      " [1082  295  353 ...,    0    0    0]\n",
      " ..., \n",
      " [4748 2617  141 ...,    0    0    0]\n",
      " [  10  697 1295 ...,    0    0    0]\n",
      " [   1  547 6865 ...,    0    0    0]]\n",
      "140/200 [====================>.........] - ETA: 27s - loss: 1.5727 - acc: 0.8041[[  37   56   37 ...,    0    0    0]\n",
      " [ 880  903   92 ...,    0    0    0]\n",
      " [4008   43 3511 ...,    0    0    0]\n",
      " ..., \n",
      " [ 347   61    2 ...,    0    0    0]\n",
      " [ 654  145   11 ...,    0    0    0]\n",
      " [ 456  119   21 ...,    0    0    0]]\n",
      "141/200 [====================>.........] - ETA: 27s - loss: 1.5731 - acc: 0.8041[[   4    1 3064 ...,    0    0    0]\n",
      " [  12 5230   13 ...,    0    0    0]\n",
      " [ 246   11 4044 ...,    0    0    0]\n",
      " ..., \n",
      " [  13    4 1453 ...,    0    0    0]\n",
      " [1109  332 8047 ...,    0    0    0]\n",
      " [  13 9504 5172 ...,    0    0    0]]\n",
      "142/200 [====================>.........] - ETA: 26s - loss: 1.5729 - acc: 0.8041[[ 685   38   62 ...,    0    0    0]\n",
      " [ 913    7 3013 ...,    0    0    0]\n",
      " [ 224    7 4494 ...,    0    0    0]\n",
      " ..., \n",
      " [ 416   13    1 ...,    0    0    0]\n",
      " [3350 2858    9 ...,    0    0    0]\n",
      " [   1  682  189 ...,    0    0    0]]\n",
      "143/200 [====================>.........] - ETA: 26s - loss: 1.5730 - acc: 0.8042[[ 1149  5222  1429 ...,     0     0     0]\n",
      " [   99   881  2396 ...,     0     0     0]\n",
      " [  726   419     3 ...,     0     0     0]\n",
      " ..., \n",
      " [    2  2011    16 ...,     0     0     0]\n",
      " [  967   130  3006 ...,     0     0     0]\n",
      " [10699    11   130 ...,     0     0     0]]\n",
      "144/200 [====================>.........] - ETA: 25s - loss: 1.5731 - acc: 0.8042[[   2   13  405 ...,    0    0    0]\n",
      " [   1  221  230 ...,    0    0    0]\n",
      " [3847 8196    3 ...,    0    0    0]\n",
      " ..., \n",
      " [   2  361    5 ...,    0    0    0]\n",
      " [  48  171    1 ...,    0    0    0]\n",
      " [  10  116  203 ...,    0    0    0]]\n",
      "145/200 [====================>.........] - ETA: 25s - loss: 1.5714 - acc: 0.8043[[ 150 8632  390 ...,    0    0    0]\n",
      " [1469  995    8 ...,    0    0    0]\n",
      " [  19  120  117 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  916  336 ...,    0    0    0]\n",
      " [   1 1797  610 ...,    0    0    0]\n",
      " [ 321   10  343 ...,    0    0    0]]\n",
      "146/200 [====================>.........] - ETA: 24s - loss: 1.5692 - acc: 0.8045[[1062   11   45 ...,    0    0    0]\n",
      " [  18   42 1535 ...,    0    0    0]\n",
      " [   2   19 1811 ...,    0    0    0]\n",
      " ..., \n",
      " [ 665  473   13 ...,    0    0    0]\n",
      " [4488   13 3072 ...,    0    0    0]\n",
      " [   1   78  360 ...,    0    0    0]]\n",
      "147/200 [=====================>........] - ETA: 24s - loss: 1.5668 - acc: 0.8047[[   2   13   14 ...,    0    0    0]\n",
      " [2909  168   41 ...,    0    0    0]\n",
      " [ 257   15   32 ...,    0    0    0]\n",
      " ..., \n",
      " [5409   11 1048 ...,    0    0    0]\n",
      " [ 246  604 5651 ...,    0    0    0]\n",
      " [ 248  604 5651 ...,    0    0    0]]\n",
      "148/200 [=====================>........] - ETA: 23s - loss: 1.5654 - acc: 0.8049[[   13 11979     9 ...,     0     0     0]\n",
      " [  978   967     7 ...,     0     0     0]\n",
      " [    2  1346  2405 ...,     0     0     0]\n",
      " ..., \n",
      " [   89     7   586 ...,     0     0     0]\n",
      " [  232    13  3269 ...,     0     0     0]\n",
      " [  347   259    63 ...,     0     0     0]]\n",
      "149/200 [=====================>........] - ETA: 23s - loss: 1.5652 - acc: 0.8049[[ 2894 11190    13 ...,     0     0     0]\n",
      " [    1  4282     8 ...,     0     0     0]\n",
      " [ 2900    13     7 ...,     0     0     0]\n",
      " ..., \n",
      " [   18     2  1884 ...,     0     0     0]\n",
      " [   15     7     1 ...,     0     0     0]\n",
      " [    1  2233    29 ...,     0     0     0]]\n",
      "150/200 [=====================>........] - ETA: 22s - loss: 1.5655 - acc: 0.8049[[7006 1123   13 ...,    0    0    0]\n",
      " [4209  971    9 ...,    0    0    0]\n",
      " [  70 2215  231 ...,    0    0    0]\n",
      " ..., \n",
      " [  13 2230   13 ...,    0    0    0]\n",
      " [  23   13  136 ...,    0    0    0]\n",
      " [ 730   13  108 ...,    0    0    0]]\n",
      "151/200 [=====================>........] - ETA: 22s - loss: 1.5667 - acc: 0.8047[[10549    13    11 ...,     0     0     0]\n",
      " [ 2820  6055   530 ...,     0     0     0]\n",
      " [  523  5302    13 ...,     0     0     0]\n",
      " ..., \n",
      " [  202    71     7 ...,     0     0     0]\n",
      " [   32     1    47 ...,     0     0     0]\n",
      " [    1  1238   336 ...,     0     0     0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/200 [=====================>........] - ETA: 21s - loss: 1.5671 - acc: 0.8047[[   34     9     1 ...,     0     0     0]\n",
      " [    1  6327     7 ...,     0     0     0]\n",
      " [   89     9     2 ...,     0     0     0]\n",
      " ..., \n",
      " [   13 10095    44 ...,     0     0     0]\n",
      " [  406    13  7620 ...,     0     0     0]\n",
      " [    1   845   770 ...,     0     0     0]]\n",
      "153/200 [=====================>........] - ETA: 21s - loss: 1.5666 - acc: 0.8047[[ 379   23 3609 ...,    0    0    0]\n",
      " [  10 1196   13 ...,    0    0    0]\n",
      " [ 166    2  259 ...,    0    0    0]\n",
      " ..., \n",
      " [ 133   39 1165 ...,    0    0    0]\n",
      " [   1 3703   11 ...,    0    0    0]\n",
      " [   1  823 5216 ...,    0    0    0]]\n",
      "154/200 [======================>.......] - ETA: 21s - loss: 1.5679 - acc: 0.8046[[ 244 2381  123 ...,    0    0    0]\n",
      " [ 409  192    2 ...,    0    0    0]\n",
      " [  13 1825    9 ...,    0    0    0]\n",
      " ..., \n",
      " [1892 7257    9 ...,    0    0    0]\n",
      " [1328   13   83 ...,    0    0    0]\n",
      " [   1  175 5681 ...,    0    0    0]]\n",
      "155/200 [======================>.......] - ETA: 20s - loss: 1.5690 - acc: 0.8045[[  54  234   63 ...,    0    0    0]\n",
      " [   1 1341   21 ...,    0    0    0]\n",
      " [  15  448   29 ...,    0    0    0]\n",
      " ..., \n",
      " [   4    1  645 ...,    0    0    0]\n",
      " [5542 2931   14 ...,    0    0    0]\n",
      " [ 586    9   18 ...,    0    0    0]]\n",
      "156/200 [======================>.......] - ETA: 20s - loss: 1.5714 - acc: 0.8042[[1265    3 2312 ...,    0    0    0]\n",
      " [   1 2456 2248 ...,    0    0    0]\n",
      " [  13  301   23 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 4946   21 ...,    0    0    0]\n",
      " [1209   13  574 ...,    0    0    0]\n",
      " [  69  451   83 ...,    0    0    0]]\n",
      "157/200 [======================>.......] - ETA: 19s - loss: 1.5714 - acc: 0.8043[[   4 1097   13 ...,    0    0    0]\n",
      " [1070 2004   23 ...,    0    0    0]\n",
      " [5232  247 1268 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   13    9 ...,    0    0    0]\n",
      " [ 171   43 7345 ...,    0    0    0]\n",
      " [ 137    2 7421 ...,    0    0    0]]\n",
      "158/200 [======================>.......] - ETA: 19s - loss: 1.5726 - acc: 0.8041[[   13    13  3647 ...,     0     0     0]\n",
      " [   13 11605     9 ...,     0     0     0]\n",
      " [  181    13   105 ...,     0     0     0]\n",
      " ..., \n",
      " [ 4851    13 10762 ...,     0     0     0]\n",
      " [ 9718     5     2 ...,     0     0     0]\n",
      " [   89     9   693 ...,     0     0     0]]\n",
      "159/200 [======================>.......] - ETA: 18s - loss: 1.5717 - acc: 0.8043[[  13 1442   13 ...,    0    0    0]\n",
      " [2461   13    9 ...,    0    0    0]\n",
      " [  13 1442   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 951    2 1118 ...,    0    0    0]\n",
      " [   1   13   98 ...,    0    0    0]\n",
      " [  17  431   14 ...,    0    0    0]]\n",
      "160/200 [=======================>......] - ETA: 18s - loss: 1.5710 - acc: 0.8044[[   4   22 2404 ...,    0    0    0]\n",
      " [1925   11 1243 ...,    0    0    0]\n",
      " [1287   13 5519 ...,    0    0    0]\n",
      " ..., \n",
      " [ 318    9 2492 ...,    0    0    0]\n",
      " [   2   13 1300 ...,    0    0    0]\n",
      " [   1   13   38 ...,    0    0    0]]\n",
      "161/200 [=======================>......] - ETA: 17s - loss: 1.5716 - acc: 0.8043[[6214  172   41 ...,    0    0    0]\n",
      " [4280  292   40 ...,    0    0    0]\n",
      " [2192   55    7 ...,    0    0    0]\n",
      " ..., \n",
      " [ 226  217  140 ...,    0    0    0]\n",
      " [3608  119   13 ...,    0    0    0]\n",
      " [ 373  423   55 ...,    0    0    0]]\n",
      "162/200 [=======================>......] - ETA: 17s - loss: 1.5719 - acc: 0.8043[[ 318    7   49 ...,    0    0    0]\n",
      " [  13   26  922 ...,    0    0    0]\n",
      " [  55   11   13 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  220  527 ...,    0    0    0]\n",
      " [   1  422 2108 ...,    0    0    0]\n",
      " [  55    7  682 ...,    0    0    0]]\n",
      "163/200 [=======================>......] - ETA: 16s - loss: 1.5721 - acc: 0.8043[[  456   307   867 ...,     0     0     0]\n",
      " [   73   240     4 ...,     0     0     0]\n",
      " [ 3906    69 11375 ...,     0     0     0]\n",
      " ..., \n",
      " [    1    13    91 ...,     0     0     0]\n",
      " [    1   547   732 ...,     0     0     0]\n",
      " [   13   275    99 ...,     0     0     0]]\n",
      "164/200 [=======================>......] - ETA: 16s - loss: 1.5725 - acc: 0.8043[[ 632   47  867 ...,    0    0    0]\n",
      " [1005   11 1492 ...,    0    0    0]\n",
      " [   2 4390   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 140  583  100 ...,    0    0    0]\n",
      " [  19  352  187 ...,    0    0    0]\n",
      " [   1   19  352 ...,    0    0    0]]\n",
      "165/200 [=======================>......] - ETA: 16s - loss: 1.5722 - acc: 0.8043[[ 884    8  491 ...,    0    0    0]\n",
      " [ 176   66  106 ...,    0    0    0]\n",
      " [  13   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  823 1876 ...,    0    0    0]\n",
      " [   1  180    7 ...,    0    0    0]\n",
      " [2176 3115   23 ...,    0    0    0]]\n",
      "166/200 [=======================>......] - ETA: 15s - loss: 1.5728 - acc: 0.8043[[   3 1428  159 ...,    0    0    0]\n",
      " [  15    7 7374 ...,    0    0    0]\n",
      " [ 717 3637  256 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13 1438 ...,    0    0    0]\n",
      " [1390 2704 3787 ...,    0    0    0]\n",
      " [1219   17 2281 ...,    0    0    0]]\n",
      "167/200 [========================>.....] - ETA: 15s - loss: 1.5723 - acc: 0.8043[[ 585 3731 1002 ...,    0    0    0]\n",
      " [   1   38 6760 ...,    0    0    0]\n",
      " [   1 5327  499 ...,    0    0    0]\n",
      " ..., \n",
      " [  89    7   80 ...,    0    0    0]\n",
      " [   2 3717  146 ...,    0    0    0]\n",
      " [   2 4572 1129 ...,    0    0    0]]\n",
      "168/200 [========================>.....] - ETA: 14s - loss: 1.5725 - acc: 0.8043[[  66    6    1 ...,    0    0    0]\n",
      " [1446   13   23 ...,    0    0    0]\n",
      " [  22  405   16 ...,    0    0    0]\n",
      " ..., \n",
      " [1577 2630   14 ...,    0    0    0]\n",
      " [ 221  230  659 ...,    0    0    0]\n",
      " [ 132   73  240 ...,    0    0    0]]\n",
      "169/200 [========================>.....] - ETA: 14s - loss: 1.5729 - acc: 0.8043[[   1 3845   11 ...,    0    0    0]\n",
      " [   1 1753 1634 ...,    0    0    0]\n",
      " [  26  115    4 ...,    0    0    0]\n",
      " ..., \n",
      " [ 545   69 5333 ...,    0    0    0]\n",
      " [ 300  133    1 ...,    0    0    0]\n",
      " [2461 8349    9 ...,    0    0    0]]\n",
      "170/200 [========================>.....] - ETA: 13s - loss: 1.5725 - acc: 0.8043[[ 350  289  129 ...,    0    0    0]\n",
      " [   1 1015    5 ...,    0    0    0]\n",
      " [ 170 1599   32 ...,    0    0    0]\n",
      " ..., \n",
      " [1822   13    7 ...,    0    0    0]\n",
      " [ 108   15   14 ...,    0    0    0]\n",
      " [ 280 1987   14 ...,    0    0    0]]\n",
      "171/200 [========================>.....] - ETA: 13s - loss: 1.5713 - acc: 0.8044[[9077   50  173 ...,    0    0    0]\n",
      " [1961 2587   11 ...,    0    0    0]\n",
      " [3697  119  157 ...,    0    0    0]\n",
      " ..., \n",
      " [1486  299    5 ...,    0    0    0]\n",
      " [7828   13   11 ...,    0    0    0]\n",
      " [ 496   11 1220 ...,    0    0    0]]\n",
      "172/200 [========================>.....] - ETA: 12s - loss: 1.5695 - acc: 0.8046[[ 355   13   11 ...,    0    0    0]\n",
      " [ 284  941 1465 ...,    0    0    0]\n",
      " [   1 1054    6 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   11 3565 ...,    0    0    0]\n",
      " [  17   13   83 ...,    0    0    0]\n",
      " [ 126  264    7 ...,    0    0    0]]\n",
      "173/200 [========================>.....] - ETA: 12s - loss: 1.5676 - acc: 0.8048[[    1   567   522 ...,     0     0     0]\n",
      " [    2    19   352 ...,     0     0     0]\n",
      " [  166    13    13 ...,     0     0     0]\n",
      " ..., \n",
      " [  812  1064 10285 ...,     0     0     0]\n",
      " [   13  1512    11 ...,     0     0     0]\n",
      " [ 1911  5863    11 ...,     0     0     0]]\n",
      "174/200 [=========================>....] - ETA: 11s - loss: 1.5660 - acc: 0.8049[[   13  2060  8660 ...,     0     0     0]\n",
      " [   13  3523  5816 ...,     0     0     0]\n",
      " [   13  1149 11626 ...,     0     0     0]\n",
      " ..., \n",
      " [  443    13    81 ...,     0     0     0]\n",
      " [    1  2791    27 ...,     0     0     0]\n",
      " [  978   967   604 ...,     0     0     0]]\n",
      "175/200 [=========================>....] - ETA: 11s - loss: 1.5647 - acc: 0.8050[[    4   347   793 ...,     0     0     0]\n",
      " [ 8530    13    27 ...,     0     0     0]\n",
      " [  599    13   112 ...,     0     0     0]\n",
      " ..., \n",
      " [   32 10814     3 ...,     0     0     0]\n",
      " [ 2704  6929     7 ...,     0     0     0]\n",
      " [  348     2   846 ...,     0     0     0]]\n",
      "176/200 [=========================>....] - ETA: 10s - loss: 1.5645 - acc: 0.8050[[ 108 4250    9 ...,    0    0    0]\n",
      " [ 301 8908 7838 ...,    0    0    0]\n",
      " [6110  222 2838 ...,    0    0    0]\n",
      " ..., \n",
      " [ 276  178   13 ...,    0    0    0]\n",
      " [ 102 7048   29 ...,    0    0    0]\n",
      " [3012    8 9083 ...,    0    0    0]]\n",
      "177/200 [=========================>....] - ETA: 10s - loss: 1.5653 - acc: 0.8050[[   68   471    39 ...,     0     0     0]\n",
      " [11204    11   269 ...,     0     0     0]\n",
      " [ 7859  1562    13 ...,     0     0     0]\n",
      " ..., \n",
      " [   15    11    45 ...,     0     0     0]\n",
      " [   75    13  4214 ...,     0     0     0]\n",
      " [   13     1   801 ...,     0     0     0]]\n",
      "178/200 [=========================>....] - ETA: 10s - loss: 1.5655 - acc: 0.8049[[    4    13    13 ...,     0     0     0]\n",
      " [11258    13    13 ...,     0     0     0]\n",
      " [ 3664    13    11 ...,     0     0     0]\n",
      " ..., \n",
      " [   80  1327    29 ...,     0     0     0]\n",
      " [  108    68  1573 ...,     0     0     0]\n",
      " [   10   116     5 ...,     0     0     0]]\n",
      "179/200 [=========================>....] - ETA: 9s - loss: 1.5660 - acc: 0.8049 [[   2 7796    3 ...,    0    0    0]\n",
      " [ 301   79   21 ...,    0    0    0]\n",
      " [1720   13 3192 ...,    0    0    0]\n",
      " ..., \n",
      " [  70  291 1018 ...,    0    0    0]\n",
      " [  10   63   13 ...,    0    0    0]\n",
      " [3604   13   14 ...,    0    0    0]]\n",
      "180/200 [==========================>...] - ETA: 9s - loss: 1.5659 - acc: 0.8049[[  34    9    2 ...,    0    0    0]\n",
      " [3309   13   10 ...,    0    0    0]\n",
      " [3138  192   39 ...,    0    0    0]\n",
      " ..., \n",
      " [9776  744    3 ...,    0    0    0]\n",
      " [  32    1  908 ...,    0    0    0]\n",
      " [  33   13 1218 ...,    0    0    0]]\n",
      "181/200 [==========================>...] - ETA: 8s - loss: 1.5671 - acc: 0.8048[[   1 9590  397 ...,    0    0    0]\n",
      " [ 803 3021  103 ...,    0    0    0]\n",
      " [ 564   13  297 ...,    0    0    0]\n",
      " ..., \n",
      " [ 558    5 2142 ...,    0    0    0]\n",
      " [ 171   70  644 ...,    0    0    0]\n",
      " [  70   15  392 ...,    0    0    0]]\n",
      "182/200 [==========================>...] - ETA: 8s - loss: 1.5680 - acc: 0.8047[[  18    1   13 ...,    0    0    0]\n",
      " [  15    9 7198 ...,    0    0    0]\n",
      " [  15   11   45 ...,    0    0    0]\n",
      " ..., \n",
      " [1381 9770    3 ...,    0    0    0]\n",
      " [6832   13 1864 ...,    0    0    0]\n",
      " [1621  546    9 ...,    0    0    0]]\n",
      "183/200 [==========================>...] - ETA: 7s - loss: 1.5699 - acc: 0.8044[[  15   11  147 ...,    0    0    0]\n",
      " [  70   15 1648 ...,    0    0    0]\n",
      " [1635   13  265 ...,    0    0    0]\n",
      " ..., \n",
      " [2069    7 1818 ...,    0    0    0]\n",
      " [  68  114 1523 ...,    0    0    0]\n",
      " [   1 1996    5 ...,    0    0    0]]\n",
      "184/200 [==========================>...] - ETA: 7s - loss: 1.5697 - acc: 0.8045[[    1  1825     5 ...,     0     0     0]\n",
      " [   16    41   826 ...,     0     0     0]\n",
      " [ 1066  2530     8 ...,     0     0     0]\n",
      " ..., \n",
      " [   13  3328    44 ...,     0     0     0]\n",
      " [   32    79 11010 ...,     0     0     0]\n",
      " [  730    13   227 ...,     0     0     0]]\n",
      "185/200 [==========================>...] - ETA: 6s - loss: 1.5708 - acc: 0.8044[[   15     7     2 ...,     0     0     0]\n",
      " [  108    68    21 ...,     0     0     0]\n",
      " [ 3903   105   505 ...,     0     0     0]\n",
      " ..., \n",
      " [    2   188   144 ...,     0     0     0]\n",
      " [    1   493  2588 ...,     0     0     0]\n",
      " [11730   303   102 ...,     0     0     0]]\n",
      "186/200 [==========================>...] - ETA: 6s - loss: 1.5710 - acc: 0.8043[[  13   68  574 ...,    0    0    0]\n",
      " [ 159   13  336 ...,    0    0    0]\n",
      " [  53    9    1 ...,    0    0    0]\n",
      " ..., \n",
      " [1236    3    1 ...,    0    0    0]\n",
      " [  13  141   39 ...,    0    0    0]\n",
      " [ 443 1112    7 ...,    0    0    0]]\n",
      "187/200 [===========================>..] - ETA: 5s - loss: 1.5707 - acc: 0.8044[[ 2905    51  1765 ...,     0     0     0]\n",
      " [ 7920    13    11 ...,     0     0     0]\n",
      " [11831   695     6 ...,     0     0     0]\n",
      " ..., \n",
      " [  109    26    65 ...,     0     0     0]\n",
      " [    2   426  2162 ...,     0     0     0]\n",
      " [ 6620  6804   100 ...,     0     0     0]]\n",
      "188/200 [===========================>..] - ETA: 5s - loss: 1.5711 - acc: 0.8044[[ 154   66    6 ...,    0    0    0]\n",
      " [  58   59 2805 ...,    0    0    0]\n",
      " [   1  785  115 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 1896  119 ...,    0    0    0]\n",
      " [  78   37   13 ...,    0    0    0]\n",
      " [   2   13    5 ...,    0    0    0]]\n",
      "189/200 [===========================>..] - ETA: 5s - loss: 1.5710 - acc: 0.8044[[   2  258    5 ...,    0    0    0]\n",
      " [  13   26  441 ...,    0    0    0]\n",
      " [  55    7 2803 ...,    0    0    0]\n",
      " ..., \n",
      " [ 219   26  441 ...,    0    0    0]\n",
      " [2928 2633    6 ...,    0    0    0]\n",
      " [ 116  191   13 ...,    0    0    0]]\n",
      "190/200 [===========================>..] - ETA: 4s - loss: 1.5709 - acc: 0.8044[[   1 1276 3182 ...,    0    0    0]\n",
      " [  38  176   66 ...,    0    0    0]\n",
      " [   1 1276 3182 ...,    0    0    0]\n",
      " ..., \n",
      " [  13 4441    5 ...,    0    0    0]\n",
      " [2253  808  514 ...,    0    0    0]\n",
      " [  13   26  113 ...,    0    0    0]]\n",
      "191/200 [===========================>..] - ETA: 4s - loss: 1.5707 - acc: 0.8045[[ 131 2788 2973 ...,    0    0    0]\n",
      " [ 109   26  101 ...,    0    0    0]\n",
      " [   2   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [1390 2704 3787 ...,    0    0    0]\n",
      " [1827 1582   10 ...,    0    0    0]\n",
      " [   1  236  477 ...,    0    0    0]]\n",
      "192/200 [===========================>..] - ETA: 3s - loss: 1.5707 - acc: 0.8045[[   2  582  405 ...,    0    0    0]\n",
      " [ 884  154   66 ...,    0    0    0]\n",
      " [ 654  117  332 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [1986    8 1431 ...,    0    0    0]\n",
      " [5682    9    4 ...,    0    0    0]]\n",
      "193/200 [===========================>..] - ETA: 3s - loss: 1.5712 - acc: 0.8044[[ 3013  9457  1060 ...,     0     0     0]\n",
      " [  109    26  1481 ...,     0     0     0]\n",
      " [10316    13    13 ...,     0     0     0]\n",
      " ..., \n",
      " [   38    62    13 ...,     0     0     0]\n",
      " [  623   157    13 ...,     0     0     0]\n",
      " [   10    13    13 ...,     0     0     0]]\n",
      "194/200 [============================>.] - ETA: 2s - loss: 1.5713 - acc: 0.8044[[1846   13   11 ...,    0    0    0]\n",
      " [3319 1708  205 ...,    0    0    0]\n",
      " [  22 8203  310 ...,    0    0    0]\n",
      " ..., \n",
      " [2425   27 1059 ...,    0    0    0]\n",
      " [ 844  217 1679 ...,    0    0    0]\n",
      " [5387  969   11 ...,    0    0    0]]\n",
      "195/200 [============================>.] - ETA: 2s - loss: 1.5712 - acc: 0.8044[[ 3377    11  4318 ...,     0     0     0]\n",
      " [10997   128    39 ...,     0     0     0]\n",
      " [   10  1461     5 ...,     0     0     0]\n",
      " ..., \n",
      " [  137     7     1 ...,     0     0     0]\n",
      " [    1  2195   236 ...,     0     0     0]\n",
      " [ 1405   100   566 ...,     0     0     0]]\n",
      "196/200 [============================>.] - ETA: 1s - loss: 1.5713 - acc: 0.8044[[  15    7 6030 ...,    0    0    0]\n",
      " [  79  121  255 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " ..., \n",
      " [ 150  199  287 ...,    0    0    0]\n",
      " [ 751   11  399 ...,    0    0    0]\n",
      " [1742    9  155 ...,    0    0    0]]\n",
      "197/200 [============================>.] - ETA: 1s - loss: 1.5714 - acc: 0.8044[[ 579    7 1010 ...,    0    0    0]\n",
      " [ 665 1252    9 ...,    0    0    0]\n",
      " [  80  199 6663 ...,    0    0    0]\n",
      " ..., \n",
      " [1385  968 1360 ...,    0    0    0]\n",
      " [8877   13   14 ...,    0    0    0]\n",
      " [   1 2097  152 ...,    0    0    0]]\n",
      "198/200 [============================>.] - ETA: 0s - loss: 1.5706 - acc: 0.8045[[ 3010   430   590 ...,     0     0     0]\n",
      " [   13  6010    11 ...,     0     0     0]\n",
      " [ 3571     9  5456 ...,     0     0     0]\n",
      " ..., \n",
      " [11295    83    15 ...,     0     0     0]\n",
      " [  219   119   157 ...,     0     0     0]\n",
      " [   22  9314  5292 ...,     0     0     0]]\n",
      "199/200 [============================>.] - ETA: 0s - loss: 1.5691 - acc: 0.8047[[ 267  157   22 ...,    0    0    0]\n",
      " [7723 1091  941 ...,    0    0    0]\n",
      " [1549  455    3 ...,    0    0    0]\n",
      " ..., \n",
      " [   2   13  394 ...,    0    0    0]\n",
      " [   2   19  545 ...,    0    0    0]\n",
      " [4883   13    5 ...,    0    0    0]]\n",
      "200/200 [==============================] - 91s - loss: 1.5673 - acc: 0.8048    \n",
      "Epoch 9/10\n",
      "[[  13 3137  600 ...,    0    0    0]\n",
      " [7760   13   27 ...,    0    0    0]\n",
      " [3079 3363   11 ...,    0    0    0]\n",
      " ..., \n",
      " [1381    8 2084 ...,    0    0    0]\n",
      " [   1  214   23 ...,    0    0    0]\n",
      " [ 109   26 1317 ...,    0    0    0]]\n",
      "  1/200 [..............................] - ETA: 90s - loss: 1.3079 - acc: 0.8247[[   13    13    13 ...,     0     0     0]\n",
      " [   13  2435 11097 ...,     0     0     0]\n",
      " [    1   191     6 ...,     0     0     0]\n",
      " ..., \n",
      " [    1   214  1301 ...,     0     0     0]\n",
      " [   34    14    48 ...,     0     0     0]\n",
      " [    1   406  5815 ...,     0     0     0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/200 [..............................] - ETA: 88s - loss: 1.3227 - acc: 0.8232[[    1  9836    23 ...,     0     0     0]\n",
      " [  154    66     6 ...,     0     0     0]\n",
      " [ 2541   748     3 ...,     0     0     0]\n",
      " ..., \n",
      " [  195    15    13 ...,     0     0     0]\n",
      " [    1 11532    14 ...,     0     0     0]\n",
      " [   56  4391     6 ...,     0     0     0]]\n",
      "  3/200 [..............................] - ETA: 88s - loss: 1.3874 - acc: 0.8190[[   1 1693 3514 ...,    0    0    0]\n",
      " [3827 4729   25 ...,    0    0    0]\n",
      " [4034 5683   10 ...,    0    0    0]\n",
      " ..., \n",
      " [ 221  230   13 ...,    0    0    0]\n",
      " [  70   15  392 ...,    0    0    0]\n",
      " [ 335    9    2 ...,    0    0    0]]\n",
      "  4/200 [..............................] - ETA: 88s - loss: 1.4186 - acc: 0.8186[[  15  748   90 ...,    0    0    0]\n",
      " [   1 1217  231 ...,    0    0    0]\n",
      " [ 152  139   11 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13   13 ...,    0    0    0]\n",
      " [   1 9395   23 ...,    0    0    0]\n",
      " [  15 1272 1558 ...,    0    0    0]]\n",
      "  5/200 [..............................] - ETA: 87s - loss: 1.4856 - acc: 0.8123[[  34  592   13 ...,    0    0    0]\n",
      " [  18   22 5726 ...,    0    0    0]\n",
      " [7167   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   13   44 ...,    0    0    0]\n",
      " [9077   50   13 ...,    0    0    0]\n",
      " [   4  189  343 ...,    0    0    0]]\n",
      "  6/200 [..............................] - ETA: 87s - loss: 1.5084 - acc: 0.8105[[  15    9    2 ...,    0    0    0]\n",
      " [  89    7   80 ...,    0    0    0]\n",
      " [  15   14   41 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  611   86 ...,    0    0    0]\n",
      " [   1  485 1456 ...,    0    0    0]\n",
      " [  15  744   90 ...,    0    0    0]]\n",
      "  7/200 [>.............................] - ETA: 86s - loss: 1.5212 - acc: 0.8089[[  56  290    5 ...,    0    0    0]\n",
      " [ 108 1971    9 ...,    0    0    0]\n",
      " [1460 1503   89 ...,    0    0    0]\n",
      " ..., \n",
      " [  78   77 9528 ...,    0    0    0]\n",
      " [ 127   63  144 ...,    0    0    0]\n",
      " [4802   76   43 ...,    0    0    0]]\n",
      "  8/200 [>.............................] - ETA: 86s - loss: 1.5268 - acc: 0.8089[[ 245  431    9 ...,    0    0    0]\n",
      " [   1   73  138 ...,    0    0    0]\n",
      " [  56  706  290 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 1540  737 ...,    0    0    0]\n",
      " [  12 2850   13 ...,    0    0    0]\n",
      " [3194  102   67 ...,    0    0    0]]\n",
      "  9/200 [>.............................] - ETA: 85s - loss: 1.5638 - acc: 0.8051[[ 202    1 2814 ...,    0    0    0]\n",
      " [   1  847   16 ...,    0    0    0]\n",
      " [2346   13   81 ...,    0    0    0]\n",
      " ..., \n",
      " [  13 1645  568 ...,    0    0    0]\n",
      " [ 535    1 3643 ...,    0    0    0]\n",
      " [5119 1903    9 ...,    0    0    0]]\n",
      " 10/200 [>.............................] - ETA: 85s - loss: 1.5847 - acc: 0.8028[[  64  598   82 ...,    0    0    0]\n",
      " [5095 1115 1312 ...,    0    0    0]\n",
      " [ 739  396   13 ...,    0    0    0]\n",
      " ..., \n",
      " [8251 4061   86 ...,    0    0    0]\n",
      " [  56   63    4 ...,    0    0    0]\n",
      " [   1 1011 1463 ...,    0    0    0]]\n",
      " 11/200 [>.............................] - ETA: 85s - loss: 1.6290 - acc: 0.7980[[  69  263   30 ...,    0    0    0]\n",
      " [ 159   13  141 ...,    0    0    0]\n",
      " [ 116   67    1 ...,    0    0    0]\n",
      " ..., \n",
      " [  89   67 5801 ...,    0    0    0]\n",
      " [   1 1033   86 ...,    0    0    0]\n",
      " [  32   13   13 ...,    0    0    0]]\n",
      " 12/200 [>.............................] - ETA: 84s - loss: 1.6079 - acc: 0.8013[[  10  885 1705 ...,    0    0    0]\n",
      " [  13 1442  947 ...,    0    0    0]\n",
      " [  34  592  630 ...,    0    0    0]\n",
      " ..., \n",
      " [7813 2029    9 ...,    0    0    0]\n",
      " [4534   43 4534 ...,    0    0    0]\n",
      " [  72 7076   83 ...,    0    0    0]]\n",
      " 13/200 [>.............................] - ETA: 84s - loss: 1.6215 - acc: 0.7995[[  13  817   17 ...,    0    0    0]\n",
      " [  10  888   13 ...,    0    0    0]\n",
      " [ 133   39   20 ...,    0    0    0]\n",
      " ..., \n",
      " [   2  223 1745 ...,    0    0    0]\n",
      " [   1  463   13 ...,    0    0    0]\n",
      " [ 194  102  504 ...,    0    0    0]]\n",
      " 14/200 [=>............................] - ETA: 83s - loss: 1.6266 - acc: 0.7993[[ 550 8168   13 ...,    0    0    0]\n",
      " [ 245   13   13 ...,    0    0    0]\n",
      " [  18    1 7564 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 6402  462 ...,    0    0    0]\n",
      " [1742  455    3 ...,    0    0    0]\n",
      " [ 104 1340   48 ...,    0    0    0]]\n",
      " 15/200 [=>............................] - ETA: 83s - loss: 1.6176 - acc: 0.8006[[  658    14   276 ...,     0     0     0]\n",
      " [    4   116  1595 ...,     0     0     0]\n",
      " [    1   416   381 ...,     0     0     0]\n",
      " ..., \n",
      " [  127  4833    63 ...,     0     0     0]\n",
      " [    1   282   339 ...,     0     0     0]\n",
      " [11976     9   111 ...,     0     0     0]]\n",
      " 16/200 [=>............................] - ETA: 83s - loss: 1.6112 - acc: 0.8014[[  93 1629   60 ...,    0    0    0]\n",
      " [1357    8 6176 ...,    0    0    0]\n",
      " [ 150 1718  133 ...,    0    0    0]\n",
      " ..., \n",
      " [ 884   73   66 ...,    0    0    0]\n",
      " [  55 9128 1070 ...,    0    0    0]\n",
      " [  13   26  182 ...,    0    0    0]]\n",
      " 17/200 [=>............................] - ETA: 82s - loss: 1.6121 - acc: 0.8015[[    1    13    91 ...,     0     0     0]\n",
      " [ 5582   217 11411 ...,     0     0     0]\n",
      " [  109    26   113 ...,     0     0     0]\n",
      " ..., \n",
      " [    1  8532   169 ...,     0     0     0]\n",
      " [  248  3499   280 ...,     0     0     0]\n",
      " [ 1695   623     6 ...,     0     0     0]]\n",
      " 18/200 [=>............................] - ETA: 82s - loss: 1.6124 - acc: 0.8014[[   1 1896  191 ...,    0    0    0]\n",
      " [  58   59 1032 ...,    0    0    0]\n",
      " [   1  884  191 ...,    0    0    0]\n",
      " ..., \n",
      " [  73 1479    4 ...,    0    0    0]\n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [1430  811   13 ...,    0    0    0]]\n",
      " 19/200 [=>............................] - ETA: 82s - loss: 1.6079 - acc: 0.8019[[  19  120 2442 ...,    0    0    0]\n",
      " [1379    1  126 ...,    0    0    0]\n",
      " [5183    4  367 ...,    0    0    0]\n",
      " ..., \n",
      " [2191    8  880 ...,    0    0    0]\n",
      " [ 546  510    6 ...,    0    0    0]\n",
      " [  13 2639 9459 ...,    0    0    0]]\n",
      " 20/200 [==>...........................] - ETA: 81s - loss: 1.6077 - acc: 0.8018[[   13    26   441 ...,     0     0     0]\n",
      " [   58    59   187 ...,     0     0     0]\n",
      " [    1  1508  1687 ...,     0     0     0]\n",
      " ..., \n",
      " [  255   160  1938 ...,     0     0     0]\n",
      " [ 7406 10480  1673 ...,     0     0     0]\n",
      " [   19   352   154 ...,     0     0     0]]\n",
      " 21/200 [==>...........................] - ETA: 81s - loss: 1.6019 - acc: 0.8027[[ 711  168   53 ...,    0    0    0]\n",
      " [   2  179  734 ...,    0    0    0]\n",
      " [1757  187  115 ...,    0    0    0]\n",
      " ..., \n",
      " [  22  864    8 ...,    0    0    0]\n",
      " [  47  867   13 ...,    0    0    0]\n",
      " [ 234 9748  289 ...,    0    0    0]]\n",
      " 22/200 [==>...........................] - ETA: 80s - loss: 1.6073 - acc: 0.8022[[ 166 7677   27 ...,    0    0    0]\n",
      " [ 654  145   11 ...,    0    0    0]\n",
      " [ 131  429 1187 ...,    0    0    0]\n",
      " ..., \n",
      " [  13 8443   11 ...,    0    0    0]\n",
      " [2084 2581 1392 ...,    0    0    0]\n",
      " [ 236  477  246 ...,    0    0    0]]\n",
      " 23/200 [==>...........................] - ETA: 80s - loss: 1.6070 - acc: 0.8021[[    2   412    12 ...,     0     0     0]\n",
      " [ 3909   267    23 ...,     0     0     0]\n",
      " [    1  6447    13 ...,     0     0     0]\n",
      " ..., \n",
      " [ 1497     8   148 ...,     0     0     0]\n",
      " [   22  4477 10665 ...,     0     0     0]\n",
      " [ 2965    13    30 ...,     0     0     0]]\n",
      " 24/200 [==>...........................] - ETA: 79s - loss: 1.6083 - acc: 0.8021[[   1  406 5815 ...,    0    0    0]\n",
      " [  13  505  105 ...,    0    0    0]\n",
      " [  22  150   13 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 4705 8115 ...,    0    0    0]\n",
      " [2453   13   13 ...,    0    0    0]\n",
      " [ 566    1 2604 ...,    0    0    0]]\n",
      " 25/200 [==>...........................] - ETA: 79s - loss: 1.6084 - acc: 0.8021[[  93   23   13 ...,    0    0    0]\n",
      " [ 147  202   13 ...,    0    0    0]\n",
      " [1693 3716 1232 ...,    0    0    0]\n",
      " ..., \n",
      " [ 119   21  616 ...,    0    0    0]\n",
      " [ 377    5   15 ...,    0    0    0]\n",
      " [3827   67 5652 ...,    0    0    0]]\n",
      " 26/200 [==>...........................] - ETA: 79s - loss: 1.6054 - acc: 0.8026[[ 1819     8  5136 ...,     0     0     0]\n",
      " [ 1770     5 11027 ...,     0     0     0]\n",
      " [    2  1355    13 ...,     0     0     0]\n",
      " ..., \n",
      " [  987    83    41 ...,     0     0     0]\n",
      " [   10  1334   123 ...,     0     0     0]\n",
      " [   15    14     1 ...,     0     0     0]]\n",
      " 27/200 [===>..........................] - ETA: 78s - loss: 1.5918 - acc: 0.8037[[  47 1907 1911 ...,    0    0    0]\n",
      " [   1   19  120 ...,    0    0    0]\n",
      " [1668   13  925 ...,    0    0    0]\n",
      " ..., \n",
      " [  15 1893   90 ...,    0    0    0]\n",
      " [   1 2757   11 ...,    0    0    0]\n",
      " [ 973 6406   11 ...,    0    0    0]]\n",
      " 28/200 [===>..........................] - ETA: 78s - loss: 1.5810 - acc: 0.8046[[  173     5    69 ...,     0     0     0]\n",
      " [11368     5  3219 ...,     0     0     0]\n",
      " [ 4915   941 11116 ...,     0     0     0]\n",
      " ..., \n",
      " [  108    68   595 ...,     0     0     0]\n",
      " [ 1224  1890    13 ...,     0     0     0]\n",
      " [ 3054   130  1046 ...,     0     0     0]]\n",
      " 29/200 [===>..........................] - ETA: 77s - loss: 1.5702 - acc: 0.8054[[  13 2097   11 ...,    0    0    0]\n",
      " [ 849 1211   10 ...,    0    0    0]\n",
      " [9739 1535    4 ...,    0    0    0]\n",
      " ..., \n",
      " [5617 3345 1822 ...,    0    0    0]\n",
      " [ 633 3324   23 ...,    0    0    0]\n",
      " [3125 1254   11 ...,    0    0    0]]\n",
      " 30/200 [===>..........................] - ETA: 77s - loss: 1.5612 - acc: 0.8060[[    1  5180 10336 ...,     0     0     0]\n",
      " [  519  5445  2648 ...,     0     0     0]\n",
      " [    1  2400    13 ...,     0     0     0]\n",
      " ..., \n",
      " [ 1369  3750   192 ...,     0     0     0]\n",
      " [ 3327     9    48 ...,     0     0     0]\n",
      " [    1    13  3351 ...,     0     0     0]]\n",
      " 31/200 [===>..........................] - ETA: 76s - loss: 1.5582 - acc: 0.8062[[   1 2510    5 ...,    0    0    0]\n",
      " [ 824    9   76 ...,    0    0    0]\n",
      " [3393 7762    8 ...,    0    0    0]\n",
      " ..., \n",
      " [ 132   26   65 ...,    0    0    0]\n",
      " [4911 2964    8 ...,    0    0    0]\n",
      " [ 930   13   14 ...,    0    0    0]]\n",
      " 32/200 [===>..........................] - ETA: 76s - loss: 1.5606 - acc: 0.8059[[ 159 5589   11 ...,    0    0    0]\n",
      " [1067  314   13 ...,    0    0    0]\n",
      " [   1 1289 3073 ...,    0    0    0]\n",
      " ..., \n",
      " [  17 4581   11 ...,    0    0    0]\n",
      " [  10    1   47 ...,    0    0    0]\n",
      " [ 155   68  718 ...,    0    0    0]]\n",
      " 33/200 [===>..........................] - ETA: 75s - loss: 1.5640 - acc: 0.8056[[ 102  123  442 ...,    0    0    0]\n",
      " [ 145  757    9 ...,    0    0    0]\n",
      " [   1 1115  291 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 7219   38 ...,    0    0    0]\n",
      " [  99 5343 2628 ...,    0    0    0]\n",
      " [7155   81    2 ...,    0    0    0]]\n",
      " 34/200 [====>.........................] - ETA: 75s - loss: 1.5649 - acc: 0.8055[[  79    5  600 ...,    0    0    0]\n",
      " [  13 1751  541 ...,    0    0    0]\n",
      " [1346 2013  163 ...,    0    0    0]\n",
      " ..., \n",
      " [1694 2380  247 ...,    0    0    0]\n",
      " [  19 1848 4197 ...,    0    0    0]\n",
      " [  70   13   13 ...,    0    0    0]]\n",
      " 35/200 [====>.........................] - ETA: 74s - loss: 1.5705 - acc: 0.8048[[  41    5    1 ...,    0    0    0]\n",
      " [  42    7  111 ...,    0    0    0]\n",
      " [   1 3532    4 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  680   13 ...,    0    0    0]\n",
      " [ 293 5775   23 ...,    0    0    0]\n",
      " [   6 4325   86 ...,    0    0    0]]\n",
      " 36/200 [====>.........................] - ETA: 74s - loss: 1.5658 - acc: 0.8054[[  12   47 4618 ...,    0    0    0]\n",
      " [  32   61    3 ...,    0    0    0]\n",
      " [   1   47  872 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   13    9 ...,    0    0    0]\n",
      " [  13 1226  876 ...,    0    0    0]\n",
      " [ 730   13  995 ...,    0    0    0]]\n",
      " 37/200 [====>.........................] - ETA: 73s - loss: 1.5682 - acc: 0.8051[[6290   23   48 ...,    0    0    0]\n",
      " [  70 2860 4117 ...,    0    0    0]\n",
      " [ 639   37   13 ...,    0    0    0]\n",
      " ..., \n",
      " [   2   19  563 ...,    0    0    0]\n",
      " [   1  747   14 ...,    0    0    0]\n",
      " [  15    7 6004 ...,    0    0    0]]\n",
      " 38/200 [====>.........................] - ETA: 73s - loss: 1.5776 - acc: 0.8041[[ 302   13  154 ...,    0    0    0]\n",
      " [  15  105   21 ...,    0    0    0]\n",
      " [5814   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [  15  871   20 ...,    0    0    0]\n",
      " [2410 9350    9 ...,    0    0    0]\n",
      " [ 644   13   81 ...,    0    0    0]]\n",
      " 39/200 [====>.........................] - ETA: 72s - loss: 1.5923 - acc: 0.8024[[   1   69    7 ...,    0    0    0]\n",
      " [ 108   68  410 ...,    0    0    0]\n",
      " [  15    7   48 ...,    0    0    0]\n",
      " ..., \n",
      " [  13  104   21 ...,    0    0    0]\n",
      " [  12  393   13 ...,    0    0    0]\n",
      " [2113    9   39 ...,    0    0    0]]\n",
      " 40/200 [=====>........................] - ETA: 72s - loss: 1.5947 - acc: 0.8022[[   1   13    5 ...,    0    0    0]\n",
      " [ 483    1  474 ...,    0    0    0]\n",
      " [ 104   13   97 ...,    0    0    0]\n",
      " ..., \n",
      " [1360 3930   11 ...,    0    0    0]\n",
      " [  43  383  244 ...,    0    0    0]\n",
      " [  15  530    3 ...,    0    0    0]]\n",
      " 41/200 [=====>........................] - ETA: 71s - loss: 1.5927 - acc: 0.8024[[  301  3343 11699 ...,     0     0     0]\n",
      " [ 9173  7862    81 ...,     0     0     0]\n",
      " [   13    13  5463 ...,     0     0     0]\n",
      " ..., \n",
      " [    4     2  1307 ...,     0     0     0]\n",
      " [   13 11062     1 ...,     0     0     0]\n",
      " [   13    13   385 ...,     0     0     0]]\n",
      " 42/200 [=====>........................] - ETA: 71s - loss: 1.5973 - acc: 0.8020[[  962   450   283 ...,     0     0     0]\n",
      " [    1   659 10774 ...,     0     0     0]\n",
      " [    2  1045   910 ...,     0     0     0]\n",
      " ..., \n",
      " [    5   738    13 ...,     0     0     0]\n",
      " [    1    13    13 ...,     0     0     0]\n",
      " [ 3056   355  1433 ...,     0     0     0]]\n",
      " 43/200 [=====>........................] - ETA: 70s - loss: 1.5950 - acc: 0.8024[[    1  1876    81 ...,     0     0     0]\n",
      " [   13    13    13 ...,     0     0     0]\n",
      " [   13  7673  2325 ...,     0     0     0]\n",
      " ..., \n",
      " [   13     1    13 ...,     0     0     0]\n",
      " [    1    13  5660 ...,     0     0     0]\n",
      " [ 4094    13 10706 ...,     0     0     0]]\n",
      " 44/200 [=====>........................] - ETA: 70s - loss: 1.5918 - acc: 0.8028[[   13    13     4 ...,     0     0     0]\n",
      " [   41   264  1023 ...,     0     0     0]\n",
      " [ 1092    13   264 ...,     0     0     0]\n",
      " ..., \n",
      " [ 1038  5235    10 ...,     0     0     0]\n",
      " [    1  1124    27 ...,     0     0     0]\n",
      " [11578  7361     4 ...,     0     0     0]]\n",
      " 45/200 [=====>........................] - ETA: 70s - loss: 1.5932 - acc: 0.8028[[  58   59  154 ...,    0    0    0]\n",
      " [1056 1719  267 ...,    0    0    0]\n",
      " [  13   69 2399 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [   2   13  405 ...,    0    0    0]]\n",
      " 46/200 [=====>........................] - ETA: 69s - loss: 1.5924 - acc: 0.8029[[ 109   26  106 ...,    0    0    0]\n",
      " [   1 1202    5 ...,    0    0    0]\n",
      " [   1 1276 3182 ...,    0    0    0]\n",
      " ..., \n",
      " [2990  674  308 ...,    0    0    0]\n",
      " [ 491   26  113 ...,    0    0    0]\n",
      " [ 152  139  106 ...,    0    0    0]]\n",
      " 47/200 [======>.......................] - ETA: 69s - loss: 1.5925 - acc: 0.8028[[ 1189   224     7 ...,     0     0     0]\n",
      " [    1    13    91 ...,     0     0     0]\n",
      " [ 2574    30    36 ...,     0     0     0]\n",
      " ..., \n",
      " [    1   551    13 ...,     0     0     0]\n",
      " [   13   104   945 ...,     0     0     0]\n",
      " [  306    27 11880 ...,     0     0     0]]\n",
      " 48/200 [======>.......................] - ETA: 68s - loss: 1.5911 - acc: 0.8031[[   1   13   91 ...,    0    0    0]\n",
      " [   1  306  119 ...,    0    0    0]\n",
      " [   1   13   91 ...,    0    0    0]\n",
      " ..., \n",
      " [ 456  187 1924 ...,    0    0    0]\n",
      " [ 234  102   67 ...,    0    0    0]\n",
      " [ 456 4785   32 ...,    0    0    0]]\n",
      " 49/200 [======>.......................] - ETA: 68s - loss: 1.5917 - acc: 0.8030[[ 456  187 1924 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [   1 6434  384 ...,    0    0    0]\n",
      " ..., \n",
      " [1195 1916   11 ...,    0    0    0]\n",
      " [ 372   11  269 ...,    0    0    0]\n",
      " [ 318    8   92 ...,    0    0    0]]\n",
      " 50/200 [======>.......................] - ETA: 67s - loss: 1.5919 - acc: 0.8029[[ 342  196    4 ...,    0    0    0]\n",
      " [ 661   10    1 ...,    0    0    0]\n",
      " [ 342  196    4 ...,    0    0    0]\n",
      " ..., \n",
      " [ 390 3598   27 ...,    0    0    0]\n",
      " [  16 4647 1418 ...,    0    0    0]\n",
      " [ 171  108 1150 ...,    0    0    0]]\n",
      " 51/200 [======>.......................] - ETA: 67s - loss: 1.5921 - acc: 0.8030[[  109    26   115 ...,     0     0     0]\n",
      " [    1    19   120 ...,     0     0     0]\n",
      " [  203   295  1943 ...,     0     0     0]\n",
      " ..., \n",
      " [ 1961  3177    14 ...,     0     0     0]\n",
      " [    1  5396     4 ...,     0     0     0]\n",
      " [   13 11404    61 ...,     0     0     0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 52/200 [======>.......................] - ETA: 66s - loss: 1.5936 - acc: 0.8029[[   2   13 7793 ...,    0    0    0]\n",
      " [2932   13   13 ...,    0    0    0]\n",
      " [   1  132  732 ...,    0    0    0]\n",
      " ..., \n",
      " [  70   15  392 ...,    0    0    0]\n",
      " [2350   11  631 ...,    0    0    0]\n",
      " [  60  110   11 ...,    0    0    0]]\n",
      " 53/200 [======>.......................] - ETA: 66s - loss: 1.5936 - acc: 0.8028[[10963  3063    83 ...,     0     0     0]\n",
      " [  987    83   318 ...,     0     0     0]\n",
      " [  193    14    13 ...,     0     0     0]\n",
      " ..., \n",
      " [   99   255    73 ...,     0     0     0]\n",
      " [    2    19   545 ...,     0     0     0]\n",
      " [  119     6    36 ...,     0     0     0]]\n",
      " 54/200 [=======>......................] - ETA: 66s - loss: 1.5933 - acc: 0.8029[[    1   339  1897 ...,     0     0     0]\n",
      " [   68   337     3 ...,     0     0     0]\n",
      " [   49    38    62 ...,     0     0     0]\n",
      " ..., \n",
      " [ 1397     1    13 ...,     0     0     0]\n",
      " [   13 11624     8 ...,     0     0     0]\n",
      " [   70  5936  6089 ...,     0     0     0]]\n",
      " 55/200 [=======>......................] - ETA: 65s - loss: 1.5919 - acc: 0.8030[[   1  785  283 ...,    0    0    0]\n",
      " [1170  159  390 ...,    0    0    0]\n",
      " [   1   13   91 ...,    0    0    0]\n",
      " ..., \n",
      " [  55    7  191 ...,    0    0    0]\n",
      " [  49 4490 7088 ...,    0    0    0]\n",
      " [   1   13  343 ...,    0    0    0]]\n",
      " 56/200 [=======>......................] - ETA: 65s - loss: 1.5857 - acc: 0.8035[[  69  418  335 ...,    0    0    0]\n",
      " [1961 8415   11 ...,    0    0    0]\n",
      " [5175  694  103 ...,    0    0    0]\n",
      " ..., \n",
      " [ 309 4632 5172 ...,    0    0    0]\n",
      " [3402 2029    7 ...,    0    0    0]\n",
      " [  13  816  276 ...,    0    0    0]]\n",
      " 57/200 [=======>......................] - ETA: 64s - loss: 1.5815 - acc: 0.8039[[  797 11533   186 ...,     0     0     0]\n",
      " [ 1801  2135   451 ...,     0     0     0]\n",
      " [ 2406    13   903 ...,     0     0     0]\n",
      " ..., \n",
      " [ 1050    13   647 ...,     0     0     0]\n",
      " [  866  4106    21 ...,     0     0     0]\n",
      " [   70     1  9107 ...,     0     0     0]]\n",
      " 58/200 [=======>......................] - ETA: 64s - loss: 1.5753 - acc: 0.8044[[6389 2097  694 ...,    0    0    0]\n",
      " [   1   13   13 ...,    0    0    0]\n",
      " [ 363 3764 1205 ...,    0    0    0]\n",
      " ..., \n",
      " [2015   11 2025 ...,    0    0    0]\n",
      " [  13   26   23 ...,    0    0    0]\n",
      " [ 761  621   13 ...,    0    0    0]]\n",
      " 59/200 [=======>......................] - ETA: 63s - loss: 1.5708 - acc: 0.8047[[  13   13  807 ...,    0    0    0]\n",
      " [ 491  187  182 ...,    0    0    0]\n",
      " [ 365    7   13 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  883 2440 ...,    0    0    0]\n",
      " [  13 1248 1710 ...,    0    0    0]\n",
      " [2613  141   39 ...,    0    0    0]]\n",
      " 60/200 [========>.....................] - ETA: 63s - loss: 1.5672 - acc: 0.8051[[  16   13    5 ...,    0    0    0]\n",
      " [5945 2617  168 ...,    0    0    0]\n",
      " [  49  177  144 ...,    0    0    0]\n",
      " ..., \n",
      " [5517 2123 6731 ...,    0    0    0]\n",
      " [   1  221  230 ...,    0    0    0]\n",
      " [ 140  553  697 ...,    0    0    0]]\n",
      " 61/200 [========>.....................] - ETA: 62s - loss: 1.5657 - acc: 0.8052[[5490    5    1 ...,    0    0    0]\n",
      " [  13   13   13 ...,    0    0    0]\n",
      " [  89    7   80 ...,    0    0    0]\n",
      " ..., \n",
      " [  93   23    1 ...,    0    0    0]\n",
      " [  12   13  161 ...,    0    0    0]\n",
      " [1770    5   13 ...,    0    0    0]]\n",
      " 62/200 [========>.....................] - ETA: 62s - loss: 1.5648 - acc: 0.8053[[  70   68  377 ...,    0    0    0]\n",
      " [   1 1556 6068 ...,    0    0    0]\n",
      " [ 194 1156  853 ...,    0    0    0]\n",
      " ..., \n",
      " [ 137    9   15 ...,    0    0    0]\n",
      " [  13   13   44 ...,    0    0    0]\n",
      " [3711  210   13 ...,    0    0    0]]\n",
      " 63/200 [========>.....................] - ETA: 61s - loss: 1.5664 - acc: 0.8051[[ 137    7   19 ...,    0    0    0]\n",
      " [   1  214   23 ...,    0    0    0]\n",
      " [ 599 2846 1433 ...,    0    0    0]\n",
      " ..., \n",
      " [1150 1900    9 ...,    0    0    0]\n",
      " [  15   11   45 ...,    0    0    0]\n",
      " [ 245 1192    8 ...,    0    0    0]]\n",
      " 64/200 [========>.....................] - ETA: 61s - loss: 1.5678 - acc: 0.8050[[  13   13    4 ...,    0    0    0]\n",
      " [1742    7 2878 ...,    0    0    0]\n",
      " [  13   13  141 ...,    0    0    0]\n",
      " ..., \n",
      " [ 644  435 5264 ...,    0    0    0]\n",
      " [   2   13  146 ...,    0    0    0]\n",
      " [   1 6418   13 ...,    0    0    0]]\n",
      " 65/200 [========>.....................] - ETA: 60s - loss: 1.5686 - acc: 0.8048[[ 630  164   13 ...,    0    0    0]\n",
      " [   4   60 9835 ...,    0    0    0]\n",
      " [ 103 1075  779 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 1274    5 ...,    0    0    0]\n",
      " [  89   23  693 ...,    0    0    0]\n",
      " [   4    2   37 ...,    0    0    0]]\n",
      " 66/200 [========>.....................] - ETA: 60s - loss: 1.5677 - acc: 0.8050[[  13   13   86 ...,    0    0    0]\n",
      " [3550    9  254 ...,    0    0    0]\n",
      " [ 605 2648   23 ...,    0    0    0]\n",
      " ..., \n",
      " [6382 6947   30 ...,    0    0    0]\n",
      " [  13  418  335 ...,    0    0    0]\n",
      " [  13 4125 5709 ...,    0    0    0]]\n",
      " 67/200 [=========>....................] - ETA: 60s - loss: 1.5717 - acc: 0.8046[[   1 1927    5 ...,    0    0    0]\n",
      " [  13   13   67 ...,    0    0    0]\n",
      " [  29 5307   13 ...,    0    0    0]\n",
      " ..., \n",
      " [6482 6781   13 ...,    0    0    0]\n",
      " [2139  210 3422 ...,    0    0    0]\n",
      " [   1 7826  218 ...,    0    0    0]]\n",
      " 68/200 [=========>....................] - ETA: 59s - loss: 1.5738 - acc: 0.8043[[ 171    4  318 ...,    0    0    0]\n",
      " [   4   22 4218 ...,    0    0    0]\n",
      " [  89    7  439 ...,    0    0    0]\n",
      " ..., \n",
      " [ 486  537   57 ...,    0    0    0]\n",
      " [  13   13   51 ...,    0    0    0]\n",
      " [4511 4278   41 ...,    0    0    0]]\n",
      " 69/200 [=========>....................] - ETA: 59s - loss: 1.5791 - acc: 0.8037[[  42   11   45 ...,    0    0    0]\n",
      " [ 586    9  939 ...,    0    0    0]\n",
      " [ 751   13  171 ...,    0    0    0]\n",
      " ..., \n",
      " [   2 9906 1477 ...,    0    0    0]\n",
      " [  13  104 1619 ...,    0    0    0]\n",
      " [   1   19  120 ...,    0    0    0]]\n",
      " 70/200 [=========>....................] - ETA: 58s - loss: 1.5778 - acc: 0.8039[[ 1546  4893    81 ...,     0     0     0]\n",
      " [  443   900    11 ...,     0     0     0]\n",
      " [   22  1241     9 ...,     0     0     0]\n",
      " ..., \n",
      " [    1  1238 11900 ...,     0     0     0]\n",
      " [ 1675  1415    11 ...,     0     0     0]\n",
      " [   13    13   292 ...,     0     0     0]]\n",
      " 71/200 [=========>....................] - ETA: 58s - loss: 1.5804 - acc: 0.8037[[  49   63  144 ...,    0    0    0]\n",
      " [   1  751 2224 ...,    0    0    0]\n",
      " [ 173  831   32 ...,    0    0    0]\n",
      " ..., \n",
      " [  13  321  285 ...,    0    0    0]\n",
      " [  34  400   77 ...,    0    0    0]\n",
      " [   2 7121    3 ...,    0    0    0]]\n",
      " 72/200 [=========>....................] - ETA: 57s - loss: 1.5820 - acc: 0.8036[[   1  156   61 ...,    0    0    0]\n",
      " [  64   82   13 ...,    0    0    0]\n",
      " [  15    7   45 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 7812    5 ...,    0    0    0]\n",
      " [ 535   13   34 ...,    0    0    0]\n",
      " [   1  541   10 ...,    0    0    0]]\n",
      " 73/200 [=========>....................] - ETA: 57s - loss: 1.5805 - acc: 0.8038[[3798  160  265 ...,    0    0    0]\n",
      " [  43   99 3083 ...,    0    0    0]\n",
      " [  22   13  736 ...,    0    0    0]\n",
      " ..., \n",
      " [1164   13    1 ...,    0    0    0]\n",
      " [  92 1800   67 ...,    0    0    0]\n",
      " [   1 4878    4 ...,    0    0    0]]\n",
      " 74/200 [==========>...................] - ETA: 56s - loss: 1.5794 - acc: 0.8040[[   17   431 11930 ...,     0     0     0]\n",
      " [ 1019  3939   103 ...,     0     0     0]\n",
      " [ 1164     1    13 ...,     0     0     0]\n",
      " ..., \n",
      " [  367    27   269 ...,     0     0     0]\n",
      " [  219    26   441 ...,     0     0     0]\n",
      " [ 1905   809  7684 ...,     0     0     0]]\n",
      " 75/200 [==========>...................] - ETA: 56s - loss: 1.5799 - acc: 0.8040[[   1 2105  941 ...,    0    0    0]\n",
      " [1324 4909   69 ...,    0    0    0]\n",
      " [   2  397 5043 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   69  297 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [6741 2232   23 ...,    0    0    0]]\n",
      " 76/200 [==========>...................] - ETA: 56s - loss: 1.5797 - acc: 0.8041[[ 214   23    1 ...,    0    0    0]\n",
      " [  13  301  155 ...,    0    0    0]\n",
      " [ 373  423   55 ...,    0    0    0]\n",
      " ..., \n",
      " [1005    9 7106 ...,    0    0    0]\n",
      " [5992   69 3226 ...,    0    0    0]\n",
      " [ 373  423   55 ...,    0    0    0]]\n",
      " 77/200 [==========>...................] - ETA: 55s - loss: 1.5787 - acc: 0.8042[[5937 1321 5794 ...,    0    0    0]\n",
      " [   1   13 3967 ...,    0    0    0]\n",
      " [  49  919 7088 ...,    0    0    0]\n",
      " ..., \n",
      " [1137 3695    4 ...,    0    0    0]\n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [   1   13   91 ...,    0    0    0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 78/200 [==========>...................] - ETA: 55s - loss: 1.5781 - acc: 0.8044[[  89   14   39 ...,    0    0    0]\n",
      " [ 481   66 1215 ...,    0    0    0]\n",
      " [   1  868   26 ...,    0    0    0]\n",
      " ..., \n",
      " [ 179  946  677 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [3491  680   13 ...,    0    0    0]]\n",
      " 79/200 [==========>...................] - ETA: 54s - loss: 1.5793 - acc: 0.8043[[ 108   68   23 ...,    0    0    0]\n",
      " [   2   19  417 ...,    0    0    0]\n",
      " [  55    7 2921 ...,    0    0    0]\n",
      " ..., \n",
      " [ 456  187  687 ...,    0    0    0]\n",
      " [ 241    7 8494 ...,    0    0    0]\n",
      " [  13 4086 3289 ...,    0    0    0]]\n",
      " 80/200 [===========>..................] - ETA: 54s - loss: 1.5799 - acc: 0.8042[[  47   15   14 ...,    0    0    0]\n",
      " [2012    5  142 ...,    0    0    0]\n",
      " [4418   11 2389 ...,    0    0    0]\n",
      " ..., \n",
      " [1449 1148   13 ...,    0    0    0]\n",
      " [   1 3494  161 ...,    0    0    0]\n",
      " [  13 2654    4 ...,    0    0    0]]\n",
      " 81/200 [===========>..................] - ETA: 53s - loss: 1.5799 - acc: 0.8042[[  64   82  107 ...,    0    0    0]\n",
      " [ 276  178   13 ...,    0    0    0]\n",
      " [ 488    8    1 ...,    0    0    0]\n",
      " ..., \n",
      " [  34   61   98 ...,    0    0    0]\n",
      " [2022 2923  205 ...,    0    0    0]\n",
      " [ 109   26   65 ...,    0    0    0]]\n",
      " 82/200 [===========>..................] - ETA: 53s - loss: 1.5797 - acc: 0.8043[[   1   91   14 ...,    0    0    0]\n",
      " [ 325  829  662 ...,    0    0    0]\n",
      " [   3  356  767 ...,    0    0    0]\n",
      " ..., \n",
      " [ 390 3686    9 ...,    0    0    0]\n",
      " [ 226   13  284 ...,    0    0    0]\n",
      " [   1 1228  808 ...,    0    0    0]]\n",
      " 83/200 [===========>..................] - ETA: 52s - loss: 1.5798 - acc: 0.8043[[ 749   12    2 ...,    0    0    0]\n",
      " [   1   13 1666 ...,    0    0    0]\n",
      " [1536   13  385 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   13   13 ...,    0    0    0]\n",
      " [ 500  455    3 ...,    0    0    0]\n",
      " [  13 3939 4822 ...,    0    0    0]]\n",
      " 84/200 [===========>..................] - ETA: 52s - loss: 1.5798 - acc: 0.8043[[  647    13   462 ...,     0     0     0]\n",
      " [    1  1343    76 ...,     0     0     0]\n",
      " [   13  9175    14 ...,     0     0     0]\n",
      " ..., \n",
      " [ 5592 10575     5 ...,     0     0     0]\n",
      " [  241    13    18 ...,     0     0     0]\n",
      " [  967  1533     3 ...,     0     0     0]]\n",
      " 85/200 [===========>..................] - ETA: 51s - loss: 1.5782 - acc: 0.8044[[2455  424 1301 ...,    0    0    0]\n",
      " [ 380    7   13 ...,    0    0    0]\n",
      " [   1   38   62 ...,    0    0    0]\n",
      " ..., \n",
      " [ 316  583 1628 ...,    0    0    0]\n",
      " [ 304 3255 1010 ...,    0    0    0]\n",
      " [ 149  186   10 ...,    0    0    0]]\n",
      " 86/200 [===========>..................] - ETA: 51s - loss: 1.5751 - acc: 0.8047[[  795    13   363 ...,     0     0     0]\n",
      " [    1  1693  3716 ...,     0     0     0]\n",
      " [   13    13    13 ...,     0     0     0]\n",
      " ..., \n",
      " [ 3696    13  4556 ...,     0     0     0]\n",
      " [ 9945    13    86 ...,     0     0     0]\n",
      " [    1  1208 11348 ...,     0     0     0]]\n",
      " 87/200 [============>.................] - ETA: 51s - loss: 1.5714 - acc: 0.8050[[3292   13    5 ...,    0    0    0]\n",
      " [   2 8614 1737 ...,    0    0    0]\n",
      " [2939   13   14 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   13    7 ...,    0    0    0]\n",
      " [   4    1  145 ...,    0    0    0]\n",
      " [5850   13  128 ...,    0    0    0]]\n",
      " 88/200 [============>.................] - ETA: 50s - loss: 1.5681 - acc: 0.8053[[    2    13   146 ...,     0     0     0]\n",
      " [ 2525  5419 11672 ...,     0     0     0]\n",
      " [  491  2381    13 ...,     0     0     0]\n",
      " ..., \n",
      " [   49    13   851 ...,     0     0     0]\n",
      " [ 4385    13    14 ...,     0     0     0]\n",
      " [ 3791  1634   761 ...,     0     0     0]]\n",
      " 89/200 [============>.................] - ETA: 50s - loss: 1.5655 - acc: 0.8055[[ 2002  4124     9 ...,     0     0     0]\n",
      " [  280  1987     7 ...,     0     0     0]\n",
      " [ 4404    27 11508 ...,     0     0     0]\n",
      " ..., \n",
      " [ 2883  5521  4566 ...,     0     0     0]\n",
      " [  226     7   212 ...,     0     0     0]\n",
      " [   10   430    13 ...,     0     0     0]]\n",
      " 90/200 [============>.................] - ETA: 49s - loss: 1.5624 - acc: 0.8057[[ 131  491  522 ...,    0    0    0]\n",
      " [1862   30   24 ...,    0    0    0]\n",
      " [ 749   80  678 ...,    0    0    0]\n",
      " ..., \n",
      " [ 433  471   39 ...,    0    0    0]\n",
      " [ 345 3419 1044 ...,    0    0    0]\n",
      " [1550 1366    7 ...,    0    0    0]]\n",
      " 91/200 [============>.................] - ETA: 49s - loss: 1.5605 - acc: 0.8059[[5746 6464  253 ...,    0    0    0]\n",
      " [   4  444   13 ...,    0    0    0]\n",
      " [ 425   27  174 ...,    0    0    0]\n",
      " ..., \n",
      " [5814   13   14 ...,    0    0    0]\n",
      " [2642 2297   40 ...,    0    0    0]\n",
      " [   2  146 1129 ...,    0    0    0]]\n",
      " 92/200 [============>.................] - ETA: 48s - loss: 1.5602 - acc: 0.8059[[   1 5049 9636 ...,    0    0    0]\n",
      " [  55 1574    6 ...,    0    0    0]\n",
      " [2700    8 1429 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  429 1887 ...,    0    0    0]\n",
      " [   1 1245 1136 ...,    0    0    0]\n",
      " [   1   49   19 ...,    0    0    0]]\n",
      " 93/200 [============>.................] - ETA: 48s - loss: 1.5608 - acc: 0.8059[[ 108   68   67 ...,    0    0    0]\n",
      " [ 930   13  415 ...,    0    0    0]\n",
      " [ 621 1404 1184 ...,    0    0    0]\n",
      " ..., \n",
      " [   2  153 3973 ...,    0    0    0]\n",
      " [  80   41   14 ...,    0    0    0]\n",
      " [1761   23   13 ...,    0    0    0]]\n",
      " 94/200 [=============>................] - ETA: 47s - loss: 1.5622 - acc: 0.8057[[ 149   53    7 ...,    0    0    0]\n",
      " [  18 1167  513 ...,    0    0    0]\n",
      " [ 337    3  338 ...,    0    0    0]\n",
      " ..., \n",
      " [  15    7    1 ...,    0    0    0]\n",
      " [  72  155    1 ...,    0    0    0]\n",
      " [   3 2748    1 ...,    0    0    0]]\n",
      " 95/200 [=============>................] - ETA: 47s - loss: 1.5633 - acc: 0.8056[[ 105    9  385 ...,    0    0    0]\n",
      " [   6    1   13 ...,    0    0    0]\n",
      " [1696 7717   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 626   13   13 ...,    0    0    0]\n",
      " [2459 7832 1904 ...,    0    0    0]\n",
      " [  15  530    3 ...,    0    0    0]]\n",
      " 96/200 [=============>................] - ETA: 47s - loss: 1.5644 - acc: 0.8055[[ 416 2716    8 ...,    0    0    0]\n",
      " [ 245 1192    8 ...,    0    0    0]\n",
      " [ 137   13    1 ...,    0    0    0]\n",
      " ..., \n",
      " [ 317   34  525 ...,    0    0    0]\n",
      " [   1  181  170 ...,    0    0    0]\n",
      " [ 618   13    5 ...,    0    0    0]]\n",
      " 97/200 [=============>................] - ETA: 46s - loss: 1.5642 - acc: 0.8055[[  13 1163   12 ...,    0    0    0]\n",
      " [ 582 1211   10 ...,    0    0    0]\n",
      " [1063 6802 3370 ...,    0    0    0]\n",
      " ..., \n",
      " [ 137    7    4 ...,    0    0    0]\n",
      " [  10   63   13 ...,    0    0    0]\n",
      " [ 644   13  521 ...,    0    0    0]]\n",
      " 98/200 [=============>................] - ETA: 46s - loss: 1.5673 - acc: 0.8051[[  13 9256    7 ...,    0    0    0]\n",
      " [6629   13   30 ...,    0    0    0]\n",
      " [  60 2510    5 ...,    0    0    0]\n",
      " ..., \n",
      " [  18   68  265 ...,    0    0    0]\n",
      " [  56   13   63 ...,    0    0    0]\n",
      " [1952 1630   13 ...,    0    0    0]]\n",
      " 99/200 [=============>................] - ETA: 45s - loss: 1.5685 - acc: 0.8050[[ 535   41   37 ...,    0    0    0]\n",
      " [  93 1671   32 ...,    0    0    0]\n",
      " [  19  120    1 ...,    0    0    0]\n",
      " ..., \n",
      " [7200   13   11 ...,    0    0    0]\n",
      " [  10    2  146 ...,    0    0    0]\n",
      " [1246   13  816 ...,    0    0    0]]\n",
      "100/200 [==============>...............] - ETA: 45s - loss: 1.5723 - acc: 0.8045[[ 3470    13   626 ...,     0     0     0]\n",
      " [ 9663 10549    11 ...,     0     0     0]\n",
      " [ 6526    13   898 ...,     0     0     0]\n",
      " ..., \n",
      " [  250    98     1 ...,     0     0     0]\n",
      " [  947    13   684 ...,     0     0     0]\n",
      " [ 3362   105    21 ...,     0     0     0]]\n",
      "101/200 [==============>...............] - ETA: 44s - loss: 1.5723 - acc: 0.8046[[2697   50  105 ...,    0    0    0]\n",
      " [1344 3402 6866 ...,    0    0    0]\n",
      " [  10  276   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 202    1  463 ...,    0    0    0]\n",
      " [  15   27 1087 ...,    0    0    0]\n",
      " [  13  390 1415 ...,    0    0    0]]\n",
      "102/200 [==============>...............] - ETA: 44s - loss: 1.5732 - acc: 0.8045[[  260    13     7 ...,     0     0     0]\n",
      " [11288  2473  8019 ...,     0     0     0]\n",
      " [ 1524     2    74 ...,     0     0     0]\n",
      " ..., \n",
      " [ 2765    23   207 ...,     0     0     0]\n",
      " [  438    13  1232 ...,     0     0     0]\n",
      " [    1  2131    23 ...,     0     0     0]]\n",
      "103/200 [==============>...............] - ETA: 43s - loss: 1.5742 - acc: 0.8044[[  344     7    73 ...,     0     0     0]\n",
      " [  194 10634    34 ...,     0     0     0]\n",
      " [    1    78   177 ...,     0     0     0]\n",
      " ..., \n",
      " [   13  3645  3446 ...,     0     0     0]\n",
      " [    1    13  1442 ...,     0     0     0]\n",
      " [   15    11    45 ...,     0     0     0]]\n",
      "104/200 [==============>...............] - ETA: 43s - loss: 1.5733 - acc: 0.8046[[1153    1   13 ...,    0    0    0]\n",
      " [ 149   13  333 ...,    0    0    0]\n",
      " [ 233  358  222 ...,    0    0    0]\n",
      " ..., \n",
      " [ 341   13    6 ...,    0    0    0]\n",
      " [  70    1  611 ...,    0    0    0]\n",
      " [6586 6960    9 ...,    0    0    0]]\n",
      "105/200 [==============>...............] - ETA: 43s - loss: 1.5725 - acc: 0.8048[[  80  678    9 ...,    0    0    0]\n",
      " [ 746  117 4585 ...,    0    0    0]\n",
      " [   1  685  135 ...,    0    0    0]\n",
      " ..., \n",
      " [ 491   26  113 ...,    0    0    0]\n",
      " [ 579   11 1749 ...,    0    0    0]\n",
      " [   2  179 2444 ...,    0    0    0]]\n",
      "106/200 [==============>...............] - ETA: 42s - loss: 1.5730 - acc: 0.8047[[ 154   66    6 ...,    0    0    0]\n",
      " [  55    7 1937 ...,    0    0    0]\n",
      " [   2 1413 1260 ...,    0    0    0]\n",
      " ..., \n",
      " [1472    7   13 ...,    0    0    0]\n",
      " [   1   47  287 ...,    0    0    0]\n",
      " [   1 9181  199 ...,    0    0    0]]\n",
      "107/200 [===============>..............] - ETA: 42s - loss: 1.5724 - acc: 0.8048[[ 496   27 1663 ...,    0    0    0]\n",
      " [3491  389  209 ...,    0    0    0]\n",
      " [   1  931    5 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13  169 ...,    0    0    0]\n",
      " [ 496  217   55 ...,    0    0    0]\n",
      " [2562   26  113 ...,    0    0    0]]\n",
      "108/200 [===============>..............] - ETA: 41s - loss: 1.5721 - acc: 0.8049[[ 373  423   55 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " ..., \n",
      " [ 496  941 3279 ...,    0    0    0]\n",
      " [   1   13   10 ...,    0    0    0]\n",
      " [   2  845  282 ...,    0    0    0]]\n",
      "109/200 [===============>..............] - ETA: 41s - loss: 1.5726 - acc: 0.8049[[  456  1494   692 ...,     0     0     0]\n",
      " [    1    13    91 ...,     0     0     0]\n",
      " [ 1382  1963   231 ...,     0     0     0]\n",
      " ..., \n",
      " [    1 11353   191 ...,     0     0     0]\n",
      " [    1    47  3229 ...,     0     0     0]\n",
      " [  248  2193   209 ...,     0     0     0]]\n",
      "110/200 [===============>..............] - ETA: 40s - loss: 1.5724 - acc: 0.8050[[  58   59   26 ...,    0    0    0]\n",
      " [   1  156   55 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " ..., \n",
      " [1454    7   13 ...,    0    0    0]\n",
      " [ 503  960    3 ...,    0    0    0]\n",
      " [ 248  800 1733 ...,    0    0    0]]\n",
      "111/200 [===============>..............] - ETA: 40s - loss: 1.5728 - acc: 0.8049[[ 5687     9    39 ...,     0     0     0]\n",
      " [    1  2182   191 ...,     0     0     0]\n",
      " [  127   102   112 ...,     0     0     0]\n",
      " ..., \n",
      " [   15    14    13 ...,     0     0     0]\n",
      " [10926    11   130 ...,     0     0     0]\n",
      " [    1  4595     5 ...,     0     0     0]]\n",
      "112/200 [===============>..............] - ETA: 39s - loss: 1.5734 - acc: 0.8049[[3236 2644   11 ...,    0    0    0]\n",
      " [  10    1   19 ...,    0    0    0]\n",
      " [   1   19   37 ...,    0    0    0]\n",
      " ..., \n",
      " [ 746  117 2526 ...,    0    0    0]\n",
      " [1268 4298  265 ...,    0    0    0]\n",
      " [2082 2177   23 ...,    0    0    0]]\n",
      "113/200 [===============>..............] - ETA: 39s - loss: 1.5738 - acc: 0.8048[[  13   13   13 ...,    0    0    0]\n",
      " [2797 4842 2347 ...,    0    0    0]\n",
      " [   2 1809  405 ...,    0    0    0]\n",
      " ..., \n",
      " [ 606    7  232 ...,    0    0    0]\n",
      " [  89   27   20 ...,    0    0    0]\n",
      " [ 546  276  178 ...,    0    0    0]]\n",
      "114/200 [================>.............] - ETA: 38s - loss: 1.5738 - acc: 0.8048[[   1   13   91 ...,    0    0    0]\n",
      " [  15   14    1 ...,    0    0    0]\n",
      " [ 353   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [8129    7 3248 ...,    0    0    0]\n",
      " [ 353    8  603 ...,    0    0    0]\n",
      " [ 532    5  131 ...,    0    0    0]]\n",
      "115/200 [================>.............] - ETA: 38s - loss: 1.5736 - acc: 0.8049[[ 267  157    2 ...,    0    0    0]\n",
      " [3295    7   19 ...,    0    0    0]\n",
      " [  58   59    7 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 2248   63 ...,    0    0    0]\n",
      " [ 119  172    2 ...,    0    0    0]\n",
      " [   4    1 3064 ...,    0    0    0]]\n",
      "116/200 [================>.............] - ETA: 38s - loss: 1.5727 - acc: 0.8050[[ 868   13   13 ...,    0    0    0]\n",
      " [  13  119  157 ...,    0    0    0]\n",
      " [ 119   21 2208 ...,    0    0    0]\n",
      " ..., \n",
      " [  43  194 6631 ...,    0    0    0]\n",
      " [ 591 6515 3079 ...,    0    0    0]\n",
      " [ 280 1987    7 ...,    0    0    0]]\n",
      "117/200 [================>.............] - ETA: 37s - loss: 1.5697 - acc: 0.8053[[1742   11 3959 ...,    0    0    0]\n",
      " [   1  199 7911 ...,    0    0    0]\n",
      " [3989  604   13 ...,    0    0    0]\n",
      " ..., \n",
      " [2735 5332   83 ...,    0    0    0]\n",
      " [  13   11 1793 ...,    0    0    0]\n",
      " [4022 7272    8 ...,    0    0    0]]\n",
      "118/200 [================>.............] - ETA: 37s - loss: 1.5669 - acc: 0.8055[[   92   456   851 ...,     0     0     0]\n",
      " [11092  8523    11 ...,     0     0     0]\n",
      " [    1  2999    91 ...,     0     0     0]\n",
      " ..., \n",
      " [   16     1   602 ...,     0     0     0]\n",
      " [ 2525  5419  2506 ...,     0     0     0]\n",
      " [ 1653  4875  1136 ...,     0     0     0]]\n",
      "119/200 [================>.............] - ETA: 36s - loss: 1.5643 - acc: 0.8057[[   1  427 1856 ...,    0    0    0]\n",
      " [ 626 3961 3254 ...,    0    0    0]\n",
      " [   2 2024 2067 ...,    0    0    0]\n",
      " ..., \n",
      " [   2  485 3233 ...,    0    0    0]\n",
      " [ 226    7   13 ...,    0    0    0]\n",
      " [   2  440  405 ...,    0    0    0]]\n",
      "120/200 [=================>............] - ETA: 36s - loss: 1.5623 - acc: 0.8059[[   1 2503   56 ...,    0    0    0]\n",
      " [   1 2266  793 ...,    0    0    0]\n",
      " [  22 1423    4 ...,    0    0    0]\n",
      " ..., \n",
      " [2490  103   13 ...,    0    0    0]\n",
      " [  13 1804  128 ...,    0    0    0]\n",
      " [ 623  157    2 ...,    0    0    0]]\n",
      "121/200 [=================>............] - ETA: 35s - loss: 1.5610 - acc: 0.8060[[ 807 1855 4922 ...,    0    0    0]\n",
      " [ 654  145  103 ...,    0    0    0]\n",
      " [   1  785    9 ...,    0    0    0]\n",
      " ..., \n",
      " [2323 2339   13 ...,    0    0    0]\n",
      " [2698    7   13 ...,    0    0    0]\n",
      " [ 979   66  664 ...,    0    0    0]]\n",
      "122/200 [=================>............] - ETA: 35s - loss: 1.5596 - acc: 0.8061[[  109    26   106 ...,     0     0     0]\n",
      " [ 1500  7999   521 ...,     0     0     0]\n",
      " [    2    13   806 ...,     0     0     0]\n",
      " ..., \n",
      " [ 3022  6500   163 ...,     0     0     0]\n",
      " [    1 11634   245 ...,     0     0     0]\n",
      " [ 3909    69  2775 ...,     0     0     0]]\n",
      "123/200 [=================>............] - ETA: 34s - loss: 1.5594 - acc: 0.8061[[ 681 3499  887 ...,    0    0    0]\n",
      " [   2   13 2444 ...,    0    0    0]\n",
      " [  13   13   27 ...,    0    0    0]\n",
      " ..., \n",
      " [2033   90    2 ...,    0    0    0]\n",
      " [  15    9    2 ...,    0    0    0]\n",
      " [ 827 1400 1298 ...,    0    0    0]]\n",
      "124/200 [=================>............] - ETA: 34s - loss: 1.5607 - acc: 0.8059[[ 706 1296    5 ...,    0    0    0]\n",
      " [   1 9248    5 ...,    0    0    0]\n",
      " [ 531  163 1980 ...,    0    0    0]\n",
      " ..., \n",
      " [ 361 5218 1328 ...,    0    0    0]\n",
      " [  72   15    7 ...,    0    0    0]\n",
      " [  13   13   13 ...,    0    0    0]]\n",
      "125/200 [=================>............] - ETA: 34s - loss: 1.5618 - acc: 0.8058[[   4 1971    7 ...,    0    0    0]\n",
      " [ 630    7 1188 ...,    0    0    0]\n",
      " [ 264    9    2 ...,    0    0    0]\n",
      " ..., \n",
      " [ 137    2  417 ...,    0    0    0]\n",
      " [2434    7   74 ...,    0    0    0]\n",
      " [  57  125   13 ...,    0    0    0]]\n",
      "126/200 [=================>............] - ETA: 33s - loss: 1.5631 - acc: 0.8056[[   1 1130    9 ...,    0    0    0]\n",
      " [1433   76    1 ...,    0    0    0]\n",
      " [ 585 7398   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 630    7  512 ...,    0    0    0]\n",
      " [2481 2736   11 ...,    0    0    0]\n",
      " [   1 5535   13 ...,    0    0    0]]\n",
      "127/200 [==================>...........] - ETA: 33s - loss: 1.5644 - acc: 0.8055[[  15    7   45 ...,    0    0    0]\n",
      " [2861  103  887 ...,    0    0    0]\n",
      " [6448   13    7 ...,    0    0    0]\n",
      " ..., \n",
      " [ 234  290   96 ...,    0    0    0]\n",
      " [ 325  829   13 ...,    0    0    0]\n",
      " [ 879   13   30 ...,    0    0    0]]\n",
      "128/200 [==================>...........] - ETA: 32s - loss: 1.5641 - acc: 0.8056[[   10    63    13 ...,     0     0     0]\n",
      " [    1    13 11795 ...,     0     0     0]\n",
      " [    4    22  1829 ...,     0     0     0]\n",
      " ..., \n",
      " [  222  2013    21 ...,     0     0     0]\n",
      " [  233   670  3884 ...,     0     0     0]\n",
      " [   70    15   392 ...,     0     0     0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/200 [==================>...........] - ETA: 32s - loss: 1.5661 - acc: 0.8054[[  41  516    5 ...,    0    0    0]\n",
      " [  13   26  115 ...,    0    0    0]\n",
      " [4122 3172 2726 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  474  429 ...,    0    0    0]\n",
      " [  13  301  354 ...,    0    0    0]\n",
      " [   1  897 1175 ...,    0    0    0]]\n",
      "130/200 [==================>...........] - ETA: 31s - loss: 1.5670 - acc: 0.8053[[  18 1387    4 ...,    0    0    0]\n",
      " [7131   13    9 ...,    0    0    0]\n",
      " [ 108   89  320 ...,    0    0    0]\n",
      " ..., \n",
      " [3587   13  128 ...,    0    0    0]\n",
      " [  13 3861   14 ...,    0    0    0]\n",
      " [ 131 1003 2940 ...,    0    0    0]]\n",
      "131/200 [==================>...........] - ETA: 31s - loss: 1.5704 - acc: 0.8049[[   1 5576  467 ...,    0    0    0]\n",
      " [  13    3  809 ...,    0    0    0]\n",
      " [ 343 3183  384 ...,    0    0    0]\n",
      " ..., \n",
      " [  15    7  155 ...,    0    0    0]\n",
      " [   1   38   95 ...,    0    0    0]\n",
      " [ 228 3503  114 ...,    0    0    0]]\n",
      "132/200 [==================>...........] - ETA: 30s - loss: 1.5700 - acc: 0.8050[[ 108    1 6103 ...,    0    0    0]\n",
      " [5401   21  256 ...,    0    0    0]\n",
      " [   1 2393  294 ...,    0    0    0]\n",
      " ..., \n",
      " [ 242   38  271 ...,    0    0    0]\n",
      " [  13  695   14 ...,    0    0    0]\n",
      " [   4    1  274 ...,    0    0    0]]\n",
      "133/200 [==================>...........] - ETA: 30s - loss: 1.5708 - acc: 0.8050[[    6    33    13 ...,     0     0     0]\n",
      " [  234   290   144 ...,     0     0     0]\n",
      " [ 2270  1190    90 ...,     0     0     0]\n",
      " ..., \n",
      " [ 4686  8679 11273 ...,     0     0     0]\n",
      " [  108  1209  2508 ...,     0     0     0]\n",
      " [   34   400    77 ...,     0     0     0]]\n",
      "134/200 [===================>..........] - ETA: 29s - loss: 1.5721 - acc: 0.8048[[ 232  725  141 ...,    0    0    0]\n",
      " [ 276  178   13 ...,    0    0    0]\n",
      " [4359 4673  247 ...,    0    0    0]\n",
      " ..., \n",
      " [2792 1898   81 ...,    0    0    0]\n",
      " [6292   13    9 ...,    0    0    0]\n",
      " [  19  226    7 ...,    0    0    0]]\n",
      "135/200 [===================>..........] - ETA: 29s - loss: 1.5720 - acc: 0.8049[[1188    1 4704 ...,    0    0    0]\n",
      " [  13   15    7 ...,    0    0    0]\n",
      " [  93   67  190 ...,    0    0    0]\n",
      " ..., \n",
      " [ 406   13    1 ...,    0    0    0]\n",
      " [  68   21   41 ...,    0    0    0]\n",
      " [ 986 1865  105 ...,    0    0    0]]\n",
      "136/200 [===================>..........] - ETA: 29s - loss: 1.5710 - acc: 0.8050[[   2   37   32 ...,    0    0    0]\n",
      " [  22 2679   13 ...,    0    0    0]\n",
      " [2334    2 8471 ...,    0    0    0]\n",
      " ..., \n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]]\n",
      "137/200 [===================>..........] - ETA: 28s - loss: 1.5713 - acc: 0.8050[[4062   13    2 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [1434   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  868   91 ...,    0    0    0]\n",
      " [   1   19  274 ...,    0    0    0]\n",
      " [  55    7  655 ...,    0    0    0]]\n",
      "138/200 [===================>..........] - ETA: 28s - loss: 1.5712 - acc: 0.8050[[1357    8  797 ...,    0    0    0]\n",
      " [  18  194   18 ...,    0    0    0]\n",
      " [   1  220   91 ...,    0    0    0]\n",
      " ..., \n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [  55   11 4380 ...,    0    0    0]\n",
      " [  12  296   13 ...,    0    0    0]]\n",
      "139/200 [===================>..........] - ETA: 27s - loss: 1.5716 - acc: 0.8050[[2504 1870 3322 ...,    0    0    0]\n",
      " [ 140  609   73 ...,    0    0    0]\n",
      " [  13  808    5 ...,    0    0    0]\n",
      " ..., \n",
      " [  55    8  284 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [ 491   26  113 ...,    0    0    0]]\n",
      "140/200 [====================>.........] - ETA: 27s - loss: 1.5712 - acc: 0.8051[[ 481   66  115 ...,    0    0    0]\n",
      " [   1   13  140 ...,    0    0    0]\n",
      " [ 318    8  913 ...,    0    0    0]\n",
      " ..., \n",
      " [2157   27  487 ...,    0    0    0]\n",
      " [  54   13 2972 ...,    0    0    0]\n",
      " [3359   67  289 ...,    0    0    0]]\n",
      "141/200 [====================>.........] - ETA: 26s - loss: 1.5716 - acc: 0.8050[[  58   59   26 ...,    0    0    0]\n",
      " [ 167  187   65 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " ..., \n",
      " [  58   59    7 ...,    0    0    0]\n",
      " [  38  170 4160 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]]\n",
      "142/200 [====================>.........] - ETA: 26s - loss: 1.5717 - acc: 0.8050[[  58   59   26 ...,    0    0    0]\n",
      " [ 220   26   65 ...,    0    0    0]\n",
      " [  55    7   73 ...,    0    0    0]\n",
      " ..., \n",
      " [ 342  196    4 ...,    0    0    0]\n",
      " [ 342  196    4 ...,    0    0    0]\n",
      " [1757  154   66 ...,    0    0    0]]\n",
      "143/200 [====================>.........] - ETA: 25s - loss: 1.5717 - acc: 0.8050[[  1  78  13 ...,   0   0   0]\n",
      " [501   6  33 ...,   0   0   0]\n",
      " [ 38 825 433 ...,   0   0   0]\n",
      " ..., \n",
      " [501   6  24 ...,   0   0   0]\n",
      " [325 829 662 ...,   0   0   0]\n",
      " [824   6  28 ...,   0   0   0]]\n",
      "144/200 [====================>.........] - ETA: 25s - loss: 1.5720 - acc: 0.8050[[  70   15  392 ...,    0    0    0]\n",
      " [8464 2259   67 ...,    0    0    0]\n",
      " [   2 4067 2268 ...,    0    0    0]\n",
      " ..., \n",
      " [  99  255   73 ...,    0    0    0]\n",
      " [ 819   26   65 ...,    0    0    0]\n",
      " [  48  950    6 ...,    0    0    0]]\n",
      "145/200 [====================>.........] - ETA: 24s - loss: 1.5728 - acc: 0.8049[[1431  450   86 ...,    0    0    0]\n",
      " [  38   13   13 ...,    0    0    0]\n",
      " [   1  424   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 442  216   51 ...,    0    0    0]\n",
      " [ 159 1832   14 ...,    0    0    0]\n",
      " [  13  694  103 ...,    0    0    0]]\n",
      "146/200 [====================>.........] - ETA: 24s - loss: 1.5729 - acc: 0.8049[[   2 2444   14 ...,    0    0    0]\n",
      " [ 919   69 7067 ...,    0    0    0]\n",
      " [ 107   10 1555 ...,    0    0    0]\n",
      " ..., \n",
      " [ 433    7 2066 ...,    0    0    0]\n",
      " [1189  150   26 ...,    0    0    0]\n",
      " [1600   11  511 ...,    0    0    0]]\n",
      "147/200 [=====================>........] - ETA: 24s - loss: 1.5736 - acc: 0.8048[[   1   13   91 ...,    0    0    0]\n",
      " [ 422  755   11 ...,    0    0    0]\n",
      " [   2 2321 4020 ...,    0    0    0]\n",
      " ..., \n",
      " [2095  745 2520 ...,    0    0    0]\n",
      " [ 206   66  115 ...,    0    0    0]\n",
      " [3365 5674  850 ...,    0    0    0]]\n",
      "148/200 [=====================>........] - ETA: 23s - loss: 1.5712 - acc: 0.8051[[    1    13    91 ...,     0     0     0]\n",
      " [ 8738   139     7 ...,     0     0     0]\n",
      " [    1  2897   188 ...,     0     0     0]\n",
      " ..., \n",
      " [  644  8658     7 ...,     0     0     0]\n",
      " [   89    23    80 ...,     0     0     0]\n",
      " [11134  1064    13 ...,     0     0     0]]\n",
      "149/200 [=====================>........] - ETA: 23s - loss: 1.5685 - acc: 0.8053[[3833 2322   13 ...,    0    0    0]\n",
      " [ 284    7   13 ...,    0    0    0]\n",
      " [ 481  176  196 ...,    0    0    0]\n",
      " ..., \n",
      " [1701 4256 2968 ...,    0    0    0]\n",
      " [3313 1131   32 ...,    0    0    0]\n",
      " [  64   82  590 ...,    0    0    0]]\n",
      "150/200 [=====================>........] - ETA: 22s - loss: 1.5666 - acc: 0.8054[[1275  650  217 ...,    0    0    0]\n",
      " [ 986  721    5 ...,    0    0    0]\n",
      " [3318 9332  114 ...,    0    0    0]\n",
      " ..., \n",
      " [2555 2115  141 ...,    0    0    0]\n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [   2  146 1214 ...,    0    0    0]]\n",
      "151/200 [=====================>........] - ETA: 22s - loss: 1.5649 - acc: 0.8056[[ 119   21   13 ...,    0    0    0]\n",
      " [3135   13   13 ...,    0    0    0]\n",
      " [   1  221  230 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 1007  674 ...,    0    0    0]\n",
      " [3587 7061    7 ...,    0    0    0]\n",
      " [  15   14    2 ...,    0    0    0]]\n",
      "152/200 [=====================>........] - ETA: 21s - loss: 1.5631 - acc: 0.8057[[   2 1373   13 ...,    0    0    0]\n",
      " [ 154   66    4 ...,    0    0    0]\n",
      " [ 167    4   13 ...,    0    0    0]\n",
      " ..., \n",
      " [3689 3693    9 ...,    0    0    0]\n",
      " [4040  505   13 ...,    0    0    0]\n",
      " [  22 1738   13 ...,    0    0    0]]\n",
      "153/200 [=====================>........] - ETA: 21s - loss: 1.5612 - acc: 0.8058[[   2  221  230 ...,    0    0    0]\n",
      " [  19  344 1113 ...,    0    0    0]\n",
      " [2237 1642   13 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  132 2251 ...,    0    0    0]\n",
      " [  64 8144   82 ...,    0    0    0]\n",
      " [ 255  598   23 ...,    0    0    0]]\n",
      "154/200 [======================>.......] - ETA: 20s - loss: 1.5600 - acc: 0.8060[[  819    26   182 ...,     0     0     0]\n",
      " [ 1792    11  1048 ...,     0     0     0]\n",
      " [ 3054   130   131 ...,     0     0     0]\n",
      " ..., \n",
      " [ 1364 11506     9 ...,     0     0     0]\n",
      " [  413   558    11 ...,     0     0     0]\n",
      " [   34   188     7 ...,     0     0     0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155/200 [======================>.......] - ETA: 20s - loss: 1.5608 - acc: 0.8059[[ 293    7 2445 ...,    0    0    0]\n",
      " [  18 2693   13 ...,    0    0    0]\n",
      " [3643 1207 2940 ...,    0    0    0]\n",
      " ..., \n",
      " [7456 9503   11 ...,    0    0    0]\n",
      " [ 280 1987  190 ...,    0    0    0]\n",
      " [8321 8845 8425 ...,    0    0    0]]\n",
      "156/200 [======================>.......] - ETA: 20s - loss: 1.5611 - acc: 0.8059[[    1    13   506 ...,     0     0     0]\n",
      " [  150  2173    13 ...,     0     0     0]\n",
      " [    2   538   123 ...,     0     0     0]\n",
      " ..., \n",
      " [ 1111   135   811 ...,     0     0     0]\n",
      " [  159  4081    81 ...,     0     0     0]\n",
      " [ 4482    13 11705 ...,     0     0     0]]\n",
      "157/200 [======================>.......] - ETA: 19s - loss: 1.5614 - acc: 0.8058[[ 873  374  289 ...,    0    0    0]\n",
      " [ 317   13   13 ...,    0    0    0]\n",
      " [2142  747 2705 ...,    0    0    0]\n",
      " ..., \n",
      " [  53    7  137 ...,    0    0    0]\n",
      " [   1   78  150 ...,    0    0    0]\n",
      " [ 633 1936   13 ...,    0    0    0]]\n",
      "158/200 [======================>.......] - ETA: 19s - loss: 1.5621 - acc: 0.8057[[   1 9492   38 ...,    0    0    0]\n",
      " [ 658    4   13 ...,    0    0    0]\n",
      " [  13   13   44 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 2039  361 ...,    0    0    0]\n",
      " [   1  459    7 ...,    0    0    0]\n",
      " [ 301   23  787 ...,    0    0    0]]\n",
      "159/200 [======================>.......] - ETA: 18s - loss: 1.5620 - acc: 0.8057[[  27 9816 3873 ...,    0    0    0]\n",
      " [ 865   13  301 ...,    0    0    0]\n",
      " [  10    2 3216 ...,    0    0    0]\n",
      " ..., \n",
      " [  10 2453 7036 ...,    0    0    0]\n",
      " [   4   40 4165 ...,    0    0    0]\n",
      " [  15    7   48 ...,    0    0    0]]\n",
      "160/200 [=======================>......] - ETA: 18s - loss: 1.5616 - acc: 0.8058[[ 184  810    1 ...,    0    0    0]\n",
      " [  13 1442   79 ...,    0    0    0]\n",
      " [1733   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 202    1 5659 ...,    0    0    0]\n",
      " [5691 1345    9 ...,    0    0    0]\n",
      " [   3 1428  116 ...,    0    0    0]]\n",
      "161/200 [=======================>......] - ETA: 17s - loss: 1.5634 - acc: 0.8056[[  943    13 11557 ...,     0     0     0]\n",
      " [   12     1   645 ...,     0     0     0]\n",
      " [ 3140    13  6136 ...,     0     0     0]\n",
      " ..., \n",
      " [   15     7   776 ...,     0     0     0]\n",
      " [ 1698     4     1 ...,     0     0     0]\n",
      " [   13  2336    21 ...,     0     0     0]]\n",
      "162/200 [=======================>......] - ETA: 17s - loss: 1.5650 - acc: 0.8054[[ 535  133   39 ...,    0    0    0]\n",
      " [ 873 2778 9301 ...,    0    0    0]\n",
      " [  13   13  802 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   49   13 ...,    0    0    0]\n",
      " [   1 7520   19 ...,    0    0    0]\n",
      " [ 161  426 1053 ...,    0    0    0]]\n",
      "163/200 [=======================>......] - ETA: 16s - loss: 1.5661 - acc: 0.8053[[ 108   68   13 ...,    0    0    0]\n",
      " [  13  104   21 ...,    0    0    0]\n",
      " [2365   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [  75  103  626 ...,    0    0    0]\n",
      " [ 276  178   13 ...,    0    0    0]\n",
      " [  10  383    2 ...,    0    0    0]]\n",
      "164/200 [=======================>......] - ETA: 16s - loss: 1.5690 - acc: 0.8050[[   13    26    67 ...,     0     0     0]\n",
      " [    1   179   161 ...,     0     0     0]\n",
      " [ 5206 10059     5 ...,     0     0     0]\n",
      " ..., \n",
      " [   90    99  1156 ...,     0     0     0]\n",
      " [    6     1   310 ...,     0     0     0]\n",
      " [ 1720    13     7 ...,     0     0     0]]\n",
      "165/200 [=======================>......] - ETA: 15s - loss: 1.5675 - acc: 0.8052[[    1   127    13 ...,     0     0     0]\n",
      " [    2   287     5 ...,     0     0     0]\n",
      " [   93    23   428 ...,     0     0     0]\n",
      " ..., \n",
      " [  606    13   606 ...,     0     0     0]\n",
      " [    1   794    11 ...,     0     0     0]\n",
      " [  584 10173  1345 ...,     0     0     0]]\n",
      "166/200 [=======================>......] - ETA: 15s - loss: 1.5688 - acc: 0.8050[[ 535    1 3629 ...,    0    0    0]\n",
      " [3685 6496   14 ...,    0    0    0]\n",
      " [ 276  178   13 ...,    0    0    0]\n",
      " ..., \n",
      " [5680   13  141 ...,    0    0    0]\n",
      " [2142  252  103 ...,    0    0    0]\n",
      " [6137   13 2621 ...,    0    0    0]]\n",
      "167/200 [========================>.....] - ETA: 15s - loss: 1.5694 - acc: 0.8050[[3485 8007   11 ...,    0    0    0]\n",
      " [  13   13  292 ...,    0    0    0]\n",
      " [  13   13    9 ...,    0    0    0]\n",
      " ..., \n",
      " [ 349    9   76 ...,    0    0    0]\n",
      " [  13   13   11 ...,    0    0    0]\n",
      " [  18 1530   13 ...,    0    0    0]]\n",
      "168/200 [========================>.....] - ETA: 14s - loss: 1.5693 - acc: 0.8050[[1768   13 1425 ...,    0    0    0]\n",
      " [3679    4 5243 ...,    0    0    0]\n",
      " [3138  105 1980 ...,    0    0    0]\n",
      " ..., \n",
      " [3022 2349 1585 ...,    0    0    0]\n",
      " [  15    7  229 ...,    0    0    0]\n",
      " [   1  221  230 ...,    0    0    0]]\n",
      "169/200 [========================>.....] - ETA: 14s - loss: 1.5686 - acc: 0.8052[[4791   13   27 ...,    0    0    0]\n",
      " [   6   25  151 ...,    0    0    0]\n",
      " [ 702  123  338 ...,    0    0    0]\n",
      " ..., \n",
      " [  15  265  107 ...,    0    0    0]\n",
      " [6796   63 1105 ...,    0    0    0]\n",
      " [  73   66 2451 ...,    0    0    0]]\n",
      "170/200 [========================>.....] - ETA: 13s - loss: 1.5693 - acc: 0.8051[[   4   13   13 ...,    0    0    0]\n",
      " [  13   13 5118 ...,    0    0    0]\n",
      " [  13  690 2463 ...,    0    0    0]\n",
      " ..., \n",
      " [1588   69   13 ...,    0    0    0]\n",
      " [ 219  970 2002 ...,    0    0    0]\n",
      " [   1  956   55 ...,    0    0    0]]\n",
      "171/200 [========================>.....] - ETA: 13s - loss: 1.5701 - acc: 0.8051[[   2 2487   32 ...,    0    0    0]\n",
      " [  13   69  297 ...,    0    0    0]\n",
      " [2181    7 1802 ...,    0    0    0]\n",
      " ..., \n",
      " [ 140  369    8 ...,    0    0    0]\n",
      " [ 491   26  113 ...,    0    0    0]\n",
      " [1396    6    2 ...,    0    0    0]]\n",
      "172/200 [========================>.....] - ETA: 12s - loss: 1.5700 - acc: 0.8051[[4946 2438 2101 ...,    0    0    0]\n",
      " [  19  352 1400 ...,    0    0    0]\n",
      " [4245   13    4 ...,    0    0    0]\n",
      " ..., \n",
      " [6465  172   12 ...,    0    0    0]\n",
      " [ 131  395  456 ...,    0    0    0]\n",
      " [   1   13 1847 ...,    0    0    0]]\n",
      "173/200 [========================>.....] - ETA: 12s - loss: 1.5700 - acc: 0.8051[[ 763 9690   21 ...,    0    0    0]\n",
      " [ 373  423   55 ...,    0    0    0]\n",
      " [   1   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 2893 2824 ...,    0    0    0]\n",
      " [  55    8 4432 ...,    0    0    0]\n",
      " [  13  792   86 ...,    0    0    0]]\n",
      "174/200 [=========================>....] - ETA: 11s - loss: 1.5700 - acc: 0.8051[[ 844    8 3029 ...,    0    0    0]\n",
      " [1910   55    7 ...,    0    0    0]\n",
      " [   1  220   73 ...,    0    0    0]\n",
      " ..., \n",
      " [ 937   13   13 ...,    0    0    0]\n",
      " [   1 1008 2973 ...,    0    0    0]\n",
      " [   1   13  191 ...,    0    0    0]]\n",
      "175/200 [=========================>....] - ETA: 11s - loss: 1.5702 - acc: 0.8051[[  58   59   26 ...,    0    0    0]\n",
      " [   1  740    5 ...,    0    0    0]\n",
      " [6094 7169  130 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  740    5 ...,    0    0    0]\n",
      " [  13 1056 6390 ...,    0    0    0]\n",
      " [ 154  635  143 ...,    0    0    0]]\n",
      "176/200 [=========================>....] - ETA: 10s - loss: 1.5698 - acc: 0.8051[[ 481   66   14 ...,    0    0    0]\n",
      " [  49   13  704 ...,    0    0    0]\n",
      " [ 167  187  106 ...,    0    0    0]\n",
      " ..., \n",
      " [1339 1553   11 ...,    0    0    0]\n",
      " [1635   13    9 ...,    0    0    0]\n",
      " [2589    5  220 ...,    0    0    0]]\n",
      "177/200 [=========================>....] - ETA: 10s - loss: 1.5699 - acc: 0.8051[[   1  132  509 ...,    0    0    0]\n",
      " [1896  187   65 ...,    0    0    0]\n",
      " [2395   13  100 ...,    0    0    0]\n",
      " ..., \n",
      " [ 185 1780   21 ...,    0    0    0]\n",
      " [ 255  154   66 ...,    0    0    0]\n",
      " [ 524   10   22 ...,    0    0    0]]\n",
      "178/200 [=========================>....] - ETA: 10s - loss: 1.5702 - acc: 0.8051[[   16  5877 11689 ...,     0     0     0]\n",
      " [11630    13    13 ...,     0     0     0]\n",
      " [    1    13    13 ...,     0     0     0]\n",
      " ..., \n",
      " [   13    13   253 ...,     0     0     0]\n",
      " [    1    13  4128 ...,     0     0     0]\n",
      " [   15   448    29 ...,     0     0     0]]\n",
      "179/200 [=========================>....] - ETA: 9s - loss: 1.5706 - acc: 0.8051 [[    1    13   879 ...,     0     0     0]\n",
      " [  364   375   411 ...,     0     0     0]\n",
      " [ 6528 11277  6082 ...,     0     0     0]\n",
      " ..., \n",
      " [10681 10044   253 ...,     0     0     0]\n",
      " [  481   176    66 ...,     0     0     0]\n",
      " [    1   919   736 ...,     0     0     0]]\n",
      "180/200 [==========================>...] - ETA: 9s - loss: 1.5707 - acc: 0.8051[[ 1360    13     9 ...,     0     0     0]\n",
      " [ 2196   418   335 ...,     0     0     0]\n",
      " [   15   247   234 ...,     0     0     0]\n",
      " ..., \n",
      " [10926     8    13 ...,     0     0     0]\n",
      " [   92  1755  3347 ...,     0     0     0]\n",
      " [  206    66    23 ...,     0     0     0]]\n",
      "181/200 [==========================>...] - ETA: 8s - loss: 1.5699 - acc: 0.8052[[   41     5     1 ...,     0     0     0]\n",
      " [10509 11024    83 ...,     0     0     0]\n",
      " [  131   248    85 ...,     0     0     0]\n",
      " ..., \n",
      " [   13    13     1 ...,     0     0     0]\n",
      " [ 1090  9071   461 ...,     0     0     0]\n",
      " [ 1491  2550  1950 ...,     0     0     0]]\n",
      "182/200 [==========================>...] - ETA: 8s - loss: 1.5682 - acc: 0.8053[[  70  152  139 ...,    0    0    0]\n",
      " [ 987    7  615 ...,    0    0    0]\n",
      " [2151   11    2 ...,    0    0    0]\n",
      " ..., \n",
      " [ 109   26  115 ...,    0    0    0]\n",
      " [1150   13   13 ...,    0    0    0]\n",
      " [   2 3865 1346 ...,    0    0    0]]\n",
      "183/200 [==========================>...] - ETA: 7s - loss: 1.5663 - acc: 0.8055[[   1 8252    5 ...,    0    0    0]\n",
      " [   1  474 1341 ...,    0    0    0]\n",
      " [ 500    7   19 ...,    0    0    0]\n",
      " ..., \n",
      " [ 962 6266    8 ...,    0    0    0]\n",
      " [   2  121 8811 ...,    0    0    0]\n",
      " [  56   13  397 ...,    0    0    0]]\n",
      "184/200 [==========================>...] - ETA: 7s - loss: 1.5646 - acc: 0.8056[[   4    1  117 ...,    0    0    0]\n",
      " [  13    7   13 ...,    0    0    0]\n",
      " [   1 4920    5 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  145  608 ...,    0    0    0]\n",
      " [   2   13  150 ...,    0    0    0]\n",
      " [1170  159  390 ...,    0    0    0]]\n",
      "185/200 [==========================>...] - ETA: 6s - loss: 1.5630 - acc: 0.8057[[2567 2560  217 ...,    0    0    0]\n",
      " [   2 1147   32 ...,    0    0    0]\n",
      " [  89   14 2631 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 5475    5 ...,    0    0    0]\n",
      " [ 955  814    5 ...,    0    0    0]\n",
      " [ 284    7   69 ...,    0    0    0]]\n",
      "186/200 [==========================>...] - ETA: 6s - loss: 1.5613 - acc: 0.8059[[3756   13    8 ...,    0    0    0]\n",
      " [2490    7  732 ...,    0    0    0]\n",
      " [  73   13    4 ...,    0    0    0]\n",
      " ..., \n",
      " [3236 2644   27 ...,    0    0    0]\n",
      " [1507   10 1061 ...,    0    0    0]\n",
      " [5489    7  390 ...,    0    0    0]]\n",
      "187/200 [===========================>..] - ETA: 5s - loss: 1.5600 - acc: 0.8060[[   2 1624 2642 ...,    0    0    0]\n",
      " [   2 1580 1048 ...,    0    0    0]\n",
      " [   1  261  401 ...,    0    0    0]\n",
      " ..., \n",
      " [   2  763  740 ...,    0    0    0]\n",
      " [  89  105   20 ...,    0    0    0]\n",
      " [1757 1483   27 ...,    0    0    0]]\n",
      "188/200 [===========================>..] - ETA: 5s - loss: 1.5590 - acc: 0.8060[[    2    74    56 ...,     0     0     0]\n",
      " [    1   528   142 ...,     0     0     0]\n",
      " [ 6686  8975  1850 ...,     0     0     0]\n",
      " ..., \n",
      " [    1   221   230 ...,     0     0     0]\n",
      " [ 1162  8454  2103 ...,     0     0     0]\n",
      " [11856  1993    11 ...,     0     0     0]]\n",
      "189/200 [===========================>..] - ETA: 5s - loss: 1.5585 - acc: 0.8061[[   1 3135  161 ...,    0    0    0]\n",
      " [3282 3426   11 ...,    0    0    0]\n",
      " [4182 2308   11 ...,    0    0    0]\n",
      " ..., \n",
      " [ 497   13   69 ...,    0    0    0]\n",
      " [ 280   13  100 ...,    0    0    0]\n",
      " [7546   13 1564 ...,    0    0    0]]\n",
      "190/200 [===========================>..] - ETA: 4s - loss: 1.5585 - acc: 0.8061[[   13    69   297 ...,     0     0     0]\n",
      " [ 2558  1063  8611 ...,     0     0     0]\n",
      " [ 3549   130   131 ...,     0     0     0]\n",
      " ..., \n",
      " [    1    91   106 ...,     0     0     0]\n",
      " [ 2461   900  3066 ...,     0     0     0]\n",
      " [11627   779    13 ...,     0     0     0]]\n",
      "191/200 [===========================>..] - ETA: 4s - loss: 1.5595 - acc: 0.8060[[  109    26    65 ...,     0     0     0]\n",
      " [  893   232 11645 ...,     0     0     0]\n",
      " [   89   684    20 ...,     0     0     0]\n",
      " ..., \n",
      " [    1   549     5 ...,     0     0     0]\n",
      " [  108  1350   543 ...,     0     0     0]\n",
      " [    5    79     1 ...,     0     0     0]]\n",
      "192/200 [===========================>..] - ETA: 3s - loss: 1.5597 - acc: 0.8060[[ 606    9 2477 ...,    0    0    0]\n",
      " [  89  684   20 ...,    0    0    0]\n",
      " [  13 2652 1558 ...,    0    0    0]\n",
      " ..., \n",
      " [1746 1574 6367 ...,    0    0    0]\n",
      " [ 508   15    1 ...,    0    0    0]\n",
      " [ 194    5    1 ...,    0    0    0]]\n",
      "193/200 [===========================>..] - ETA: 3s - loss: 1.5608 - acc: 0.8059[[    6     1  5556 ...,     0     0     0]\n",
      " [ 5526    13     1 ...,     0     0     0]\n",
      " [  108  4713    51 ...,     0     0     0]\n",
      " ..., \n",
      " [10537   558    30 ...,     0     0     0]\n",
      " [   13    13   430 ...,     0     0     0]\n",
      " [ 7029    13     9 ...,     0     0     0]]\n",
      "194/200 [============================>.] - ETA: 2s - loss: 1.5601 - acc: 0.8060[[   49    63   144 ...,     0     0     0]\n",
      " [11254    13    13 ...,     0     0     0]\n",
      " [ 1851     9  2938 ...,     0     0     0]\n",
      " ..., \n",
      " [   13    13   221 ...,     0     0     0]\n",
      " [  584     1  7157 ...,     0     0     0]\n",
      " [   13  8426  6054 ...,     0     0     0]]\n",
      "195/200 [============================>.] - ETA: 2s - loss: 1.5605 - acc: 0.8059[[   1 2324    5 ...,    0    0    0]\n",
      " [  13  104   21 ...,    0    0    0]\n",
      " [2543    1 1744 ...,    0    0    0]\n",
      " ..., \n",
      " [9196 5800    7 ...,    0    0    0]\n",
      " [  81   42 7503 ...,    0    0    0]\n",
      " [   1  166  371 ...,    0    0    0]]\n",
      "196/200 [============================>.] - ETA: 1s - loss: 1.5619 - acc: 0.8058[[1384   15   51 ...,    0    0    0]\n",
      " [  12   47  643 ...,    0    0    0]\n",
      " [  13    3 2537 ...,    0    0    0]\n",
      " ..., \n",
      " [  13 1432   10 ...,    0    0    0]\n",
      " [1386    7   73 ...,    0    0    0]\n",
      " [3954   13  192 ...,    0    0    0]]\n",
      "197/200 [============================>.] - ETA: 1s - loss: 1.5633 - acc: 0.8056[[   1 3955    9 ...,    0    0    0]\n",
      " [   1 2943  217 ...,    0    0    0]\n",
      " [ 278    1   63 ...,    0    0    0]\n",
      " ..., \n",
      " [ 439   90   34 ...,    0    0    0]\n",
      " [  32  155    6 ...,    0    0    0]\n",
      " [9404  375 8160 ...,    0    0    0]]\n",
      "198/200 [============================>.] - ETA: 0s - loss: 1.5648 - acc: 0.8054[[ 116  163  157 ...,    0    0    0]\n",
      " [ 220  324  209 ...,    0    0    0]\n",
      " [   1 1130   14 ...,    0    0    0]\n",
      " ..., \n",
      " [  13    1  681 ...,    0    0    0]\n",
      " [ 104  107 3647 ...,    0    0    0]\n",
      " [  12    1  908 ...,    0    0    0]]\n",
      "199/200 [============================>.] - ETA: 0s - loss: 1.5649 - acc: 0.8055[[1811    7   47 ...,    0    0    0]\n",
      " [  93   67   13 ...,    0    0    0]\n",
      " [3884  176  298 ...,    0    0    0]\n",
      " ..., \n",
      " [ 531   67  207 ...,    0    0    0]\n",
      " [  27 2828  247 ...,    0    0    0]\n",
      " [  13 2635   67 ...,    0    0    0]]\n",
      "200/200 [==============================] - 90s - loss: 1.5654 - acc: 0.8054    \n",
      "Epoch 10/10\n",
      "[[7069  123    7 ...,    0    0    0]\n",
      " [  13   13  200 ...,    0    0    0]\n",
      " [   1 1443   67 ...,    0    0    0]\n",
      " ..., \n",
      " [   4   22  408 ...,    0    0    0]\n",
      " [  10   63   13 ...,    0    0    0]\n",
      " [  18   22   13 ...,    0    0    0]]\n",
      "  1/200 [..............................] - ETA: 85s - loss: 1.7565 - acc: 0.7825[[  13    6    1 ...,    0    0    0]\n",
      " [  27 1415  128 ...,    0    0    0]\n",
      " [   1  831   99 ...,    0    0    0]\n",
      " ..., \n",
      " [ 116   13 9748 ...,    0    0    0]\n",
      " [5391   13   13 ...,    0    0    0]\n",
      " [   1 6447   13 ...,    0    0    0]]\n",
      "  2/200 [..............................] - ETA: 85s - loss: 1.6739 - acc: 0.7918[[   1 1769 2672 ...,    0    0    0]\n",
      " [ 557  733   13 ...,    0    0    0]\n",
      " [ 427   21 2318 ...,    0    0    0]\n",
      " ..., \n",
      " [ 108   93  959 ...,    0    0    0]\n",
      " [1304   23    2 ...,    0    0    0]\n",
      " [  12   34  692 ...,    0    0    0]]\n",
      "  3/200 [..............................] - ETA: 85s - loss: 1.6051 - acc: 0.8016[[  80   41  384 ...,    0    0    0]\n",
      " [   1  474  558 ...,    0    0    0]\n",
      " [  15   27  257 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   13   13 ...,    0    0    0]\n",
      " [  18    1  381 ...,    0    0    0]\n",
      " [ 958 5040  747 ...,    0    0    0]]\n",
      "  4/200 [..............................] - ETA: 85s - loss: 1.5974 - acc: 0.8034[[  10   34   13 ...,    0    0    0]\n",
      " [1853  135 2585 ...,    0    0    0]\n",
      " [  70   15  392 ...,    0    0    0]\n",
      " ..., \n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [ 109   26   65 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5/200 [..............................] - ETA: 85s - loss: 1.6162 - acc: 0.8017[[4504 3102    1 ...,    0    0    0]\n",
      " [2504    8 1654 ...,    0    0    0]\n",
      " [   1  286    5 ...,    0    0    0]\n",
      " ..., \n",
      " [ 599  102    4 ...,    0    0    0]\n",
      " [1247   11  850 ...,    0    0    0]\n",
      " [5164   21  269 ...,    0    0    0]]\n",
      "  6/200 [..............................] - ETA: 84s - loss: 1.6004 - acc: 0.8032[[   1   47 2903 ...,    0    0    0]\n",
      " [   2   13 3238 ...,    0    0    0]\n",
      " [   1 2059 1158 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  214   23 ...,    0    0    0]\n",
      " [ 167 1865   13 ...,    0    0    0]\n",
      " [2017   67  694 ...,    0    0    0]]\n",
      "  7/200 [>.............................] - ETA: 84s - loss: 1.5941 - acc: 0.8037[[   1 3635    5 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " ..., \n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [2562   26  249 ...,    0    0    0]\n",
      " [  55   11 3290 ...,    0    0    0]]\n",
      "  8/200 [>.............................] - ETA: 84s - loss: 1.5968 - acc: 0.8035[[1267   26  113 ...,    0    0    0]\n",
      " [ 167  161  162 ...,    0    0    0]\n",
      " [ 234  435  167 ...,    0    0    0]\n",
      " ..., \n",
      " [1863   13   69 ...,    0    0    0]\n",
      " [  38  481  176 ...,    0    0    0]\n",
      " [   1 3317  310 ...,    0    0    0]]\n",
      "  9/200 [>.............................] - ETA: 83s - loss: 1.5860 - acc: 0.8049[[ 109   26  113 ...,    0    0    0]\n",
      " [  55  231   53 ...,    0    0    0]\n",
      " [1695  736 1528 ...,    0    0    0]\n",
      " ..., \n",
      " [  55   11 1220 ...,    0    0    0]\n",
      " [   1 1653 1614 ...,    0    0    0]\n",
      " [ 444 5769   40 ...,    0    0    0]]\n",
      " 10/200 [>.............................] - ETA: 83s - loss: 1.5885 - acc: 0.8050[[  19  352   30 ...,    0    0    0]\n",
      " [1757  119   27 ...,    0    0    0]\n",
      " [ 193   27  971 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  161  657 ...,    0    0    0]\n",
      " [   1  156 8704 ...,    0    0    0]\n",
      " [2198   69 8009 ...,    0    0    0]]\n",
      " 11/200 [>.............................] - ETA: 82s - loss: 1.5920 - acc: 0.8044[[  55   11 2025 ...,    0    0    0]\n",
      " [  58   59    7 ...,    0    0    0]\n",
      " [  49 1839    4 ...,    0    0    0]\n",
      " ..., \n",
      " [ 553  509   13 ...,    0    0    0]\n",
      " [ 342  196   66 ...,    0    0    0]\n",
      " [  32    2 2393 ...,    0    0    0]]\n",
      " 12/200 [>.............................] - ETA: 82s - loss: 1.5926 - acc: 0.8043[[1848  249   13 ...,    0    0    0]\n",
      " [   2   13 1373 ...,    0    0    0]\n",
      " [ 501  154   66 ...,    0    0    0]\n",
      " ..., \n",
      " [  55  100    1 ...,    0    0    0]\n",
      " [  55    7   13 ...,    0    0    0]\n",
      " [5591 5759    5 ...,    0    0    0]]\n",
      " 13/200 [>.............................] - ETA: 82s - loss: 1.5909 - acc: 0.8050[[ 131  179   69 ...,    0    0    0]\n",
      " [1745 3701    4 ...,    0    0    0]\n",
      " [1695  424  240 ...,    0    0    0]\n",
      " ..., \n",
      " [2323 2339  587 ...,    0    0    0]\n",
      " [1109    7  660 ...,    0    0    0]\n",
      " [   2 6148   74 ...,    0    0    0]]\n",
      " 14/200 [=>............................] - ETA: 81s - loss: 1.5874 - acc: 0.8054[[ 109   26  268 ...,    0    0    0]\n",
      " [ 447  200    9 ...,    0    0    0]\n",
      " [6526   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 514 2246   13 ...,    0    0    0]\n",
      " [ 108 6764   13 ...,    0    0    0]\n",
      " [  42   14 7660 ...,    0    0    0]]\n",
      " 15/200 [=>............................] - ETA: 81s - loss: 1.5769 - acc: 0.8058[[5230  558   83 ...,    0    0    0]\n",
      " [  13  800  390 ...,    0    0    0]\n",
      " [2535 6304   28 ...,    0    0    0]\n",
      " ..., \n",
      " [6992   11 1402 ...,    0    0    0]\n",
      " [ 299    5   19 ...,    0    0    0]\n",
      " [7181  721    7 ...,    0    0    0]]\n",
      " 16/200 [=>............................] - ETA: 80s - loss: 1.5547 - acc: 0.8070[[  55    7 4530 ...,    0    0    0]\n",
      " [   1  601    5 ...,    0    0    0]\n",
      " [   2  582  405 ...,    0    0    0]\n",
      " ..., \n",
      " [2002 4124 1060 ...,    0    0    0]\n",
      " [2000    5 3866 ...,    0    0    0]\n",
      " [  26   67   84 ...,    0    0    0]]\n",
      " 17/200 [=>............................] - ETA: 80s - loss: 1.5321 - acc: 0.8089[[  429  1887   484 ...,     0     0     0]\n",
      " [10146   971  9777 ...,     0     0     0]\n",
      " [  133    39  1899 ...,     0     0     0]\n",
      " ..., \n",
      " [ 9355 10993    11 ...,     0     0     0]\n",
      " [   22    13     9 ...,     0     0     0]\n",
      " [ 5353   963    13 ...,     0     0     0]]\n",
      " 18/200 [=>............................] - ETA: 80s - loss: 1.5165 - acc: 0.8101[[ 276  178   13 ...,    0    0    0]\n",
      " [1573 2461  450 ...,    0    0    0]\n",
      " [1727  812   13 ...,    0    0    0]\n",
      " ..., \n",
      " [1431  450    9 ...,    0    0    0]\n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [  26  113   88 ...,    0    0    0]]\n",
      " 19/200 [=>............................] - ETA: 79s - loss: 1.5013 - acc: 0.8110[[  15 1312   79 ...,    0    0    0]\n",
      " [1267  970 5527 ...,    0    0    0]\n",
      " [ 155  790 2047 ...,    0    0    0]\n",
      " ..., \n",
      " [5274 6861   11 ...,    0    0    0]\n",
      " [ 685  720 1150 ...,    0    0    0]\n",
      " [2371  532 1090 ...,    0    0    0]]\n",
      " 20/200 [==>...........................] - ETA: 79s - loss: 1.4904 - acc: 0.8118[[ 819   26   65 ...,    0    0    0]\n",
      " [  15   27   20 ...,    0    0    0]\n",
      " [1046  332 4746 ...,    0    0    0]\n",
      " ..., \n",
      " [   2   19  432 ...,    0    0    0]\n",
      " [ 131   69  309 ...,    0    0    0]\n",
      " [   1   13 3709 ...,    0    0    0]]\n",
      " 21/200 [==>...........................] - ETA: 79s - loss: 1.4790 - acc: 0.8127[[  22 1830   13 ...,    0    0    0]\n",
      " [1644 4243   13 ...,    0    0    0]\n",
      " [2160    2   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 706 3156   21 ...,    0    0    0]\n",
      " [  22  529 1376 ...,    0    0    0]\n",
      " [ 654  145    9 ...,    0    0    0]]\n",
      " 22/200 [==>...........................] - ETA: 78s - loss: 1.4692 - acc: 0.8133[[   2  440 3626 ...,    0    0    0]\n",
      " [ 150 4118 1345 ...,    0    0    0]\n",
      " [6629   27 3067 ...,    0    0    0]\n",
      " ..., \n",
      " [4526 2393 3885 ...,    0    0    0]\n",
      " [5829    7  732 ...,    0    0    0]\n",
      " [  13  761 6404 ...,    0    0    0]]\n",
      " 23/200 [==>...........................] - ETA: 78s - loss: 1.4628 - acc: 0.8139[[   2  676 2398 ...,    0    0    0]\n",
      " [ 792    7   13 ...,    0    0    0]\n",
      " [3408  157    2 ...,    0    0    0]\n",
      " ..., \n",
      " [3007    4  672 ...,    0    0    0]\n",
      " [ 226  752   13 ...,    0    0    0]\n",
      " [5933 5876 1425 ...,    0    0    0]]\n",
      " 24/200 [==>...........................] - ETA: 77s - loss: 1.4654 - acc: 0.8134[[ 226 1448  280 ...,    0    0    0]\n",
      " [   1  145  608 ...,    0    0    0]\n",
      " [ 807 4022   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 381  228  615 ...,    0    0    0]\n",
      " [   2 4374 9858 ...,    0    0    0]\n",
      " [  49 7088   21 ...,    0    0    0]]\n",
      " 25/200 [==>...........................] - ETA: 77s - loss: 1.4675 - acc: 0.8134[[ 676   19  352 ...,    0    0    0]\n",
      " [ 221  230  782 ...,    0    0    0]\n",
      " [5028   13  100 ...,    0    0    0]\n",
      " ..., \n",
      " [  15   14 1222 ...,    0    0    0]\n",
      " [  56  430    2 ...,    0    0    0]\n",
      " [   1   73  138 ...,    0    0    0]]\n",
      " 26/200 [==>...........................] - ETA: 77s - loss: 1.4802 - acc: 0.8121[[   1   13   91 ...,    0    0    0]\n",
      " [   1 3272 1040 ...,    0    0    0]\n",
      " [   1  330   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 219  324  209 ...,    0    0    0]\n",
      " [ 219  414  808 ...,    0    0    0]\n",
      " [ 697 1295  268 ...,    0    0    0]]\n",
      " 27/200 [===>..........................] - ETA: 76s - loss: 1.4824 - acc: 0.8119[[324 209  13 ...,   0   0   0]\n",
      " [745  11  39 ...,   0   0   0]\n",
      " [ 13   7 131 ...,   0   0   0]\n",
      " ..., \n",
      " [  4   1  38 ...,   0   0   0]\n",
      " [ 15   7   2 ...,   0   0   0]\n",
      " [ 43  41  13 ...,   0   0   0]]\n",
      " 28/200 [===>..........................] - ETA: 76s - loss: 1.4859 - acc: 0.8116[[  13 1578   15 ...,    0    0    0]\n",
      " [1578   13  105 ...,    0    0    0]\n",
      " [  70  159 1505 ...,    0    0    0]\n",
      " ..., \n",
      " [ 102  123 1944 ...,    0    0    0]\n",
      " [ 158  165    6 ...,    0    0    0]\n",
      " [   1   49   19 ...,    0    0    0]]\n",
      " 29/200 [===>..........................] - ETA: 75s - loss: 1.4916 - acc: 0.8111[[  41  237 1212 ...,    0    0    0]\n",
      " [2343   13    9 ...,    0    0    0]\n",
      " [   1   13  124 ...,    0    0    0]\n",
      " ..., \n",
      " [2265 3954    9 ...,    0    0    0]\n",
      " [ 104 1585   96 ...,    0    0    0]\n",
      " [   1   13 1459 ...,    0    0    0]]\n",
      " 30/200 [===>..........................] - ETA: 75s - loss: 1.4939 - acc: 0.8111[[  13   27 1181 ...,    0    0    0]\n",
      " [  13   15    7 ...,    0    0    0]\n",
      " [ 730   13 1067 ...,    0    0    0]\n",
      " ..., \n",
      " [  13  301 1384 ...,    0    0    0]\n",
      " [ 309  451   11 ...,    0    0    0]\n",
      " [   1 1017  182 ...,    0    0    0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 31/200 [===>..........................] - ETA: 75s - loss: 1.5059 - acc: 0.8099[[ 463   27   20 ...,    0    0    0]\n",
      " [ 194  563  374 ...,    0    0    0]\n",
      " [  56   13   63 ...,    0    0    0]\n",
      " ..., \n",
      " [ 443  900    7 ...,    0    0    0]\n",
      " [3491   26  619 ...,    0    0    0]\n",
      " [1940  536   13 ...,    0    0    0]]\n",
      " 32/200 [===>..........................] - ETA: 74s - loss: 1.5150 - acc: 0.8090[[ 626    8 6161 ...,    0    0    0]\n",
      " [ 232   13 3343 ...,    0    0    0]\n",
      " [   1  751 2224 ...,    0    0    0]\n",
      " ..., \n",
      " [1014   13  381 ...,    0    0    0]\n",
      " [   2  259 2110 ...,    0    0    0]\n",
      " [3578  510   24 ...,    0    0    0]]\n",
      " 33/200 [===>..........................] - ETA: 74s - loss: 1.5212 - acc: 0.8084[[    1  4995    86 ...,     0     0     0]\n",
      " [   93  1163    13 ...,     0     0     0]\n",
      " [   15     7  2204 ...,     0     0     0]\n",
      " ..., \n",
      " [  458  3535     9 ...,     0     0     0]\n",
      " [  882   283    50 ...,     0     0     0]\n",
      " [   93 11772  1166 ...,     0     0     0]]\n",
      " 34/200 [====>.........................] - ETA: 73s - loss: 1.5335 - acc: 0.8071[[    1  1086   123 ...,     0     0     0]\n",
      " [    1   730  3049 ...,     0     0     0]\n",
      " [    1  1559  2887 ...,     0     0     0]\n",
      " ..., \n",
      " [  564    13  1068 ...,     0     0     0]\n",
      " [  116   589 11609 ...,     0     0     0]\n",
      " [   10    92   888 ...,     0     0     0]]\n",
      " 35/200 [====>.........................] - ETA: 73s - loss: 1.5347 - acc: 0.8071[[ 232 3459   81 ...,    0    0    0]\n",
      " [ 379  177   13 ...,    0    0    0]\n",
      " [  19  120  105 ...,    0    0    0]\n",
      " ..., \n",
      " [  70    2 5322 ...,    0    0    0]\n",
      " [  13 1171   13 ...,    0    0    0]\n",
      " [ 599   63 1105 ...,    0    0    0]]\n",
      " 36/200 [====>.........................] - ETA: 72s - loss: 1.5373 - acc: 0.8069[[   3 1141    2 ...,    0    0    0]\n",
      " [  13  104 2467 ...,    0    0    0]\n",
      " [  15  105   21 ...,    0    0    0]\n",
      " ..., \n",
      " [   4  552  173 ...,    0    0    0]\n",
      " [5707  610   11 ...,    0    0    0]\n",
      " [   1 5269   23 ...,    0    0    0]]\n",
      " 37/200 [====>.........................] - ETA: 72s - loss: 1.5457 - acc: 0.8061[[  166   234    63 ...,     0     0     0]\n",
      " [   13     9   407 ...,     0     0     0]\n",
      " [    4    13  4290 ...,     0     0     0]\n",
      " ..., \n",
      " [   70   193 11373 ...,     0     0     0]\n",
      " [ 1760   898     1 ...,     0     0     0]\n",
      " [   15     7    54 ...,     0     0     0]]\n",
      " 38/200 [====>.........................] - ETA: 71s - loss: 1.5430 - acc: 0.8064[[  72   29    7 ...,    0    0    0]\n",
      " [ 108    1   13 ...,    0    0    0]\n",
      " [ 304 1173  695 ...,    0    0    0]\n",
      " ..., \n",
      " [  99  102 2728 ...,    0    0    0]\n",
      " [2203   13  260 ...,    0    0    0]\n",
      " [ 382    3 2264 ...,    0    0    0]]\n",
      " 39/200 [====>.........................] - ETA: 71s - loss: 1.5419 - acc: 0.8066[[   1  629    5 ...,    0    0    0]\n",
      " [ 221  230   13 ...,    0    0    0]\n",
      " [  15    7   18 ...,    0    0    0]\n",
      " ..., \n",
      " [  34    9    1 ...,    0    0    0]\n",
      " [   1  526 2248 ...,    0    0    0]\n",
      " [   1  431    5 ...,    0    0    0]]\n",
      " 40/200 [=====>........................] - ETA: 71s - loss: 1.5413 - acc: 0.8069[[  26 1533   24 ...,    0    0    0]\n",
      " [  13  137    7 ...,    0    0    0]\n",
      " [   2 5193  165 ...,    0    0    0]\n",
      " ..., \n",
      " [  13 4006 7600 ...,    0    0    0]\n",
      " [ 108 3929   13 ...,    0    0    0]\n",
      " [  42   13    1 ...,    0    0    0]]\n",
      " 41/200 [=====>........................] - ETA: 70s - loss: 1.5462 - acc: 0.8064[[ 229    2   13 ...,    0    0    0]\n",
      " [  68 1108  377 ...,    0    0    0]\n",
      " [  90  244 6505 ...,    0    0    0]\n",
      " ..., \n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [ 248   85  295 ...,    0    0    0]]\n",
      " 42/200 [=====>........................] - ETA: 70s - loss: 1.5476 - acc: 0.8064[[    1   545   191 ...,     0     0     0]\n",
      " [    1   701     5 ...,     0     0     0]\n",
      " [  561    75   329 ...,     0     0     0]\n",
      " ..., \n",
      " [  561     8  1386 ...,     0     0     0]\n",
      " [11855   252   205 ...,     0     0     0]\n",
      " [  727     6    57 ...,     0     0     0]]\n",
      " 43/200 [=====>........................] - ETA: 69s - loss: 1.5490 - acc: 0.8063[[  58   59   26 ...,    0    0    0]\n",
      " [   2  146   11 ...,    0    0    0]\n",
      " [ 109   26  619 ...,    0    0    0]\n",
      " ..., \n",
      " [  55    6   28 ...,    0    0    0]\n",
      " [ 109   26 1452 ...,    0    0    0]\n",
      " [  38  481  176 ...,    0    0    0]]\n",
      " 44/200 [=====>........................] - ETA: 69s - loss: 1.5488 - acc: 0.8064[[ 214   23    1 ...,    0    0    0]\n",
      " [ 214   23    1 ...,    0    0    0]\n",
      " [ 214   23    1 ...,    0    0    0]\n",
      " ..., \n",
      " [ 546    6   25 ...,    0    0    0]\n",
      " [1717   13    5 ...,    0    0    0]\n",
      " [  13    9  498 ...,    0    0    0]]\n",
      " 45/200 [=====>........................] - ETA: 68s - loss: 1.5489 - acc: 0.8066[[   1   13  736 ...,    0    0    0]\n",
      " [ 167  187  113 ...,    0    0    0]\n",
      " [1337    7 2059 ...,    0    0    0]\n",
      " ..., \n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [ 119    4  140 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]]\n",
      " 46/200 [=====>........................] - ETA: 68s - loss: 1.5505 - acc: 0.8065[[   1   13   91 ...,    0    0    0]\n",
      " [  26   12 2893 ...,    0    0    0]\n",
      " [ 454  205 2072 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 2011  283 ...,    0    0    0]\n",
      " [ 219   73  138 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]]\n",
      " 47/200 [======>.......................] - ETA: 67s - loss: 1.5508 - acc: 0.8066[[    1    19   352 ...,     0     0     0]\n",
      " [  284   550   940 ...,     0     0     0]\n",
      " [ 2593 10809   555 ...,     0     0     0]\n",
      " ..., \n",
      " [10034   398  4821 ...,     0     0     0]\n",
      " [    1    55  2892 ...,     0     0     0]\n",
      " [  547  3499    13 ...,     0     0     0]]\n",
      " 48/200 [======>.......................] - ETA: 67s - loss: 1.5515 - acc: 0.8066[[  884  4570     6 ...,     0     0     0]\n",
      " [    1   956   199 ...,     0     0     0]\n",
      " [   58    59   975 ...,     0     0     0]\n",
      " ..., \n",
      " [ 3213  4089     5 ...,     0     0     0]\n",
      " [11193   532  3291 ...,     0     0     0]\n",
      " [ 1525   398    13 ...,     0     0     0]]\n",
      " 49/200 [======>.......................] - ETA: 67s - loss: 1.5525 - acc: 0.8065[[1757  187   65 ...,    0    0    0]\n",
      " [ 444   36  921 ...,    0    0    0]\n",
      " [ 342  196   66 ...,    0    0    0]\n",
      " ..., \n",
      " [1896  187  182 ...,    0    0    0]\n",
      " [  13 2757  455 ...,    0    0    0]\n",
      " [   1 1669 3689 ...,    0    0    0]]\n",
      " 50/200 [======>.......................] - ETA: 66s - loss: 1.5539 - acc: 0.8064[[   1  881  509 ...,    0    0    0]\n",
      " [  12  296   49 ...,    0    0    0]\n",
      " [  15    7   61 ...,    0    0    0]\n",
      " ..., \n",
      " [ 119    4 1910 ...,    0    0    0]\n",
      " [1275  650  103 ...,    0    0    0]\n",
      " [  13   13    5 ...,    0    0    0]]\n",
      " 51/200 [======>.......................] - ETA: 66s - loss: 1.5546 - acc: 0.8064[[ 2387    93   281 ...,     0     0     0]\n",
      " [11592    13    27 ...,     0     0     0]\n",
      " [ 1236    34     3 ...,     0     0     0]\n",
      " ..., \n",
      " [   10   152   139 ...,     0     0     0]\n",
      " [   13   192    39 ...,     0     0     0]\n",
      " [   13  1844    13 ...,     0     0     0]]\n",
      " 52/200 [======>.......................] - ETA: 65s - loss: 1.5503 - acc: 0.8065[[  92   13 4159 ...,    0    0    0]\n",
      " [ 171  108   15 ...,    0    0    0]\n",
      " [2455  119 2005 ...,    0    0    0]\n",
      " ..., \n",
      " [ 309 4293    9 ...,    0    0    0]\n",
      " [2991 1171  100 ...,    0    0    0]\n",
      " [ 206   65   12 ...,    0    0    0]]\n",
      " 53/200 [======>.......................] - ETA: 65s - loss: 1.5421 - acc: 0.8072[[ 224    9  539 ...,    0    0    0]\n",
      " [   1   13  223 ...,    0    0    0]\n",
      " [ 978 4090   14 ...,    0    0    0]\n",
      " ..., \n",
      " [6373   11  694 ...,    0    0    0]\n",
      " [   1 3530  692 ...,    0    0    0]\n",
      " [ 131  573  478 ...,    0    0    0]]\n",
      " 54/200 [=======>......................] - ETA: 65s - loss: 1.5357 - acc: 0.8077[[ 391    5   17 ...,    0    0    0]\n",
      " [  17 1583   13 ...,    0    0    0]\n",
      " [   2 2442 1103 ...,    0    0    0]\n",
      " ..., \n",
      " [1248 3664 2995 ...,    0    0    0]\n",
      " [1862   27 2804 ...,    0    0    0]\n",
      " [3289  604 2206 ...,    0    0    0]]\n",
      " 55/200 [=======>......................] - ETA: 64s - loss: 1.5305 - acc: 0.8080[[    1   132   509 ...,     0     0     0]\n",
      " [    4   173   472 ...,     0     0     0]\n",
      " [   80   160    67 ...,     0     0     0]\n",
      " ..., \n",
      " [ 7394  6442    14 ...,     0     0     0]\n",
      " [ 3597  7808   715 ...,     0     0     0]\n",
      " [ 2966 10273    13 ...,     0     0     0]]\n",
      " 56/200 [=======>......................] - ETA: 64s - loss: 1.5250 - acc: 0.8083[[11032    13   289 ...,     0     0     0]\n",
      " [   15   247  4604 ...,     0     0     0]\n",
      " [    4     2   430 ...,     0     0     0]\n",
      " ..., \n",
      " [   13    13    27 ...,     0     0     0]\n",
      " [    1  1912  3553 ...,     0     0     0]\n",
      " [ 1339  1553    27 ...,     0     0     0]]\n",
      " 57/200 [=======>......................] - ETA: 63s - loss: 1.5218 - acc: 0.8085[[   1 4023   21 ...,    0    0    0]\n",
      " [   1  884 1054 ...,    0    0    0]\n",
      " [  55    7 1263 ...,    0    0    0]\n",
      " ..., \n",
      " [   2 1373   13 ...,    0    0    0]\n",
      " [   2  633  417 ...,    0    0    0]\n",
      " [   1  456  732 ...,    0    0    0]]\n",
      " 58/200 [=======>......................] - ETA: 63s - loss: 1.5184 - acc: 0.8088[[  55    7 4244 ...,    0    0    0]\n",
      " [  26   21  691 ...,    0    0    0]\n",
      " [ 425  217   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 626 2846    7 ...,    0    0    0]\n",
      " [ 127   19  661 ...,    0    0    0]\n",
      " [   1 1610    5 ...,    0    0    0]]\n",
      " 59/200 [=======>......................] - ETA: 62s - loss: 1.5148 - acc: 0.8090[[ 545 2882  267 ...,    0    0    0]\n",
      " [ 488   11  336 ...,    0    0    0]\n",
      " [1546 1415 1270 ...,    0    0    0]\n",
      " ..., \n",
      " [  49 2455 9170 ...,    0    0    0]\n",
      " [1337   30   33 ...,    0    0    0]\n",
      " [ 987    7  705 ...,    0    0    0]]\n",
      " 60/200 [========>.....................] - ETA: 62s - loss: 1.5118 - acc: 0.8091[[  38  499  295 ...,    0    0    0]\n",
      " [4384  130  880 ...,    0    0    0]\n",
      " [1935  295 7857 ...,    0    0    0]\n",
      " ..., \n",
      " [ 116 2700    8 ...,    0    0    0]\n",
      " [4358   13 7852 ...,    0    0    0]\n",
      " [1172  720   13 ...,    0    0    0]]\n",
      " 61/200 [========>.....................] - ETA: 62s - loss: 1.5114 - acc: 0.8091[[1075  280    8 ...,    0    0    0]\n",
      " [   1  214   23 ...,    0    0    0]\n",
      " [ 987    6   36 ...,    0    0    0]\n",
      " ..., \n",
      " [ 485   13   19 ...,    0    0    0]\n",
      " [1753  135 1266 ...,    0    0    0]\n",
      " [3062    8 1597 ...,    0    0    0]]\n",
      " 62/200 [========>.....................] - ETA: 61s - loss: 1.5139 - acc: 0.8088[[3733   13 3322 ...,    0    0    0]\n",
      " [  15    7   48 ...,    0    0    0]\n",
      " [3674 2252    4 ...,    0    0    0]\n",
      " ..., \n",
      " [ 844  329   24 ...,    0    0    0]\n",
      " [ 109   26   67 ...,    0    0    0]\n",
      " [ 107   70   15 ...,    0    0    0]]\n",
      " 63/200 [========>.....................] - ETA: 61s - loss: 1.5126 - acc: 0.8091[[ 930 9779   14 ...,    0    0    0]\n",
      " [ 109   26  106 ...,    0    0    0]\n",
      " [1405    7 1096 ...,    0    0    0]\n",
      " ..., \n",
      " [ 390 3380   11 ...,    0    0    0]\n",
      " [ 790 2047    9 ...,    0    0    0]\n",
      " [ 131  488  103 ...,    0    0    0]]\n",
      " 64/200 [========>.....................] - ETA: 60s - loss: 1.5159 - acc: 0.8088[[1339 1553    9 ...,    0    0    0]\n",
      " [3194   13  165 ...,    0    0    0]\n",
      " [  13   13    9 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13  568 ...,    0    0    0]\n",
      " [4368 5452  265 ...,    0    0    0]\n",
      " [ 109  154   66 ...,    0    0    0]]\n",
      " 65/200 [========>.....................] - ETA: 60s - loss: 1.5173 - acc: 0.8087[[1597  196 2573 ...,    0    0    0]\n",
      " [  15   14 1237 ...,    0    0    0]\n",
      " [   1 3982   13 ...,    0    0    0]\n",
      " ..., \n",
      " [  16   22  355 ...,    0    0    0]\n",
      " [   2 2041 1874 ...,    0    0    0]\n",
      " [ 280 9433 4699 ...,    0    0    0]]\n",
      " 66/200 [========>.....................] - ETA: 59s - loss: 1.5208 - acc: 0.8083[[10386     4    34 ...,     0     0     0]\n",
      " [ 9006  2116     9 ...,     0     0     0]\n",
      " [    1  9067     5 ...,     0     0     0]\n",
      " ..., \n",
      " [ 8231  3112    13 ...,     0     0     0]\n",
      " [ 3279    11   385 ...,     0     0     0]\n",
      " [   44    13   857 ...,     0     0     0]]\n",
      " 67/200 [=========>....................] - ETA: 59s - loss: 1.5201 - acc: 0.8084[[10745   112    36 ...,     0     0     0]\n",
      " [    1   542     9 ...,     0     0     0]\n",
      " [   93    67     1 ...,     0     0     0]\n",
      " ..., \n",
      " [ 7442  2021  1913 ...,     0     0     0]\n",
      " [  107    70     1 ...,     0     0     0]\n",
      " [    4    64    82 ...,     0     0     0]]\n",
      " 68/200 [=========>....................] - ETA: 58s - loss: 1.5213 - acc: 0.8084[[   10    99  1044 ...,     0     0     0]\n",
      " [   15     9    48 ...,     0     0     0]\n",
      " [10062  6003     4 ...,     0     0     0]\n",
      " ..., \n",
      " [  165   349   252 ...,     0     0     0]\n",
      " [  949     3     1 ...,     0     0     0]\n",
      " [   26  2920    60 ...,     0     0     0]]\n",
      " 69/200 [=========>....................] - ETA: 58s - loss: 1.5254 - acc: 0.8079[[   1   13  400 ...,    0    0    0]\n",
      " [ 474    1 1475 ...,    0    0    0]\n",
      " [ 931  309   13 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   13    1 ...,    0    0    0]\n",
      " [  80  110    4 ...,    0    0    0]\n",
      " [   2 1762  368 ...,    0    0    0]]\n",
      " 70/200 [=========>....................] - ETA: 58s - loss: 1.5303 - acc: 0.8074[[ 531   23  149 ...,    0    0    0]\n",
      " [   1 2923  253 ...,    0    0    0]\n",
      " [4685   54   13 ...,    0    0    0]\n",
      " ..., \n",
      " [2965   13    7 ...,    0    0    0]\n",
      " [ 276   13   15 ...,    0    0    0]\n",
      " [   4    1 1161 ...,    0    0    0]]\n",
      " 71/200 [=========>....................] - ETA: 57s - loss: 1.5353 - acc: 0.8069[[ 350   21 2683 ...,    0    0    0]\n",
      " [2379  627  247 ...,    0    0    0]\n",
      " [   1 1341   86 ...,    0    0    0]\n",
      " ..., \n",
      " [  43 1798    5 ...,    0    0    0]\n",
      " [  15  448   29 ...,    0    0    0]\n",
      " [ 937   13    8 ...,    0    0    0]]\n",
      " 72/200 [=========>....................] - ETA: 57s - loss: 1.5384 - acc: 0.8065[[   3 4041    2 ...,    0    0    0]\n",
      " [  95    1   63 ...,    0    0    0]\n",
      " [   4 1408   13 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 2192  757 ...,    0    0    0]\n",
      " [ 893 3353 1117 ...,    0    0    0]\n",
      " [  34 1226   96 ...,    0    0    0]]\n",
      " 73/200 [=========>....................] - ETA: 56s - loss: 1.5369 - acc: 0.8068[[  49    5    1 ...,    0    0    0]\n",
      " [1500   13 6988 ...,    0    0    0]\n",
      " [   1  873   13 ...,    0    0    0]\n",
      " ..., \n",
      " [   4   13   13 ...,    0    0    0]\n",
      " [ 108   68   23 ...,    0    0    0]\n",
      " [ 232  725   14 ...,    0    0    0]]\n",
      " 74/200 [==========>...................] - ETA: 56s - loss: 1.5379 - acc: 0.8067[[  74    5    1 ...,    0    0    0]\n",
      " [ 187    5   13 ...,    0    0    0]\n",
      " [ 264  105   20 ...,    0    0    0]\n",
      " ..., \n",
      " [   4    1   78 ...,    0    0    0]\n",
      " [9224 1119  993 ...,    0    0    0]\n",
      " [ 221  230   13 ...,    0    0    0]]\n",
      " 75/200 [==========>...................] - ETA: 55s - loss: 1.5418 - acc: 0.8063[[  16  166   49 ...,    0    0    0]\n",
      " [   2 1983  302 ...,    0    0    0]\n",
      " [  13 1287   13 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13 1211 ...,    0    0    0]\n",
      " [5470    8   13 ...,    0    0    0]\n",
      " [4315 4331   81 ...,    0    0    0]]\n",
      " 76/200 [==========>...................] - ETA: 55s - loss: 1.5419 - acc: 0.8064[[   13    13    13 ...,     0     0     0]\n",
      " [  137     2  5678 ...,     0     0     0]\n",
      " [  721    74    13 ...,     0     0     0]\n",
      " ..., \n",
      " [ 9513 11644  2385 ...,     0     0     0]\n",
      " [  104  1340    80 ...,     0     0     0]\n",
      " [   85     1  3845 ...,     0     0     0]]\n",
      " 77/200 [==========>...................] - ETA: 54s - loss: 1.5409 - acc: 0.8066[[ 812   13    9 ...,    0    0    0]\n",
      " [6382 6947    9 ...,    0    0    0]\n",
      " [ 153  729  574 ...,    0    0    0]\n",
      " ..., \n",
      " [  89   23  702 ...,    0    0    0]\n",
      " [  13   23 5447 ...,    0    0    0]\n",
      " [ 299    5  474 ...,    0    0    0]]\n",
      " 78/200 [==========>...................] - ETA: 54s - loss: 1.5402 - acc: 0.8068[[   1 1676 4129 ...,    0    0    0]\n",
      " [  12    1 5062 ...,    0    0    0]\n",
      " [ 242   69  263 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   27 3418 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]]\n",
      " 79/200 [==========>...................] - ETA: 54s - loss: 1.5415 - acc: 0.8067[[  22  905 1755 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [   1 2065 2164 ...,    0    0    0]\n",
      " ..., \n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [   1  191    5 ...,    0    0    0]]\n",
      " 80/200 [===========>..................] - ETA: 53s - loss: 1.5413 - acc: 0.8068[[  58   59   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [   1 1522  433 ...,    0    0    0]\n",
      " ..., \n",
      " [ 214   23    1 ...,    0    0    0]\n",
      " [2079   12    1 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]]\n",
      " 81/200 [===========>..................] - ETA: 53s - loss: 1.5417 - acc: 0.8068[[ 140  609   73 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [   1   13 2164 ...,    0    0    0]\n",
      " ..., \n",
      " [ 444    9  155 ...,    0    0    0]\n",
      " [ 127   76    5 ...,    0    0    0]\n",
      " [7042 2036   75 ...,    0    0    0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 82/200 [===========>..................] - ETA: 52s - loss: 1.5412 - acc: 0.8069[[    2    13   701 ...,     0     0     0]\n",
      " [ 1189   224     7 ...,     0     0     0]\n",
      " [  200     7   176 ...,     0     0     0]\n",
      " ..., \n",
      " [    2    13 10143 ...,     0     0     0]\n",
      " [   13    26   182 ...,     0     0     0]\n",
      " [   42  1808    29 ...,     0     0     0]]\n",
      " 83/200 [===========>..................] - ETA: 52s - loss: 1.5416 - acc: 0.8070[[ 176   66  115 ...,    0    0    0]\n",
      " [   1  102    7 ...,    0    0    0]\n",
      " [ 167   69 3369 ...,    0    0    0]\n",
      " ..., \n",
      " [ 167   13   21 ...,    0    0    0]\n",
      " [4370 1038    8 ...,    0    0    0]\n",
      " [   2   13  167 ...,    0    0    0]]\n",
      " 84/200 [===========>..................] - ETA: 51s - loss: 1.5422 - acc: 0.8069[[ 131  226  398 ...,    0    0    0]\n",
      " [   1   13 1438 ...,    0    0    0]\n",
      " [   1   13   38 ...,    0    0    0]\n",
      " ..., \n",
      " [ 491   26  113 ...,    0    0    0]\n",
      " [ 727  292   13 ...,    0    0    0]\n",
      " [1221   13  941 ...,    0    0    0]]\n",
      " 85/200 [===========>..................] - ETA: 51s - loss: 1.5426 - acc: 0.8069[[ 109   26  113 ...,    0    0    0]\n",
      " [ 546 8112  200 ...,    0    0    0]\n",
      " [ 632  528  142 ...,    0    0    0]\n",
      " ..., \n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [   1   13   58 ...,    0    0    0]\n",
      " [1355 2777   13 ...,    0    0    0]]\n",
      " 86/200 [===========>..................] - ETA: 51s - loss: 1.5428 - acc: 0.8069[[9786 2086   13 ...,    0    0    0]\n",
      " [  13    4  429 ...,    0    0    0]\n",
      " [ 884   26  115 ...,    0    0    0]\n",
      " ..., \n",
      " [ 383   13   46 ...,    0    0    0]\n",
      " [1827   25  308 ...,    0    0    0]\n",
      " [  13 3689 3693 ...,    0    0    0]]\n",
      " 87/200 [============>.................] - ETA: 50s - loss: 1.5435 - acc: 0.8069[[  55  292  728 ...,    0    0    0]\n",
      " [  19  352   26 ...,    0    0    0]\n",
      " [8676   13    5 ...,    0    0    0]\n",
      " ..., \n",
      " [ 444 5335    1 ...,    0    0    0]\n",
      " [ 154   66    4 ...,    0    0    0]\n",
      " [1827   36 2934 ...,    0    0    0]]\n",
      " 88/200 [============>.................] - ETA: 50s - loss: 1.5449 - acc: 0.8068[[    1    19   352 ...,     0     0     0]\n",
      " [11098  3659     9 ...,     0     0     0]\n",
      " [  501   154    66 ...,     0     0     0]\n",
      " ..., \n",
      " [    1   529   223 ...,     0     0     0]\n",
      " [ 1454   100     1 ...,     0     0     0]\n",
      " [ 2405  7209   700 ...,     0     0     0]]\n",
      " 89/200 [============>.................] - ETA: 49s - loss: 1.5452 - acc: 0.8068[[   1   13   13 ...,    0    0    0]\n",
      " [   2  440  842 ...,    0    0    0]\n",
      " [ 255   73  240 ...,    0    0    0]\n",
      " ..., \n",
      " [ 109   26  115 ...,    0    0    0]\n",
      " [   1 2930   86 ...,    0    0    0]\n",
      " [3830 1927 1531 ...,    0    0    0]]\n",
      " 90/200 [============>.................] - ETA: 49s - loss: 1.5408 - acc: 0.8070[[  66    6    1 ...,    0    0    0]\n",
      " [ 726 2576 4672 ...,    0    0    0]\n",
      " [   2   13   12 ...,    0    0    0]\n",
      " ..., \n",
      " [  22   13  704 ...,    0    0    0]\n",
      " [   1   19  120 ...,    0    0    0]\n",
      " [2346 4931 7102 ...,    0    0    0]]\n",
      " 91/200 [============>.................] - ETA: 48s - loss: 1.5378 - acc: 0.8072[[   1  260  438 ...,    0    0    0]\n",
      " [ 849  394 1610 ...,    0    0    0]\n",
      " [ 356  767  484 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 3525  294 ...,    0    0    0]\n",
      " [  13 3323    9 ...,    0    0    0]\n",
      " [  10    2   13 ...,    0    0    0]]\n",
      " 92/200 [============>.................] - ETA: 48s - loss: 1.5338 - acc: 0.8075[[ 654  145  398 ...,    0    0    0]\n",
      " [   1 2181    8 ...,    0    0    0]\n",
      " [  49   64 4137 ...,    0    0    0]\n",
      " ..., \n",
      " [1337  217    1 ...,    0    0    0]\n",
      " [  15  336   64 ...,    0    0    0]\n",
      " [1536 4331   13 ...,    0    0    0]]\n",
      " 93/200 [============>.................] - ETA: 47s - loss: 1.5309 - acc: 0.8076[[4424 4371  227 ...,    0    0    0]\n",
      " [ 119  267  157 ...,    0    0    0]\n",
      " [4139  398 2129 ...,    0    0    0]\n",
      " ..., \n",
      " [2536 2391  212 ...,    0    0    0]\n",
      " [1224   69 4841 ...,    0    0    0]\n",
      " [   1   13  241 ...,    0    0    0]]\n",
      " 94/200 [=============>................] - ETA: 47s - loss: 1.5281 - acc: 0.8078[[3492 4168  766 ...,    0    0    0]\n",
      " [   1   13   86 ...,    0    0    0]\n",
      " [ 790 2426   11 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   11 2586 ...,    0    0    0]\n",
      " [ 206   66   21 ...,    0    0    0]\n",
      " [1282    7  732 ...,    0    0    0]]\n",
      " 95/200 [=============>................] - ETA: 47s - loss: 1.5256 - acc: 0.8081[[6829 5421    9 ...,    0    0    0]\n",
      " [3153 1924    4 ...,    0    0    0]\n",
      " [  13   13  312 ...,    0    0    0]\n",
      " ..., \n",
      " [6292 9645   11 ...,    0    0    0]\n",
      " [1742    7 6252 ...,    0    0    0]\n",
      " [1331   11 1992 ...,    0    0    0]]\n",
      " 96/200 [=============>................] - ETA: 46s - loss: 1.5229 - acc: 0.8083[[  150  1697    13 ...,     0     0     0]\n",
      " [ 4458     8 11411 ...,     0     0     0]\n",
      " [  158   268     4 ...,     0     0     0]\n",
      " ..., \n",
      " [    1    13   680 ...,     0     0     0]\n",
      " [    1  2657   680 ...,     0     0     0]\n",
      " [ 6308   694  5350 ...,     0     0     0]]\n",
      " 97/200 [=============>................] - ETA: 46s - loss: 1.5209 - acc: 0.8084[[ 623  157   22 ...,    0    0    0]\n",
      " [  69  297   13 ...,    0    0    0]\n",
      " [ 344   83   15 ...,    0    0    0]\n",
      " ..., \n",
      " [   2   13  282 ...,    0    0    0]\n",
      " [  13   13    1 ...,    0    0    0]\n",
      " [  13   13 2385 ...,    0    0    0]]\n",
      " 98/200 [=============>................] - ETA: 45s - loss: 1.5189 - acc: 0.8086[[ 727   30   25 ...,    0    0    0]\n",
      " [ 119  462    8 ...,    0    0    0]\n",
      " [ 719  137    1 ...,    0    0    0]\n",
      " ..., \n",
      " [  13 8281 2278 ...,    0    0    0]\n",
      " [   2   13 1489 ...,    0    0    0]\n",
      " [ 708   82    2 ...,    0    0    0]]\n",
      " 99/200 [=============>................] - ETA: 45s - loss: 1.5178 - acc: 0.8087[[ 547 1206    2 ...,    0    0    0]\n",
      " [  19  120  662 ...,    0    0    0]\n",
      " [   2 1779  321 ...,    0    0    0]\n",
      " ..., \n",
      " [6404   27 5918 ...,    0    0    0]\n",
      " [1680   13  484 ...,    0    0    0]\n",
      " [   1  167  117 ...,    0    0    0]]\n",
      "100/200 [==============>...............] - ETA: 44s - loss: 1.5185 - acc: 0.8086[[1046   11  510 ...,    0    0    0]\n",
      " [  15    7  461 ...,    0    0    0]\n",
      " [  15 1272 1322 ...,    0    0    0]\n",
      " ..., \n",
      " [ 116    5    1 ...,    0    0    0]\n",
      " [5209   13   83 ...,    0    0    0]\n",
      " [   1 1547 1127 ...,    0    0    0]]\n",
      "101/200 [==============>...............] - ETA: 44s - loss: 1.5207 - acc: 0.8085[[  790  3805    11 ...,     0     0     0]\n",
      " [ 1635 10089    13 ...,     0     0     0]\n",
      " [ 1052     8  1465 ...,     0     0     0]\n",
      " ..., \n",
      " [  206   113    24 ...,     0     0     0]\n",
      " [  220    13    21 ...,     0     0     0]\n",
      " [   13    13     7 ...,     0     0     0]]\n",
      "102/200 [==============>...............] - ETA: 44s - loss: 1.5240 - acc: 0.8082[[4800 4919  247 ...,    0    0    0]\n",
      " [1696  729    8 ...,    0    0    0]\n",
      " [ 545 1007  674 ...,    0    0    0]\n",
      " ..., \n",
      " [7710   13   51 ...,    0    0    0]\n",
      " [ 108   68  410 ...,    0    0    0]\n",
      " [ 232 3054    9 ...,    0    0    0]]\n",
      "103/200 [==============>...............] - ETA: 43s - loss: 1.5255 - acc: 0.8080[[ 1332  9266    27 ...,     0     0     0]\n",
      " [    1   288 11255 ...,     0     0     0]\n",
      " [    1   580   473 ...,     0     0     0]\n",
      " ..., \n",
      " [  353  4319     7 ...,     0     0     0]\n",
      " [   70    15   283 ...,     0     0     0]\n",
      " [  353    13    14 ...,     0     0     0]]\n",
      "104/200 [==============>...............] - ETA: 43s - loss: 1.5268 - acc: 0.8079[[3252 3114   11 ...,    0    0    0]\n",
      " [   1  535  765 ...,    0    0    0]\n",
      " [1490 3312 1528 ...,    0    0    0]\n",
      " ..., \n",
      " [   2  131 4181 ...,    0    0    0]\n",
      " [   1 6409  360 ...,    0    0    0]\n",
      " [4181 2149   21 ...,    0    0    0]]\n",
      "105/200 [==============>...............] - ETA: 42s - loss: 1.5261 - acc: 0.8080[[ 1802    13    68 ...,     0     0     0]\n",
      " [   13 11267  8560 ...,     0     0     0]\n",
      " [  213    14  1099 ...,     0     0     0]\n",
      " ..., \n",
      " [   15     7    48 ...,     0     0     0]\n",
      " [  133    39   321 ...,     0     0     0]\n",
      " [    1  1942     5 ...,     0     0     0]]\n",
      "106/200 [==============>...............] - ETA: 42s - loss: 1.5257 - acc: 0.8081[[9231  112    5 ...,    0    0    0]\n",
      " [  13   13   44 ...,    0    0    0]\n",
      " [  68  114  321 ...,    0    0    0]\n",
      " ..., \n",
      " [  13  104   21 ...,    0    0    0]\n",
      " [  93  265  337 ...,    0    0    0]\n",
      " [ 171  108   13 ...,    0    0    0]]\n",
      "107/200 [===============>..............] - ETA: 41s - loss: 1.5277 - acc: 0.8079[[   1  166  371 ...,    0    0    0]\n",
      " [  13  572 3510 ...,    0    0    0]\n",
      " [   1 3776   10 ...,    0    0    0]\n",
      " ..., \n",
      " [  89   67    2 ...,    0    0    0]\n",
      " [ 137  336   18 ...,    0    0    0]\n",
      " [ 150  466  142 ...,    0    0    0]]\n",
      "108/200 [===============>..............] - ETA: 41s - loss: 1.5299 - acc: 0.8076[[   42   471    39 ...,     0     0     0]\n",
      " [    1   214     9 ...,     0     0     0]\n",
      " [    1    13    13 ...,     0     0     0]\n",
      " ..., \n",
      " [   41  2088  4006 ...,     0     0     0]\n",
      " [    1  2538  2476 ...,     0     0     0]\n",
      " [   13  1442 10169 ...,     0     0     0]]\n",
      "109/200 [===============>..............] - ETA: 40s - loss: 1.5327 - acc: 0.8073[[ 301 1351    3 ...,    0    0    0]\n",
      " [2860   13 1184 ...,    0    0    0]\n",
      " [ 719  577   10 ...,    0    0    0]\n",
      " ..., \n",
      " [ 156  213   27 ...,    0    0    0]\n",
      " [ 751 2527  532 ...,    0    0    0]\n",
      " [  80   41  805 ...,    0    0    0]]\n",
      "110/200 [===============>..............] - ETA: 40s - loss: 1.5358 - acc: 0.8070[[   1 1761    5 ...,    0    0    0]\n",
      " [ 194   63  144 ...,    0    0    0]\n",
      " [1054    9   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 280   13   13 ...,    0    0    0]\n",
      " [ 693    2  181 ...,    0    0    0]\n",
      " [ 474  572    7 ...,    0    0    0]]\n",
      "111/200 [===============>..............] - ETA: 40s - loss: 1.5359 - acc: 0.8070[[  89    7    2 ...,    0    0    0]\n",
      " [   1  662  934 ...,    0    0    0]\n",
      " [ 108   15   67 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   99 4777 ...,    0    0    0]\n",
      " [1232 3185   13 ...,    0    0    0]\n",
      " [1036   16  728 ...,    0    0    0]]\n",
      "112/200 [===============>..............] - ETA: 39s - loss: 1.5353 - acc: 0.8071[[   2  487    5 ...,    0    0    0]\n",
      " [   1   38  949 ...,    0    0    0]\n",
      " [5734   13   14 ...,    0    0    0]\n",
      " ..., \n",
      " [1000 2290    8 ...,    0    0    0]\n",
      " [   1   38   62 ...,    0    0    0]\n",
      " [ 250 1318  105 ...,    0    0    0]]\n",
      "113/200 [===============>..............] - ETA: 39s - loss: 1.5370 - acc: 0.8069[[ 194   63  144 ...,    0    0    0]\n",
      " [  10   92  888 ...,    0    0    0]\n",
      " [   1  467    5 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  170   29 ...,    0    0    0]\n",
      " [  80   41 1018 ...,    0    0    0]\n",
      " [  10   13  558 ...,    0    0    0]]\n",
      "114/200 [================>.............] - ETA: 38s - loss: 1.5378 - acc: 0.8069[[ 823   13    1 ...,    0    0    0]\n",
      " [ 341   13  104 ...,    0    0    0]\n",
      " [2308   13 6010 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13   13 ...,    0    0    0]\n",
      " [  56    2  497 ...,    0    0    0]\n",
      " [  13  458 7740 ...,    0    0    0]]\n",
      "115/200 [================>.............] - ETA: 38s - loss: 1.5377 - acc: 0.8069[[4496 3567  385 ...,    0    0    0]\n",
      " [  78   94   13 ...,    0    0    0]\n",
      " [3007  256    1 ...,    0    0    0]\n",
      " ..., \n",
      " [   4   17 3237 ...,    0    0    0]\n",
      " [  92   63  144 ...,    0    0    0]\n",
      " [  49   63  144 ...,    0    0    0]]\n",
      "116/200 [================>.............] - ETA: 37s - loss: 1.5372 - acc: 0.8071[[1753  676 6299 ...,    0    0    0]\n",
      " [   2 3272   74 ...,    0    0    0]\n",
      " [  13    7 4633 ...,    0    0    0]\n",
      " ..., \n",
      " [  13  104   21 ...,    0    0    0]\n",
      " [ 309 4211    9 ...,    0    0    0]\n",
      " [2071   11  147 ...,    0    0    0]]\n",
      "117/200 [================>.............] - ETA: 37s - loss: 1.5380 - acc: 0.8071[[ 379  177   13 ...,    0    0    0]\n",
      " [  99  177   13 ...,    0    0    0]\n",
      " [ 973   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [  18 1780   10 ...,    0    0    0]\n",
      " [  15  128   48 ...,    0    0    0]\n",
      " [  13   13   81 ...,    0    0    0]]\n",
      "118/200 [================>.............] - ETA: 36s - loss: 1.5385 - acc: 0.8071[[   1  885  981 ...,    0    0    0]\n",
      " [  13  133   68 ...,    0    0    0]\n",
      " [2318  133   92 ...,    0    0    0]\n",
      " ..., \n",
      " [  13 1186    4 ...,    0    0    0]\n",
      " [  89   23  155 ...,    0    0    0]\n",
      " [  55   27   13 ...,    0    0    0]]\n",
      "119/200 [================>.............] - ETA: 36s - loss: 1.5381 - acc: 0.8072[[  58   59   26 ...,    0    0    0]\n",
      " [ 454  883 2440 ...,    0    0    0]\n",
      " [   1   13  518 ...,    0    0    0]\n",
      " ..., \n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [5182   11  130 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]]\n",
      "120/200 [=================>............] - ETA: 35s - loss: 1.5382 - acc: 0.8072[[1267 7727 2130 ...,    0    0    0]\n",
      " [   1  220   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  187  635 ...,    0    0    0]\n",
      " [   2 1267 1547 ...,    0    0    0]\n",
      " [2239  720 2558 ...,    0    0    0]]\n",
      "121/200 [=================>............] - ETA: 35s - loss: 1.5394 - acc: 0.8072[[   58    59    26 ...,     0     0     0]\n",
      " [  681  1281    13 ...,     0     0     0]\n",
      " [  318     7    49 ...,     0     0     0]\n",
      " ..., \n",
      " [  844     8   284 ...,     0     0     0]\n",
      " [   58    59    26 ...,     0     0     0]\n",
      " [10907    46     5 ...,     0     0     0]]\n",
      "122/200 [=================>............] - ETA: 35s - loss: 1.5400 - acc: 0.8071[[ 318  329   10 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " ..., \n",
      " [   2  806    8 ...,    0    0    0]\n",
      " [  13   26  115 ...,    0    0    0]\n",
      " [   2 1135   13 ...,    0    0    0]]\n",
      "123/200 [=================>............] - ETA: 34s - loss: 1.5404 - acc: 0.8071[[1811 2457    1 ...,    0    0    0]\n",
      " [3730  326  209 ...,    0    0    0]\n",
      " [1282    7  732 ...,    0    0    0]\n",
      " ..., \n",
      " [4244  404   27 ...,    0    0    0]\n",
      " [ 481   66  106 ...,    0    0    0]\n",
      " [   1  214   23 ...,    0    0    0]]\n",
      "124/200 [=================>............] - ETA: 34s - loss: 1.5408 - acc: 0.8071[[ 167 2079  664 ...,    0    0    0]\n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [ 167 2004  336 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13 1997 ...,    0    0    0]\n",
      " [ 913    7 1014 ...,    0    0    0]\n",
      " [  55    7  536 ...,    0    0    0]]\n",
      "125/200 [=================>............] - ETA: 33s - loss: 1.5414 - acc: 0.8070[[    2    19  5809 ...,     0     0     0]\n",
      " [    1   884   223 ...,     0     0     0]\n",
      " [    2   258     5 ...,     0     0     0]\n",
      " ..., \n",
      " [    1  9295     5 ...,     0     0     0]\n",
      " [10274    13  1362 ...,     0     0     0]\n",
      " [    1   367  2161 ...,     0     0     0]]\n",
      "126/200 [=================>............] - ETA: 33s - loss: 1.5421 - acc: 0.8070[[   1   13 1333 ...,    0    0    0]\n",
      " [   1  367 2161 ...,    0    0    0]\n",
      " [ 481   66 1160 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   11   45 ...,    0    0    0]\n",
      " [4943   13   11 ...,    0    0    0]\n",
      " [  10    1  156 ...,    0    0    0]]\n",
      "127/200 [==================>...........] - ETA: 32s - loss: 1.5433 - acc: 0.8068[[  55  292  607 ...,    0    0    0]\n",
      " [  55   25  292 ...,    0    0    0]\n",
      " [ 116   13 3115 ...,    0    0    0]\n",
      " ..., \n",
      " [   2  712  778 ...,    0    0    0]\n",
      " [   1   91 3267 ...,    0    0    0]\n",
      " [  15    7  211 ...,    0    0    0]]\n",
      "128/200 [==================>...........] - ETA: 32s - loss: 1.5445 - acc: 0.8068[[1896  187   66 ...,    0    0    0]\n",
      " [   1  601    5 ...,    0    0    0]\n",
      " [ 342  196   66 ...,    0    0    0]\n",
      " ..., \n",
      " [  15 1272   29 ...,    0    0    0]\n",
      " [   1 1606 2590 ...,    0    0    0]\n",
      " [ 553 5541   23 ...,    0    0    0]]\n",
      "129/200 [==================>...........] - ETA: 32s - loss: 1.5443 - acc: 0.8068[[ 131  522 7535 ...,    0    0    0]\n",
      " [   2   94  144 ...,    0    0    0]\n",
      " [5180    8  717 ...,    0    0    0]\n",
      " ..., \n",
      " [  13  236  477 ...,    0    0    0]\n",
      " [   2  117    4 ...,    0    0    0]\n",
      " [3838    8 6077 ...,    0    0    0]]\n",
      "130/200 [==================>...........] - ETA: 31s - loss: 1.5417 - acc: 0.8069[[9096 8866    7 ...,    0    0    0]\n",
      " [   2   13 3220 ...,    0    0    0]\n",
      " [   1  145  218 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 3839  737 ...,    0    0    0]\n",
      " [ 119 4410    2 ...,    0    0    0]\n",
      " [3516 1053   33 ...,    0    0    0]]\n",
      "131/200 [==================>...........] - ETA: 31s - loss: 1.5395 - acc: 0.8071[[ 365    7  326 ...,    0    0    0]\n",
      " [  13  248   85 ...,    0    0    0]\n",
      " [ 116 2185   10 ...,    0    0    0]\n",
      " ..., \n",
      " [  13  811 1415 ...,    0    0    0]\n",
      " [2081    6   57 ...,    0    0    0]\n",
      " [3409   13  969 ...,    0    0    0]]\n",
      "132/200 [==================>...........] - ETA: 30s - loss: 1.5369 - acc: 0.8073[[   2   13 3238 ...,    0    0    0]\n",
      " [ 514 2246   13 ...,    0    0    0]\n",
      " [  22  282   83 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  161 7867 ...,    0    0    0]\n",
      " [ 603 5303    7 ...,    0    0    0]\n",
      " [ 119   30   28 ...,    0    0    0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/200 [==================>...........] - ETA: 30s - loss: 1.5350 - acc: 0.8074[[  89    7    2 ...,    0    0    0]\n",
      " [1600    8  444 ...,    0    0    0]\n",
      " [ 425    8 2535 ...,    0    0    0]\n",
      " ..., \n",
      " [ 187    4  109 ...,    0    0    0]\n",
      " [  13 8417   13 ...,    0    0    0]\n",
      " [3398 8587    7 ...,    0    0    0]]\n",
      "134/200 [===================>..........] - ETA: 29s - loss: 1.5324 - acc: 0.8076[[  607   816   878 ...,     0     0     0]\n",
      " [    2    13   905 ...,     0     0     0]\n",
      " [    2   877   172 ...,     0     0     0]\n",
      " ..., \n",
      " [  190  1455 11957 ...,     0     0     0]\n",
      " [ 1792   455     3 ...,     0     0     0]\n",
      " [  131   721   765 ...,     0     0     0]]\n",
      "135/200 [===================>..........] - ETA: 29s - loss: 1.5312 - acc: 0.8077[[  69 1710   13 ...,    0    0    0]\n",
      " [2486   13   13 ...,    0    0    0]\n",
      " [ 185  102   67 ...,    0    0    0]\n",
      " ..., \n",
      " [2523  398 4359 ...,    0    0    0]\n",
      " [1431  450   13 ...,    0    0    0]\n",
      " [  13  199 1448 ...,    0    0    0]]\n",
      "136/200 [===================>..........] - ETA: 28s - loss: 1.5286 - acc: 0.8079[[ 131 1194  295 ...,    0    0    0]\n",
      " [ 365    7  326 ...,    0    0    0]\n",
      " [2237 4702 1748 ...,    0    0    0]\n",
      " ..., \n",
      " [ 389  209 6340 ...,    0    0    0]\n",
      " [3207  128   20 ...,    0    0    0]\n",
      " [  13   13 1465 ...,    0    0    0]]\n",
      "137/200 [===================>..........] - ETA: 28s - loss: 1.5270 - acc: 0.8080[[ 425    7  169 ...,    0    0    0]\n",
      " [8008  565  444 ...,    0    0    0]\n",
      " [ 978 4090    7 ...,    0    0    0]\n",
      " ..., \n",
      " [ 905  162 2004 ...,    0    0    0]\n",
      " [5171   66 1869 ...,    0    0    0]\n",
      " [   2  943  258 ...,    0    0    0]]\n",
      "138/200 [===================>..........] - ETA: 27s - loss: 1.5255 - acc: 0.8081[[ 1848    11  1632 ...,     0     0     0]\n",
      " [ 1625   266    13 ...,     0     0     0]\n",
      " [   26    65  1709 ...,     0     0     0]\n",
      " ..., \n",
      " [  131  1194   295 ...,     0     0     0]\n",
      " [  893 10455  2073 ...,     0     0     0]\n",
      " [  154    66     6 ...,     0     0     0]]\n",
      "139/200 [===================>..........] - ETA: 27s - loss: 1.5246 - acc: 0.8081[[ 155   29    1 ...,    0    0    0]\n",
      " [  13   13    5 ...,    0    0    0]\n",
      " [  13 8751   23 ...,    0    0    0]\n",
      " ..., \n",
      " [9174 7457 3359 ...,    0    0    0]\n",
      " [1717   13  100 ...,    0    0    0]\n",
      " [1558  455    3 ...,    0    0    0]]\n",
      "140/200 [====================>.........] - ETA: 27s - loss: 1.5256 - acc: 0.8080[[  913     7  2134 ...,     0     0     0]\n",
      " [   13    68   871 ...,     0     0     0]\n",
      " [    1   221   230 ...,     0     0     0]\n",
      " ..., \n",
      " [   89     7     2 ...,     0     0     0]\n",
      " [   13  2459 10892 ...,     0     0     0]\n",
      " [  171    70    60 ...,     0     0     0]]\n",
      "141/200 [====================>.........] - ETA: 26s - loss: 1.5253 - acc: 0.8081[[5631 5868 1796 ...,    0    0    0]\n",
      " [ 131   69  263 ...,    0    0    0]\n",
      " [5040 1880  204 ...,    0    0    0]\n",
      " ..., \n",
      " [3400    8 6841 ...,    0    0    0]\n",
      " [  15   14   39 ...,    0    0    0]\n",
      " [ 119   30   36 ...,    0    0    0]]\n",
      "142/200 [====================>.........] - ETA: 26s - loss: 1.5265 - acc: 0.8080[[ 119  616  127 ...,    0    0    0]\n",
      " [   2 5523 3632 ...,    0    0    0]\n",
      " [   1  304 3255 ...,    0    0    0]\n",
      " ..., \n",
      " [ 140  150 4086 ...,    0    0    0]\n",
      " [   1 4874    5 ...,    0    0    0]\n",
      " [  13    9 2370 ...,    0    0    0]]\n",
      "143/200 [====================>.........] - ETA: 25s - loss: 1.5275 - acc: 0.8079[[ 444   83   40 ...,    0    0    0]\n",
      " [1634   13   13 ...,    0    0    0]\n",
      " [   1  248  252 ...,    0    0    0]\n",
      " ..., \n",
      " [ 291  126 1512 ...,    0    0    0]\n",
      " [   2 4493  167 ...,    0    0    0]\n",
      " [ 501  154   66 ...,    0    0    0]]\n",
      "144/200 [====================>.........] - ETA: 25s - loss: 1.5283 - acc: 0.8078[[  13  119   21 ...,    0    0    0]\n",
      " [   2  501 5214 ...,    0    0    0]\n",
      " [ 501    6   25 ...,    0    0    0]\n",
      " ..., \n",
      " [  15   14 1676 ...,    0    0    0]\n",
      " [2215  170   86 ...,    0    0    0]\n",
      " [9754 6508  276 ...,    0    0    0]]\n",
      "145/200 [====================>.........] - ETA: 24s - loss: 1.5293 - acc: 0.8077[[1115 3628   23 ...,    0    0    0]\n",
      " [  70   13   13 ...,    0    0    0]\n",
      " [  34    9    1 ...,    0    0    0]\n",
      " ..., \n",
      " [ 104   21  184 ...,    0    0    0]\n",
      " [  13  199    9 ...,    0    0    0]\n",
      " [ 137  336   18 ...,    0    0    0]]\n",
      "146/200 [====================>.........] - ETA: 24s - loss: 1.5290 - acc: 0.8078[[  13   13   14 ...,    0    0    0]\n",
      " [   1 1456  310 ...,    0    0    0]\n",
      " [   2  131  883 ...,    0    0    0]\n",
      " ..., \n",
      " [2603    6    1 ...,    0    0    0]\n",
      " [2565    1  482 ...,    0    0    0]\n",
      " [7079 1435    4 ...,    0    0    0]]\n",
      "147/200 [=====================>........] - ETA: 23s - loss: 1.5304 - acc: 0.8076[[    1    13 10332 ...,     0     0     0]\n",
      " [   42    14     1 ...,     0     0     0]\n",
      " [  149   495    13 ...,     0     0     0]\n",
      " ..., \n",
      " [   34   629    14 ...,     0     0     0]\n",
      " [   89     7     2 ...,     0     0     0]\n",
      " [    1  2013   312 ...,     0     0     0]]\n",
      "148/200 [=====================>........] - ETA: 23s - loss: 1.5318 - acc: 0.8075[[  245  2713    13 ...,     0     0     0]\n",
      " [   13  8595    14 ...,     0     0     0]\n",
      " [ 2731    34    77 ...,     0     0     0]\n",
      " ..., \n",
      " [   13   104  1108 ...,     0     0     0]\n",
      " [   13   159 10506 ...,     0     0     0]\n",
      " [ 1675  3294     9 ...,     0     0     0]]\n",
      "149/200 [=====================>........] - ETA: 23s - loss: 1.5342 - acc: 0.8072[[ 13 492  12 ...,   0   0   0]\n",
      " [ 48 194 629 ...,   0   0   0]\n",
      " [264   7  53 ...,   0   0   0]\n",
      " ..., \n",
      " [ 13  13  13 ...,   0   0   0]\n",
      " [108  68 253 ...,   0   0   0]\n",
      " [ 13  13 221 ...,   0   0   0]]\n",
      "150/200 [=====================>........] - ETA: 22s - loss: 1.5370 - acc: 0.8070[[ 1395  8395    14 ...,     0     0     0]\n",
      " [ 2333   610   249 ...,     0     0     0]\n",
      " [  116   350    21 ...,     0     0     0]\n",
      " ..., \n",
      " [ 3599    13   198 ...,     0     0     0]\n",
      " [    2 10742     5 ...,     0     0     0]\n",
      " [ 1332    13     9 ...,     0     0     0]]\n",
      "151/200 [=====================>........] - ETA: 22s - loss: 1.5372 - acc: 0.8070[[ 281  713   13 ...,    0    0    0]\n",
      " [6628   13    8 ...,    0    0    0]\n",
      " [  10  790 2047 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  177  676 ...,    0    0    0]\n",
      " [ 730   13    1 ...,    0    0    0]\n",
      " [  18  318    9 ...,    0    0    0]]\n",
      "152/200 [=====================>........] - ETA: 21s - loss: 1.5373 - acc: 0.8070[[   1  576 5200 ...,    0    0    0]\n",
      " [1066  912   23 ...,    0    0    0]\n",
      " [  89   11  184 ...,    0    0    0]\n",
      " ..., \n",
      " [ 234  402  144 ...,    0    0    0]\n",
      " [6839 1112   83 ...,    0    0    0]\n",
      " [ 159 3747    9 ...,    0    0    0]]\n",
      "153/200 [=====================>........] - ETA: 21s - loss: 1.5384 - acc: 0.8068[[ 746  117    8 ...,    0    0    0]\n",
      " [ 328   13   15 ...,    0    0    0]\n",
      " [  34   61   13 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   13 1846 ...,    0    0    0]\n",
      " [   2  999  144 ...,    0    0    0]\n",
      " [   4    1  204 ...,    0    0    0]]\n",
      "154/200 [======================>.......] - ETA: 20s - loss: 1.5392 - acc: 0.8068[[  13   26  106 ...,    0    0    0]\n",
      " [   1 2352   86 ...,    0    0    0]\n",
      " [1014   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [  18   69   13 ...,    0    0    0]\n",
      " [ 108   68 1632 ...,    0    0    0]\n",
      " [  89   23   39 ...,    0    0    0]]\n",
      "155/200 [======================>.......] - ETA: 20s - loss: 1.5392 - acc: 0.8068[[3599   13   13 ...,    0    0    0]\n",
      " [4956   13 1836 ...,    0    0    0]\n",
      " [   1   13 6850 ...,    0    0    0]\n",
      " ..., \n",
      " [ 415    6  210 ...,    0    0    0]\n",
      " [ 193    7   13 ...,    0    0    0]\n",
      " [   1  131  523 ...,    0    0    0]]\n",
      "156/200 [======================>.......] - ETA: 19s - loss: 1.5390 - acc: 0.8069[[   1 5684 9095 ...,    0    0    0]\n",
      " [2568 5828    9 ...,    0    0    0]\n",
      " [5543 1537 1471 ...,    0    0    0]\n",
      " ..., \n",
      " [   2  259  290 ...,    0    0    0]\n",
      " [  89   23 2497 ...,    0    0    0]\n",
      " [ 104 1629    1 ...,    0    0    0]]\n",
      "157/200 [======================>.......] - ETA: 19s - loss: 1.5399 - acc: 0.8068[[   1   13 1978 ...,    0    0    0]\n",
      " [ 697 2427  798 ...,    0    0    0]\n",
      " [ 333   13 1334 ...,    0    0    0]\n",
      " ..., \n",
      " [ 805   34   94 ...,    0    0    0]\n",
      " [  15    7   13 ...,    0    0    0]\n",
      " [6306 5860   13 ...,    0    0    0]]\n",
      "158/200 [======================>.......] - ETA: 18s - loss: 1.5403 - acc: 0.8068[[ 316  583 1622 ...,    0    0    0]\n",
      " [  34   94    7 ...,    0    0    0]\n",
      " [  78 1362   13 ...,    0    0    0]\n",
      " ..., \n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [5163 1765   29 ...,    0    0    0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/200 [======================>.......] - ETA: 18s - loss: 1.5408 - acc: 0.8068[[2574    7   19 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " [  58   59   26 ...,    0    0    0]\n",
      " ..., \n",
      " [6152   69 3226 ...,    0    0    0]\n",
      " [3222   13  163 ...,    0    0    0]\n",
      " [   1   13  191 ...,    0    0    0]]\n",
      "160/200 [=======================>......] - ETA: 18s - loss: 1.5412 - acc: 0.8068[[ 131  284 2368 ...,    0    0    0]\n",
      " [2065   69 5102 ...,    0    0    0]\n",
      " [ 167   13 3369 ...,    0    0    0]\n",
      " ..., \n",
      " [1324 1657   27 ...,    0    0    0]\n",
      " [ 284  100    1 ...,    0    0    0]\n",
      " [2808 2755  130 ...,    0    0    0]]\n",
      "161/200 [=======================>......] - ETA: 17s - loss: 1.5417 - acc: 0.8068[[6030   13   12 ...,    0    0    0]\n",
      " [4759   19  324 ...,    0    0    0]\n",
      " [   2   19 3634 ...,    0    0    0]\n",
      " ..., \n",
      " [1434   27 4474 ...,    0    0    0]\n",
      " [   2  852    3 ...,    0    0    0]\n",
      " [   1   19  352 ...,    0    0    0]]\n",
      "162/200 [=======================>......] - ETA: 17s - loss: 1.5421 - acc: 0.8067[[   1  143    5 ...,    0    0    0]\n",
      " [  55    8 1792 ...,    0    0    0]\n",
      " [   1  132  509 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13 1847 ...,    0    0    0]\n",
      " [   1  469    8 ...,    0    0    0]\n",
      " [ 140  553    8 ...,    0    0    0]]\n",
      "163/200 [=======================>......] - ETA: 16s - loss: 1.5428 - acc: 0.8067[[ 523 1898  925 ...,    0    0    0]\n",
      " [   2 1569 2114 ...,    0    0    0]\n",
      " [   1 6528  191 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13   91 ...,    0    0    0]\n",
      " [3050   55  100 ...,    0    0    0]\n",
      " [ 316   55    7 ...,    0    0    0]]\n",
      "164/200 [=======================>......] - ETA: 16s - loss: 1.5431 - acc: 0.8067[[3258    4 2081 ...,    0    0    0]\n",
      " [   1   47 6189 ...,    0    0    0]\n",
      " [1434    7  161 ...,    0    0    0]\n",
      " ..., \n",
      " [   2  145  608 ...,    0    0    0]\n",
      " [ 561 3076   36 ...,    0    0    0]\n",
      " [   1  220   73 ...,    0    0    0]]\n",
      "165/200 [=======================>......] - ETA: 15s - loss: 1.5434 - acc: 0.8066[[   1   13   11 ...,    0    0    0]\n",
      " [   2   58   59 ...,    0    0    0]\n",
      " [   1  220   91 ...,    0    0    0]\n",
      " ..., \n",
      " [ 366    6    1 ...,    0    0    0]\n",
      " [ 306 3262   13 ...,    0    0    0]\n",
      " [   1 1363  199 ...,    0    0    0]]\n",
      "166/200 [=======================>......] - ETA: 15s - loss: 1.5433 - acc: 0.8067[[   58    59    26 ...,     0     0     0]\n",
      " [   58    59    26 ...,     0     0     0]\n",
      " [   41     5  1056 ...,     0     0     0]\n",
      " ..., \n",
      " [   13    13    14 ...,     0     0     0]\n",
      " [ 1248 10206 10206 ...,     0     0     0]\n",
      " [   13     8  5949 ...,     0     0     0]]\n",
      "167/200 [========================>.....] - ETA: 14s - loss: 1.5436 - acc: 0.8067[[1224   27 3823 ...,    0    0    0]\n",
      " [  58   59  154 ...,    0    0    0]\n",
      " [ 501  154   66 ...,    0    0    0]\n",
      " ..., \n",
      " [  13   13   13 ...,    0    0    0]\n",
      " [  12  296   13 ...,    0    0    0]\n",
      " [1491  102   67 ...,    0    0    0]]\n",
      "168/200 [========================>.....] - ETA: 14s - loss: 1.5437 - acc: 0.8067[[ 179 1315 4973 ...,    0    0    0]\n",
      " [ 234 4869  112 ...,    0    0    0]\n",
      " [   1  214   23 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  635    5 ...,    0    0    0]\n",
      " [ 342  196   66 ...,    0    0    0]\n",
      " [ 155   29  697 ...,    0    0    0]]\n",
      "169/200 [========================>.....] - ETA: 14s - loss: 1.5419 - acc: 0.8067[[ 958  998    7 ...,    0    0    0]\n",
      " [2490    9 2492 ...,    0    0    0]\n",
      " [   2 2602    4 ...,    0    0    0]\n",
      " ..., \n",
      " [  26   23  974 ...,    0    0    0]\n",
      " [  56   79    1 ...,    0    0    0]\n",
      " [ 561   11 1913 ...,    0    0    0]]\n",
      "170/200 [========================>.....] - ETA: 13s - loss: 1.5399 - acc: 0.8069[[ 478    2 1319 ...,    0    0    0]\n",
      " [1935  295 8426 ...,    0    0    0]\n",
      " [1525  326  267 ...,    0    0    0]\n",
      " ..., \n",
      " [ 108   13    9 ...,    0    0    0]\n",
      " [  26   23 7417 ...,    0    0    0]\n",
      " [ 579  217  226 ...,    0    0    0]]\n",
      "171/200 [========================>.....] - ETA: 13s - loss: 1.5382 - acc: 0.8070[[4458   21  933 ...,    0    0    0]\n",
      " [1248 2508   13 ...,    0    0    0]\n",
      " [  22  405   16 ...,    0    0    0]\n",
      " ..., \n",
      " [  22  405 2244 ...,    0    0    0]\n",
      " [ 166   41  970 ...,    0    0    0]\n",
      " [   1  751 2224 ...,    0    0    0]]\n",
      "172/200 [========================>.....] - ETA: 12s - loss: 1.5364 - acc: 0.8071[[ 131 2642   13 ...,    0    0    0]\n",
      " [  13   13  247 ...,    0    0    0]\n",
      " [   2  146   11 ...,    0    0    0]\n",
      " ..., \n",
      " [3689 3693   13 ...,    0    0    0]\n",
      " [ 500    7 1791 ...,    0    0    0]\n",
      " [ 374    5   13 ...,    0    0    0]]\n",
      "173/200 [========================>.....] - ETA: 12s - loss: 1.5349 - acc: 0.8073[[ 912    5    1 ...,    0    0    0]\n",
      " [2036  462  470 ...,    0    0    0]\n",
      " [1171 5423   13 ...,    0    0    0]\n",
      " ..., \n",
      " [8266  694  131 ...,    0    0    0]\n",
      " [   2   13 7637 ...,    0    0    0]\n",
      " [ 582 1927 1531 ...,    0    0    0]]\n",
      "174/200 [=========================>....] - ETA: 11s - loss: 1.5332 - acc: 0.8074[[3213 4089 1732 ...,    0    0    0]\n",
      " [ 390   13 8287 ...,    0    0    0]\n",
      " [ 246  190   10 ...,    0    0    0]\n",
      " ..., \n",
      " [   1 1152 2403 ...,    0    0    0]\n",
      " [  87  632    9 ...,    0    0    0]\n",
      " [   1  474  429 ...,    0    0    0]]\n",
      "175/200 [=========================>....] - ETA: 11s - loss: 1.5320 - acc: 0.8075[[ 186   11   45 ...,    0    0    0]\n",
      " [  13 3488  521 ...,    0    0    0]\n",
      " [3396   13   49 ...,    0    0    0]\n",
      " ..., \n",
      " [  10  234 4098 ...,    0    0    0]\n",
      " [ 232  627    8 ...,    0    0    0]\n",
      " [3491  119  157 ...,    0    0    0]]\n",
      "176/200 [=========================>....] - ETA: 10s - loss: 1.5306 - acc: 0.8076[[   73   196   441 ...,     0     0     0]\n",
      " [11981  4113    27 ...,     0     0     0]\n",
      " [  380     7   322 ...,     0     0     0]\n",
      " ..., \n",
      " [ 5138  6683    83 ...,     0     0     0]\n",
      " [  185   854     5 ...,     0     0     0]\n",
      " [ 2746  7951  9616 ...,     0     0     0]]\n",
      "177/200 [=========================>....] - ETA: 10s - loss: 1.5292 - acc: 0.8076[[ 140  369 6301 ...,    0    0    0]\n",
      " [  42  471   39 ...,    0    0    0]\n",
      " [3007  157    2 ...,    0    0    0]\n",
      " ..., \n",
      " [   1  580  473 ...,    0    0    0]\n",
      " [ 456  970 8511 ...,    0    0    0]\n",
      " [1046  217 2808 ...,    0    0    0]]\n",
      "178/200 [=========================>....] - ETA: 9s - loss: 1.5282 - acc: 0.8077 [[   2  287 7391 ...,    0    0    0]\n",
      " [1446   13    9 ...,    0    0    0]\n",
      " [   2  146 1214 ...,    0    0    0]\n",
      " ..., \n",
      " [  10    2   61 ...,    0    0    0]\n",
      " [   1  717  117 ...,    0    0    0]\n",
      " [   4   13   13 ...,    0    0    0]]\n",
      "179/200 [=========================>....] - ETA: 9s - loss: 1.5273 - acc: 0.8077[[ 131  381  228 ...,    0    0    0]\n",
      " [1562 4241   14 ...,    0    0    0]\n",
      " [  13   21   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 284    7  274 ...,    0    0    0]\n",
      " [   2  219  734 ...,    0    0    0]\n",
      " [ 623  631   24 ...,    0    0    0]]\n",
      "180/200 [==========================>...] - ETA: 9s - loss: 1.5279 - acc: 0.8077[[  108    68   410 ...,     0     0     0]\n",
      " [ 3928   600 11308 ...,     0     0     0]\n",
      " [  492    13     5 ...,     0     0     0]\n",
      " ..., \n",
      " [   19  1620     6 ...,     0     0     0]\n",
      " [ 8181    63    56 ...,     0     0     0]\n",
      " [10148 10148   231 ...,     0     0     0]]\n",
      "181/200 [==========================>...] - ETA: 8s - loss: 1.5281 - acc: 0.8077[[ 131 1767  332 ...,    0    0    0]\n",
      " [   6    1 2532 ...,    0    0    0]\n",
      " [1381  147  407 ...,    0    0    0]\n",
      " ..., \n",
      " [ 109    7 1276 ...,    0    0    0]\n",
      " [   2   13  613 ...,    0    0    0]\n",
      " [1230  951    4 ...,    0    0    0]]\n",
      "182/200 [==========================>...] - ETA: 8s - loss: 1.5292 - acc: 0.8076[[ 131  121 3113 ...,    0    0    0]\n",
      " [ 623   21 7905 ...,    0    0    0]\n",
      " [   1  785    9 ...,    0    0    0]\n",
      " ..., \n",
      " [   1   13  203 ...,    0    0    0]\n",
      " [   2  146 1129 ...,    0    0    0]\n",
      " [  10    2 1090 ...,    0    0    0]]\n",
      "183/200 [==========================>...] - ETA: 7s - loss: 1.5295 - acc: 0.8076[[   1   13   91 ...,    0    0    0]\n",
      " [   1  199 4208 ...,    0    0    0]\n",
      " [  58   59  187 ...,    0    0    0]\n",
      " ..., \n",
      " [ 495   32    2 ...,    0    0    0]\n",
      " [   2   13  734 ...,    0    0    0]\n",
      " [1573 6341 5974 ...,    0    0    0]]\n",
      "184/200 [==========================>...] - ETA: 7s - loss: 1.5305 - acc: 0.8075[[   1  998 3979 ...,    0    0    0]\n",
      " [ 263  267   13 ...,    0    0    0]\n",
      " [1247    7   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 650   13  365 ...,    0    0    0]\n",
      " [  34    1   61 ...,    0    0    0]\n",
      " [3819    7  780 ...,    0    0    0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/200 [==========================>...] - ETA: 6s - loss: 1.5317 - acc: 0.8073[[   2  551  861 ...,    0    0    0]\n",
      " [1675   13  192 ...,    0    0    0]\n",
      " [ 293 1222 2501 ...,    0    0    0]\n",
      " ..., \n",
      " [ 344  117   13 ...,    0    0    0]\n",
      " [1004  421 2149 ...,    0    0    0]\n",
      " [1761   23  210 ...,    0    0    0]]\n",
      "186/200 [==========================>...] - ETA: 6s - loss: 1.5316 - acc: 0.8074[[ 300   23  400 ...,    0    0    0]\n",
      " [  15    9 6069 ...,    0    0    0]\n",
      " [3978  157    1 ...,    0    0    0]\n",
      " ..., \n",
      " [3100   15    9 ...,    0    0    0]\n",
      " [ 348 2320 5144 ...,    0    0    0]\n",
      " [  13   13 3164 ...,    0    0    0]]\n",
      "187/200 [===========================>..] - ETA: 5s - loss: 1.5323 - acc: 0.8073[[   49   164   816 ...,     0     0     0]\n",
      " [  301   934  8133 ...,     0     0     0]\n",
      " [11585   112     5 ...,     0     0     0]\n",
      " ..., \n",
      " [    1    19    13 ...,     0     0     0]\n",
      " [   13     6  3737 ...,     0     0     0]\n",
      " [11163    13  1243 ...,     0     0     0]]\n",
      "188/200 [===========================>..] - ETA: 5s - loss: 1.5335 - acc: 0.8072[[  15   11   45 ...,    0    0    0]\n",
      " [ 184  810   29 ...,    0    0    0]\n",
      " [  89    7   22 ...,    0    0    0]\n",
      " ..., \n",
      " [1925 1207 2354 ...,    0    0    0]\n",
      " [  10    1  345 ...,    0    0    0]\n",
      " [ 108   68  410 ...,    0    0    0]]\n",
      "189/200 [===========================>..] - ETA: 4s - loss: 1.5356 - acc: 0.8069[[2206   13 2298 ...,    0    0    0]\n",
      " [  10  383    2 ...,    0    0    0]\n",
      " [9208   67 9798 ...,    0    0    0]\n",
      " ..., \n",
      " [  68   21    3 ...,    0    0    0]\n",
      " [  13  744    3 ...,    0    0    0]\n",
      " [  89   27  317 ...,    0    0    0]]\n",
      "190/200 [===========================>..] - ETA: 4s - loss: 1.5366 - acc: 0.8068[[1892 7168    4 ...,    0    0    0]\n",
      " [3006 2446   14 ...,    0    0    0]\n",
      " [1170 2169 2080 ...,    0    0    0]\n",
      " ..., \n",
      " [ 726    7  191 ...,    0    0    0]\n",
      " [1231   70   68 ...,    0    0    0]\n",
      " [   2  293 1244 ...,    0    0    0]]\n",
      "191/200 [===========================>..] - ETA: 4s - loss: 1.5384 - acc: 0.8066[[   13 10823     7 ...,     0     0     0]\n",
      " [   13   435  7769 ...,     0     0     0]\n",
      " [   13    13     9 ...,     0     0     0]\n",
      " ..., \n",
      " [    2  1745  3196 ...,     0     0     0]\n",
      " [ 8017  1395     9 ...,     0     0     0]\n",
      " [    2    13   796 ...,     0     0     0]]\n",
      "192/200 [===========================>..] - ETA: 3s - loss: 1.5394 - acc: 0.8065[[   19   352     8 ...,     0     0     0]\n",
      " [  187     5  4712 ...,     0     0     0]\n",
      " [ 3222  7637    13 ...,     0     0     0]\n",
      " ..., \n",
      " [  500     7 10824 ...,     0     0     0]\n",
      " [   69   297    13 ...,     0     0     0]\n",
      " [ 1152  4028   252 ...,     0     0     0]]\n",
      "193/200 [===========================>..] - ETA: 3s - loss: 1.5387 - acc: 0.8067[[8602    9 2859 ...,    0    0    0]\n",
      " [   2 6397    3 ...,    0    0    0]\n",
      " [3252   13   13 ...,    0    0    0]\n",
      " ..., \n",
      " [ 325 1063 1998 ...,    0    0    0]\n",
      " [   1  126 2437 ...,    0    0    0]\n",
      " [  13   13   14 ...,    0    0    0]]\n",
      "194/200 [============================>.] - ETA: 2s - loss: 1.5402 - acc: 0.8065[[   1   99 4711 ...,    0    0    0]\n",
      " [ 154   66    6 ...,    0    0    0]\n",
      " [ 154   66    6 ...,    0    0    0]\n",
      " ..., \n",
      " [2288   13  105 ...,    0    0    0]\n",
      " [  15  748   90 ...,    0    0    0]\n",
      " [ 356  767  811 ...,    0    0    0]]\n",
      "195/200 [============================>.] - ETA: 2s - loss: 1.5408 - acc: 0.8064[[    2   222 10613 ...,     0     0     0]\n",
      " [   10    63    13 ...,     0     0     0]\n",
      " [    1    13    32 ...,     0     0     0]\n",
      " ..., \n",
      " [   13    13   298 ...,     0     0     0]\n",
      " [   19   120   438 ...,     0     0     0]\n",
      " [   34    61  6449 ...,     0     0     0]]\n",
      "196/200 [============================>.] - ETA: 1s - loss: 1.5409 - acc: 0.8064[[  304  3255   103 ...,     0     0     0]\n",
      " [ 2379  7422     8 ...,     0     0     0]\n",
      " [10485 10333   100 ...,     0     0     0]\n",
      " ..., \n",
      " [    4    13   816 ...,     0     0     0]\n",
      " [   13     9    48 ...,     0     0     0]\n",
      " [  890  2211   114 ...,     0     0     0]]\n",
      "197/200 [============================>.] - ETA: 1s - loss: 1.5408 - acc: 0.8065[[5267 2367   14 ...,    0    0    0]\n",
      " [ 108  104 2357 ...,    0    0    0]\n",
      " [   4    1  894 ...,    0    0    0]\n",
      " ..., \n",
      " [ 155  301  338 ...,    0    0    0]\n",
      " [ 377 4559   13 ...,    0    0    0]\n",
      " [   4  432   68 ...,    0    0    0]]\n",
      "198/200 [============================>.] - ETA: 0s - loss: 1.5411 - acc: 0.8065[[  18    1 1558 ...,    0    0    0]\n",
      " [ 986 5031  703 ...,    0    0    0]\n",
      " [3001 6530 5388 ...,    0    0    0]\n",
      " ..., \n",
      " [1289   13    2 ...,    0    0    0]\n",
      " [ 406   13 8740 ...,    0    0    0]\n",
      " [   1  387 3348 ...,    0    0    0]]\n",
      "199/200 [============================>.] - ETA: 0s - loss: 1.5415 - acc: 0.8065[[ 3470    13   626 ...,     0     0     0]\n",
      " [ 7322     9  1842 ...,     0     0     0]\n",
      " [  483  4428    10 ...,     0     0     0]\n",
      " ..., \n",
      " [   13   391     5 ...,     0     0     0]\n",
      " [ 7029  2222    81 ...,     0     0     0]\n",
      " [10683  9535    11 ...,     0     0     0]]\n",
      "200/200 [==============================] - 90s - loss: 1.5426 - acc: 0.8064    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fec16374550>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator(transformed_article_data_train ,transformed_summary_data_train,100),steps_per_epoch=200, \n",
    "     nb_epoch=10,verbose=1,callbacks=[tbCallBack])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArsAAAEXCAYAAACtVYyKAAAYJ2lDQ1BJQ0MgUHJvZmlsZQAAWIWV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\nCIAACASGwP8DzgzydMplixgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='tensorboard.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unidirectional LSTM Encoder Decoder With Attention "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the parameters for your LSTM encoder decoder model with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "MAX_LEN = 26\n",
    "VOCAB_SIZE = 8000\n",
    "\n",
    "\n",
    "BATCH_SIZE = 150 \n",
    "NUM_LAYERS = 1\n",
    "HIDDEN_DIM = 30\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TO-DO \n",
    "article_text_train2 =  open('data/train_article.txt', 'r')\n",
    "summary_text_train2 =  open('data/train_title.txt', 'r')\n",
    "\n",
    "articleTrain_data2=article_text_train2.read().splitlines()\n",
    "summaryTrain_data2=summary_text_train2.read().splitlines()\n",
    "\n",
    "training_article_data2 = load_data(articleTrain_data2,summaryTrain_data2,MAX_LEN,VOCAB_SIZE)\n",
    "\n",
    "transformed_article_data_train2 = training_article_data2[0]\n",
    "Vocab_size_of_article_train2 = training_article_data2[1]\n",
    "word2idx_article_train2 = training_article_data2[2]\n",
    "dx2word_articl_train2 = training_article_data2[3]\n",
    "transformed_summary_data_train2 = training_article_data2[4]\n",
    "Vocab_size_of_summary_train2 = training_article_data2[5]\n",
    "word2idx_summary_train2 = training_article_data2[6]\n",
    "idx2word_summary_train2 = training_article_data2[7]\n",
    "\n",
    "# idx2word_summary_test2[6]  DON'T USE THIS ONE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You would've observed that the summaries are not yet perfect. This is because in encoder decoder architecture, only the final state of encoder is used to calculate the probabilities. We now move to a more general approach called attention based approach. In this, we take a weighted sum of all weights of encoder instead of just the last one. You are already provided an attention_decoder.py file with AttentionDecoder. Add this layer on top of your encoder and run the same experiment as before. For this part, you don't need to worry about return_probabilities argument to create_UniLSTMwithAttention function. Just pass it as an argument to your attention decoder layer. When return_probabilities is false, the attention decoder returns prediction model, which is what you need for this part of the assignment. When return_probabilities is true, the attention decoder returns the probability model, which you will be using later in the Analysis part of this assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from attention_decoder import AttentionDecoder\n",
    "\n",
    "def create_UniLSTMwithAttention(X_vocab_len, X_max_len, y_vocab_len, y_max_len, hidden_size, num_layers, return_probabilities = False):\n",
    "\n",
    "    # TO-DO\n",
    "    model = Sequential()\n",
    "    # Add embedding layer\n",
    "    model.add(Embedding(input_dim=X_vocab_len, output_dim=hidden_size,  input_length=MAX_LEN,mask_zero=True,trainable=True))\n",
    "    # add LSTM encoder layer\n",
    "    for _ in range (num_layers):\n",
    "        model.add(LSTM(hidden_size,return_sequences=True, dropout=0.2,recurrent_dropout=0.2))    \n",
    "    # Add attention decoder layer\n",
    "    model.add(AttentionDecoder(hidden_size, X_vocab_len))\n",
    "    # Add compile layer\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "    # Add summary layer\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model, as you did before, for the model without attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 26, 30)            240000    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 26, 30)            7320      \n",
      "_________________________________________________________________\n",
      "AttentionDecoder (AttentionD (None, 26, 8000)          65216250  \n",
      "=================================================================\n",
      "Total params: 65,463,570\n",
      "Trainable params: 65,463,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# TO-DO\n",
    "\n",
    "sum_voc_len_attention2 = transformed_summary_data_train2.max()+1\n",
    "art_voc_len_attention2 = transformed_article_data_train2.max()+1\n",
    "\n",
    "model_with_attention=create_UniLSTMwithAttention(sum_voc_len_attention2,MAX_LEN,art_voc_len_attention2,MAX_LEN,HIDDEN_DIM,NUM_LAYERS)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medel is training: epoch 1th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 5.2105 - acc: 0.4537 - val_loss: 4.7461 - val_acc: 0.5051\n",
      "Medel is training: epoch 1th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 4.5315 - acc: 0.5077 - val_loss: 4.1816 - val_acc: 0.5290\n",
      "Medel is training: epoch 1th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 4.4339 - acc: 0.4801 - val_loss: 4.3093 - val_acc: 0.4784\n",
      "Medel is training: epoch 1th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 4.0775 - acc: 0.5067 - val_loss: 4.0009 - val_acc: 0.5074\n",
      "Medel is training: epoch 1th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.9256 - acc: 0.5209 - val_loss: 4.1989 - val_acc: 0.4901\n",
      "Medel is training: epoch 1th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 4.4071 - acc: 0.4505 - val_loss: 3.6771 - val_acc: 0.5482\n",
      "Medel is training: epoch 1th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.9858 - acc: 0.5041 - val_loss: 3.9678 - val_acc: 0.5146\n",
      "Medel is training: epoch 1th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.9032 - acc: 0.5137 - val_loss: 4.2128 - val_acc: 0.4794\n",
      "Medel is training: epoch 1th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 4.2264 - acc: 0.4653 - val_loss: 3.7680 - val_acc: 0.5288\n",
      "Medel is training: epoch 1th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.9013 - acc: 0.5170 - val_loss: 3.5741 - val_acc: 0.5564\n",
      "Medel is training: epoch 1th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.9773 - acc: 0.5058 - val_loss: 4.5253 - val_acc: 0.4269\n",
      "Medel is training: epoch 1th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 4.0021 - acc: 0.4993 - val_loss: 3.8178 - val_acc: 0.5224\n",
      "Medel is training: epoch 1th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.7784 - acc: 0.5309 - val_loss: 3.6362 - val_acc: 0.5408\n",
      "Medel is training: epoch 1th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 4.0963 - acc: 0.4839 - val_loss: 4.7374 - val_acc: 0.4038\n",
      "Medel is training: epoch 1th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.7336 - acc: 0.5294 - val_loss: 3.7870 - val_acc: 0.5123\n",
      "Medel is training: epoch 1th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6818 - acc: 0.5337 - val_loss: 3.6159 - val_acc: 0.5421\n",
      "Medel is training: epoch 1th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.9392 - acc: 0.4945 - val_loss: 4.0975 - val_acc: 0.4741\n",
      "Medel is training: epoch 1th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6652 - acc: 0.5326 - val_loss: 3.7858 - val_acc: 0.5138\n",
      "Medel is training: epoch 1th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5559 - acc: 0.5421 - val_loss: 3.5183 - val_acc: 0.5390\n",
      "Medel is training: epoch 1th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.9188 - acc: 0.4982 - val_loss: 4.2661 - val_acc: 0.4465\n",
      "Medel is training: epoch 1th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5896 - acc: 0.5396 - val_loss: 3.5324 - val_acc: 0.5373\n",
      "Medel is training: epoch 1th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4760 - acc: 0.5504 - val_loss: 3.3642 - val_acc: 0.5648\n",
      "Medel is training: epoch 1th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.7845 - acc: 0.5101 - val_loss: 4.0222 - val_acc: 0.4766\n",
      "Medel is training: epoch 1th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.7160 - acc: 0.5189 - val_loss: 3.4539 - val_acc: 0.5445\n",
      "Medel is training: epoch 1th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5212 - acc: 0.5393 - val_loss: 3.1703 - val_acc: 0.5840\n",
      "Medel is training: epoch 1th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5532 - acc: 0.5322 - val_loss: 3.5390 - val_acc: 0.5454\n",
      "Medel is training: epoch 1th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.9084 - acc: 0.5010 - val_loss: 3.3609 - val_acc: 0.5767\n",
      "Medel is training: epoch 1th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4461 - acc: 0.5628 - val_loss: 3.4451 - val_acc: 0.5625\n",
      "Medel is training: epoch 1th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1740 - acc: 0.5830 - val_loss: 3.5166 - val_acc: 0.5518\n",
      "Medel is training: epoch 1th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.8872 - acc: 0.5059 - val_loss: 3.5940 - val_acc: 0.5542\n",
      "Medel is training: epoch 1th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4541 - acc: 0.5637 - val_loss: 3.2424 - val_acc: 0.5964\n",
      "Medel is training: epoch 1th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2065 - acc: 0.5875 - val_loss: 3.0422 - val_acc: 0.5894\n",
      "Medel is training: epoch 1th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4199 - acc: 0.5575 - val_loss: 3.5898 - val_acc: 0.5522\n",
      "Medel is training: epoch 1th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.8583 - acc: 0.5145 - val_loss: 3.1532 - val_acc: 0.6094\n",
      "Medel is training: epoch 1th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3576 - acc: 0.5868 - val_loss: 3.3397 - val_acc: 0.5866\n",
      "Medel is training: epoch 1th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0354 - acc: 0.6003 - val_loss: 3.1547 - val_acc: 0.5792\n",
      "Medel is training: epoch 1th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5454 - acc: 0.5550 - val_loss: 4.0118 - val_acc: 0.4943\n",
      "Medel is training: epoch 1th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5030 - acc: 0.5655 - val_loss: 3.2944 - val_acc: 0.5962\n",
      "Medel is training: epoch 1th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2634 - acc: 0.6017 - val_loss: 3.0353 - val_acc: 0.5935\n",
      "Medel is training: epoch 1th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9913 - acc: 0.6058 - val_loss: 3.3558 - val_acc: 0.5770\n",
      "Medel is training: epoch 1th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6548 - acc: 0.5438 - val_loss: 4.0253 - val_acc: 0.4971\n",
      "Medel is training: epoch 1th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2997 - acc: 0.5940 - val_loss: 3.0548 - val_acc: 0.6246\n",
      "Medel is training: epoch 1th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3364 - acc: 0.5881 - val_loss: 2.9973 - val_acc: 0.6063\n",
      "Medel is training: epoch 1th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9203 - acc: 0.6143 - val_loss: 3.4114 - val_acc: 0.5672\n",
      "Medel is training: epoch 1th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5707 - acc: 0.5555 - val_loss: 4.1460 - val_acc: 0.4990\n",
      "Medel is training: epoch 1th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3247 - acc: 0.5891 - val_loss: 3.2360 - val_acc: 0.6035\n",
      "Medel is training: epoch 1th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2473 - acc: 0.6010 - val_loss: 2.8117 - val_acc: 0.6102\n",
      "Medel is training: epoch 1th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9576 - acc: 0.6099 - val_loss: 3.3049 - val_acc: 0.5793\n",
      "Medel is training: epoch 1th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5503 - acc: 0.5579 - val_loss: 3.9046 - val_acc: 0.5175\n",
      "Medel is training: epoch 1th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4235 - acc: 0.5798 - val_loss: 3.3075 - val_acc: 0.5968\n",
      "Medel is training: epoch 2th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 4.0946 - acc: 0.4937 - val_loss: 3.7502 - val_acc: 0.5387\n",
      "Medel is training: epoch 2th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6293 - acc: 0.5519 - val_loss: 3.3673 - val_acc: 0.5577\n",
      "Medel is training: epoch 2th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.8194 - acc: 0.5144 - val_loss: 3.8902 - val_acc: 0.5181\n",
      "Medel is training: epoch 2th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6297 - acc: 0.5502 - val_loss: 3.5790 - val_acc: 0.5533\n",
      "Medel is training: epoch 2th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5080 - acc: 0.5564 - val_loss: 3.7973 - val_acc: 0.5328\n",
      "Medel is training: epoch 2th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 4.0527 - acc: 0.4962 - val_loss: 3.3178 - val_acc: 0.5917\n",
      "Medel is training: epoch 2th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6305 - acc: 0.5466 - val_loss: 3.6213 - val_acc: 0.5520\n",
      "Medel is training: epoch 2th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5301 - acc: 0.5501 - val_loss: 3.8577 - val_acc: 0.5194\n",
      "Medel is training: epoch 2th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.9419 - acc: 0.5064 - val_loss: 3.4271 - val_acc: 0.5704\n",
      "Medel is training: epoch 2th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5488 - acc: 0.5556 - val_loss: 3.2268 - val_acc: 0.5847\n",
      "Medel is training: epoch 2th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6437 - acc: 0.5456 - val_loss: 4.2735 - val_acc: 0.4706\n",
      "Medel is training: epoch 2th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.7204 - acc: 0.5403 - val_loss: 3.5220 - val_acc: 0.5588\n",
      "Medel is training: epoch 2th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4729 - acc: 0.5645 - val_loss: 3.3173 - val_acc: 0.5646\n",
      "Medel is training: epoch 2th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.8326 - acc: 0.5229 - val_loss: 4.5234 - val_acc: 0.4427\n",
      "Medel is training: epoch 2th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4914 - acc: 0.5678 - val_loss: 3.5367 - val_acc: 0.5559\n",
      "Medel is training: epoch 2th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4245 - acc: 0.5666 - val_loss: 3.3399 - val_acc: 0.5681\n",
      "Medel is training: epoch 2th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.7319 - acc: 0.5341 - val_loss: 3.9109 - val_acc: 0.5174\n",
      "Medel is training: epoch 2th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4570 - acc: 0.5751 - val_loss: 3.5837 - val_acc: 0.5510\n",
      "Medel is training: epoch 2th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3362 - acc: 0.5778 - val_loss: 3.2772 - val_acc: 0.5730\n",
      "Medel is training: epoch 2th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.7406 - acc: 0.5353 - val_loss: 4.1243 - val_acc: 0.4857\n",
      "Medel is training: epoch 2th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4287 - acc: 0.5796 - val_loss: 3.3551 - val_acc: 0.5856\n",
      "Medel is training: epoch 2th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3117 - acc: 0.5849 - val_loss: 3.1973 - val_acc: 0.5833\n",
      "Medel is training: epoch 2th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6396 - acc: 0.5426 - val_loss: 3.9087 - val_acc: 0.5176\n",
      "Medel is training: epoch 2th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5881 - acc: 0.5593 - val_loss: 3.3303 - val_acc: 0.5867\n",
      "Medel is training: epoch 2th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3895 - acc: 0.5761 - val_loss: 3.0241 - val_acc: 0.6030\n",
      "Medel is training: epoch 2th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 3.4165 - acc: 0.5660 - val_loss: 3.4316 - val_acc: 0.5721\n",
      "Medel is training: epoch 2th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.8066 - acc: 0.5301 - val_loss: 3.2575 - val_acc: 0.6030\n",
      "Medel is training: epoch 2th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3452 - acc: 0.5873 - val_loss: 3.3581 - val_acc: 0.5862\n",
      "Medel is training: epoch 2th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0626 - acc: 0.6001 - val_loss: 3.4057 - val_acc: 0.5762\n",
      "Medel is training: epoch 2th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.7912 - acc: 0.5297 - val_loss: 3.5315 - val_acc: 0.5688\n",
      "Medel is training: epoch 2th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3701 - acc: 0.5815 - val_loss: 3.1625 - val_acc: 0.6095\n",
      "Medel is training: epoch 2th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1232 - acc: 0.5999 - val_loss: 2.9565 - val_acc: 0.6023\n",
      "Medel is training: epoch 2th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3305 - acc: 0.5745 - val_loss: 3.5229 - val_acc: 0.5678\n",
      "Medel is training: epoch 2th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.7818 - acc: 0.5325 - val_loss: 3.0906 - val_acc: 0.6183\n",
      "Medel is training: epoch 2th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2919 - acc: 0.5935 - val_loss: 3.2931 - val_acc: 0.5880\n",
      "Medel is training: epoch 2th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9539 - acc: 0.6042 - val_loss: 3.0708 - val_acc: 0.5856\n",
      "Medel is training: epoch 2th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4678 - acc: 0.5686 - val_loss: 3.9650 - val_acc: 0.5073\n",
      "Medel is training: epoch 2th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4478 - acc: 0.5757 - val_loss: 3.2480 - val_acc: 0.6017\n",
      "Medel is training: epoch 2th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2090 - acc: 0.6048 - val_loss: 2.9603 - val_acc: 0.5978\n",
      "Medel is training: epoch 2th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9165 - acc: 0.6088 - val_loss: 3.3008 - val_acc: 0.5851\n",
      "Medel is training: epoch 2th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5943 - acc: 0.5556 - val_loss: 3.9681 - val_acc: 0.5060\n",
      "Medel is training: epoch 2th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2576 - acc: 0.5995 - val_loss: 3.0204 - val_acc: 0.6301\n",
      "Medel is training: epoch 2th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2911 - acc: 0.5911 - val_loss: 2.9448 - val_acc: 0.6057\n",
      "Medel is training: epoch 2th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8492 - acc: 0.6139 - val_loss: 3.3593 - val_acc: 0.5746\n",
      "Medel is training: epoch 2th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5227 - acc: 0.5609 - val_loss: 4.1167 - val_acc: 0.5060\n",
      "Medel is training: epoch 2th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2855 - acc: 0.5934 - val_loss: 3.2128 - val_acc: 0.6052\n",
      "Medel is training: epoch 2th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2118 - acc: 0.6036 - val_loss: 2.7417 - val_acc: 0.6090\n",
      "Medel is training: epoch 2th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8873 - acc: 0.6112 - val_loss: 3.2605 - val_acc: 0.5842\n",
      "Medel is training: epoch 2th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5084 - acc: 0.5631 - val_loss: 3.8704 - val_acc: 0.5241\n",
      "Medel is training: epoch 2th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3898 - acc: 0.5817 - val_loss: 3.2876 - val_acc: 0.5987\n",
      "Medel is training: epoch 3th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 4.0612 - acc: 0.4949 - val_loss: 3.7247 - val_acc: 0.5353\n",
      "Medel is training: epoch 3th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6017 - acc: 0.5513 - val_loss: 3.3196 - val_acc: 0.5599\n",
      "Medel is training: epoch 3th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.7825 - acc: 0.5167 - val_loss: 3.8681 - val_acc: 0.5202\n",
      "Medel is training: epoch 3th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5999 - acc: 0.5521 - val_loss: 3.5556 - val_acc: 0.5562\n",
      "Medel is training: epoch 3th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4768 - acc: 0.5579 - val_loss: 3.7619 - val_acc: 0.5328\n",
      "Medel is training: epoch 3th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 4.0189 - acc: 0.4980 - val_loss: 3.2961 - val_acc: 0.5914\n",
      "Medel is training: epoch 3th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6060 - acc: 0.5472 - val_loss: 3.6023 - val_acc: 0.5523\n",
      "Medel is training: epoch 3th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4896 - acc: 0.5506 - val_loss: 3.8291 - val_acc: 0.5228\n",
      "Medel is training: epoch 3th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.9163 - acc: 0.5095 - val_loss: 3.4111 - val_acc: 0.5730\n",
      "Medel is training: epoch 3th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5230 - acc: 0.5567 - val_loss: 3.1797 - val_acc: 0.5829\n",
      "Medel is training: epoch 3th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6051 - acc: 0.5451 - val_loss: 4.2524 - val_acc: 0.4720\n",
      "Medel is training: epoch 3th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6914 - acc: 0.5420 - val_loss: 3.5075 - val_acc: 0.5588\n",
      "Medel is training: epoch 3th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4398 - acc: 0.5670 - val_loss: 3.2685 - val_acc: 0.5650\n",
      "Medel is training: epoch 3th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 3.7988 - acc: 0.5238 - val_loss: 4.5109 - val_acc: 0.4434\n",
      "Medel is training: epoch 3th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4613 - acc: 0.5687 - val_loss: 3.5234 - val_acc: 0.5555\n",
      "Medel is training: epoch 3th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3889 - acc: 0.5672 - val_loss: 3.2901 - val_acc: 0.5695\n",
      "Medel is training: epoch 3th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6985 - acc: 0.5360 - val_loss: 3.8900 - val_acc: 0.5190\n",
      "Medel is training: epoch 3th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4314 - acc: 0.5753 - val_loss: 3.5714 - val_acc: 0.5494\n",
      "Medel is training: epoch 3th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3016 - acc: 0.5780 - val_loss: 3.2246 - val_acc: 0.5737\n",
      "Medel is training: epoch 3th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.7061 - acc: 0.5369 - val_loss: 4.1018 - val_acc: 0.4874\n",
      "Medel is training: epoch 3th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4044 - acc: 0.5806 - val_loss: 3.3365 - val_acc: 0.5859\n",
      "Medel is training: epoch 3th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2783 - acc: 0.5848 - val_loss: 3.1448 - val_acc: 0.5819\n",
      "Medel is training: epoch 3th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6016 - acc: 0.5436 - val_loss: 3.8842 - val_acc: 0.5202\n",
      "Medel is training: epoch 3th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5632 - acc: 0.5600 - val_loss: 3.3147 - val_acc: 0.5857\n",
      "Medel is training: epoch 3th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3579 - acc: 0.5757 - val_loss: 2.9521 - val_acc: 0.6040\n",
      "Medel is training: epoch 3th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3721 - acc: 0.5658 - val_loss: 3.4066 - val_acc: 0.5744\n",
      "Medel is training: epoch 3th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.7757 - acc: 0.5312 - val_loss: 3.2437 - val_acc: 0.6024\n",
      "Medel is training: epoch 3th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3220 - acc: 0.5873 - val_loss: 3.3446 - val_acc: 0.5844\n",
      "Medel is training: epoch 3th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9975 - acc: 0.6000 - val_loss: 3.3784 - val_acc: 0.5788\n",
      "Medel is training: epoch 3th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.7557 - acc: 0.5318 - val_loss: 3.5108 - val_acc: 0.5694\n",
      "Medel is training: epoch 3th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3441 - acc: 0.5824 - val_loss: 3.1431 - val_acc: 0.6086\n",
      "Medel is training: epoch 3th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0627 - acc: 0.6007 - val_loss: 2.8687 - val_acc: 0.6124\n",
      "Medel is training: epoch 3th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2820 - acc: 0.5759 - val_loss: 3.4976 - val_acc: 0.5688\n",
      "Medel is training: epoch 3th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.7492 - acc: 0.5340 - val_loss: 3.0782 - val_acc: 0.6165\n",
      "Medel is training: epoch 3th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2711 - acc: 0.5938 - val_loss: 3.2826 - val_acc: 0.5868\n",
      "Medel is training: epoch 3th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8672 - acc: 0.6118 - val_loss: 2.9693 - val_acc: 0.5885\n",
      "Medel is training: epoch 3th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4266 - acc: 0.5697 - val_loss: 3.9381 - val_acc: 0.5076\n",
      "Medel is training: epoch 3th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4189 - acc: 0.5759 - val_loss: 3.2320 - val_acc: 0.6014\n",
      "Medel is training: epoch 3th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1892 - acc: 0.6041 - val_loss: 2.8366 - val_acc: 0.6100\n",
      "Medel is training: epoch 3th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8021 - acc: 0.6172 - val_loss: 3.2601 - val_acc: 0.5857\n",
      "Medel is training: epoch 3th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5683 - acc: 0.5558 - val_loss: 3.9474 - val_acc: 0.5069\n",
      "Medel is training: epoch 3th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2310 - acc: 0.5995 - val_loss: 3.0042 - val_acc: 0.6278\n",
      "Medel is training: epoch 3th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2721 - acc: 0.5913 - val_loss: 2.8532 - val_acc: 0.6185\n",
      "Medel is training: epoch 3th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7208 - acc: 0.6318 - val_loss: 3.3070 - val_acc: 0.5756\n",
      "Medel is training: epoch 3th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4932 - acc: 0.5621 - val_loss: 4.1097 - val_acc: 0.5063\n",
      "Medel is training: epoch 3th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2544 - acc: 0.5938 - val_loss: 3.1998 - val_acc: 0.6024\n",
      "Medel is training: epoch 3th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1910 - acc: 0.6023 - val_loss: 2.5573 - val_acc: 0.6374\n",
      "Medel is training: epoch 3th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7577 - acc: 0.6275 - val_loss: 3.2151 - val_acc: 0.5848\n",
      "Medel is training: epoch 3th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4840 - acc: 0.5630 - val_loss: 3.8512 - val_acc: 0.5244\n",
      "Medel is training: epoch 3th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3523 - acc: 0.5829 - val_loss: 3.2731 - val_acc: 0.5985\n",
      "Medel is training: epoch 4th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 4.0231 - acc: 0.4944 - val_loss: 3.7131 - val_acc: 0.5330\n",
      "Medel is training: epoch 4th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 3.5835 - acc: 0.5508 - val_loss: 3.2759 - val_acc: 0.5610\n",
      "Medel is training: epoch 4th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.7412 - acc: 0.5173 - val_loss: 3.8430 - val_acc: 0.5206\n",
      "Medel is training: epoch 4th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5771 - acc: 0.5521 - val_loss: 3.5403 - val_acc: 0.5572\n",
      "Medel is training: epoch 4th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4301 - acc: 0.5589 - val_loss: 3.7315 - val_acc: 0.5335\n",
      "Medel is training: epoch 4th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.9752 - acc: 0.4987 - val_loss: 3.2869 - val_acc: 0.5904\n",
      "Medel is training: epoch 4th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5861 - acc: 0.5466 - val_loss: 3.5877 - val_acc: 0.5526\n",
      "Medel is training: epoch 4th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4234 - acc: 0.5532 - val_loss: 3.7910 - val_acc: 0.5231\n",
      "Medel is training: epoch 4th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.8872 - acc: 0.5102 - val_loss: 3.3957 - val_acc: 0.5736\n",
      "Medel is training: epoch 4th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4965 - acc: 0.5570 - val_loss: 3.0728 - val_acc: 0.5843\n",
      "Medel is training: epoch 4th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5472 - acc: 0.5457 - val_loss: 4.2086 - val_acc: 0.4730\n",
      "Medel is training: epoch 4th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6620 - acc: 0.5430 - val_loss: 3.4959 - val_acc: 0.5591\n",
      "Medel is training: epoch 4th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3899 - acc: 0.5686 - val_loss: 3.1652 - val_acc: 0.5688\n",
      "Medel is training: epoch 4th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.7511 - acc: 0.5244 - val_loss: 4.4649 - val_acc: 0.4444\n",
      "Medel is training: epoch 4th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4406 - acc: 0.5684 - val_loss: 3.5090 - val_acc: 0.5552\n",
      "Medel is training: epoch 4th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3225 - acc: 0.5705 - val_loss: 3.1735 - val_acc: 0.5719\n",
      "Medel is training: epoch 4th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6588 - acc: 0.5373 - val_loss: 3.8576 - val_acc: 0.5213\n",
      "Medel is training: epoch 4th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4069 - acc: 0.5756 - val_loss: 3.5533 - val_acc: 0.5491\n",
      "Medel is training: epoch 4th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2379 - acc: 0.5806 - val_loss: 3.1088 - val_acc: 0.5826\n",
      "Medel is training: epoch 4th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6660 - acc: 0.5379 - val_loss: 4.0737 - val_acc: 0.4877\n",
      "Medel is training: epoch 4th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3777 - acc: 0.5808 - val_loss: 3.3193 - val_acc: 0.5859\n",
      "Medel is training: epoch 4th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2139 - acc: 0.5894 - val_loss: 3.0166 - val_acc: 0.5982\n",
      "Medel is training: epoch 4th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5402 - acc: 0.5463 - val_loss: 3.8573 - val_acc: 0.5214\n",
      "Medel is training: epoch 4th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5306 - acc: 0.5612 - val_loss: 3.2992 - val_acc: 0.5863\n",
      "Medel is training: epoch 4th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3123 - acc: 0.5814 - val_loss: 2.7404 - val_acc: 0.6352\n",
      "Medel is training: epoch 4th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2834 - acc: 0.5718 - val_loss: 3.3723 - val_acc: 0.5747\n",
      "Medel is training: epoch 4th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.7412 - acc: 0.5318 - val_loss: 3.2303 - val_acc: 0.6021\n",
      "Medel is training: epoch 4th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3015 - acc: 0.5873 - val_loss: 3.3286 - val_acc: 0.5844\n",
      "Medel is training: epoch 4th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8334 - acc: 0.6229 - val_loss: 3.3461 - val_acc: 0.5788\n",
      "Medel is training: epoch 4th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.7211 - acc: 0.5340 - val_loss: 3.4780 - val_acc: 0.5691\n",
      "Medel is training: epoch 4th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3166 - acc: 0.5830 - val_loss: 3.1229 - val_acc: 0.6086\n",
      "Medel is training: epoch 4th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9585 - acc: 0.6137 - val_loss: 2.7035 - val_acc: 0.6237\n",
      "Medel is training: epoch 4th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2061 - acc: 0.5796 - val_loss: 3.4584 - val_acc: 0.5713\n",
      "Medel is training: epoch 4th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.7080 - acc: 0.5356 - val_loss: 3.0677 - val_acc: 0.6162\n",
      "Medel is training: epoch 4th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2483 - acc: 0.5929 - val_loss: 3.2676 - val_acc: 0.5871\n",
      "Medel is training: epoch 4th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7213 - acc: 0.6357 - val_loss: 2.8550 - val_acc: 0.5933\n",
      "Medel is training: epoch 4th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3816 - acc: 0.5706 - val_loss: 3.8938 - val_acc: 0.5094\n",
      "Medel is training: epoch 4th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3808 - acc: 0.5762 - val_loss: 3.2118 - val_acc: 0.6012\n",
      "Medel is training: epoch 4th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1617 - acc: 0.6046 - val_loss: 2.6982 - val_acc: 0.6344\n",
      "Medel is training: epoch 4th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.6853 - acc: 0.6328 - val_loss: 3.2099 - val_acc: 0.5863\n",
      "Medel is training: epoch 4th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5271 - acc: 0.5573 - val_loss: 3.9091 - val_acc: 0.5078\n",
      "Medel is training: epoch 4th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1955 - acc: 0.6004 - val_loss: 2.9860 - val_acc: 0.6278\n",
      "Medel is training: epoch 4th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2497 - acc: 0.5913 - val_loss: 2.7830 - val_acc: 0.6305\n",
      "Medel is training: epoch 4th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6182 - acc: 0.6441 - val_loss: 3.2468 - val_acc: 0.5762\n",
      "Medel is training: epoch 4th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4402 - acc: 0.5634 - val_loss: 4.0831 - val_acc: 0.5072\n",
      "Medel is training: epoch 4th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2233 - acc: 0.5947 - val_loss: 3.1835 - val_acc: 0.6035\n",
      "Medel is training: epoch 4th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1654 - acc: 0.6036 - val_loss: 2.4490 - val_acc: 0.6538\n",
      "Medel is training: epoch 4th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6630 - acc: 0.6393 - val_loss: 3.1624 - val_acc: 0.5860\n",
      "Medel is training: epoch 4th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4417 - acc: 0.5650 - val_loss: 3.8186 - val_acc: 0.5241\n",
      "Medel is training: epoch 4th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3233 - acc: 0.5831 - val_loss: 3.2601 - val_acc: 0.5993\n",
      "Medel is training: epoch 5th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.9824 - acc: 0.4959 - val_loss: 3.6933 - val_acc: 0.5333\n",
      "Medel is training: epoch 5th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5576 - acc: 0.5528 - val_loss: 3.2301 - val_acc: 0.5639\n",
      "Medel is training: epoch 5th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6971 - acc: 0.5187 - val_loss: 3.8111 - val_acc: 0.5212\n",
      "Medel is training: epoch 5th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5454 - acc: 0.5530 - val_loss: 3.5286 - val_acc: 0.5562\n",
      "Medel is training: epoch 5th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3923 - acc: 0.5595 - val_loss: 3.6980 - val_acc: 0.5356\n",
      "Medel is training: epoch 5th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.9387 - acc: 0.5002 - val_loss: 3.2611 - val_acc: 0.5937\n",
      "Medel is training: epoch 5th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5659 - acc: 0.5475 - val_loss: 3.5742 - val_acc: 0.5519\n",
      "Medel is training: epoch 5th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3630 - acc: 0.5531 - val_loss: 3.7438 - val_acc: 0.5255\n",
      "Medel is training: epoch 5th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.8445 - acc: 0.5121 - val_loss: 3.3874 - val_acc: 0.5736\n",
      "Medel is training: epoch 5th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4726 - acc: 0.5573 - val_loss: 2.9763 - val_acc: 0.5868\n",
      "Medel is training: epoch 5th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4964 - acc: 0.5478 - val_loss: 4.1795 - val_acc: 0.4744\n",
      "Medel is training: epoch 5th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6376 - acc: 0.5436 - val_loss: 3.4883 - val_acc: 0.5601\n",
      "Medel is training: epoch 5th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3546 - acc: 0.5696 - val_loss: 3.0948 - val_acc: 0.5716\n",
      "Medel is training: epoch 5th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.7095 - acc: 0.5261 - val_loss: 4.4289 - val_acc: 0.4447\n",
      "Medel is training: epoch 5th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4217 - acc: 0.5689 - val_loss: 3.5006 - val_acc: 0.5562\n",
      "Medel is training: epoch 5th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2693 - acc: 0.5714 - val_loss: 3.0944 - val_acc: 0.5750\n",
      "Medel is training: epoch 5th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6189 - acc: 0.5380 - val_loss: 3.8175 - val_acc: 0.5220\n",
      "Medel is training: epoch 5th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3868 - acc: 0.5763 - val_loss: 3.5514 - val_acc: 0.5497\n",
      "Medel is training: epoch 5th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1950 - acc: 0.5811 - val_loss: 3.0313 - val_acc: 0.5792\n",
      "Medel is training: epoch 5th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6258 - acc: 0.5377 - val_loss: 4.0517 - val_acc: 0.4870\n",
      "Medel is training: epoch 5th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3554 - acc: 0.5823 - val_loss: 3.3139 - val_acc: 0.5865\n",
      "Medel is training: epoch 5th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1766 - acc: 0.5876 - val_loss: 2.9400 - val_acc: 0.5962\n",
      "Medel is training: epoch 5th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4957 - acc: 0.5467 - val_loss: 3.8339 - val_acc: 0.5211\n",
      "Medel is training: epoch 5th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5078 - acc: 0.5620 - val_loss: 3.2963 - val_acc: 0.5873\n",
      "Medel is training: epoch 5th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2933 - acc: 0.5816 - val_loss: 2.6518 - val_acc: 0.6336\n",
      "Medel is training: epoch 5th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2249 - acc: 0.5733 - val_loss: 3.3435 - val_acc: 0.5773\n",
      "Medel is training: epoch 5th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.7063 - acc: 0.5327 - val_loss: 3.2320 - val_acc: 0.6018\n",
      "Medel is training: epoch 5th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 3.2874 - acc: 0.5883 - val_loss: 3.3208 - val_acc: 0.5844\n",
      "Medel is training: epoch 5th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7598 - acc: 0.6256 - val_loss: 3.3178 - val_acc: 0.5765\n",
      "Medel is training: epoch 5th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6871 - acc: 0.5340 - val_loss: 3.4531 - val_acc: 0.5685\n",
      "Medel is training: epoch 5th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2944 - acc: 0.5836 - val_loss: 3.1082 - val_acc: 0.6095\n",
      "Medel is training: epoch 5th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9208 - acc: 0.6214 - val_loss: 2.6546 - val_acc: 0.6380\n",
      "Medel is training: epoch 5th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1591 - acc: 0.5812 - val_loss: 3.4295 - val_acc: 0.5697\n",
      "Medel is training: epoch 5th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6755 - acc: 0.5354 - val_loss: 3.0582 - val_acc: 0.6174\n",
      "Medel is training: epoch 5th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2290 - acc: 0.5949 - val_loss: 3.2583 - val_acc: 0.5895\n",
      "Medel is training: epoch 5th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6694 - acc: 0.6353 - val_loss: 2.7916 - val_acc: 0.5939\n",
      "Medel is training: epoch 5th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3468 - acc: 0.5713 - val_loss: 3.8670 - val_acc: 0.5119\n",
      "Medel is training: epoch 5th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3557 - acc: 0.5772 - val_loss: 3.1984 - val_acc: 0.6006\n",
      "Medel is training: epoch 5th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1452 - acc: 0.6048 - val_loss: 2.6590 - val_acc: 0.6398\n",
      "Medel is training: epoch 5th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6315 - acc: 0.6363 - val_loss: 3.1743 - val_acc: 0.5857\n",
      "Medel is training: epoch 5th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4918 - acc: 0.5593 - val_loss: 3.8836 - val_acc: 0.5078\n",
      "Medel is training: epoch 5th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1769 - acc: 0.6006 - val_loss: 2.9758 - val_acc: 0.6287\n",
      "Medel is training: epoch 5th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2381 - acc: 0.5911 - val_loss: 2.7513 - val_acc: 0.6320\n",
      "Medel is training: epoch 5th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5697 - acc: 0.6474 - val_loss: 3.2064 - val_acc: 0.5759\n",
      "Medel is training: epoch 5th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4114 - acc: 0.5643 - val_loss: 4.0626 - val_acc: 0.5060\n",
      "Medel is training: epoch 5th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2000 - acc: 0.5951 - val_loss: 3.1794 - val_acc: 0.6035\n",
      "Medel is training: epoch 5th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1483 - acc: 0.6042 - val_loss: 2.3980 - val_acc: 0.6603\n",
      "Medel is training: epoch 5th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6151 - acc: 0.6410 - val_loss: 3.1287 - val_acc: 0.5885\n",
      "Medel is training: epoch 5th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4117 - acc: 0.5654 - val_loss: 3.7948 - val_acc: 0.5241\n",
      "Medel is training: epoch 5th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2990 - acc: 0.5836 - val_loss: 3.2532 - val_acc: 0.5987\n",
      "Medel is training: epoch 6th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.9516 - acc: 0.4973 - val_loss: 3.6851 - val_acc: 0.5343\n",
      "Medel is training: epoch 6th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5467 - acc: 0.5527 - val_loss: 3.1882 - val_acc: 0.5654\n",
      "Medel is training: epoch 6th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6543 - acc: 0.5195 - val_loss: 3.7896 - val_acc: 0.5209\n",
      "Medel is training: epoch 6th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5302 - acc: 0.5523 - val_loss: 3.5273 - val_acc: 0.5562\n",
      "Medel is training: epoch 6th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3527 - acc: 0.5604 - val_loss: 3.6745 - val_acc: 0.5356\n",
      "Medel is training: epoch 6th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.9091 - acc: 0.5009 - val_loss: 3.2704 - val_acc: 0.5920\n",
      "Medel is training: epoch 6th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5584 - acc: 0.5477 - val_loss: 3.5780 - val_acc: 0.5516\n",
      "Medel is training: epoch 6th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3235 - acc: 0.5548 - val_loss: 3.7221 - val_acc: 0.5275\n",
      "Medel is training: epoch 6th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.8231 - acc: 0.5121 - val_loss: 3.3835 - val_acc: 0.5730\n",
      "Medel is training: epoch 6th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4565 - acc: 0.5577 - val_loss: 2.9309 - val_acc: 0.5900\n",
      "Medel is training: epoch 6th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4634 - acc: 0.5491 - val_loss: 4.1636 - val_acc: 0.4754\n",
      "Medel is training: epoch 6th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6197 - acc: 0.5441 - val_loss: 3.4863 - val_acc: 0.5591\n",
      "Medel is training: epoch 6th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3308 - acc: 0.5695 - val_loss: 3.0585 - val_acc: 0.5706\n",
      "Medel is training: epoch 6th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6860 - acc: 0.5261 - val_loss: 4.4110 - val_acc: 0.4451\n",
      "Medel is training: epoch 6th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4068 - acc: 0.5689 - val_loss: 3.4993 - val_acc: 0.5559\n",
      "Medel is training: epoch 6th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 3.2418 - acc: 0.5738 - val_loss: 3.0627 - val_acc: 0.5757\n",
      "Medel is training: epoch 6th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5921 - acc: 0.5378 - val_loss: 3.7986 - val_acc: 0.5207\n",
      "Medel is training: epoch 6th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3745 - acc: 0.5763 - val_loss: 3.5493 - val_acc: 0.5500\n",
      "Medel is training: epoch 6th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1706 - acc: 0.5827 - val_loss: 2.9956 - val_acc: 0.5816\n",
      "Medel is training: epoch 6th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5996 - acc: 0.5387 - val_loss: 4.0413 - val_acc: 0.4877\n",
      "Medel is training: epoch 6th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3409 - acc: 0.5823 - val_loss: 3.3090 - val_acc: 0.5862\n",
      "Medel is training: epoch 6th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1554 - acc: 0.5897 - val_loss: 2.8922 - val_acc: 0.5989\n",
      "Medel is training: epoch 6th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4726 - acc: 0.5465 - val_loss: 3.8194 - val_acc: 0.5218\n",
      "Medel is training: epoch 6th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4874 - acc: 0.5625 - val_loss: 3.2959 - val_acc: 0.5873\n",
      "Medel is training: epoch 6th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2778 - acc: 0.5816 - val_loss: 2.6142 - val_acc: 0.6386\n",
      "Medel is training: epoch 6th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1910 - acc: 0.5734 - val_loss: 3.3292 - val_acc: 0.5782\n",
      "Medel is training: epoch 6th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6899 - acc: 0.5334 - val_loss: 3.2330 - val_acc: 0.6009\n",
      "Medel is training: epoch 6th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2789 - acc: 0.5882 - val_loss: 3.3206 - val_acc: 0.5838\n",
      "Medel is training: epoch 6th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7207 - acc: 0.6268 - val_loss: 3.3062 - val_acc: 0.5772\n",
      "Medel is training: epoch 6th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6700 - acc: 0.5349 - val_loss: 3.4452 - val_acc: 0.5685\n",
      "Medel is training: epoch 6th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2810 - acc: 0.5833 - val_loss: 3.1050 - val_acc: 0.6092\n",
      "Medel is training: epoch 6th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8970 - acc: 0.6222 - val_loss: 2.6235 - val_acc: 0.6389\n",
      "Medel is training: epoch 6th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1306 - acc: 0.5820 - val_loss: 3.4161 - val_acc: 0.5707\n",
      "Medel is training: epoch 6th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6510 - acc: 0.5356 - val_loss: 3.0627 - val_acc: 0.6171\n",
      "Medel is training: epoch 6th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2199 - acc: 0.5945 - val_loss: 3.2577 - val_acc: 0.5868\n",
      "Medel is training: epoch 6th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6351 - acc: 0.6379 - val_loss: 2.7670 - val_acc: 0.5936\n",
      "Medel is training: epoch 6th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3280 - acc: 0.5720 - val_loss: 3.8636 - val_acc: 0.5116\n",
      "Medel is training: epoch 6th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3399 - acc: 0.5774 - val_loss: 3.1964 - val_acc: 0.6012\n",
      "Medel is training: epoch 6th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1355 - acc: 0.6049 - val_loss: 2.6455 - val_acc: 0.6386\n",
      "Medel is training: epoch 6th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6041 - acc: 0.6377 - val_loss: 3.1608 - val_acc: 0.5860\n",
      "Medel is training: epoch 6th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4750 - acc: 0.5597 - val_loss: 3.8784 - val_acc: 0.5081\n",
      "Medel is training: epoch 6th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1663 - acc: 0.6004 - val_loss: 2.9750 - val_acc: 0.6272\n",
      "Medel is training: epoch 6th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2291 - acc: 0.5914 - val_loss: 2.7431 - val_acc: 0.6277\n",
      "Medel is training: epoch 6th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5501 - acc: 0.6446 - val_loss: 3.1917 - val_acc: 0.5756\n",
      "Medel is training: epoch 6th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3881 - acc: 0.5643 - val_loss: 4.0557 - val_acc: 0.5054\n",
      "Medel is training: epoch 6th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1861 - acc: 0.5960 - val_loss: 3.1758 - val_acc: 0.6026\n",
      "Medel is training: epoch 6th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1360 - acc: 0.6044 - val_loss: 2.3766 - val_acc: 0.6597\n",
      "Medel is training: epoch 6th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5924 - acc: 0.6417 - val_loss: 3.1156 - val_acc: 0.5879\n",
      "Medel is training: epoch 6th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3945 - acc: 0.5662 - val_loss: 3.7869 - val_acc: 0.5250\n",
      "Medel is training: epoch 6th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2863 - acc: 0.5834 - val_loss: 3.2521 - val_acc: 0.5979\n",
      "Medel is training: epoch 7th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.9352 - acc: 0.4977 - val_loss: 3.6813 - val_acc: 0.5340\n",
      "Medel is training: epoch 7th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5345 - acc: 0.5528 - val_loss: 3.1571 - val_acc: 0.5668\n",
      "Medel is training: epoch 7th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6370 - acc: 0.5200 - val_loss: 3.7796 - val_acc: 0.5199\n",
      "Medel is training: epoch 7th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 3.5179 - acc: 0.5536 - val_loss: 3.5222 - val_acc: 0.5558\n",
      "Medel is training: epoch 7th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3364 - acc: 0.5600 - val_loss: 3.6635 - val_acc: 0.5373\n",
      "Medel is training: epoch 7th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.8956 - acc: 0.5009 - val_loss: 3.2669 - val_acc: 0.5930\n",
      "Medel is training: epoch 7th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5463 - acc: 0.5474 - val_loss: 3.5764 - val_acc: 0.5516\n",
      "Medel is training: epoch 7th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2962 - acc: 0.5565 - val_loss: 3.7147 - val_acc: 0.5303\n",
      "Medel is training: epoch 7th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.8058 - acc: 0.5127 - val_loss: 3.3797 - val_acc: 0.5739\n",
      "Medel is training: epoch 7th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4470 - acc: 0.5572 - val_loss: 2.9057 - val_acc: 0.5938\n",
      "Medel is training: epoch 7th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4448 - acc: 0.5484 - val_loss: 4.1492 - val_acc: 0.4778\n",
      "Medel is training: epoch 7th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6014 - acc: 0.5451 - val_loss: 3.4859 - val_acc: 0.5585\n",
      "Medel is training: epoch 7th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3177 - acc: 0.5704 - val_loss: 3.0372 - val_acc: 0.5734\n",
      "Medel is training: epoch 7th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6676 - acc: 0.5272 - val_loss: 4.4052 - val_acc: 0.4464\n",
      "Medel is training: epoch 7th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3963 - acc: 0.5695 - val_loss: 3.4972 - val_acc: 0.5549\n",
      "Medel is training: epoch 7th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2227 - acc: 0.5739 - val_loss: 3.0414 - val_acc: 0.5774\n",
      "Medel is training: epoch 7th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5776 - acc: 0.5387 - val_loss: 3.7916 - val_acc: 0.5193\n",
      "Medel is training: epoch 7th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3619 - acc: 0.5762 - val_loss: 3.5518 - val_acc: 0.5494\n",
      "Medel is training: epoch 7th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1521 - acc: 0.5836 - val_loss: 2.9733 - val_acc: 0.5819\n",
      "Medel is training: epoch 7th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5838 - acc: 0.5398 - val_loss: 4.0330 - val_acc: 0.4903\n",
      "Medel is training: epoch 7th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3268 - acc: 0.5831 - val_loss: 3.3059 - val_acc: 0.5862\n",
      "Medel is training: epoch 7th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1413 - acc: 0.5910 - val_loss: 2.8688 - val_acc: 0.5995\n",
      "Medel is training: epoch 7th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4557 - acc: 0.5473 - val_loss: 3.8114 - val_acc: 0.5214\n",
      "Medel is training: epoch 7th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4765 - acc: 0.5616 - val_loss: 3.2954 - val_acc: 0.5876\n",
      "Medel is training: epoch 7th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2653 - acc: 0.5830 - val_loss: 2.5887 - val_acc: 0.6406\n",
      "Medel is training: epoch 7th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1699 - acc: 0.5745 - val_loss: 3.3205 - val_acc: 0.5766\n",
      "Medel is training: epoch 7th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6663 - acc: 0.5337 - val_loss: 3.2364 - val_acc: 0.5997\n",
      "Medel is training: epoch 7th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2698 - acc: 0.5879 - val_loss: 3.3140 - val_acc: 0.5844\n",
      "Medel is training: epoch 7th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6922 - acc: 0.6277 - val_loss: 3.3034 - val_acc: 0.5775\n",
      "Medel is training: epoch 7th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6560 - acc: 0.5350 - val_loss: 3.4398 - val_acc: 0.5688\n",
      "Medel is training: epoch 7th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2747 - acc: 0.5839 - val_loss: 3.1127 - val_acc: 0.6095\n",
      "Medel is training: epoch 7th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8925 - acc: 0.6222 - val_loss: 2.6034 - val_acc: 0.6412\n",
      "Medel is training: epoch 7th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1134 - acc: 0.5821 - val_loss: 3.4156 - val_acc: 0.5707\n",
      "Medel is training: epoch 7th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6426 - acc: 0.5355 - val_loss: 3.0647 - val_acc: 0.6174\n",
      "Medel is training: epoch 7th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2102 - acc: 0.5949 - val_loss: 3.2576 - val_acc: 0.5874\n",
      "Medel is training: epoch 7th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6153 - acc: 0.6376 - val_loss: 2.7506 - val_acc: 0.5936\n",
      "Medel is training: epoch 7th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3109 - acc: 0.5720 - val_loss: 3.8611 - val_acc: 0.5125\n",
      "Medel is training: epoch 7th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3247 - acc: 0.5784 - val_loss: 3.1966 - val_acc: 0.6006\n",
      "Medel is training: epoch 7th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1291 - acc: 0.6043 - val_loss: 2.6364 - val_acc: 0.6386\n",
      "Medel is training: epoch 7th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5859 - acc: 0.6385 - val_loss: 3.1587 - val_acc: 0.5863\n",
      "Medel is training: epoch 7th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4625 - acc: 0.5602 - val_loss: 3.8748 - val_acc: 0.5087\n",
      "Medel is training: epoch 7th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 3.1557 - acc: 0.6006 - val_loss: 2.9702 - val_acc: 0.6290\n",
      "Medel is training: epoch 7th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2204 - acc: 0.5922 - val_loss: 2.7295 - val_acc: 0.6283\n",
      "Medel is training: epoch 7th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5286 - acc: 0.6455 - val_loss: 3.1805 - val_acc: 0.5756\n",
      "Medel is training: epoch 7th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3772 - acc: 0.5648 - val_loss: 4.0592 - val_acc: 0.5048\n",
      "Medel is training: epoch 7th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1787 - acc: 0.5950 - val_loss: 3.1768 - val_acc: 0.6023\n",
      "Medel is training: epoch 7th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1274 - acc: 0.6043 - val_loss: 2.3516 - val_acc: 0.6597\n",
      "Medel is training: epoch 7th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5671 - acc: 0.6415 - val_loss: 3.1061 - val_acc: 0.5879\n",
      "Medel is training: epoch 7th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3759 - acc: 0.5665 - val_loss: 3.7769 - val_acc: 0.5244\n",
      "Medel is training: epoch 7th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2743 - acc: 0.5839 - val_loss: 3.2500 - val_acc: 0.5985\n",
      "Medel is training: epoch 8th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.9217 - acc: 0.4976 - val_loss: 3.6869 - val_acc: 0.5333\n",
      "Medel is training: epoch 8th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5305 - acc: 0.5519 - val_loss: 3.1382 - val_acc: 0.5676\n",
      "Medel is training: epoch 8th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6160 - acc: 0.5201 - val_loss: 3.7760 - val_acc: 0.5202\n",
      "Medel is training: epoch 8th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5079 - acc: 0.5534 - val_loss: 3.5207 - val_acc: 0.5562\n",
      "Medel is training: epoch 8th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3152 - acc: 0.5611 - val_loss: 3.6539 - val_acc: 0.5380\n",
      "Medel is training: epoch 8th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.8806 - acc: 0.5016 - val_loss: 3.2745 - val_acc: 0.5907\n",
      "Medel is training: epoch 8th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5359 - acc: 0.5480 - val_loss: 3.5728 - val_acc: 0.5526\n",
      "Medel is training: epoch 8th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2698 - acc: 0.5572 - val_loss: 3.7112 - val_acc: 0.5296\n",
      "Medel is training: epoch 8th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.7903 - acc: 0.5138 - val_loss: 3.3809 - val_acc: 0.5730\n",
      "Medel is training: epoch 8th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4404 - acc: 0.5583 - val_loss: 2.8863 - val_acc: 0.5949\n",
      "Medel is training: epoch 8th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4252 - acc: 0.5486 - val_loss: 4.1543 - val_acc: 0.4774\n",
      "Medel is training: epoch 8th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5941 - acc: 0.5452 - val_loss: 3.4831 - val_acc: 0.5588\n",
      "Medel is training: epoch 8th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3025 - acc: 0.5713 - val_loss: 3.0175 - val_acc: 0.5748\n",
      "Medel is training: epoch 8th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6516 - acc: 0.5272 - val_loss: 4.3914 - val_acc: 0.4464\n",
      "Medel is training: epoch 8th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3880 - acc: 0.5709 - val_loss: 3.4972 - val_acc: 0.5552\n",
      "Medel is training: epoch 8th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2035 - acc: 0.5754 - val_loss: 3.0251 - val_acc: 0.5815\n",
      "Medel is training: epoch 8th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5638 - acc: 0.5394 - val_loss: 3.7870 - val_acc: 0.5223\n",
      "Medel is training: epoch 8th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3548 - acc: 0.5759 - val_loss: 3.5503 - val_acc: 0.5478\n",
      "Medel is training: epoch 8th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1363 - acc: 0.5866 - val_loss: 2.9558 - val_acc: 0.5826\n",
      "Medel is training: epoch 8th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5725 - acc: 0.5398 - val_loss: 4.0360 - val_acc: 0.4897\n",
      "Medel is training: epoch 8th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3177 - acc: 0.5829 - val_loss: 3.3063 - val_acc: 0.5862\n",
      "Medel is training: epoch 8th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1262 - acc: 0.5895 - val_loss: 2.8476 - val_acc: 0.5948\n",
      "Medel is training: epoch 8th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4423 - acc: 0.5460 - val_loss: 3.8164 - val_acc: 0.5208\n",
      "Medel is training: epoch 8th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4674 - acc: 0.5621 - val_loss: 3.2898 - val_acc: 0.5857\n",
      "Medel is training: epoch 8th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2549 - acc: 0.5834 - val_loss: 2.5724 - val_acc: 0.6402\n",
      "Medel is training: epoch 8th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1532 - acc: 0.5757 - val_loss: 3.3165 - val_acc: 0.5776\n",
      "Medel is training: epoch 8th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6614 - acc: 0.5337 - val_loss: 3.2306 - val_acc: 0.5994\n",
      "Medel is training: epoch 8th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2561 - acc: 0.5886 - val_loss: 3.3179 - val_acc: 0.5841\n",
      "Medel is training: epoch 8th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6681 - acc: 0.6283 - val_loss: 3.2938 - val_acc: 0.5778\n",
      "Medel is training: epoch 8th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 3.6343 - acc: 0.5356 - val_loss: 3.4379 - val_acc: 0.5676\n",
      "Medel is training: epoch 8th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2658 - acc: 0.5836 - val_loss: 3.1079 - val_acc: 0.6095\n",
      "Medel is training: epoch 8th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8674 - acc: 0.6221 - val_loss: 2.5812 - val_acc: 0.6438\n",
      "Medel is training: epoch 8th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0971 - acc: 0.5829 - val_loss: 3.4046 - val_acc: 0.5707\n",
      "Medel is training: epoch 8th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6270 - acc: 0.5362 - val_loss: 3.0668 - val_acc: 0.6180\n",
      "Medel is training: epoch 8th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2001 - acc: 0.5949 - val_loss: 3.2538 - val_acc: 0.5871\n",
      "Medel is training: epoch 8th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5964 - acc: 0.6401 - val_loss: 2.7331 - val_acc: 0.5936\n",
      "Medel is training: epoch 8th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3009 - acc: 0.5717 - val_loss: 3.8621 - val_acc: 0.5138\n",
      "Medel is training: epoch 8th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3142 - acc: 0.5780 - val_loss: 3.1934 - val_acc: 0.5994\n",
      "Medel is training: epoch 8th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1210 - acc: 0.6047 - val_loss: 2.6177 - val_acc: 0.6453\n",
      "Medel is training: epoch 8th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5570 - acc: 0.6405 - val_loss: 3.1520 - val_acc: 0.5873\n",
      "Medel is training: epoch 8th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4524 - acc: 0.5602 - val_loss: 3.8736 - val_acc: 0.5097\n",
      "Medel is training: epoch 8th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1457 - acc: 0.6007 - val_loss: 2.9726 - val_acc: 0.6284\n",
      "Medel is training: epoch 8th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2137 - acc: 0.5921 - val_loss: 2.7178 - val_acc: 0.6326\n",
      "Medel is training: epoch 8th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5039 - acc: 0.6489 - val_loss: 3.1704 - val_acc: 0.5759\n",
      "Medel is training: epoch 8th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3709 - acc: 0.5646 - val_loss: 4.0578 - val_acc: 0.5066\n",
      "Medel is training: epoch 8th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1710 - acc: 0.5956 - val_loss: 3.1768 - val_acc: 0.6029\n",
      "Medel is training: epoch 8th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1193 - acc: 0.6041 - val_loss: 2.3215 - val_acc: 0.6600\n",
      "Medel is training: epoch 8th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5414 - acc: 0.6416 - val_loss: 3.0955 - val_acc: 0.5869\n",
      "Medel is training: epoch 8th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3639 - acc: 0.5670 - val_loss: 3.7663 - val_acc: 0.5248\n",
      "Medel is training: epoch 8th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2647 - acc: 0.5836 - val_loss: 3.2490 - val_acc: 0.5979\n",
      "Medel is training: epoch 9th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.9057 - acc: 0.4985 - val_loss: 3.6787 - val_acc: 0.5340\n",
      "Medel is training: epoch 9th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5191 - acc: 0.5524 - val_loss: 3.1152 - val_acc: 0.5665\n",
      "Medel is training: epoch 9th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5994 - acc: 0.5205 - val_loss: 3.7673 - val_acc: 0.5199\n",
      "Medel is training: epoch 9th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4963 - acc: 0.5538 - val_loss: 3.5138 - val_acc: 0.5562\n",
      "Medel is training: epoch 9th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2967 - acc: 0.5623 - val_loss: 3.6463 - val_acc: 0.5397\n",
      "Medel is training: epoch 9th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.8661 - acc: 0.5022 - val_loss: 3.2749 - val_acc: 0.5890\n",
      "Medel is training: epoch 9th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5295 - acc: 0.5478 - val_loss: 3.5747 - val_acc: 0.5516\n",
      "Medel is training: epoch 9th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2502 - acc: 0.5580 - val_loss: 3.7069 - val_acc: 0.5296\n",
      "Medel is training: epoch 9th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.7831 - acc: 0.5135 - val_loss: 3.3762 - val_acc: 0.5733\n",
      "Medel is training: epoch 9th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4281 - acc: 0.5580 - val_loss: 2.8592 - val_acc: 0.5949\n",
      "Medel is training: epoch 9th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4112 - acc: 0.5498 - val_loss: 4.1482 - val_acc: 0.4771\n",
      "Medel is training: epoch 9th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5827 - acc: 0.5446 - val_loss: 3.4867 - val_acc: 0.5582\n",
      "Medel is training: epoch 9th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2884 - acc: 0.5711 - val_loss: 2.9900 - val_acc: 0.5758\n",
      "Medel is training: epoch 9th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6397 - acc: 0.5280 - val_loss: 4.3863 - val_acc: 0.4478\n",
      "Medel is training: epoch 9th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3779 - acc: 0.5710 - val_loss: 3.4996 - val_acc: 0.5555\n",
      "Medel is training: epoch 9th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1857 - acc: 0.5755 - val_loss: 3.0022 - val_acc: 0.5812\n",
      "Medel is training: epoch 9th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5467 - acc: 0.5409 - val_loss: 3.7789 - val_acc: 0.5223\n",
      "Medel is training: epoch 9th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 3.3470 - acc: 0.5754 - val_loss: 3.5568 - val_acc: 0.5497\n",
      "Medel is training: epoch 9th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1167 - acc: 0.5885 - val_loss: 2.9301 - val_acc: 0.5871\n",
      "Medel is training: epoch 9th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5571 - acc: 0.5409 - val_loss: 4.0301 - val_acc: 0.4893\n",
      "Medel is training: epoch 9th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3112 - acc: 0.5828 - val_loss: 3.3038 - val_acc: 0.5856\n",
      "Medel is training: epoch 9th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1133 - acc: 0.5936 - val_loss: 2.8170 - val_acc: 0.6068\n",
      "Medel is training: epoch 9th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4253 - acc: 0.5481 - val_loss: 3.8094 - val_acc: 0.5214\n",
      "Medel is training: epoch 9th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4567 - acc: 0.5623 - val_loss: 3.2922 - val_acc: 0.5860\n",
      "Medel is training: epoch 9th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2437 - acc: 0.5831 - val_loss: 2.5420 - val_acc: 0.6442\n",
      "Medel is training: epoch 9th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1301 - acc: 0.5776 - val_loss: 3.3073 - val_acc: 0.5779\n",
      "Medel is training: epoch 9th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6485 - acc: 0.5345 - val_loss: 3.2379 - val_acc: 0.5972\n",
      "Medel is training: epoch 9th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2522 - acc: 0.5879 - val_loss: 3.3156 - val_acc: 0.5844\n",
      "Medel is training: epoch 9th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6372 - acc: 0.6302 - val_loss: 3.2896 - val_acc: 0.5791\n",
      "Medel is training: epoch 9th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6154 - acc: 0.5361 - val_loss: 3.4358 - val_acc: 0.5676\n",
      "Medel is training: epoch 9th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2553 - acc: 0.5839 - val_loss: 3.1053 - val_acc: 0.6092\n",
      "Medel is training: epoch 9th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8525 - acc: 0.6235 - val_loss: 2.5615 - val_acc: 0.6441\n",
      "Medel is training: epoch 9th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0804 - acc: 0.5834 - val_loss: 3.3997 - val_acc: 0.5722\n",
      "Medel is training: epoch 9th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6107 - acc: 0.5371 - val_loss: 3.0746 - val_acc: 0.6156\n",
      "Medel is training: epoch 9th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2046 - acc: 0.5932 - val_loss: 3.2626 - val_acc: 0.5854\n",
      "Medel is training: epoch 9th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5761 - acc: 0.6385 - val_loss: 2.6944 - val_acc: 0.6035\n",
      "Medel is training: epoch 9th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2904 - acc: 0.5725 - val_loss: 3.8618 - val_acc: 0.5141\n",
      "Medel is training: epoch 9th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3038 - acc: 0.5774 - val_loss: 3.1920 - val_acc: 0.5994\n",
      "Medel is training: epoch 9th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1135 - acc: 0.6055 - val_loss: 2.6093 - val_acc: 0.6441\n",
      "Medel is training: epoch 9th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5324 - acc: 0.6421 - val_loss: 3.1395 - val_acc: 0.5885\n",
      "Medel is training: epoch 9th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4355 - acc: 0.5608 - val_loss: 3.8739 - val_acc: 0.5091\n",
      "Medel is training: epoch 9th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1382 - acc: 0.6015 - val_loss: 2.9702 - val_acc: 0.6284\n",
      "Medel is training: epoch 9th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2073 - acc: 0.5921 - val_loss: 2.7101 - val_acc: 0.6314\n",
      "Medel is training: epoch 9th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4771 - acc: 0.6510 - val_loss: 3.1499 - val_acc: 0.5824\n",
      "Medel is training: epoch 9th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3506 - acc: 0.5654 - val_loss: 4.0538 - val_acc: 0.5057\n",
      "Medel is training: epoch 9th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1618 - acc: 0.5962 - val_loss: 3.1760 - val_acc: 0.6026\n",
      "Medel is training: epoch 9th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1139 - acc: 0.6038 - val_loss: 2.3023 - val_acc: 0.6590\n",
      "Medel is training: epoch 9th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5157 - acc: 0.6440 - val_loss: 3.0808 - val_acc: 0.5909\n",
      "Medel is training: epoch 9th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3588 - acc: 0.5673 - val_loss: 3.7696 - val_acc: 0.5250\n",
      "Medel is training: epoch 9th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2550 - acc: 0.5841 - val_loss: 3.2487 - val_acc: 0.5967\n",
      "Medel is training: epoch 10th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.8932 - acc: 0.4997 - val_loss: 3.6788 - val_acc: 0.5333\n",
      "Medel is training: epoch 10th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5076 - acc: 0.5534 - val_loss: 3.0720 - val_acc: 0.5658\n",
      "Medel is training: epoch 10th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5828 - acc: 0.5211 - val_loss: 3.7729 - val_acc: 0.5212\n",
      "Medel is training: epoch 10th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4911 - acc: 0.5539 - val_loss: 3.5117 - val_acc: 0.5558\n",
      "Medel is training: epoch 10th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2730 - acc: 0.5622 - val_loss: 3.6375 - val_acc: 0.5387\n",
      "Medel is training: epoch 10th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 3.8459 - acc: 0.5036 - val_loss: 3.2897 - val_acc: 0.5854\n",
      "Medel is training: epoch 10th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5220 - acc: 0.5480 - val_loss: 3.5768 - val_acc: 0.5509\n",
      "Medel is training: epoch 10th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2216 - acc: 0.5584 - val_loss: 3.7073 - val_acc: 0.5299\n",
      "Medel is training: epoch 10th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.7697 - acc: 0.5141 - val_loss: 3.3753 - val_acc: 0.5726\n",
      "Medel is training: epoch 10th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4219 - acc: 0.5572 - val_loss: 2.8348 - val_acc: 0.5960\n",
      "Medel is training: epoch 10th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3945 - acc: 0.5504 - val_loss: 4.1428 - val_acc: 0.4771\n",
      "Medel is training: epoch 10th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5753 - acc: 0.5451 - val_loss: 3.4849 - val_acc: 0.5582\n",
      "Medel is training: epoch 10th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2725 - acc: 0.5721 - val_loss: 2.9630 - val_acc: 0.5794\n",
      "Medel is training: epoch 10th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6235 - acc: 0.5283 - val_loss: 4.3727 - val_acc: 0.4478\n",
      "Medel is training: epoch 10th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3702 - acc: 0.5710 - val_loss: 3.5036 - val_acc: 0.5565\n",
      "Medel is training: epoch 10th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1664 - acc: 0.5794 - val_loss: 2.9724 - val_acc: 0.5873\n",
      "Medel is training: epoch 10th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5308 - acc: 0.5413 - val_loss: 3.7669 - val_acc: 0.5213\n",
      "Medel is training: epoch 10th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3388 - acc: 0.5750 - val_loss: 3.5589 - val_acc: 0.5469\n",
      "Medel is training: epoch 10th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0937 - acc: 0.5904 - val_loss: 2.8986 - val_acc: 0.5895\n",
      "Medel is training: epoch 10th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5418 - acc: 0.5417 - val_loss: 4.0286 - val_acc: 0.4890\n",
      "Medel is training: epoch 10th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2986 - acc: 0.5831 - val_loss: 3.3014 - val_acc: 0.5853\n",
      "Medel is training: epoch 10th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0968 - acc: 0.5940 - val_loss: 2.7836 - val_acc: 0.6118\n",
      "Medel is training: epoch 10th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4024 - acc: 0.5511 - val_loss: 3.8008 - val_acc: 0.5231\n",
      "Medel is training: epoch 10th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4424 - acc: 0.5621 - val_loss: 3.2867 - val_acc: 0.5857\n",
      "Medel is training: epoch 10th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2294 - acc: 0.5844 - val_loss: 2.5035 - val_acc: 0.6452\n",
      "Medel is training: epoch 10th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0992 - acc: 0.5810 - val_loss: 3.2942 - val_acc: 0.5776\n",
      "Medel is training: epoch 10th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6310 - acc: 0.5350 - val_loss: 3.2352 - val_acc: 0.5975\n",
      "Medel is training: epoch 10th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2387 - acc: 0.5889 - val_loss: 3.3112 - val_acc: 0.5838\n",
      "Medel is training: epoch 10th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5945 - acc: 0.6354 - val_loss: 3.2711 - val_acc: 0.5813\n",
      "Medel is training: epoch 10th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5998 - acc: 0.5364 - val_loss: 3.4336 - val_acc: 0.5679\n",
      "Medel is training: epoch 10th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2455 - acc: 0.5844 - val_loss: 3.1013 - val_acc: 0.6089\n",
      "Medel is training: epoch 10th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8282 - acc: 0.6246 - val_loss: 2.5332 - val_acc: 0.6454\n",
      "Medel is training: epoch 10th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0525 - acc: 0.5870 - val_loss: 3.3896 - val_acc: 0.5719\n",
      "Medel is training: epoch 10th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5969 - acc: 0.5376 - val_loss: 3.0665 - val_acc: 0.6171\n",
      "Medel is training: epoch 10th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1878 - acc: 0.5950 - val_loss: 3.2618 - val_acc: 0.5868\n",
      "Medel is training: epoch 10th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5434 - acc: 0.6416 - val_loss: 2.6667 - val_acc: 0.6124\n",
      "Medel is training: epoch 10th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2657 - acc: 0.5736 - val_loss: 3.8542 - val_acc: 0.5138\n",
      "Medel is training: epoch 10th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2908 - acc: 0.5788 - val_loss: 3.1858 - val_acc: 0.5994\n",
      "Medel is training: epoch 10th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1044 - acc: 0.6050 - val_loss: 2.5797 - val_acc: 0.6447\n",
      "Medel is training: epoch 10th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4948 - acc: 0.6452 - val_loss: 3.1204 - val_acc: 0.5916\n",
      "Medel is training: epoch 10th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4153 - acc: 0.5615 - val_loss: 3.8684 - val_acc: 0.5091\n",
      "Medel is training: epoch 10th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1263 - acc: 0.6013 - val_loss: 2.9684 - val_acc: 0.6272\n",
      "Medel is training: epoch 10th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2002 - acc: 0.5926 - val_loss: 2.6888 - val_acc: 0.6323\n",
      "Medel is training: epoch 10th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.4417 - acc: 0.6522 - val_loss: 3.1283 - val_acc: 0.5852\n",
      "Medel is training: epoch 10th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3390 - acc: 0.5659 - val_loss: 4.0466 - val_acc: 0.5075\n",
      "Medel is training: epoch 10th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1488 - acc: 0.5953 - val_loss: 3.1776 - val_acc: 0.6012\n",
      "Medel is training: epoch 10th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1062 - acc: 0.6032 - val_loss: 2.2726 - val_acc: 0.6618\n",
      "Medel is training: epoch 10th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4872 - acc: 0.6459 - val_loss: 3.0662 - val_acc: 0.5940\n",
      "Medel is training: epoch 10th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3387 - acc: 0.5677 - val_loss: 3.7539 - val_acc: 0.5247\n",
      "Medel is training: epoch 10th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2411 - acc: 0.5835 - val_loss: 3.2465 - val_acc: 0.5965\n",
      "Medel is training: epoch 11th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.8817 - acc: 0.5000 - val_loss: 3.6751 - val_acc: 0.5343\n",
      "Medel is training: epoch 11th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4959 - acc: 0.5530 - val_loss: 3.0244 - val_acc: 0.5647\n",
      "Medel is training: epoch 11th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5592 - acc: 0.5220 - val_loss: 3.7603 - val_acc: 0.5192\n",
      "Medel is training: epoch 11th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4762 - acc: 0.5544 - val_loss: 3.5070 - val_acc: 0.5548\n",
      "Medel is training: epoch 11th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2529 - acc: 0.5616 - val_loss: 3.6252 - val_acc: 0.5397\n",
      "Medel is training: epoch 11th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.8305 - acc: 0.5027 - val_loss: 3.2853 - val_acc: 0.5871\n",
      "Medel is training: epoch 11th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5126 - acc: 0.5480 - val_loss: 3.5724 - val_acc: 0.5509\n",
      "Medel is training: epoch 11th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1965 - acc: 0.5597 - val_loss: 3.6909 - val_acc: 0.5303\n",
      "Medel is training: epoch 11th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.7488 - acc: 0.5145 - val_loss: 3.3716 - val_acc: 0.5717\n",
      "Medel is training: epoch 11th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4103 - acc: 0.5582 - val_loss: 2.7715 - val_acc: 0.6080\n",
      "Medel is training: epoch 11th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3695 - acc: 0.5534 - val_loss: 4.1225 - val_acc: 0.4768\n",
      "Medel is training: epoch 11th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5578 - acc: 0.5462 - val_loss: 3.4833 - val_acc: 0.5585\n",
      "Medel is training: epoch 11th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2546 - acc: 0.5744 - val_loss: 2.9222 - val_acc: 0.5850\n",
      "Medel is training: epoch 11th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6082 - acc: 0.5283 - val_loss: 4.3679 - val_acc: 0.4475\n",
      "Medel is training: epoch 11th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3595 - acc: 0.5713 - val_loss: 3.5062 - val_acc: 0.5552\n",
      "Medel is training: epoch 11th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1381 - acc: 0.5811 - val_loss: 2.9409 - val_acc: 0.5901\n",
      "Medel is training: epoch 11th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5083 - acc: 0.5415 - val_loss: 3.7595 - val_acc: 0.5223\n",
      "Medel is training: epoch 11th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3280 - acc: 0.5747 - val_loss: 3.5634 - val_acc: 0.5478\n",
      "Medel is training: epoch 11th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0719 - acc: 0.5911 - val_loss: 2.8647 - val_acc: 0.5950\n",
      "Medel is training: epoch 11th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5203 - acc: 0.5418 - val_loss: 4.0105 - val_acc: 0.4884\n",
      "Medel is training: epoch 11th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2890 - acc: 0.5822 - val_loss: 3.3012 - val_acc: 0.5850\n",
      "Medel is training: epoch 11th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0791 - acc: 0.5951 - val_loss: 2.7556 - val_acc: 0.6117\n",
      "Medel is training: epoch 11th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3857 - acc: 0.5524 - val_loss: 3.7919 - val_acc: 0.5234\n",
      "Medel is training: epoch 11th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4306 - acc: 0.5618 - val_loss: 3.2883 - val_acc: 0.5854\n",
      "Medel is training: epoch 11th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2199 - acc: 0.5856 - val_loss: 2.4692 - val_acc: 0.6486\n",
      "Medel is training: epoch 11th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0744 - acc: 0.5821 - val_loss: 3.2824 - val_acc: 0.5773\n",
      "Medel is training: epoch 11th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6134 - acc: 0.5359 - val_loss: 3.2297 - val_acc: 0.5975\n",
      "Medel is training: epoch 11th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2306 - acc: 0.5885 - val_loss: 3.3074 - val_acc: 0.5832\n",
      "Medel is training: epoch 11th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5659 - acc: 0.6391 - val_loss: 3.2546 - val_acc: 0.5810\n",
      "Medel is training: epoch 11th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5840 - acc: 0.5374 - val_loss: 3.4320 - val_acc: 0.5685\n",
      "Medel is training: epoch 11th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 3.2318 - acc: 0.5841 - val_loss: 3.1018 - val_acc: 0.6086\n",
      "Medel is training: epoch 11th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 10s - loss: 2.8128 - acc: 0.6271 - val_loss: 2.5053 - val_acc: 0.6519\n",
      "Medel is training: epoch 11th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0243 - acc: 0.5895 - val_loss: 3.3752 - val_acc: 0.5722\n",
      "Medel is training: epoch 11th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5783 - acc: 0.5375 - val_loss: 3.0607 - val_acc: 0.6171\n",
      "Medel is training: epoch 11th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1748 - acc: 0.5950 - val_loss: 3.2568 - val_acc: 0.5868\n",
      "Medel is training: epoch 11th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5152 - acc: 0.6458 - val_loss: 2.6390 - val_acc: 0.6115\n",
      "Medel is training: epoch 11th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2478 - acc: 0.5744 - val_loss: 3.8406 - val_acc: 0.5141\n",
      "Medel is training: epoch 11th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2773 - acc: 0.5788 - val_loss: 3.1828 - val_acc: 0.6000\n",
      "Medel is training: epoch 11th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0988 - acc: 0.6050 - val_loss: 2.5642 - val_acc: 0.6477\n",
      "Medel is training: epoch 11th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4640 - acc: 0.6481 - val_loss: 3.1055 - val_acc: 0.5910\n",
      "Medel is training: epoch 11th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3986 - acc: 0.5623 - val_loss: 3.8588 - val_acc: 0.5091\n",
      "Medel is training: epoch 11th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1171 - acc: 0.6015 - val_loss: 2.9681 - val_acc: 0.6275\n",
      "Medel is training: epoch 11th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1955 - acc: 0.5925 - val_loss: 2.6698 - val_acc: 0.6341\n",
      "Medel is training: epoch 11th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4102 - acc: 0.6546 - val_loss: 3.1077 - val_acc: 0.5846\n",
      "Medel is training: epoch 11th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3181 - acc: 0.5660 - val_loss: 4.0372 - val_acc: 0.5072\n",
      "Medel is training: epoch 11th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1358 - acc: 0.5956 - val_loss: 3.1757 - val_acc: 0.6021\n",
      "Medel is training: epoch 11th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1008 - acc: 0.6035 - val_loss: 2.2531 - val_acc: 0.6627\n",
      "Medel is training: epoch 11th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4645 - acc: 0.6474 - val_loss: 3.0521 - val_acc: 0.5937\n",
      "Medel is training: epoch 11th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3205 - acc: 0.5676 - val_loss: 3.7441 - val_acc: 0.5253\n",
      "Medel is training: epoch 11th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2253 - acc: 0.5848 - val_loss: 3.2471 - val_acc: 0.5959\n",
      "Medel is training: epoch 12th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.8657 - acc: 0.4990 - val_loss: 3.6760 - val_acc: 0.5333\n",
      "Medel is training: epoch 12th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4883 - acc: 0.5523 - val_loss: 2.9717 - val_acc: 0.5668\n",
      "Medel is training: epoch 12th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5313 - acc: 0.5222 - val_loss: 3.7543 - val_acc: 0.5185\n",
      "Medel is training: epoch 12th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4687 - acc: 0.5539 - val_loss: 3.5053 - val_acc: 0.5545\n",
      "Medel is training: epoch 12th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2231 - acc: 0.5657 - val_loss: 3.6095 - val_acc: 0.5390\n",
      "Medel is training: epoch 12th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.8128 - acc: 0.5036 - val_loss: 3.2940 - val_acc: 0.5841\n",
      "Medel is training: epoch 12th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5014 - acc: 0.5478 - val_loss: 3.5686 - val_acc: 0.5509\n",
      "Medel is training: epoch 12th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1646 - acc: 0.5634 - val_loss: 3.6760 - val_acc: 0.5310\n",
      "Medel is training: epoch 12th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.7385 - acc: 0.5137 - val_loss: 3.3672 - val_acc: 0.5730\n",
      "Medel is training: epoch 12th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3978 - acc: 0.5596 - val_loss: 2.7276 - val_acc: 0.6087\n",
      "Medel is training: epoch 12th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3429 - acc: 0.5549 - val_loss: 4.1131 - val_acc: 0.4781\n",
      "Medel is training: epoch 12th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5436 - acc: 0.5456 - val_loss: 3.4843 - val_acc: 0.5578\n",
      "Medel is training: epoch 12th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2376 - acc: 0.5756 - val_loss: 2.8755 - val_acc: 0.5860\n",
      "Medel is training: epoch 12th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5908 - acc: 0.5288 - val_loss: 4.3597 - val_acc: 0.4481\n",
      "Medel is training: epoch 12th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3471 - acc: 0.5715 - val_loss: 3.5019 - val_acc: 0.5546\n",
      "Medel is training: epoch 12th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1138 - acc: 0.5819 - val_loss: 2.9060 - val_acc: 0.5917\n",
      "Medel is training: epoch 12th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4896 - acc: 0.5417 - val_loss: 3.7476 - val_acc: 0.5233\n",
      "Medel is training: epoch 12th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3172 - acc: 0.5746 - val_loss: 3.5643 - val_acc: 0.5478\n",
      "Medel is training: epoch 12th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0480 - acc: 0.5924 - val_loss: 2.8281 - val_acc: 0.5963\n",
      "Medel is training: epoch 12th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 3.4992 - acc: 0.5426 - val_loss: 4.0046 - val_acc: 0.4900\n",
      "Medel is training: epoch 12th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2785 - acc: 0.5824 - val_loss: 3.2923 - val_acc: 0.5853\n",
      "Medel is training: epoch 12th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0630 - acc: 0.5950 - val_loss: 2.7182 - val_acc: 0.6141\n",
      "Medel is training: epoch 12th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3613 - acc: 0.5529 - val_loss: 3.7809 - val_acc: 0.5237\n",
      "Medel is training: epoch 12th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4188 - acc: 0.5623 - val_loss: 3.2842 - val_acc: 0.5863\n",
      "Medel is training: epoch 12th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2064 - acc: 0.5859 - val_loss: 2.4399 - val_acc: 0.6496\n",
      "Medel is training: epoch 12th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 3.0434 - acc: 0.5848 - val_loss: 3.2698 - val_acc: 0.5769\n",
      "Medel is training: epoch 12th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5942 - acc: 0.5355 - val_loss: 3.2260 - val_acc: 0.5978\n",
      "Medel is training: epoch 12th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2235 - acc: 0.5894 - val_loss: 3.3047 - val_acc: 0.5832\n",
      "Medel is training: epoch 12th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5273 - acc: 0.6421 - val_loss: 3.2354 - val_acc: 0.5813\n",
      "Medel is training: epoch 12th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5612 - acc: 0.5388 - val_loss: 3.4296 - val_acc: 0.5663\n",
      "Medel is training: epoch 12th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2234 - acc: 0.5838 - val_loss: 3.0979 - val_acc: 0.6089\n",
      "Medel is training: epoch 12th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7910 - acc: 0.6280 - val_loss: 2.4712 - val_acc: 0.6532\n",
      "Medel is training: epoch 12th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0047 - acc: 0.5909 - val_loss: 3.3580 - val_acc: 0.5719\n",
      "Medel is training: epoch 12th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5574 - acc: 0.5384 - val_loss: 3.0632 - val_acc: 0.6159\n",
      "Medel is training: epoch 12th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1673 - acc: 0.5947 - val_loss: 3.2578 - val_acc: 0.5868\n",
      "Medel is training: epoch 12th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4885 - acc: 0.6476 - val_loss: 2.6094 - val_acc: 0.6118\n",
      "Medel is training: epoch 12th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2310 - acc: 0.5737 - val_loss: 3.8332 - val_acc: 0.5147\n",
      "Medel is training: epoch 12th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2656 - acc: 0.5797 - val_loss: 3.1806 - val_acc: 0.5994\n",
      "Medel is training: epoch 12th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0908 - acc: 0.6055 - val_loss: 2.5520 - val_acc: 0.6496\n",
      "Medel is training: epoch 12th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4390 - acc: 0.6493 - val_loss: 3.0856 - val_acc: 0.5919\n",
      "Medel is training: epoch 12th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3810 - acc: 0.5616 - val_loss: 3.8538 - val_acc: 0.5078\n",
      "Medel is training: epoch 12th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1003 - acc: 0.6024 - val_loss: 2.9665 - val_acc: 0.6272\n",
      "Medel is training: epoch 12th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1870 - acc: 0.5922 - val_loss: 2.6601 - val_acc: 0.6350\n",
      "Medel is training: epoch 12th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3819 - acc: 0.6570 - val_loss: 3.0905 - val_acc: 0.5846\n",
      "Medel is training: epoch 12th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2966 - acc: 0.5660 - val_loss: 4.0208 - val_acc: 0.5078\n",
      "Medel is training: epoch 12th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1236 - acc: 0.5967 - val_loss: 3.1703 - val_acc: 0.6021\n",
      "Medel is training: epoch 12th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0916 - acc: 0.6034 - val_loss: 2.2337 - val_acc: 0.6661\n",
      "Medel is training: epoch 12th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4321 - acc: 0.6494 - val_loss: 3.0332 - val_acc: 0.5934\n",
      "Medel is training: epoch 12th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2981 - acc: 0.5684 - val_loss: 3.7334 - val_acc: 0.5247\n",
      "Medel is training: epoch 12th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2108 - acc: 0.5849 - val_loss: 3.2452 - val_acc: 0.5959\n",
      "Medel is training: epoch 13th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.8506 - acc: 0.5003 - val_loss: 3.6742 - val_acc: 0.5323\n",
      "Medel is training: epoch 13th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4801 - acc: 0.5528 - val_loss: 2.8936 - val_acc: 0.5760\n",
      "Medel is training: epoch 13th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4965 - acc: 0.5234 - val_loss: 3.7467 - val_acc: 0.5192\n",
      "Medel is training: epoch 13th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4561 - acc: 0.5546 - val_loss: 3.5007 - val_acc: 0.5542\n",
      "Medel is training: epoch 13th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1841 - acc: 0.5692 - val_loss: 3.5959 - val_acc: 0.5387\n",
      "Medel is training: epoch 13th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.7975 - acc: 0.5036 - val_loss: 3.2817 - val_acc: 0.5881\n",
      "Medel is training: epoch 13th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4874 - acc: 0.5471 - val_loss: 3.5672 - val_acc: 0.5499\n",
      "Medel is training: epoch 13th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 3.1315 - acc: 0.5679 - val_loss: 3.6557 - val_acc: 0.5327\n",
      "Medel is training: epoch 13th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.7105 - acc: 0.5152 - val_loss: 3.3636 - val_acc: 0.5723\n",
      "Medel is training: epoch 13th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3863 - acc: 0.5589 - val_loss: 2.6813 - val_acc: 0.6140\n",
      "Medel is training: epoch 13th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3163 - acc: 0.5577 - val_loss: 4.0946 - val_acc: 0.4802\n",
      "Medel is training: epoch 13th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5318 - acc: 0.5459 - val_loss: 3.4833 - val_acc: 0.5582\n",
      "Medel is training: epoch 13th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2184 - acc: 0.5765 - val_loss: 2.8259 - val_acc: 0.5941\n",
      "Medel is training: epoch 13th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5701 - acc: 0.5294 - val_loss: 4.3405 - val_acc: 0.4502\n",
      "Medel is training: epoch 13th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3389 - acc: 0.5720 - val_loss: 3.4978 - val_acc: 0.5543\n",
      "Medel is training: epoch 13th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0882 - acc: 0.5850 - val_loss: 2.8639 - val_acc: 0.6017\n",
      "Medel is training: epoch 13th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4734 - acc: 0.5431 - val_loss: 3.7364 - val_acc: 0.5230\n",
      "Medel is training: epoch 13th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3033 - acc: 0.5752 - val_loss: 3.5614 - val_acc: 0.5478\n",
      "Medel is training: epoch 13th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0265 - acc: 0.5946 - val_loss: 2.8013 - val_acc: 0.5987\n",
      "Medel is training: epoch 13th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4757 - acc: 0.5443 - val_loss: 3.9989 - val_acc: 0.4916\n",
      "Medel is training: epoch 13th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2678 - acc: 0.5832 - val_loss: 3.2888 - val_acc: 0.5846\n",
      "Medel is training: epoch 13th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0443 - acc: 0.5971 - val_loss: 2.6826 - val_acc: 0.6188\n",
      "Medel is training: epoch 13th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3380 - acc: 0.5551 - val_loss: 3.7702 - val_acc: 0.5243\n",
      "Medel is training: epoch 13th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4072 - acc: 0.5621 - val_loss: 3.2858 - val_acc: 0.5857\n",
      "Medel is training: epoch 13th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1952 - acc: 0.5865 - val_loss: 2.4046 - val_acc: 0.6549\n",
      "Medel is training: epoch 13th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0141 - acc: 0.5876 - val_loss: 3.2496 - val_acc: 0.5798\n",
      "Medel is training: epoch 13th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5713 - acc: 0.5365 - val_loss: 3.2290 - val_acc: 0.5954\n",
      "Medel is training: epoch 13th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2154 - acc: 0.5887 - val_loss: 3.2993 - val_acc: 0.5832\n",
      "Medel is training: epoch 13th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4999 - acc: 0.6431 - val_loss: 3.2227 - val_acc: 0.5813\n",
      "Medel is training: epoch 13th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5392 - acc: 0.5392 - val_loss: 3.4215 - val_acc: 0.5679\n",
      "Medel is training: epoch 13th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2125 - acc: 0.5841 - val_loss: 3.0992 - val_acc: 0.6083\n",
      "Medel is training: epoch 13th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7736 - acc: 0.6283 - val_loss: 2.4455 - val_acc: 0.6506\n",
      "Medel is training: epoch 13th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9783 - acc: 0.5909 - val_loss: 3.3355 - val_acc: 0.5735\n",
      "Medel is training: epoch 13th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5361 - acc: 0.5397 - val_loss: 3.0606 - val_acc: 0.6165\n",
      "Medel is training: epoch 13th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1557 - acc: 0.5952 - val_loss: 3.2531 - val_acc: 0.5877\n",
      "Medel is training: epoch 13th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4623 - acc: 0.6501 - val_loss: 2.5827 - val_acc: 0.6144\n",
      "Medel is training: epoch 13th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2101 - acc: 0.5754 - val_loss: 3.8117 - val_acc: 0.5147\n",
      "Medel is training: epoch 13th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2512 - acc: 0.5799 - val_loss: 3.1769 - val_acc: 0.6006\n",
      "Medel is training: epoch 13th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0826 - acc: 0.6049 - val_loss: 2.5348 - val_acc: 0.6520\n",
      "Medel is training: epoch 13th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4104 - acc: 0.6518 - val_loss: 3.0614 - val_acc: 0.5932\n",
      "Medel is training: epoch 13th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3647 - acc: 0.5630 - val_loss: 3.8362 - val_acc: 0.5091\n",
      "Medel is training: epoch 13th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0891 - acc: 0.6019 - val_loss: 2.9677 - val_acc: 0.6272\n",
      "Medel is training: epoch 13th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1766 - acc: 0.5928 - val_loss: 2.6527 - val_acc: 0.6375\n",
      "Medel is training: epoch 13th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3564 - acc: 0.6579 - val_loss: 3.0737 - val_acc: 0.5874\n",
      "Medel is training: epoch 13th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2792 - acc: 0.5667 - val_loss: 4.0217 - val_acc: 0.5069\n",
      "Medel is training: epoch 13th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 3.1086 - acc: 0.5968 - val_loss: 3.1636 - val_acc: 0.6032\n",
      "Medel is training: epoch 13th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0834 - acc: 0.6033 - val_loss: 2.2154 - val_acc: 0.6686\n",
      "Medel is training: epoch 13th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4058 - acc: 0.6513 - val_loss: 3.0180 - val_acc: 0.5931\n",
      "Medel is training: epoch 13th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2755 - acc: 0.5687 - val_loss: 3.7136 - val_acc: 0.5250\n",
      "Medel is training: epoch 13th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1928 - acc: 0.5853 - val_loss: 3.2401 - val_acc: 0.5962\n",
      "Medel is training: epoch 14th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.8317 - acc: 0.4999 - val_loss: 3.6780 - val_acc: 0.5313\n",
      "Medel is training: epoch 14th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4710 - acc: 0.5519 - val_loss: 2.8330 - val_acc: 0.5774\n",
      "Medel is training: epoch 14th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4699 - acc: 0.5240 - val_loss: 3.7470 - val_acc: 0.5199\n",
      "Medel is training: epoch 14th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4489 - acc: 0.5541 - val_loss: 3.4972 - val_acc: 0.5545\n",
      "Medel is training: epoch 14th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1530 - acc: 0.5712 - val_loss: 3.5761 - val_acc: 0.5400\n",
      "Medel is training: epoch 14th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.7775 - acc: 0.5035 - val_loss: 3.2874 - val_acc: 0.5854\n",
      "Medel is training: epoch 14th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4790 - acc: 0.5472 - val_loss: 3.5606 - val_acc: 0.5519\n",
      "Medel is training: epoch 14th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1001 - acc: 0.5684 - val_loss: 3.6381 - val_acc: 0.5323\n",
      "Medel is training: epoch 14th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6971 - acc: 0.5150 - val_loss: 3.3588 - val_acc: 0.5726\n",
      "Medel is training: epoch 14th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3703 - acc: 0.5598 - val_loss: 2.6314 - val_acc: 0.6172\n",
      "Medel is training: epoch 14th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2937 - acc: 0.5585 - val_loss: 4.0821 - val_acc: 0.4795\n",
      "Medel is training: epoch 14th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5164 - acc: 0.5461 - val_loss: 3.4783 - val_acc: 0.5591\n",
      "Medel is training: epoch 14th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2038 - acc: 0.5784 - val_loss: 2.7829 - val_acc: 0.5983\n",
      "Medel is training: epoch 14th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5529 - acc: 0.5301 - val_loss: 4.3397 - val_acc: 0.4495\n",
      "Medel is training: epoch 14th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3246 - acc: 0.5719 - val_loss: 3.4960 - val_acc: 0.5543\n",
      "Medel is training: epoch 14th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0658 - acc: 0.5863 - val_loss: 2.8313 - val_acc: 0.6017\n",
      "Medel is training: epoch 14th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4538 - acc: 0.5423 - val_loss: 3.7249 - val_acc: 0.5252\n",
      "Medel is training: epoch 14th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2913 - acc: 0.5761 - val_loss: 3.5594 - val_acc: 0.5485\n",
      "Medel is training: epoch 14th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0071 - acc: 0.5961 - val_loss: 2.7716 - val_acc: 0.5994\n",
      "Medel is training: epoch 14th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4554 - acc: 0.5446 - val_loss: 3.9861 - val_acc: 0.4913\n",
      "Medel is training: epoch 14th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2574 - acc: 0.5827 - val_loss: 3.2874 - val_acc: 0.5853\n",
      "Medel is training: epoch 14th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0295 - acc: 0.5976 - val_loss: 2.6499 - val_acc: 0.6221\n",
      "Medel is training: epoch 14th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3135 - acc: 0.5558 - val_loss: 3.7537 - val_acc: 0.5247\n",
      "Medel is training: epoch 14th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3921 - acc: 0.5635 - val_loss: 3.2828 - val_acc: 0.5854\n",
      "Medel is training: epoch 14th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1835 - acc: 0.5864 - val_loss: 2.3852 - val_acc: 0.6566\n",
      "Medel is training: epoch 14th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9909 - acc: 0.5883 - val_loss: 3.2317 - val_acc: 0.5798\n",
      "Medel is training: epoch 14th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5598 - acc: 0.5362 - val_loss: 3.2265 - val_acc: 0.5948\n",
      "Medel is training: epoch 14th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2048 - acc: 0.5882 - val_loss: 3.2991 - val_acc: 0.5820\n",
      "Medel is training: epoch 14th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4701 - acc: 0.6444 - val_loss: 3.2077 - val_acc: 0.5826\n",
      "Medel is training: epoch 14th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5144 - acc: 0.5402 - val_loss: 3.4152 - val_acc: 0.5676\n",
      "Medel is training: epoch 14th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2004 - acc: 0.5841 - val_loss: 3.0904 - val_acc: 0.6101\n",
      "Medel is training: epoch 14th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7528 - acc: 0.6300 - val_loss: 2.4229 - val_acc: 0.6516\n",
      "Medel is training: epoch 14th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9585 - acc: 0.5929 - val_loss: 3.3189 - val_acc: 0.5735\n",
      "Medel is training: epoch 14th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 3.5212 - acc: 0.5398 - val_loss: 3.0610 - val_acc: 0.6154\n",
      "Medel is training: epoch 14th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1488 - acc: 0.5951 - val_loss: 3.2478 - val_acc: 0.5871\n",
      "Medel is training: epoch 14th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4321 - acc: 0.6531 - val_loss: 2.5638 - val_acc: 0.6150\n",
      "Medel is training: epoch 14th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1878 - acc: 0.5757 - val_loss: 3.7886 - val_acc: 0.5166\n",
      "Medel is training: epoch 14th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2336 - acc: 0.5798 - val_loss: 3.1722 - val_acc: 0.6003\n",
      "Medel is training: epoch 14th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0723 - acc: 0.6054 - val_loss: 2.5222 - val_acc: 0.6520\n",
      "Medel is training: epoch 14th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3853 - acc: 0.6525 - val_loss: 3.0401 - val_acc: 0.5957\n",
      "Medel is training: epoch 14th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3414 - acc: 0.5625 - val_loss: 3.8053 - val_acc: 0.5109\n",
      "Medel is training: epoch 14th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0749 - acc: 0.6029 - val_loss: 2.9615 - val_acc: 0.6275\n",
      "Medel is training: epoch 14th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1689 - acc: 0.5935 - val_loss: 2.6445 - val_acc: 0.6411\n",
      "Medel is training: epoch 14th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3299 - acc: 0.6604 - val_loss: 3.0517 - val_acc: 0.5880\n",
      "Medel is training: epoch 14th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2596 - acc: 0.5670 - val_loss: 4.0130 - val_acc: 0.5069\n",
      "Medel is training: epoch 14th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0944 - acc: 0.5972 - val_loss: 3.1575 - val_acc: 0.6015\n",
      "Medel is training: epoch 14th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0761 - acc: 0.6042 - val_loss: 2.1978 - val_acc: 0.6695\n",
      "Medel is training: epoch 14th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3790 - acc: 0.6523 - val_loss: 3.0004 - val_acc: 0.5949\n",
      "Medel is training: epoch 14th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2545 - acc: 0.5693 - val_loss: 3.7042 - val_acc: 0.5253\n",
      "Medel is training: epoch 14th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1815 - acc: 0.5865 - val_loss: 3.2413 - val_acc: 0.5970\n",
      "Medel is training: epoch 15th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.8188 - acc: 0.5000 - val_loss: 3.6702 - val_acc: 0.5320\n",
      "Medel is training: epoch 15th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4584 - acc: 0.5524 - val_loss: 2.7997 - val_acc: 0.5862\n",
      "Medel is training: epoch 15th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4362 - acc: 0.5271 - val_loss: 3.7318 - val_acc: 0.5192\n",
      "Medel is training: epoch 15th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4380 - acc: 0.5546 - val_loss: 3.4983 - val_acc: 0.5548\n",
      "Medel is training: epoch 15th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1238 - acc: 0.5753 - val_loss: 3.5617 - val_acc: 0.5393\n",
      "Medel is training: epoch 15th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.7489 - acc: 0.5050 - val_loss: 3.2958 - val_acc: 0.5841\n",
      "Medel is training: epoch 15th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4715 - acc: 0.5473 - val_loss: 3.5641 - val_acc: 0.5496\n",
      "Medel is training: epoch 15th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0747 - acc: 0.5705 - val_loss: 3.6329 - val_acc: 0.5323\n",
      "Medel is training: epoch 15th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6832 - acc: 0.5153 - val_loss: 3.3602 - val_acc: 0.5720\n",
      "Medel is training: epoch 15th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3648 - acc: 0.5606 - val_loss: 2.6123 - val_acc: 0.6183\n",
      "Medel is training: epoch 15th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2694 - acc: 0.5593 - val_loss: 4.0868 - val_acc: 0.4785\n",
      "Medel is training: epoch 15th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5100 - acc: 0.5462 - val_loss: 3.4705 - val_acc: 0.5595\n",
      "Medel is training: epoch 15th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1933 - acc: 0.5772 - val_loss: 2.7531 - val_acc: 0.6007\n",
      "Medel is training: epoch 15th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5322 - acc: 0.5302 - val_loss: 4.3310 - val_acc: 0.4488\n",
      "Medel is training: epoch 15th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3139 - acc: 0.5721 - val_loss: 3.4994 - val_acc: 0.5546\n",
      "Medel is training: epoch 15th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0460 - acc: 0.5875 - val_loss: 2.8036 - val_acc: 0.6027\n",
      "Medel is training: epoch 15th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4319 - acc: 0.5429 - val_loss: 3.7136 - val_acc: 0.5216\n",
      "Medel is training: epoch 15th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2851 - acc: 0.5756 - val_loss: 3.5595 - val_acc: 0.5481\n",
      "Medel is training: epoch 15th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9848 - acc: 0.5977 - val_loss: 2.7462 - val_acc: 0.6005\n",
      "Medel is training: epoch 15th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4360 - acc: 0.5446 - val_loss: 3.9774 - val_acc: 0.4913\n",
      "Medel is training: epoch 15th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2410 - acc: 0.5829 - val_loss: 3.2827 - val_acc: 0.5844\n",
      "Medel is training: epoch 15th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 3.0144 - acc: 0.5989 - val_loss: 2.6237 - val_acc: 0.6241\n",
      "Medel is training: epoch 15th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2929 - acc: 0.5559 - val_loss: 3.7319 - val_acc: 0.5256\n",
      "Medel is training: epoch 15th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3787 - acc: 0.5625 - val_loss: 3.2795 - val_acc: 0.5848\n",
      "Medel is training: epoch 15th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1740 - acc: 0.5865 - val_loss: 2.3490 - val_acc: 0.6596\n",
      "Medel is training: epoch 15th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9672 - acc: 0.5902 - val_loss: 3.2220 - val_acc: 0.5792\n",
      "Medel is training: epoch 15th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5344 - acc: 0.5364 - val_loss: 3.2286 - val_acc: 0.5948\n",
      "Medel is training: epoch 15th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1921 - acc: 0.5892 - val_loss: 3.2925 - val_acc: 0.5832\n",
      "Medel is training: epoch 15th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4477 - acc: 0.6468 - val_loss: 3.1972 - val_acc: 0.5835\n",
      "Medel is training: epoch 15th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4937 - acc: 0.5410 - val_loss: 3.4124 - val_acc: 0.5657\n",
      "Medel is training: epoch 15th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1911 - acc: 0.5844 - val_loss: 3.0873 - val_acc: 0.6107\n",
      "Medel is training: epoch 15th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7422 - acc: 0.6308 - val_loss: 2.3951 - val_acc: 0.6567\n",
      "Medel is training: epoch 15th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9357 - acc: 0.5940 - val_loss: 3.3023 - val_acc: 0.5738\n",
      "Medel is training: epoch 15th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5029 - acc: 0.5393 - val_loss: 3.0602 - val_acc: 0.6165\n",
      "Medel is training: epoch 15th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1444 - acc: 0.5956 - val_loss: 3.2465 - val_acc: 0.5871\n",
      "Medel is training: epoch 15th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4146 - acc: 0.6535 - val_loss: 2.5395 - val_acc: 0.6176\n",
      "Medel is training: epoch 15th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1681 - acc: 0.5764 - val_loss: 3.7788 - val_acc: 0.5156\n",
      "Medel is training: epoch 15th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2208 - acc: 0.5806 - val_loss: 3.1641 - val_acc: 0.6003\n",
      "Medel is training: epoch 15th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0643 - acc: 0.6061 - val_loss: 2.5104 - val_acc: 0.6520\n",
      "Medel is training: epoch 15th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3563 - acc: 0.6532 - val_loss: 3.0222 - val_acc: 0.5947\n",
      "Medel is training: epoch 15th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3234 - acc: 0.5630 - val_loss: 3.8075 - val_acc: 0.5109\n",
      "Medel is training: epoch 15th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0634 - acc: 0.6023 - val_loss: 2.9596 - val_acc: 0.6275\n",
      "Medel is training: epoch 15th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1596 - acc: 0.5934 - val_loss: 2.6355 - val_acc: 0.6421\n",
      "Medel is training: epoch 15th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3065 - acc: 0.6623 - val_loss: 3.0351 - val_acc: 0.5877\n",
      "Medel is training: epoch 15th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2437 - acc: 0.5678 - val_loss: 4.0009 - val_acc: 0.5066\n",
      "Medel is training: epoch 15th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0829 - acc: 0.5969 - val_loss: 3.1544 - val_acc: 0.6003\n",
      "Medel is training: epoch 15th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0712 - acc: 0.6033 - val_loss: 2.1855 - val_acc: 0.6686\n",
      "Medel is training: epoch 15th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3563 - acc: 0.6542 - val_loss: 2.9853 - val_acc: 0.5958\n",
      "Medel is training: epoch 15th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2315 - acc: 0.5693 - val_loss: 3.6827 - val_acc: 0.5272\n",
      "Medel is training: epoch 15th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1649 - acc: 0.5870 - val_loss: 3.2432 - val_acc: 0.5956\n",
      "Medel is training: epoch 16th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.7974 - acc: 0.5020 - val_loss: 3.6624 - val_acc: 0.5326\n",
      "Medel is training: epoch 16th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4478 - acc: 0.5533 - val_loss: 2.7597 - val_acc: 0.5910\n",
      "Medel is training: epoch 16th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4132 - acc: 0.5273 - val_loss: 3.7218 - val_acc: 0.5192\n",
      "Medel is training: epoch 16th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4250 - acc: 0.5544 - val_loss: 3.4967 - val_acc: 0.5548\n",
      "Medel is training: epoch 16th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1029 - acc: 0.5751 - val_loss: 3.5476 - val_acc: 0.5397\n",
      "Medel is training: epoch 16th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.7390 - acc: 0.5050 - val_loss: 3.2962 - val_acc: 0.5857\n",
      "Medel is training: epoch 16th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4554 - acc: 0.5482 - val_loss: 3.5598 - val_acc: 0.5509\n",
      "Medel is training: epoch 16th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0454 - acc: 0.5711 - val_loss: 3.6238 - val_acc: 0.5327\n",
      "Medel is training: epoch 16th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6660 - acc: 0.5159 - val_loss: 3.3593 - val_acc: 0.5723\n",
      "Medel is training: epoch 16th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 3.3494 - acc: 0.5605 - val_loss: 2.5673 - val_acc: 0.6193\n",
      "Medel is training: epoch 16th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2473 - acc: 0.5597 - val_loss: 4.0719 - val_acc: 0.4795\n",
      "Medel is training: epoch 16th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4894 - acc: 0.5467 - val_loss: 3.4613 - val_acc: 0.5601\n",
      "Medel is training: epoch 16th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1735 - acc: 0.5792 - val_loss: 2.7208 - val_acc: 0.6039\n",
      "Medel is training: epoch 16th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5116 - acc: 0.5309 - val_loss: 4.3240 - val_acc: 0.4491\n",
      "Medel is training: epoch 16th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3043 - acc: 0.5723 - val_loss: 3.4961 - val_acc: 0.5533\n",
      "Medel is training: epoch 16th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0309 - acc: 0.5890 - val_loss: 2.7792 - val_acc: 0.6035\n",
      "Medel is training: epoch 16th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4143 - acc: 0.5430 - val_loss: 3.7012 - val_acc: 0.5230\n",
      "Medel is training: epoch 16th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2702 - acc: 0.5762 - val_loss: 3.5514 - val_acc: 0.5491\n",
      "Medel is training: epoch 16th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9690 - acc: 0.5971 - val_loss: 2.7237 - val_acc: 0.6029\n",
      "Medel is training: epoch 16th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4154 - acc: 0.5452 - val_loss: 3.9618 - val_acc: 0.4916\n",
      "Medel is training: epoch 16th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2268 - acc: 0.5834 - val_loss: 3.2784 - val_acc: 0.5847\n",
      "Medel is training: epoch 16th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9992 - acc: 0.5995 - val_loss: 2.6095 - val_acc: 0.6248\n",
      "Medel is training: epoch 16th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2608 - acc: 0.5568 - val_loss: 3.7152 - val_acc: 0.5247\n",
      "Medel is training: epoch 16th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3671 - acc: 0.5626 - val_loss: 3.2720 - val_acc: 0.5873\n",
      "Medel is training: epoch 16th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1640 - acc: 0.5863 - val_loss: 2.3250 - val_acc: 0.6609\n",
      "Medel is training: epoch 16th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9439 - acc: 0.5897 - val_loss: 3.2078 - val_acc: 0.5798\n",
      "Medel is training: epoch 16th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5128 - acc: 0.5369 - val_loss: 3.2355 - val_acc: 0.5939\n",
      "Medel is training: epoch 16th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1833 - acc: 0.5896 - val_loss: 3.2887 - val_acc: 0.5817\n",
      "Medel is training: epoch 16th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4232 - acc: 0.6485 - val_loss: 3.1799 - val_acc: 0.5851\n",
      "Medel is training: epoch 16th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4768 - acc: 0.5406 - val_loss: 3.4061 - val_acc: 0.5660\n",
      "Medel is training: epoch 16th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1730 - acc: 0.5848 - val_loss: 3.0792 - val_acc: 0.6109\n",
      "Medel is training: epoch 16th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7240 - acc: 0.6309 - val_loss: 2.3726 - val_acc: 0.6564\n",
      "Medel is training: epoch 16th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9109 - acc: 0.5958 - val_loss: 3.2780 - val_acc: 0.5747\n",
      "Medel is training: epoch 16th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4736 - acc: 0.5412 - val_loss: 3.0693 - val_acc: 0.6154\n",
      "Medel is training: epoch 16th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1327 - acc: 0.5953 - val_loss: 3.2361 - val_acc: 0.5871\n",
      "Medel is training: epoch 16th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3903 - acc: 0.6549 - val_loss: 2.5171 - val_acc: 0.6166\n",
      "Medel is training: epoch 16th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1511 - acc: 0.5757 - val_loss: 3.7524 - val_acc: 0.5156\n",
      "Medel is training: epoch 16th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2015 - acc: 0.5808 - val_loss: 3.1629 - val_acc: 0.6006\n",
      "Medel is training: epoch 16th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0599 - acc: 0.6050 - val_loss: 2.4969 - val_acc: 0.6520\n",
      "Medel is training: epoch 16th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3308 - acc: 0.6555 - val_loss: 3.0048 - val_acc: 0.5947\n",
      "Medel is training: epoch 16th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3043 - acc: 0.5627 - val_loss: 3.7857 - val_acc: 0.5112\n",
      "Medel is training: epoch 16th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0457 - acc: 0.6037 - val_loss: 2.9595 - val_acc: 0.6275\n",
      "Medel is training: epoch 16th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1506 - acc: 0.5936 - val_loss: 2.6186 - val_acc: 0.6421\n",
      "Medel is training: epoch 16th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2833 - acc: 0.6633 - val_loss: 3.0205 - val_acc: 0.5930\n",
      "Medel is training: epoch 16th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2186 - acc: 0.5687 - val_loss: 3.9888 - val_acc: 0.5078\n",
      "Medel is training: epoch 16th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0653 - acc: 0.5972 - val_loss: 3.1456 - val_acc: 0.5998\n",
      "Medel is training: epoch 16th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0596 - acc: 0.6029 - val_loss: 2.1625 - val_acc: 0.6716\n",
      "Medel is training: epoch 16th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.3340 - acc: 0.6555 - val_loss: 2.9657 - val_acc: 0.5968\n",
      "Medel is training: epoch 16th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2076 - acc: 0.5695 - val_loss: 3.6656 - val_acc: 0.5266\n",
      "Medel is training: epoch 16th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1455 - acc: 0.5873 - val_loss: 3.2360 - val_acc: 0.5950\n",
      "Medel is training: epoch 17th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.7801 - acc: 0.5014 - val_loss: 3.6598 - val_acc: 0.5320\n",
      "Medel is training: epoch 17th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4390 - acc: 0.5525 - val_loss: 2.7307 - val_acc: 0.5914\n",
      "Medel is training: epoch 17th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3904 - acc: 0.5280 - val_loss: 3.7103 - val_acc: 0.5202\n",
      "Medel is training: epoch 17th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4162 - acc: 0.5549 - val_loss: 3.4932 - val_acc: 0.5555\n",
      "Medel is training: epoch 17th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0830 - acc: 0.5760 - val_loss: 3.5315 - val_acc: 0.5421\n",
      "Medel is training: epoch 17th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.7148 - acc: 0.5049 - val_loss: 3.2886 - val_acc: 0.5854\n",
      "Medel is training: epoch 17th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4441 - acc: 0.5485 - val_loss: 3.5573 - val_acc: 0.5499\n",
      "Medel is training: epoch 17th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0210 - acc: 0.5726 - val_loss: 3.6032 - val_acc: 0.5330\n",
      "Medel is training: epoch 17th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6492 - acc: 0.5161 - val_loss: 3.3576 - val_acc: 0.5720\n",
      "Medel is training: epoch 17th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3358 - acc: 0.5607 - val_loss: 2.5373 - val_acc: 0.6207\n",
      "Medel is training: epoch 17th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2232 - acc: 0.5604 - val_loss: 4.0596 - val_acc: 0.4808\n",
      "Medel is training: epoch 17th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4755 - acc: 0.5462 - val_loss: 3.4615 - val_acc: 0.5595\n",
      "Medel is training: epoch 17th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1600 - acc: 0.5783 - val_loss: 2.6999 - val_acc: 0.6031\n",
      "Medel is training: epoch 17th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4866 - acc: 0.5311 - val_loss: 4.3028 - val_acc: 0.4495\n",
      "Medel is training: epoch 17th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2919 - acc: 0.5729 - val_loss: 3.4859 - val_acc: 0.5543\n",
      "Medel is training: epoch 17th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0071 - acc: 0.5869 - val_loss: 2.7569 - val_acc: 0.6014\n",
      "Medel is training: epoch 17th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3895 - acc: 0.5437 - val_loss: 3.6879 - val_acc: 0.5223\n",
      "Medel is training: epoch 17th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2571 - acc: 0.5759 - val_loss: 3.5566 - val_acc: 0.5478\n",
      "Medel is training: epoch 17th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9551 - acc: 0.5976 - val_loss: 2.7001 - val_acc: 0.6039\n",
      "Medel is training: epoch 17th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3932 - acc: 0.5452 - val_loss: 3.9405 - val_acc: 0.4926\n",
      "Medel is training: epoch 17th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2159 - acc: 0.5832 - val_loss: 3.2770 - val_acc: 0.5840\n",
      "Medel is training: epoch 17th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9867 - acc: 0.6000 - val_loss: 2.5832 - val_acc: 0.6241\n",
      "Medel is training: epoch 17th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2375 - acc: 0.5570 - val_loss: 3.7049 - val_acc: 0.5276\n",
      "Medel is training: epoch 17th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3493 - acc: 0.5630 - val_loss: 3.2691 - val_acc: 0.5885\n",
      "Medel is training: epoch 17th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1513 - acc: 0.5865 - val_loss: 2.3036 - val_acc: 0.6606\n",
      "Medel is training: epoch 17th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9184 - acc: 0.5909 - val_loss: 3.1943 - val_acc: 0.5818\n",
      "Medel is training: epoch 17th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4936 - acc: 0.5369 - val_loss: 3.2318 - val_acc: 0.5933\n",
      "Medel is training: epoch 17th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1682 - acc: 0.5898 - val_loss: 3.2848 - val_acc: 0.5835\n",
      "Medel is training: epoch 17th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4023 - acc: 0.6475 - val_loss: 3.1646 - val_acc: 0.5854\n",
      "Medel is training: epoch 17th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4483 - acc: 0.5417 - val_loss: 3.3971 - val_acc: 0.5648\n",
      "Medel is training: epoch 17th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1618 - acc: 0.5857 - val_loss: 3.0683 - val_acc: 0.6110\n",
      "Medel is training: epoch 17th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7073 - acc: 0.6310 - val_loss: 2.3481 - val_acc: 0.6561\n",
      "Medel is training: epoch 17th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8856 - acc: 0.5969 - val_loss: 3.2606 - val_acc: 0.5769\n",
      "Medel is training: epoch 17th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4564 - acc: 0.5399 - val_loss: 3.0679 - val_acc: 0.6159\n",
      "Medel is training: epoch 17th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1182 - acc: 0.5959 - val_loss: 3.2256 - val_acc: 0.5889\n",
      "Medel is training: epoch 17th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.3650 - acc: 0.6565 - val_loss: 2.4965 - val_acc: 0.6223\n",
      "Medel is training: epoch 17th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1299 - acc: 0.5777 - val_loss: 3.7338 - val_acc: 0.5144\n",
      "Medel is training: epoch 17th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1822 - acc: 0.5822 - val_loss: 3.1562 - val_acc: 0.6017\n",
      "Medel is training: epoch 17th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0464 - acc: 0.6056 - val_loss: 2.4825 - val_acc: 0.6541\n",
      "Medel is training: epoch 17th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3039 - acc: 0.6560 - val_loss: 2.9835 - val_acc: 0.5966\n",
      "Medel is training: epoch 17th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2795 - acc: 0.5632 - val_loss: 3.7698 - val_acc: 0.5118\n",
      "Medel is training: epoch 17th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0265 - acc: 0.6026 - val_loss: 2.9548 - val_acc: 0.6275\n",
      "Medel is training: epoch 17th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1354 - acc: 0.5934 - val_loss: 2.5964 - val_acc: 0.6412\n",
      "Medel is training: epoch 17th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2575 - acc: 0.6652 - val_loss: 3.0047 - val_acc: 0.5955\n",
      "Medel is training: epoch 17th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1941 - acc: 0.5704 - val_loss: 3.9677 - val_acc: 0.5075\n",
      "Medel is training: epoch 17th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0489 - acc: 0.5979 - val_loss: 3.1404 - val_acc: 0.6009\n",
      "Medel is training: epoch 17th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0487 - acc: 0.6042 - val_loss: 2.1427 - val_acc: 0.6753\n",
      "Medel is training: epoch 17th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3105 - acc: 0.6583 - val_loss: 2.9527 - val_acc: 0.5983\n",
      "Medel is training: epoch 17th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1919 - acc: 0.5703 - val_loss: 3.6546 - val_acc: 0.5271\n",
      "Medel is training: epoch 17th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1257 - acc: 0.5872 - val_loss: 3.2404 - val_acc: 0.5962\n",
      "Medel is training: epoch 18th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.7616 - acc: 0.5021 - val_loss: 3.6490 - val_acc: 0.5326\n",
      "Medel is training: epoch 18th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4251 - acc: 0.5529 - val_loss: 2.7027 - val_acc: 0.5903\n",
      "Medel is training: epoch 18th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3598 - acc: 0.5286 - val_loss: 3.6901 - val_acc: 0.5206\n",
      "Medel is training: epoch 18th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3992 - acc: 0.5552 - val_loss: 3.4941 - val_acc: 0.5552\n",
      "Medel is training: epoch 18th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0570 - acc: 0.5761 - val_loss: 3.5168 - val_acc: 0.5431\n",
      "Medel is training: epoch 18th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6901 - acc: 0.5060 - val_loss: 3.2950 - val_acc: 0.5847\n",
      "Medel is training: epoch 18th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4313 - acc: 0.5494 - val_loss: 3.5502 - val_acc: 0.5523\n",
      "Medel is training: epoch 18th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9939 - acc: 0.5731 - val_loss: 3.5825 - val_acc: 0.5341\n",
      "Medel is training: epoch 18th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6237 - acc: 0.5168 - val_loss: 3.3574 - val_acc: 0.5717\n",
      "Medel is training: epoch 18th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3231 - acc: 0.5621 - val_loss: 2.5146 - val_acc: 0.6190\n",
      "Medel is training: epoch 18th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2028 - acc: 0.5614 - val_loss: 4.0430 - val_acc: 0.4802\n",
      "Medel is training: epoch 18th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4603 - acc: 0.5472 - val_loss: 3.4488 - val_acc: 0.5601\n",
      "Medel is training: epoch 18th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1427 - acc: 0.5789 - val_loss: 2.6796 - val_acc: 0.6039\n",
      "Medel is training: epoch 18th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4661 - acc: 0.5330 - val_loss: 4.2915 - val_acc: 0.4481\n",
      "Medel is training: epoch 18th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2750 - acc: 0.5723 - val_loss: 3.4927 - val_acc: 0.5533\n",
      "Medel is training: epoch 18th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9943 - acc: 0.5893 - val_loss: 2.7361 - val_acc: 0.6035\n",
      "Medel is training: epoch 18th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3647 - acc: 0.5448 - val_loss: 3.6747 - val_acc: 0.5220\n",
      "Medel is training: epoch 18th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2475 - acc: 0.5758 - val_loss: 3.5489 - val_acc: 0.5491\n",
      "Medel is training: epoch 18th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9375 - acc: 0.5973 - val_loss: 2.6756 - val_acc: 0.6046\n",
      "Medel is training: epoch 18th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3713 - acc: 0.5459 - val_loss: 3.9165 - val_acc: 0.4916\n",
      "Medel is training: epoch 18th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2000 - acc: 0.5841 - val_loss: 3.2721 - val_acc: 0.5856\n",
      "Medel is training: epoch 18th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9728 - acc: 0.5999 - val_loss: 2.5584 - val_acc: 0.6238\n",
      "Medel is training: epoch 18th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2178 - acc: 0.5575 - val_loss: 3.6854 - val_acc: 0.5279\n",
      "Medel is training: epoch 18th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 3.3331 - acc: 0.5641 - val_loss: 3.2698 - val_acc: 0.5854\n",
      "Medel is training: epoch 18th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1366 - acc: 0.5863 - val_loss: 2.2850 - val_acc: 0.6632\n",
      "Medel is training: epoch 18th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8952 - acc: 0.5910 - val_loss: 3.1836 - val_acc: 0.5824\n",
      "Medel is training: epoch 18th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4697 - acc: 0.5381 - val_loss: 3.2337 - val_acc: 0.5936\n",
      "Medel is training: epoch 18th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1626 - acc: 0.5894 - val_loss: 3.2800 - val_acc: 0.5832\n",
      "Medel is training: epoch 18th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3770 - acc: 0.6482 - val_loss: 3.1531 - val_acc: 0.5880\n",
      "Medel is training: epoch 18th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4325 - acc: 0.5418 - val_loss: 3.3875 - val_acc: 0.5670\n",
      "Medel is training: epoch 18th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1531 - acc: 0.5855 - val_loss: 3.0702 - val_acc: 0.6107\n",
      "Medel is training: epoch 18th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6945 - acc: 0.6305 - val_loss: 2.3282 - val_acc: 0.6571\n",
      "Medel is training: epoch 18th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8652 - acc: 0.5985 - val_loss: 3.2474 - val_acc: 0.5766\n",
      "Medel is training: epoch 18th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4340 - acc: 0.5408 - val_loss: 3.0612 - val_acc: 0.6165\n",
      "Medel is training: epoch 18th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1101 - acc: 0.5952 - val_loss: 3.2274 - val_acc: 0.5883\n",
      "Medel is training: epoch 18th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3461 - acc: 0.6564 - val_loss: 2.4810 - val_acc: 0.6355\n",
      "Medel is training: epoch 18th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1109 - acc: 0.5778 - val_loss: 3.7368 - val_acc: 0.5135\n",
      "Medel is training: epoch 18th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1683 - acc: 0.5812 - val_loss: 3.1560 - val_acc: 0.6017\n",
      "Medel is training: epoch 18th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0384 - acc: 0.6058 - val_loss: 2.4759 - val_acc: 0.6526\n",
      "Medel is training: epoch 18th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2848 - acc: 0.6583 - val_loss: 2.9684 - val_acc: 0.6003\n",
      "Medel is training: epoch 18th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2563 - acc: 0.5640 - val_loss: 3.7618 - val_acc: 0.5124\n",
      "Medel is training: epoch 18th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0143 - acc: 0.6026 - val_loss: 2.9490 - val_acc: 0.6275\n",
      "Medel is training: epoch 18th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1269 - acc: 0.5933 - val_loss: 2.5800 - val_acc: 0.6439\n",
      "Medel is training: epoch 18th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2350 - acc: 0.6661 - val_loss: 2.9883 - val_acc: 0.5939\n",
      "Medel is training: epoch 18th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1664 - acc: 0.5708 - val_loss: 3.9654 - val_acc: 0.5084\n",
      "Medel is training: epoch 18th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0358 - acc: 0.5995 - val_loss: 3.1345 - val_acc: 0.6003\n",
      "Medel is training: epoch 18th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0375 - acc: 0.6040 - val_loss: 2.1243 - val_acc: 0.6732\n",
      "Medel is training: epoch 18th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2868 - acc: 0.6608 - val_loss: 2.9349 - val_acc: 0.5998\n",
      "Medel is training: epoch 18th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1705 - acc: 0.5710 - val_loss: 3.6445 - val_acc: 0.5280\n",
      "Medel is training: epoch 18th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1075 - acc: 0.5881 - val_loss: 3.2393 - val_acc: 0.5953\n",
      "Medel is training: epoch 19th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.7381 - acc: 0.5023 - val_loss: 3.6458 - val_acc: 0.5333\n",
      "Medel is training: epoch 19th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4124 - acc: 0.5529 - val_loss: 2.6876 - val_acc: 0.5899\n",
      "Medel is training: epoch 19th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3344 - acc: 0.5284 - val_loss: 3.6745 - val_acc: 0.5219\n",
      "Medel is training: epoch 19th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3840 - acc: 0.5564 - val_loss: 3.4902 - val_acc: 0.5549\n",
      "Medel is training: epoch 19th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0363 - acc: 0.5763 - val_loss: 3.5063 - val_acc: 0.5428\n",
      "Medel is training: epoch 19th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6718 - acc: 0.5049 - val_loss: 3.2888 - val_acc: 0.5824\n",
      "Medel is training: epoch 19th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4205 - acc: 0.5485 - val_loss: 3.5484 - val_acc: 0.5506\n",
      "Medel is training: epoch 19th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9651 - acc: 0.5744 - val_loss: 3.5688 - val_acc: 0.5344\n",
      "Medel is training: epoch 19th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6095 - acc: 0.5169 - val_loss: 3.3455 - val_acc: 0.5704\n",
      "Medel is training: epoch 19th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3127 - acc: 0.5610 - val_loss: 2.4932 - val_acc: 0.6214\n",
      "Medel is training: epoch 19th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1775 - acc: 0.5619 - val_loss: 4.0327 - val_acc: 0.4822\n",
      "Medel is training: epoch 19th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 3.4433 - acc: 0.5468 - val_loss: 3.4469 - val_acc: 0.5585\n",
      "Medel is training: epoch 19th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1284 - acc: 0.5783 - val_loss: 2.6624 - val_acc: 0.6060\n",
      "Medel is training: epoch 19th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4405 - acc: 0.5326 - val_loss: 4.2828 - val_acc: 0.4485\n",
      "Medel is training: epoch 19th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2580 - acc: 0.5720 - val_loss: 3.4882 - val_acc: 0.5546\n",
      "Medel is training: epoch 19th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9712 - acc: 0.5899 - val_loss: 2.7102 - val_acc: 0.6085\n",
      "Medel is training: epoch 19th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3439 - acc: 0.5458 - val_loss: 3.6623 - val_acc: 0.5223\n",
      "Medel is training: epoch 19th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2331 - acc: 0.5764 - val_loss: 3.5462 - val_acc: 0.5497\n",
      "Medel is training: epoch 19th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9158 - acc: 0.5990 - val_loss: 2.6604 - val_acc: 0.6080\n",
      "Medel is training: epoch 19th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3437 - acc: 0.5459 - val_loss: 3.8952 - val_acc: 0.4916\n",
      "Medel is training: epoch 19th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1838 - acc: 0.5843 - val_loss: 3.2694 - val_acc: 0.5850\n",
      "Medel is training: epoch 19th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9568 - acc: 0.6007 - val_loss: 2.5355 - val_acc: 0.6234\n",
      "Medel is training: epoch 19th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1913 - acc: 0.5598 - val_loss: 3.6651 - val_acc: 0.5263\n",
      "Medel is training: epoch 19th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3139 - acc: 0.5644 - val_loss: 3.2616 - val_acc: 0.5848\n",
      "Medel is training: epoch 19th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1243 - acc: 0.5874 - val_loss: 2.2576 - val_acc: 0.6666\n",
      "Medel is training: epoch 19th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8659 - acc: 0.5943 - val_loss: 3.1690 - val_acc: 0.5814\n",
      "Medel is training: epoch 19th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4522 - acc: 0.5385 - val_loss: 3.2284 - val_acc: 0.5918\n",
      "Medel is training: epoch 19th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1472 - acc: 0.5898 - val_loss: 3.2779 - val_acc: 0.5829\n",
      "Medel is training: epoch 19th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3555 - acc: 0.6493 - val_loss: 3.1351 - val_acc: 0.5889\n",
      "Medel is training: epoch 19th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4054 - acc: 0.5428 - val_loss: 3.3761 - val_acc: 0.5663\n",
      "Medel is training: epoch 19th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1373 - acc: 0.5850 - val_loss: 3.0632 - val_acc: 0.6095\n",
      "Medel is training: epoch 19th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6796 - acc: 0.6308 - val_loss: 2.3080 - val_acc: 0.6577\n",
      "Medel is training: epoch 19th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8438 - acc: 0.6000 - val_loss: 3.2335 - val_acc: 0.5772\n",
      "Medel is training: epoch 19th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4082 - acc: 0.5412 - val_loss: 3.0670 - val_acc: 0.6153\n",
      "Medel is training: epoch 19th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0993 - acc: 0.5960 - val_loss: 3.2264 - val_acc: 0.5874\n",
      "Medel is training: epoch 19th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3282 - acc: 0.6576 - val_loss: 2.4602 - val_acc: 0.6335\n",
      "Medel is training: epoch 19th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0835 - acc: 0.5771 - val_loss: 3.7337 - val_acc: 0.5144\n",
      "Medel is training: epoch 19th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1507 - acc: 0.5823 - val_loss: 3.1503 - val_acc: 0.6006\n",
      "Medel is training: epoch 19th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0252 - acc: 0.6059 - val_loss: 2.4635 - val_acc: 0.6526\n",
      "Medel is training: epoch 19th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2592 - acc: 0.6598 - val_loss: 2.9574 - val_acc: 0.6006\n",
      "Medel is training: epoch 19th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2386 - acc: 0.5646 - val_loss: 3.7531 - val_acc: 0.5127\n",
      "Medel is training: epoch 19th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9960 - acc: 0.6030 - val_loss: 2.9464 - val_acc: 0.6264\n",
      "Medel is training: epoch 19th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1152 - acc: 0.5927 - val_loss: 2.5586 - val_acc: 0.6439\n",
      "Medel is training: epoch 19th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2111 - acc: 0.6683 - val_loss: 2.9718 - val_acc: 0.5945\n",
      "Medel is training: epoch 19th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1407 - acc: 0.5715 - val_loss: 3.9548 - val_acc: 0.5072\n",
      "Medel is training: epoch 19th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0170 - acc: 0.5983 - val_loss: 3.1345 - val_acc: 0.6009\n",
      "Medel is training: epoch 19th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0249 - acc: 0.6037 - val_loss: 2.1109 - val_acc: 0.6720\n",
      "Medel is training: epoch 19th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2658 - acc: 0.6597 - val_loss: 2.9160 - val_acc: 0.6017\n",
      "Medel is training: epoch 19th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1469 - acc: 0.5709 - val_loss: 3.6257 - val_acc: 0.5274\n",
      "Medel is training: epoch 19th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 3.0921 - acc: 0.5883 - val_loss: 3.2414 - val_acc: 0.5962\n",
      "Medel is training: epoch 20th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.7172 - acc: 0.5038 - val_loss: 3.6429 - val_acc: 0.5323\n",
      "Medel is training: epoch 20th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3996 - acc: 0.5531 - val_loss: 2.6558 - val_acc: 0.5888\n",
      "Medel is training: epoch 20th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3014 - acc: 0.5297 - val_loss: 3.6629 - val_acc: 0.5223\n",
      "Medel is training: epoch 20th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3680 - acc: 0.5554 - val_loss: 3.4881 - val_acc: 0.5539\n",
      "Medel is training: epoch 20th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0139 - acc: 0.5782 - val_loss: 3.4948 - val_acc: 0.5441\n",
      "Medel is training: epoch 20th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6418 - acc: 0.5076 - val_loss: 3.2922 - val_acc: 0.5804\n",
      "Medel is training: epoch 20th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4099 - acc: 0.5490 - val_loss: 3.5486 - val_acc: 0.5506\n",
      "Medel is training: epoch 20th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9425 - acc: 0.5748 - val_loss: 3.5525 - val_acc: 0.5358\n",
      "Medel is training: epoch 20th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5822 - acc: 0.5181 - val_loss: 3.3420 - val_acc: 0.5710\n",
      "Medel is training: epoch 20th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2935 - acc: 0.5622 - val_loss: 2.4748 - val_acc: 0.6271\n",
      "Medel is training: epoch 20th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1577 - acc: 0.5637 - val_loss: 4.0244 - val_acc: 0.4829\n",
      "Medel is training: epoch 20th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4275 - acc: 0.5473 - val_loss: 3.4393 - val_acc: 0.5585\n",
      "Medel is training: epoch 20th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1130 - acc: 0.5801 - val_loss: 2.6415 - val_acc: 0.6053\n",
      "Medel is training: epoch 20th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4191 - acc: 0.5347 - val_loss: 4.2682 - val_acc: 0.4488\n",
      "Medel is training: epoch 20th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2462 - acc: 0.5725 - val_loss: 3.4845 - val_acc: 0.5530\n",
      "Medel is training: epoch 20th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9523 - acc: 0.5909 - val_loss: 2.6967 - val_acc: 0.6082\n",
      "Medel is training: epoch 20th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3190 - acc: 0.5463 - val_loss: 3.6543 - val_acc: 0.5223\n",
      "Medel is training: epoch 20th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2175 - acc: 0.5766 - val_loss: 3.5458 - val_acc: 0.5478\n",
      "Medel is training: epoch 20th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9028 - acc: 0.5989 - val_loss: 2.6387 - val_acc: 0.6104\n",
      "Medel is training: epoch 20th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3240 - acc: 0.5472 - val_loss: 3.8828 - val_acc: 0.4939\n",
      "Medel is training: epoch 20th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1613 - acc: 0.5849 - val_loss: 3.2661 - val_acc: 0.5856\n",
      "Medel is training: epoch 20th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9465 - acc: 0.6017 - val_loss: 2.5169 - val_acc: 0.6235\n",
      "Medel is training: epoch 20th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1670 - acc: 0.5600 - val_loss: 3.6514 - val_acc: 0.5260\n",
      "Medel is training: epoch 20th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2967 - acc: 0.5638 - val_loss: 3.2589 - val_acc: 0.5851\n",
      "Medel is training: epoch 20th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1125 - acc: 0.5868 - val_loss: 2.2385 - val_acc: 0.6679\n",
      "Medel is training: epoch 20th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8443 - acc: 0.5943 - val_loss: 3.1623 - val_acc: 0.5837\n",
      "Medel is training: epoch 20th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4285 - acc: 0.5391 - val_loss: 3.2287 - val_acc: 0.5945\n",
      "Medel is training: epoch 20th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1334 - acc: 0.5895 - val_loss: 3.2800 - val_acc: 0.5832\n",
      "Medel is training: epoch 20th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3315 - acc: 0.6517 - val_loss: 3.1251 - val_acc: 0.5886\n",
      "Medel is training: epoch 20th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3838 - acc: 0.5438 - val_loss: 3.3652 - val_acc: 0.5666\n",
      "Medel is training: epoch 20th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1221 - acc: 0.5854 - val_loss: 3.0593 - val_acc: 0.6095\n",
      "Medel is training: epoch 20th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6585 - acc: 0.6330 - val_loss: 2.2848 - val_acc: 0.6616\n",
      "Medel is training: epoch 20th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8153 - acc: 0.6014 - val_loss: 3.2077 - val_acc: 0.5766\n",
      "Medel is training: epoch 20th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3864 - acc: 0.5422 - val_loss: 3.0718 - val_acc: 0.6148\n",
      "Medel is training: epoch 20th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0892 - acc: 0.5956 - val_loss: 3.2153 - val_acc: 0.5883\n",
      "Medel is training: epoch 20th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2979 - acc: 0.6618 - val_loss: 2.4353 - val_acc: 0.6377\n",
      "Medel is training: epoch 20th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0630 - acc: 0.5797 - val_loss: 3.7128 - val_acc: 0.5160\n",
      "Medel is training: epoch 20th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 3.1309 - acc: 0.5828 - val_loss: 3.1458 - val_acc: 0.6014\n",
      "Medel is training: epoch 20th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0131 - acc: 0.6062 - val_loss: 2.4494 - val_acc: 0.6548\n",
      "Medel is training: epoch 20th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2364 - acc: 0.6612 - val_loss: 2.9368 - val_acc: 0.6000\n",
      "Medel is training: epoch 20th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2094 - acc: 0.5655 - val_loss: 3.7350 - val_acc: 0.5155\n",
      "Medel is training: epoch 20th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9798 - acc: 0.6029 - val_loss: 2.9399 - val_acc: 0.6275\n",
      "Medel is training: epoch 20th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1035 - acc: 0.5931 - val_loss: 2.5549 - val_acc: 0.6430\n",
      "Medel is training: epoch 20th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1938 - acc: 0.6698 - val_loss: 2.9557 - val_acc: 0.5942\n",
      "Medel is training: epoch 20th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1193 - acc: 0.5731 - val_loss: 3.9472 - val_acc: 0.5075\n",
      "Medel is training: epoch 20th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0016 - acc: 0.5991 - val_loss: 3.1331 - val_acc: 0.5998\n",
      "Medel is training: epoch 20th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0121 - acc: 0.6040 - val_loss: 2.0946 - val_acc: 0.6711\n",
      "Medel is training: epoch 20th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2384 - acc: 0.6620 - val_loss: 2.9008 - val_acc: 0.6008\n",
      "Medel is training: epoch 20th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1223 - acc: 0.5727 - val_loss: 3.6115 - val_acc: 0.5290\n",
      "Medel is training: epoch 20th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0723 - acc: 0.5885 - val_loss: 3.2462 - val_acc: 0.5968\n",
      "Medel is training: epoch 21th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6942 - acc: 0.5040 - val_loss: 3.6443 - val_acc: 0.5310\n",
      "Medel is training: epoch 21th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3879 - acc: 0.5530 - val_loss: 2.6397 - val_acc: 0.5895\n",
      "Medel is training: epoch 21th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2877 - acc: 0.5299 - val_loss: 3.6583 - val_acc: 0.5230\n",
      "Medel is training: epoch 21th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3548 - acc: 0.5557 - val_loss: 3.4872 - val_acc: 0.5546\n",
      "Medel is training: epoch 21th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9947 - acc: 0.5789 - val_loss: 3.4831 - val_acc: 0.5428\n",
      "Medel is training: epoch 21th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6208 - acc: 0.5070 - val_loss: 3.2844 - val_acc: 0.5838\n",
      "Medel is training: epoch 21th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3946 - acc: 0.5493 - val_loss: 3.5435 - val_acc: 0.5506\n",
      "Medel is training: epoch 21th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9157 - acc: 0.5770 - val_loss: 3.5365 - val_acc: 0.5385\n",
      "Medel is training: epoch 21th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5580 - acc: 0.5195 - val_loss: 3.3441 - val_acc: 0.5697\n",
      "Medel is training: epoch 21th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2822 - acc: 0.5620 - val_loss: 2.4445 - val_acc: 0.6313\n",
      "Medel is training: epoch 21th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1366 - acc: 0.5632 - val_loss: 4.0161 - val_acc: 0.4842\n",
      "Medel is training: epoch 21th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4158 - acc: 0.5476 - val_loss: 3.4361 - val_acc: 0.5582\n",
      "Medel is training: epoch 21th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0919 - acc: 0.5815 - val_loss: 2.6203 - val_acc: 0.6084\n",
      "Medel is training: epoch 21th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3939 - acc: 0.5338 - val_loss: 4.2548 - val_acc: 0.4488\n",
      "Medel is training: epoch 21th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2330 - acc: 0.5726 - val_loss: 3.4811 - val_acc: 0.5540\n",
      "Medel is training: epoch 21th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9346 - acc: 0.5915 - val_loss: 2.6726 - val_acc: 0.6099\n",
      "Medel is training: epoch 21th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2933 - acc: 0.5462 - val_loss: 3.6398 - val_acc: 0.5237\n",
      "Medel is training: epoch 21th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2030 - acc: 0.5760 - val_loss: 3.5429 - val_acc: 0.5494\n",
      "Medel is training: epoch 21th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8845 - acc: 0.6005 - val_loss: 2.6171 - val_acc: 0.6101\n",
      "Medel is training: epoch 21th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2969 - acc: 0.5482 - val_loss: 3.8664 - val_acc: 0.4929\n",
      "Medel is training: epoch 21th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1502 - acc: 0.5839 - val_loss: 3.2686 - val_acc: 0.5844\n",
      "Medel is training: epoch 21th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9299 - acc: 0.6018 - val_loss: 2.4916 - val_acc: 0.6268\n",
      "Medel is training: epoch 21th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1406 - acc: 0.5617 - val_loss: 3.6383 - val_acc: 0.5263\n",
      "Medel is training: epoch 21th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2782 - acc: 0.5646 - val_loss: 3.2555 - val_acc: 0.5851\n",
      "Medel is training: epoch 21th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0737 - acc: 0.5956 - val_loss: 3.2087 - val_acc: 0.5889\n",
      "Medel is training: epoch 21th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.2819 - acc: 0.6600 - val_loss: 2.4169 - val_acc: 0.6425\n",
      "Medel is training: epoch 21th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0451 - acc: 0.5796 - val_loss: 3.7095 - val_acc: 0.5157\n",
      "Medel is training: epoch 21th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1118 - acc: 0.5824 - val_loss: 3.1431 - val_acc: 0.5997\n",
      "Medel is training: epoch 21th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0119 - acc: 0.6055 - val_loss: 2.4444 - val_acc: 0.6532\n",
      "Medel is training: epoch 21th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2164 - acc: 0.6610 - val_loss: 2.9278 - val_acc: 0.6000\n",
      "Medel is training: epoch 21th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1919 - acc: 0.5652 - val_loss: 3.7254 - val_acc: 0.5146\n",
      "Medel is training: epoch 21th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9638 - acc: 0.6036 - val_loss: 2.9375 - val_acc: 0.6278\n",
      "Medel is training: epoch 21th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0908 - acc: 0.5942 - val_loss: 2.5436 - val_acc: 0.6445\n",
      "Medel is training: epoch 21th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1732 - acc: 0.6693 - val_loss: 2.9378 - val_acc: 0.5973\n",
      "Medel is training: epoch 21th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0996 - acc: 0.5729 - val_loss: 3.9330 - val_acc: 0.5078\n",
      "Medel is training: epoch 21th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9873 - acc: 0.5994 - val_loss: 3.1306 - val_acc: 0.6006\n",
      "Medel is training: epoch 21th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0025 - acc: 0.6042 - val_loss: 2.0746 - val_acc: 0.6769\n",
      "Medel is training: epoch 21th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2199 - acc: 0.6649 - val_loss: 2.8871 - val_acc: 0.6008\n",
      "Medel is training: epoch 21th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1056 - acc: 0.5728 - val_loss: 3.6045 - val_acc: 0.5281\n",
      "Medel is training: epoch 21th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0546 - acc: 0.5892 - val_loss: 3.2458 - val_acc: 0.5962\n",
      "Medel is training: epoch 22th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6724 - acc: 0.5044 - val_loss: 3.6415 - val_acc: 0.5313\n",
      "Medel is training: epoch 22th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3709 - acc: 0.5536 - val_loss: 2.6025 - val_acc: 0.5910\n",
      "Medel is training: epoch 22th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2534 - acc: 0.5323 - val_loss: 3.6509 - val_acc: 0.5240\n",
      "Medel is training: epoch 22th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3377 - acc: 0.5561 - val_loss: 3.4882 - val_acc: 0.5546\n",
      "Medel is training: epoch 22th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9696 - acc: 0.5811 - val_loss: 3.4735 - val_acc: 0.5414\n",
      "Medel is training: epoch 22th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6020 - acc: 0.5074 - val_loss: 3.2809 - val_acc: 0.5831\n",
      "Medel is training: epoch 22th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3802 - acc: 0.5493 - val_loss: 3.5398 - val_acc: 0.5506\n",
      "Medel is training: epoch 22th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8883 - acc: 0.5792 - val_loss: 3.5233 - val_acc: 0.5361\n",
      "Medel is training: epoch 22th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5425 - acc: 0.5183 - val_loss: 3.3391 - val_acc: 0.5717\n",
      "Medel is training: epoch 22th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2639 - acc: 0.5619 - val_loss: 2.4272 - val_acc: 0.6310\n",
      "Medel is training: epoch 22th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1166 - acc: 0.5640 - val_loss: 3.9947 - val_acc: 0.4829\n",
      "Medel is training: epoch 22th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3942 - acc: 0.5481 - val_loss: 3.4313 - val_acc: 0.5588\n",
      "Medel is training: epoch 22th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0769 - acc: 0.5808 - val_loss: 2.5994 - val_acc: 0.6109\n",
      "Medel is training: epoch 22th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3690 - acc: 0.5347 - val_loss: 4.2513 - val_acc: 0.4475\n",
      "Medel is training: epoch 22th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2183 - acc: 0.5730 - val_loss: 3.4892 - val_acc: 0.5540\n",
      "Medel is training: epoch 22th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9165 - acc: 0.5922 - val_loss: 2.6531 - val_acc: 0.6102\n",
      "Medel is training: epoch 22th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2729 - acc: 0.5470 - val_loss: 3.6350 - val_acc: 0.5230\n",
      "Medel is training: epoch 22th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1917 - acc: 0.5765 - val_loss: 3.5419 - val_acc: 0.5507\n",
      "Medel is training: epoch 22th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8687 - acc: 0.6008 - val_loss: 2.6027 - val_acc: 0.6104\n",
      "Medel is training: epoch 22th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2795 - acc: 0.5478 - val_loss: 3.8672 - val_acc: 0.4926\n",
      "Medel is training: epoch 22th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1368 - acc: 0.5841 - val_loss: 3.2651 - val_acc: 0.5841\n",
      "Medel is training: epoch 22th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9154 - acc: 0.6015 - val_loss: 2.4769 - val_acc: 0.6265\n",
      "Medel is training: epoch 22th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1233 - acc: 0.5611 - val_loss: 3.6338 - val_acc: 0.5266\n",
      "Medel is training: epoch 22th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 3.2638 - acc: 0.5648 - val_loss: 3.2544 - val_acc: 0.5848\n",
      "Medel is training: epoch 22th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0869 - acc: 0.5878 - val_loss: 2.1965 - val_acc: 0.6689\n",
      "Medel is training: epoch 22th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8046 - acc: 0.5966 - val_loss: 3.1354 - val_acc: 0.5818\n",
      "Medel is training: epoch 22th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3838 - acc: 0.5399 - val_loss: 3.2345 - val_acc: 0.5909\n",
      "Medel is training: epoch 22th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1091 - acc: 0.5903 - val_loss: 3.2707 - val_acc: 0.5832\n",
      "Medel is training: epoch 22th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2847 - acc: 0.6536 - val_loss: 3.1004 - val_acc: 0.5902\n",
      "Medel is training: epoch 22th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3371 - acc: 0.5444 - val_loss: 3.3398 - val_acc: 0.5651\n",
      "Medel is training: epoch 22th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0938 - acc: 0.5863 - val_loss: 3.0617 - val_acc: 0.6098\n",
      "Medel is training: epoch 22th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6274 - acc: 0.6361 - val_loss: 2.2485 - val_acc: 0.6703\n",
      "Medel is training: epoch 22th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7676 - acc: 0.6047 - val_loss: 3.1871 - val_acc: 0.5763\n",
      "Medel is training: epoch 22th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3434 - acc: 0.5437 - val_loss: 3.0671 - val_acc: 0.6156\n",
      "Medel is training: epoch 22th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0541 - acc: 0.5964 - val_loss: 3.2085 - val_acc: 0.5889\n",
      "Medel is training: epoch 22th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2568 - acc: 0.6619 - val_loss: 2.3998 - val_acc: 0.6412\n",
      "Medel is training: epoch 22th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0183 - acc: 0.5804 - val_loss: 3.6948 - val_acc: 0.5163\n",
      "Medel is training: epoch 22th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0960 - acc: 0.5830 - val_loss: 3.1410 - val_acc: 0.5997\n",
      "Medel is training: epoch 22th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9914 - acc: 0.6056 - val_loss: 2.4285 - val_acc: 0.6645\n",
      "Medel is training: epoch 22th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1928 - acc: 0.6640 - val_loss: 2.9106 - val_acc: 0.6025\n",
      "Medel is training: epoch 22th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1699 - acc: 0.5655 - val_loss: 3.6996 - val_acc: 0.5140\n",
      "Medel is training: epoch 22th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9469 - acc: 0.6050 - val_loss: 2.9296 - val_acc: 0.6281\n",
      "Medel is training: epoch 22th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0795 - acc: 0.5939 - val_loss: 2.5271 - val_acc: 0.6463\n",
      "Medel is training: epoch 22th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1460 - acc: 0.6711 - val_loss: 2.9205 - val_acc: 0.5955\n",
      "Medel is training: epoch 22th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0776 - acc: 0.5728 - val_loss: 3.9292 - val_acc: 0.5075\n",
      "Medel is training: epoch 22th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9755 - acc: 0.6007 - val_loss: 3.1256 - val_acc: 0.6012\n",
      "Medel is training: epoch 22th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9887 - acc: 0.6052 - val_loss: 2.0580 - val_acc: 0.6790\n",
      "Medel is training: epoch 22th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1952 - acc: 0.6668 - val_loss: 2.8646 - val_acc: 0.6014\n",
      "Medel is training: epoch 22th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0808 - acc: 0.5732 - val_loss: 3.5876 - val_acc: 0.5277\n",
      "Medel is training: epoch 22th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0330 - acc: 0.5884 - val_loss: 3.2425 - val_acc: 0.5953\n",
      "Medel is training: epoch 23th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6494 - acc: 0.5041 - val_loss: 3.6376 - val_acc: 0.5306\n",
      "Medel is training: epoch 23th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3581 - acc: 0.5534 - val_loss: 2.5772 - val_acc: 0.5899\n",
      "Medel is training: epoch 23th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2279 - acc: 0.5318 - val_loss: 3.6381 - val_acc: 0.5216\n",
      "Medel is training: epoch 23th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3242 - acc: 0.5561 - val_loss: 3.4876 - val_acc: 0.5545\n",
      "Medel is training: epoch 23th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9523 - acc: 0.5812 - val_loss: 3.4616 - val_acc: 0.5424\n",
      "Medel is training: epoch 23th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5791 - acc: 0.5082 - val_loss: 3.2784 - val_acc: 0.5831\n",
      "Medel is training: epoch 23th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3674 - acc: 0.5497 - val_loss: 3.5319 - val_acc: 0.5516\n",
      "Medel is training: epoch 23th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8645 - acc: 0.5799 - val_loss: 3.5105 - val_acc: 0.5364\n",
      "Medel is training: epoch 23th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5148 - acc: 0.5192 - val_loss: 3.3392 - val_acc: 0.5707\n",
      "Medel is training: epoch 23th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2523 - acc: 0.5638 - val_loss: 2.3890 - val_acc: 0.6356\n",
      "Medel is training: epoch 23th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0891 - acc: 0.5653 - val_loss: 3.9706 - val_acc: 0.4829\n",
      "Medel is training: epoch 23th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 3.3728 - acc: 0.5478 - val_loss: 3.4356 - val_acc: 0.5565\n",
      "Medel is training: epoch 23th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0618 - acc: 0.5835 - val_loss: 2.5758 - val_acc: 0.6116\n",
      "Medel is training: epoch 23th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3510 - acc: 0.5360 - val_loss: 4.2252 - val_acc: 0.4464\n",
      "Medel is training: epoch 23th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2041 - acc: 0.5731 - val_loss: 3.4910 - val_acc: 0.5527\n",
      "Medel is training: epoch 23th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8985 - acc: 0.5936 - val_loss: 2.6385 - val_acc: 0.6119\n",
      "Medel is training: epoch 23th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2538 - acc: 0.5478 - val_loss: 3.6294 - val_acc: 0.5223\n",
      "Medel is training: epoch 23th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1744 - acc: 0.5767 - val_loss: 3.5348 - val_acc: 0.5494\n",
      "Medel is training: epoch 23th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8523 - acc: 0.6025 - val_loss: 2.5822 - val_acc: 0.6121\n",
      "Medel is training: epoch 23th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2608 - acc: 0.5485 - val_loss: 3.8576 - val_acc: 0.4923\n",
      "Medel is training: epoch 23th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1248 - acc: 0.5855 - val_loss: 3.2634 - val_acc: 0.5847\n",
      "Medel is training: epoch 23th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9027 - acc: 0.6034 - val_loss: 2.4495 - val_acc: 0.6324\n",
      "Medel is training: epoch 23th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0991 - acc: 0.5617 - val_loss: 3.6226 - val_acc: 0.5276\n",
      "Medel is training: epoch 23th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2461 - acc: 0.5650 - val_loss: 3.2511 - val_acc: 0.5845\n",
      "Medel is training: epoch 23th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0741 - acc: 0.5879 - val_loss: 2.1899 - val_acc: 0.6735\n",
      "Medel is training: epoch 23th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7796 - acc: 0.5973 - val_loss: 3.1248 - val_acc: 0.5853\n",
      "Medel is training: epoch 23th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3654 - acc: 0.5397 - val_loss: 3.2411 - val_acc: 0.5906\n",
      "Medel is training: epoch 23th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1081 - acc: 0.5897 - val_loss: 3.2733 - val_acc: 0.5838\n",
      "Medel is training: epoch 23th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2632 - acc: 0.6573 - val_loss: 3.0890 - val_acc: 0.5902\n",
      "Medel is training: epoch 23th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3183 - acc: 0.5443 - val_loss: 3.3379 - val_acc: 0.5660\n",
      "Medel is training: epoch 23th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0786 - acc: 0.5858 - val_loss: 3.0594 - val_acc: 0.6089\n",
      "Medel is training: epoch 23th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6153 - acc: 0.6367 - val_loss: 2.2345 - val_acc: 0.6691\n",
      "Medel is training: epoch 23th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7493 - acc: 0.6035 - val_loss: 3.1798 - val_acc: 0.5769\n",
      "Medel is training: epoch 23th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3235 - acc: 0.5431 - val_loss: 3.0679 - val_acc: 0.6136\n",
      "Medel is training: epoch 23th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0451 - acc: 0.5972 - val_loss: 3.2093 - val_acc: 0.5880\n",
      "Medel is training: epoch 23th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2360 - acc: 0.6640 - val_loss: 2.3829 - val_acc: 0.6409\n",
      "Medel is training: epoch 23th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0040 - acc: 0.5808 - val_loss: 3.6898 - val_acc: 0.5166\n",
      "Medel is training: epoch 23th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0778 - acc: 0.5825 - val_loss: 3.1371 - val_acc: 0.6006\n",
      "Medel is training: epoch 23th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9814 - acc: 0.6070 - val_loss: 2.4180 - val_acc: 0.6657\n",
      "Medel is training: epoch 23th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1791 - acc: 0.6674 - val_loss: 2.8995 - val_acc: 0.6037\n",
      "Medel is training: epoch 23th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1543 - acc: 0.5659 - val_loss: 3.6977 - val_acc: 0.5146\n",
      "Medel is training: epoch 23th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9317 - acc: 0.6047 - val_loss: 2.9390 - val_acc: 0.6275\n",
      "Medel is training: epoch 23th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0709 - acc: 0.5943 - val_loss: 2.5101 - val_acc: 0.6482\n",
      "Medel is training: epoch 23th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1247 - acc: 0.6716 - val_loss: 2.9075 - val_acc: 0.5955\n",
      "Medel is training: epoch 23th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0621 - acc: 0.5734 - val_loss: 3.9174 - val_acc: 0.5075\n",
      "Medel is training: epoch 23th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9583 - acc: 0.6006 - val_loss: 3.1231 - val_acc: 0.6015\n",
      "Medel is training: epoch 23th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9821 - acc: 0.6048 - val_loss: 2.0416 - val_acc: 0.6811\n",
      "Medel is training: epoch 23th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1759 - acc: 0.6695 - val_loss: 2.8519 - val_acc: 0.6023\n",
      "Medel is training: epoch 23th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0659 - acc: 0.5756 - val_loss: 3.5773 - val_acc: 0.5289\n",
      "Medel is training: epoch 23th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 3.0218 - acc: 0.5891 - val_loss: 3.2407 - val_acc: 0.5968\n",
      "Medel is training: epoch 24th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6290 - acc: 0.5050 - val_loss: 3.6340 - val_acc: 0.5280\n",
      "Medel is training: epoch 24th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3427 - acc: 0.5528 - val_loss: 2.5505 - val_acc: 0.5994\n",
      "Medel is training: epoch 24th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2019 - acc: 0.5342 - val_loss: 3.6319 - val_acc: 0.5205\n",
      "Medel is training: epoch 24th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3088 - acc: 0.5551 - val_loss: 3.4874 - val_acc: 0.5546\n",
      "Medel is training: epoch 24th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9268 - acc: 0.5847 - val_loss: 3.4564 - val_acc: 0.5417\n",
      "Medel is training: epoch 24th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5597 - acc: 0.5091 - val_loss: 3.2816 - val_acc: 0.5804\n",
      "Medel is training: epoch 24th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3524 - acc: 0.5496 - val_loss: 3.5291 - val_acc: 0.5519\n",
      "Medel is training: epoch 24th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8343 - acc: 0.5830 - val_loss: 3.5011 - val_acc: 0.5351\n",
      "Medel is training: epoch 24th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4980 - acc: 0.5194 - val_loss: 3.3352 - val_acc: 0.5720\n",
      "Medel is training: epoch 24th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2402 - acc: 0.5625 - val_loss: 2.3768 - val_acc: 0.6377\n",
      "Medel is training: epoch 24th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0705 - acc: 0.5670 - val_loss: 3.9758 - val_acc: 0.4829\n",
      "Medel is training: epoch 24th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3645 - acc: 0.5470 - val_loss: 3.4300 - val_acc: 0.5582\n",
      "Medel is training: epoch 24th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0510 - acc: 0.5826 - val_loss: 2.5540 - val_acc: 0.6151\n",
      "Medel is training: epoch 24th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3239 - acc: 0.5370 - val_loss: 4.2306 - val_acc: 0.4471\n",
      "Medel is training: epoch 24th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1932 - acc: 0.5737 - val_loss: 3.4832 - val_acc: 0.5517\n",
      "Medel is training: epoch 24th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8760 - acc: 0.5937 - val_loss: 2.6133 - val_acc: 0.6140\n",
      "Medel is training: epoch 24th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2320 - acc: 0.5473 - val_loss: 3.6271 - val_acc: 0.5227\n",
      "Medel is training: epoch 24th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1626 - acc: 0.5755 - val_loss: 3.5351 - val_acc: 0.5475\n",
      "Medel is training: epoch 24th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8309 - acc: 0.6028 - val_loss: 2.5655 - val_acc: 0.6132\n",
      "Medel is training: epoch 24th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2362 - acc: 0.5491 - val_loss: 3.8711 - val_acc: 0.4906\n",
      "Medel is training: epoch 24th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1093 - acc: 0.5865 - val_loss: 3.2644 - val_acc: 0.5822\n",
      "Medel is training: epoch 24th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8884 - acc: 0.6049 - val_loss: 2.4316 - val_acc: 0.6341\n",
      "Medel is training: epoch 24th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0768 - acc: 0.5623 - val_loss: 3.6105 - val_acc: 0.5279\n",
      "Medel is training: epoch 24th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2287 - acc: 0.5653 - val_loss: 3.2475 - val_acc: 0.5854\n",
      "Medel is training: epoch 24th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0596 - acc: 0.5885 - val_loss: 2.1673 - val_acc: 0.6732\n",
      "Medel is training: epoch 24th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7587 - acc: 0.5993 - val_loss: 3.1151 - val_acc: 0.5837\n",
      "Medel is training: epoch 24th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3408 - acc: 0.5414 - val_loss: 3.2334 - val_acc: 0.5915\n",
      "Medel is training: epoch 24th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0921 - acc: 0.5903 - val_loss: 3.2773 - val_acc: 0.5829\n",
      "Medel is training: epoch 24th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2416 - acc: 0.6596 - val_loss: 3.0803 - val_acc: 0.5908\n",
      "Medel is training: epoch 24th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3002 - acc: 0.5461 - val_loss: 3.3309 - val_acc: 0.5651\n",
      "Medel is training: epoch 24th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0645 - acc: 0.5862 - val_loss: 3.0585 - val_acc: 0.6089\n",
      "Medel is training: epoch 24th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5999 - acc: 0.6383 - val_loss: 2.2178 - val_acc: 0.6723\n",
      "Medel is training: epoch 24th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7276 - acc: 0.6029 - val_loss: 3.1752 - val_acc: 0.5775\n",
      "Medel is training: epoch 24th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3020 - acc: 0.5433 - val_loss: 3.0777 - val_acc: 0.6109\n",
      "Medel is training: epoch 24th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0389 - acc: 0.5972 - val_loss: 3.2104 - val_acc: 0.5866\n",
      "Medel is training: epoch 24th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2188 - acc: 0.6668 - val_loss: 2.3666 - val_acc: 0.6415\n",
      "Medel is training: epoch 24th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9822 - acc: 0.5812 - val_loss: 3.6844 - val_acc: 0.5188\n",
      "Medel is training: epoch 24th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 3.0613 - acc: 0.5843 - val_loss: 3.1401 - val_acc: 0.6006\n",
      "Medel is training: epoch 24th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9726 - acc: 0.6064 - val_loss: 2.4123 - val_acc: 0.6648\n",
      "Medel is training: epoch 24th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1502 - acc: 0.6670 - val_loss: 2.8922 - val_acc: 0.6044\n",
      "Medel is training: epoch 24th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1390 - acc: 0.5672 - val_loss: 3.6990 - val_acc: 0.5149\n",
      "Medel is training: epoch 24th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9164 - acc: 0.6058 - val_loss: 2.9388 - val_acc: 0.6267\n",
      "Medel is training: epoch 24th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0613 - acc: 0.5936 - val_loss: 2.5116 - val_acc: 0.6469\n",
      "Medel is training: epoch 24th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1044 - acc: 0.6733 - val_loss: 2.8938 - val_acc: 0.5976\n",
      "Medel is training: epoch 24th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0466 - acc: 0.5736 - val_loss: 3.9229 - val_acc: 0.5078\n",
      "Medel is training: epoch 24th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9495 - acc: 0.6006 - val_loss: 3.1270 - val_acc: 0.6018\n",
      "Medel is training: epoch 24th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9723 - acc: 0.6045 - val_loss: 2.0335 - val_acc: 0.6824\n",
      "Medel is training: epoch 24th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1584 - acc: 0.6721 - val_loss: 2.8321 - val_acc: 0.6035\n",
      "Medel is training: epoch 24th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0446 - acc: 0.5751 - val_loss: 3.5688 - val_acc: 0.5286\n",
      "Medel is training: epoch 24th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0037 - acc: 0.5904 - val_loss: 3.2429 - val_acc: 0.5950\n",
      "Medel is training: epoch 25th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.6111 - acc: 0.5062 - val_loss: 3.6292 - val_acc: 0.5296\n",
      "Medel is training: epoch 25th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3300 - acc: 0.5542 - val_loss: 2.5216 - val_acc: 0.6005\n",
      "Medel is training: epoch 25th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1826 - acc: 0.5358 - val_loss: 3.6205 - val_acc: 0.5212\n",
      "Medel is training: epoch 25th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2973 - acc: 0.5562 - val_loss: 3.4859 - val_acc: 0.5539\n",
      "Medel is training: epoch 25th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 2.9058 - acc: 0.5871 - val_loss: 3.4465 - val_acc: 0.5435\n",
      "Medel is training: epoch 25th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5403 - acc: 0.5087 - val_loss: 3.2769 - val_acc: 0.5821\n",
      "Medel is training: epoch 25th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3456 - acc: 0.5491 - val_loss: 3.5290 - val_acc: 0.5523\n",
      "Medel is training: epoch 25th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8136 - acc: 0.5851 - val_loss: 3.4862 - val_acc: 0.5344\n",
      "Medel is training: epoch 25th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4806 - acc: 0.5195 - val_loss: 3.3311 - val_acc: 0.5723\n",
      "Medel is training: epoch 25th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2262 - acc: 0.5632 - val_loss: 2.3530 - val_acc: 0.6402\n",
      "Medel is training: epoch 25th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0492 - acc: 0.5674 - val_loss: 3.9565 - val_acc: 0.4846\n",
      "Medel is training: epoch 25th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3459 - acc: 0.5487 - val_loss: 3.4334 - val_acc: 0.5552\n",
      "Medel is training: epoch 25th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0343 - acc: 0.5825 - val_loss: 2.5346 - val_acc: 0.6140\n",
      "Medel is training: epoch 25th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3050 - acc: 0.5371 - val_loss: 4.2223 - val_acc: 0.4485\n",
      "Medel is training: epoch 25th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1780 - acc: 0.5737 - val_loss: 3.4908 - val_acc: 0.5524\n",
      "Medel is training: epoch 25th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8618 - acc: 0.5947 - val_loss: 2.6003 - val_acc: 0.6164\n",
      "Medel is training: epoch 25th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2093 - acc: 0.5491 - val_loss: 3.6198 - val_acc: 0.5207\n",
      "Medel is training: epoch 25th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1495 - acc: 0.5762 - val_loss: 3.5386 - val_acc: 0.5453\n",
      "Medel is training: epoch 25th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8232 - acc: 0.6026 - val_loss: 2.5476 - val_acc: 0.6142\n",
      "Medel is training: epoch 25th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2185 - acc: 0.5495 - val_loss: 3.8574 - val_acc: 0.4884\n",
      "Medel is training: epoch 25th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0933 - acc: 0.5852 - val_loss: 3.2622 - val_acc: 0.5819\n",
      "Medel is training: epoch 25th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8694 - acc: 0.6049 - val_loss: 2.4119 - val_acc: 0.6344\n",
      "Medel is training: epoch 25th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0568 - acc: 0.5630 - val_loss: 3.5994 - val_acc: 0.5295\n",
      "Medel is training: epoch 25th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2097 - acc: 0.5649 - val_loss: 3.2459 - val_acc: 0.5833\n",
      "Medel is training: epoch 25th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0487 - acc: 0.5888 - val_loss: 2.1543 - val_acc: 0.6742\n",
      "Medel is training: epoch 25th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.7402 - acc: 0.6001 - val_loss: 3.1032 - val_acc: 0.5843\n",
      "Medel is training: epoch 25th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3216 - acc: 0.5422 - val_loss: 3.2391 - val_acc: 0.5900\n",
      "Medel is training: epoch 25th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0836 - acc: 0.5900 - val_loss: 3.2717 - val_acc: 0.5838\n",
      "Medel is training: epoch 25th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2201 - acc: 0.6603 - val_loss: 3.0691 - val_acc: 0.5905\n",
      "Medel is training: epoch 25th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2757 - acc: 0.5465 - val_loss: 3.3245 - val_acc: 0.5670\n",
      "Medel is training: epoch 25th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0550 - acc: 0.5867 - val_loss: 3.0543 - val_acc: 0.6080\n",
      "Medel is training: epoch 25th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5838 - acc: 0.6388 - val_loss: 2.1957 - val_acc: 0.6746\n",
      "Medel is training: epoch 25th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7081 - acc: 0.6065 - val_loss: 3.1638 - val_acc: 0.5753\n",
      "Medel is training: epoch 25th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2779 - acc: 0.5452 - val_loss: 3.0732 - val_acc: 0.6115\n",
      "Medel is training: epoch 25th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0229 - acc: 0.5963 - val_loss: 3.2067 - val_acc: 0.5869\n",
      "Medel is training: epoch 25th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1890 - acc: 0.6682 - val_loss: 2.3496 - val_acc: 0.6447\n",
      "Medel is training: epoch 25th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9613 - acc: 0.5824 - val_loss: 3.6746 - val_acc: 0.5191\n",
      "Medel is training: epoch 25th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0438 - acc: 0.5838 - val_loss: 3.1400 - val_acc: 0.5997\n",
      "Medel is training: epoch 25th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9640 - acc: 0.6060 - val_loss: 2.4050 - val_acc: 0.6663\n",
      "Medel is training: epoch 25th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1309 - acc: 0.6694 - val_loss: 2.8806 - val_acc: 0.6059\n",
      "Medel is training: epoch 25th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1085 - acc: 0.5686 - val_loss: 3.6849 - val_acc: 0.5152\n",
      "Medel is training: epoch 25th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9061 - acc: 0.6060 - val_loss: 2.9351 - val_acc: 0.6275\n",
      "Medel is training: epoch 25th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0531 - acc: 0.5946 - val_loss: 2.5028 - val_acc: 0.6479\n",
      "Medel is training: epoch 25th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0812 - acc: 0.6749 - val_loss: 2.8782 - val_acc: 0.5955\n",
      "Medel is training: epoch 25th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0220 - acc: 0.5758 - val_loss: 3.9051 - val_acc: 0.5078\n",
      "Medel is training: epoch 25th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9297 - acc: 0.6007 - val_loss: 3.1197 - val_acc: 0.6015\n",
      "Medel is training: epoch 25th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9592 - acc: 0.6045 - val_loss: 2.0200 - val_acc: 0.6818\n",
      "Medel is training: epoch 25th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1330 - acc: 0.6716 - val_loss: 2.8196 - val_acc: 0.6057\n",
      "Medel is training: epoch 25th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0255 - acc: 0.5760 - val_loss: 3.5594 - val_acc: 0.5305\n",
      "Medel is training: epoch 25th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9874 - acc: 0.5893 - val_loss: 3.2486 - val_acc: 0.5945\n",
      "Medel is training: epoch 26th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5951 - acc: 0.5068 - val_loss: 3.6270 - val_acc: 0.5290\n",
      "Medel is training: epoch 26th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3204 - acc: 0.5545 - val_loss: 2.4988 - val_acc: 0.6045\n",
      "Medel is training: epoch 26th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1588 - acc: 0.5372 - val_loss: 3.6163 - val_acc: 0.5202\n",
      "Medel is training: epoch 26th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2802 - acc: 0.5559 - val_loss: 3.4814 - val_acc: 0.5519\n",
      "Medel is training: epoch 26th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8869 - acc: 0.5874 - val_loss: 3.4377 - val_acc: 0.5434\n",
      "Medel is training: epoch 26th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5263 - acc: 0.5088 - val_loss: 3.2730 - val_acc: 0.5818\n",
      "Medel is training: epoch 26th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3264 - acc: 0.5501 - val_loss: 3.5251 - val_acc: 0.5509\n",
      "Medel is training: epoch 26th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7912 - acc: 0.5837 - val_loss: 3.4809 - val_acc: 0.5354\n",
      "Medel is training: epoch 26th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4602 - acc: 0.5202 - val_loss: 3.3334 - val_acc: 0.5710\n",
      "Medel is training: epoch 26th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2132 - acc: 0.5641 - val_loss: 2.3311 - val_acc: 0.6444\n",
      "Medel is training: epoch 26th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0253 - acc: 0.5692 - val_loss: 3.9464 - val_acc: 0.4846\n",
      "Medel is training: epoch 26th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3242 - acc: 0.5494 - val_loss: 3.4320 - val_acc: 0.5546\n",
      "Medel is training: epoch 26th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0202 - acc: 0.5832 - val_loss: 2.5170 - val_acc: 0.6175\n",
      "Medel is training: epoch 26th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 3.2834 - acc: 0.5369 - val_loss: 4.2137 - val_acc: 0.4481\n",
      "Medel is training: epoch 26th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1675 - acc: 0.5745 - val_loss: 3.4819 - val_acc: 0.5524\n",
      "Medel is training: epoch 26th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8466 - acc: 0.5968 - val_loss: 2.5822 - val_acc: 0.6168\n",
      "Medel is training: epoch 26th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1895 - acc: 0.5493 - val_loss: 3.6196 - val_acc: 0.5214\n",
      "Medel is training: epoch 26th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1336 - acc: 0.5764 - val_loss: 3.5397 - val_acc: 0.5463\n",
      "Medel is training: epoch 26th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8027 - acc: 0.6035 - val_loss: 2.5289 - val_acc: 0.6152\n",
      "Medel is training: epoch 26th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1938 - acc: 0.5513 - val_loss: 3.8495 - val_acc: 0.4880\n",
      "Medel is training: epoch 26th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0827 - acc: 0.5840 - val_loss: 3.2594 - val_acc: 0.5834\n",
      "Medel is training: epoch 26th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8616 - acc: 0.6046 - val_loss: 2.3964 - val_acc: 0.6358\n",
      "Medel is training: epoch 26th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0349 - acc: 0.5643 - val_loss: 3.5921 - val_acc: 0.5295\n",
      "Medel is training: epoch 26th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2004 - acc: 0.5671 - val_loss: 3.2465 - val_acc: 0.5857\n",
      "Medel is training: epoch 26th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0375 - acc: 0.5894 - val_loss: 2.1300 - val_acc: 0.6779\n",
      "Medel is training: epoch 26th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7223 - acc: 0.6000 - val_loss: 3.0955 - val_acc: 0.5863\n",
      "Medel is training: epoch 26th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3046 - acc: 0.5426 - val_loss: 3.2409 - val_acc: 0.5879\n",
      "Medel is training: epoch 26th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0722 - acc: 0.5901 - val_loss: 3.2760 - val_acc: 0.5826\n",
      "Medel is training: epoch 26th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2058 - acc: 0.6611 - val_loss: 3.0643 - val_acc: 0.5915\n",
      "Medel is training: epoch 26th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2608 - acc: 0.5463 - val_loss: 3.3187 - val_acc: 0.5673\n",
      "Medel is training: epoch 26th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0392 - acc: 0.5874 - val_loss: 3.0585 - val_acc: 0.6080\n",
      "Medel is training: epoch 26th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5704 - acc: 0.6398 - val_loss: 2.1889 - val_acc: 0.6746\n",
      "Medel is training: epoch 26th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6902 - acc: 0.6049 - val_loss: 3.1572 - val_acc: 0.5757\n",
      "Medel is training: epoch 26th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2606 - acc: 0.5453 - val_loss: 3.0704 - val_acc: 0.6121\n",
      "Medel is training: epoch 26th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0146 - acc: 0.5971 - val_loss: 3.2096 - val_acc: 0.5863\n",
      "Medel is training: epoch 26th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1735 - acc: 0.6703 - val_loss: 2.3359 - val_acc: 0.6444\n",
      "Medel is training: epoch 26th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9412 - acc: 0.5829 - val_loss: 3.6594 - val_acc: 0.5191\n",
      "Medel is training: epoch 26th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0328 - acc: 0.5841 - val_loss: 3.1400 - val_acc: 0.5982\n",
      "Medel is training: epoch 26th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9501 - acc: 0.6062 - val_loss: 2.3937 - val_acc: 0.6684\n",
      "Medel is training: epoch 26th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1084 - acc: 0.6702 - val_loss: 2.8710 - val_acc: 0.6072\n",
      "Medel is training: epoch 26th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0919 - acc: 0.5686 - val_loss: 3.6754 - val_acc: 0.5161\n",
      "Medel is training: epoch 26th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8896 - acc: 0.6053 - val_loss: 2.9341 - val_acc: 0.6275\n",
      "Medel is training: epoch 26th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0403 - acc: 0.5940 - val_loss: 2.4988 - val_acc: 0.6479\n",
      "Medel is training: epoch 26th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0689 - acc: 0.6754 - val_loss: 2.8667 - val_acc: 0.5976\n",
      "Medel is training: epoch 26th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0047 - acc: 0.5764 - val_loss: 3.9083 - val_acc: 0.5075\n",
      "Medel is training: epoch 26th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9199 - acc: 0.6020 - val_loss: 3.1176 - val_acc: 0.6012\n",
      "Medel is training: epoch 26th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9500 - acc: 0.6047 - val_loss: 2.0127 - val_acc: 0.6815\n",
      "Medel is training: epoch 26th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1214 - acc: 0.6714 - val_loss: 2.8068 - val_acc: 0.6041\n",
      "Medel is training: epoch 26th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0120 - acc: 0.5744 - val_loss: 3.5538 - val_acc: 0.5298\n",
      "Medel is training: epoch 26th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9758 - acc: 0.5904 - val_loss: 3.2496 - val_acc: 0.5945\n",
      "Medel is training: epoch 27th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5734 - acc: 0.5076 - val_loss: 3.6204 - val_acc: 0.5303\n",
      "Medel is training: epoch 27th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 3.3026 - acc: 0.5546 - val_loss: 2.4782 - val_acc: 0.6086\n",
      "Medel is training: epoch 27th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1316 - acc: 0.5400 - val_loss: 3.6138 - val_acc: 0.5209\n",
      "Medel is training: epoch 27th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2706 - acc: 0.5569 - val_loss: 3.4853 - val_acc: 0.5529\n",
      "Medel is training: epoch 27th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8667 - acc: 0.5878 - val_loss: 3.4232 - val_acc: 0.5445\n",
      "Medel is training: epoch 27th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5055 - acc: 0.5086 - val_loss: 3.2738 - val_acc: 0.5814\n",
      "Medel is training: epoch 27th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 10s - loss: 3.3136 - acc: 0.5509 - val_loss: 3.5172 - val_acc: 0.5533\n",
      "Medel is training: epoch 27th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7695 - acc: 0.5865 - val_loss: 3.4722 - val_acc: 0.5347\n",
      "Medel is training: epoch 27th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4423 - acc: 0.5212 - val_loss: 3.3337 - val_acc: 0.5717\n",
      "Medel is training: epoch 27th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2054 - acc: 0.5628 - val_loss: 2.3157 - val_acc: 0.6462\n",
      "Medel is training: epoch 27th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9997 - acc: 0.5690 - val_loss: 3.9564 - val_acc: 0.4852\n",
      "Medel is training: epoch 27th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3175 - acc: 0.5488 - val_loss: 3.4342 - val_acc: 0.5546\n",
      "Medel is training: epoch 27th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0012 - acc: 0.5852 - val_loss: 2.5020 - val_acc: 0.6186\n",
      "Medel is training: epoch 27th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2679 - acc: 0.5394 - val_loss: 4.2146 - val_acc: 0.4481\n",
      "Medel is training: epoch 27th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1523 - acc: 0.5741 - val_loss: 3.4801 - val_acc: 0.5536\n",
      "Medel is training: epoch 27th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8287 - acc: 0.5966 - val_loss: 2.5638 - val_acc: 0.6178\n",
      "Medel is training: epoch 27th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1707 - acc: 0.5507 - val_loss: 3.6135 - val_acc: 0.5210\n",
      "Medel is training: epoch 27th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1154 - acc: 0.5777 - val_loss: 3.5368 - val_acc: 0.5475\n",
      "Medel is training: epoch 27th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7881 - acc: 0.6049 - val_loss: 2.5127 - val_acc: 0.6183\n",
      "Medel is training: epoch 27th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1794 - acc: 0.5501 - val_loss: 3.8432 - val_acc: 0.4893\n",
      "Medel is training: epoch 27th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0679 - acc: 0.5848 - val_loss: 3.2588 - val_acc: 0.5825\n",
      "Medel is training: epoch 27th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8500 - acc: 0.6052 - val_loss: 2.3773 - val_acc: 0.6354\n",
      "Medel is training: epoch 27th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0123 - acc: 0.5655 - val_loss: 3.5830 - val_acc: 0.5302\n",
      "Medel is training: epoch 27th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1801 - acc: 0.5662 - val_loss: 3.2418 - val_acc: 0.5860\n",
      "Medel is training: epoch 27th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0239 - acc: 0.5900 - val_loss: 2.1166 - val_acc: 0.6789\n",
      "Medel is training: epoch 27th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6975 - acc: 0.6015 - val_loss: 3.0840 - val_acc: 0.5856\n",
      "Medel is training: epoch 27th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2794 - acc: 0.5431 - val_loss: 3.2463 - val_acc: 0.5873\n",
      "Medel is training: epoch 27th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0596 - acc: 0.5905 - val_loss: 3.2797 - val_acc: 0.5826\n",
      "Medel is training: epoch 27th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1822 - acc: 0.6628 - val_loss: 3.0553 - val_acc: 0.5911\n",
      "Medel is training: epoch 27th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2317 - acc: 0.5486 - val_loss: 3.3195 - val_acc: 0.5676\n",
      "Medel is training: epoch 27th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0278 - acc: 0.5875 - val_loss: 3.0564 - val_acc: 0.6089\n",
      "Medel is training: epoch 27th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5588 - acc: 0.6400 - val_loss: 2.1760 - val_acc: 0.6771\n",
      "Medel is training: epoch 27th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6679 - acc: 0.6059 - val_loss: 3.1479 - val_acc: 0.5763\n",
      "Medel is training: epoch 27th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2421 - acc: 0.5448 - val_loss: 3.0845 - val_acc: 0.6100\n",
      "Medel is training: epoch 27th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0070 - acc: 0.5964 - val_loss: 3.2123 - val_acc: 0.5845\n",
      "Medel is training: epoch 27th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1564 - acc: 0.6720 - val_loss: 2.3287 - val_acc: 0.6451\n",
      "Medel is training: epoch 27th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9266 - acc: 0.5819 - val_loss: 3.6682 - val_acc: 0.5178\n",
      "Medel is training: epoch 27th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0176 - acc: 0.5846 - val_loss: 3.1420 - val_acc: 0.5994\n",
      "Medel is training: epoch 27th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9421 - acc: 0.6066 - val_loss: 2.3946 - val_acc: 0.6669\n",
      "Medel is training: epoch 27th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.0945 - acc: 0.6704 - val_loss: 2.8580 - val_acc: 0.6090\n",
      "Medel is training: epoch 27th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0767 - acc: 0.5689 - val_loss: 3.6652 - val_acc: 0.5180\n",
      "Medel is training: epoch 27th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8749 - acc: 0.6058 - val_loss: 2.9340 - val_acc: 0.6287\n",
      "Medel is training: epoch 27th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0349 - acc: 0.5952 - val_loss: 2.4959 - val_acc: 0.6485\n",
      "Medel is training: epoch 27th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0460 - acc: 0.6763 - val_loss: 2.8583 - val_acc: 0.5986\n",
      "Medel is training: epoch 27th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9851 - acc: 0.5770 - val_loss: 3.9059 - val_acc: 0.5081\n",
      "Medel is training: epoch 27th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9021 - acc: 0.6024 - val_loss: 3.1185 - val_acc: 0.6009\n",
      "Medel is training: epoch 27th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9364 - acc: 0.6055 - val_loss: 1.9950 - val_acc: 0.6852\n",
      "Medel is training: epoch 27th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0898 - acc: 0.6762 - val_loss: 2.7930 - val_acc: 0.6038\n",
      "Medel is training: epoch 27th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9944 - acc: 0.5753 - val_loss: 3.5465 - val_acc: 0.5301\n",
      "Medel is training: epoch 27th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9571 - acc: 0.5915 - val_loss: 3.2551 - val_acc: 0.5939\n",
      "Medel is training: epoch 28th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5533 - acc: 0.5066 - val_loss: 3.6335 - val_acc: 0.5296\n",
      "Medel is training: epoch 28th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2903 - acc: 0.5547 - val_loss: 2.4543 - val_acc: 0.6115\n",
      "Medel is training: epoch 28th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1110 - acc: 0.5425 - val_loss: 3.6110 - val_acc: 0.5206\n",
      "Medel is training: epoch 28th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2650 - acc: 0.5559 - val_loss: 3.4865 - val_acc: 0.5522\n",
      "Medel is training: epoch 28th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8488 - acc: 0.5885 - val_loss: 3.4108 - val_acc: 0.5441\n",
      "Medel is training: epoch 28th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4816 - acc: 0.5109 - val_loss: 3.2722 - val_acc: 0.5818\n",
      "Medel is training: epoch 28th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3051 - acc: 0.5506 - val_loss: 3.5227 - val_acc: 0.5529\n",
      "Medel is training: epoch 28th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7456 - acc: 0.5884 - val_loss: 3.4600 - val_acc: 0.5347\n",
      "Medel is training: epoch 28th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4192 - acc: 0.5209 - val_loss: 3.3344 - val_acc: 0.5723\n",
      "Medel is training: epoch 28th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1935 - acc: 0.5632 - val_loss: 2.2906 - val_acc: 0.6455\n",
      "Medel is training: epoch 28th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9843 - acc: 0.5701 - val_loss: 3.9352 - val_acc: 0.4862\n",
      "Medel is training: epoch 28th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2961 - acc: 0.5494 - val_loss: 3.4379 - val_acc: 0.5549\n",
      "Medel is training: epoch 28th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9902 - acc: 0.5845 - val_loss: 2.4823 - val_acc: 0.6203\n",
      "Medel is training: epoch 28th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2404 - acc: 0.5401 - val_loss: 4.1947 - val_acc: 0.4488\n",
      "Medel is training: epoch 28th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1391 - acc: 0.5741 - val_loss: 3.4835 - val_acc: 0.5536\n",
      "Medel is training: epoch 28th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8116 - acc: 0.5960 - val_loss: 2.5472 - val_acc: 0.6226\n",
      "Medel is training: epoch 28th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1511 - acc: 0.5513 - val_loss: 3.6031 - val_acc: 0.5194\n",
      "Medel is training: epoch 28th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1086 - acc: 0.5776 - val_loss: 3.5426 - val_acc: 0.5463\n",
      "Medel is training: epoch 28th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7704 - acc: 0.6059 - val_loss: 2.4974 - val_acc: 0.6200\n",
      "Medel is training: epoch 28th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1600 - acc: 0.5518 - val_loss: 3.8360 - val_acc: 0.4893\n",
      "Medel is training: epoch 28th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0541 - acc: 0.5854 - val_loss: 3.2565 - val_acc: 0.5837\n",
      "Medel is training: epoch 28th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8411 - acc: 0.6059 - val_loss: 2.3573 - val_acc: 0.6381\n",
      "Medel is training: epoch 28th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9924 - acc: 0.5666 - val_loss: 3.5733 - val_acc: 0.5321\n",
      "Medel is training: epoch 28th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1666 - acc: 0.5675 - val_loss: 3.2422 - val_acc: 0.5845\n",
      "Medel is training: epoch 28th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0096 - acc: 0.5912 - val_loss: 2.1067 - val_acc: 0.6789\n",
      "Medel is training: epoch 28th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6816 - acc: 0.6023 - val_loss: 3.0754 - val_acc: 0.5837\n",
      "Medel is training: epoch 28th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2586 - acc: 0.5437 - val_loss: 3.2515 - val_acc: 0.5851\n",
      "Medel is training: epoch 28th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 3.0476 - acc: 0.5904 - val_loss: 3.2838 - val_acc: 0.5817\n",
      "Medel is training: epoch 28th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1652 - acc: 0.6648 - val_loss: 3.0449 - val_acc: 0.5918\n",
      "Medel is training: epoch 28th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2150 - acc: 0.5484 - val_loss: 3.3135 - val_acc: 0.5654\n",
      "Medel is training: epoch 28th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0177 - acc: 0.5867 - val_loss: 3.0586 - val_acc: 0.6071\n",
      "Medel is training: epoch 28th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5490 - acc: 0.6391 - val_loss: 2.1646 - val_acc: 0.6765\n",
      "Medel is training: epoch 28th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6507 - acc: 0.6068 - val_loss: 3.1438 - val_acc: 0.5757\n",
      "Medel is training: epoch 28th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2271 - acc: 0.5456 - val_loss: 3.0871 - val_acc: 0.6095\n",
      "Medel is training: epoch 28th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9933 - acc: 0.5972 - val_loss: 3.2119 - val_acc: 0.5857\n",
      "Medel is training: epoch 28th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1318 - acc: 0.6730 - val_loss: 2.3119 - val_acc: 0.6486\n",
      "Medel is training: epoch 28th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9061 - acc: 0.5826 - val_loss: 3.6609 - val_acc: 0.5172\n",
      "Medel is training: epoch 28th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0042 - acc: 0.5854 - val_loss: 3.1470 - val_acc: 0.5970\n",
      "Medel is training: epoch 28th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9295 - acc: 0.6061 - val_loss: 2.3925 - val_acc: 0.6672\n",
      "Medel is training: epoch 28th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0743 - acc: 0.6738 - val_loss: 2.8462 - val_acc: 0.6124\n",
      "Medel is training: epoch 28th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0591 - acc: 0.5682 - val_loss: 3.6572 - val_acc: 0.5171\n",
      "Medel is training: epoch 28th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8635 - acc: 0.6056 - val_loss: 2.9326 - val_acc: 0.6287\n",
      "Medel is training: epoch 28th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0200 - acc: 0.5943 - val_loss: 2.4898 - val_acc: 0.6481\n",
      "Medel is training: epoch 28th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0221 - acc: 0.6785 - val_loss: 2.8447 - val_acc: 0.5989\n",
      "Medel is training: epoch 28th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9723 - acc: 0.5762 - val_loss: 3.8988 - val_acc: 0.5066\n",
      "Medel is training: epoch 28th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8885 - acc: 0.6033 - val_loss: 3.1129 - val_acc: 0.6003\n",
      "Medel is training: epoch 28th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9295 - acc: 0.6064 - val_loss: 1.9822 - val_acc: 0.6870\n",
      "Medel is training: epoch 28th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0778 - acc: 0.6760 - val_loss: 2.7735 - val_acc: 0.6038\n",
      "Medel is training: epoch 28th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9660 - acc: 0.5778 - val_loss: 3.5368 - val_acc: 0.5301\n",
      "Medel is training: epoch 28th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9491 - acc: 0.5906 - val_loss: 3.2514 - val_acc: 0.5939\n",
      "Medel is training: epoch 29th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5371 - acc: 0.5078 - val_loss: 3.6289 - val_acc: 0.5286\n",
      "Medel is training: epoch 29th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2828 - acc: 0.5540 - val_loss: 2.4264 - val_acc: 0.6152\n",
      "Medel is training: epoch 29th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0847 - acc: 0.5428 - val_loss: 3.5996 - val_acc: 0.5199\n",
      "Medel is training: epoch 29th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2438 - acc: 0.5579 - val_loss: 3.4887 - val_acc: 0.5525\n",
      "Medel is training: epoch 29th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8274 - acc: 0.5899 - val_loss: 3.3964 - val_acc: 0.5469\n",
      "Medel is training: epoch 29th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4631 - acc: 0.5112 - val_loss: 3.2677 - val_acc: 0.5824\n",
      "Medel is training: epoch 29th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2917 - acc: 0.5506 - val_loss: 3.5195 - val_acc: 0.5516\n",
      "Medel is training: epoch 29th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7231 - acc: 0.5886 - val_loss: 3.4535 - val_acc: 0.5337\n",
      "Medel is training: epoch 29th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4018 - acc: 0.5231 - val_loss: 3.3295 - val_acc: 0.5726\n",
      "Medel is training: epoch 29th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1788 - acc: 0.5638 - val_loss: 2.2783 - val_acc: 0.6469\n",
      "Medel is training: epoch 29th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9539 - acc: 0.5708 - val_loss: 3.9173 - val_acc: 0.4879\n",
      "Medel is training: epoch 29th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2824 - acc: 0.5499 - val_loss: 3.4307 - val_acc: 0.5536\n",
      "Medel is training: epoch 29th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9759 - acc: 0.5856 - val_loss: 2.4681 - val_acc: 0.6196\n",
      "Medel is training: epoch 29th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2196 - acc: 0.5417 - val_loss: 4.1953 - val_acc: 0.4519\n",
      "Medel is training: epoch 29th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1294 - acc: 0.5746 - val_loss: 3.4797 - val_acc: 0.5527\n",
      "Medel is training: epoch 29th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.7976 - acc: 0.5978 - val_loss: 2.5404 - val_acc: 0.6240\n",
      "Medel is training: epoch 29th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1284 - acc: 0.5527 - val_loss: 3.5984 - val_acc: 0.5197\n",
      "Medel is training: epoch 29th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1012 - acc: 0.5780 - val_loss: 3.5444 - val_acc: 0.5459\n",
      "Medel is training: epoch 29th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7597 - acc: 0.6053 - val_loss: 2.4854 - val_acc: 0.6186\n",
      "Medel is training: epoch 29th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1385 - acc: 0.5531 - val_loss: 3.8306 - val_acc: 0.4900\n",
      "Medel is training: epoch 29th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0423 - acc: 0.5860 - val_loss: 3.2597 - val_acc: 0.5816\n",
      "Medel is training: epoch 29th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8245 - acc: 0.6075 - val_loss: 2.3410 - val_acc: 0.6401\n",
      "Medel is training: epoch 29th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9756 - acc: 0.5675 - val_loss: 3.5585 - val_acc: 0.5311\n",
      "Medel is training: epoch 29th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1519 - acc: 0.5672 - val_loss: 3.2458 - val_acc: 0.5860\n",
      "Medel is training: epoch 29th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0019 - acc: 0.5896 - val_loss: 2.0903 - val_acc: 0.6789\n",
      "Medel is training: epoch 29th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6646 - acc: 0.6023 - val_loss: 3.0656 - val_acc: 0.5834\n",
      "Medel is training: epoch 29th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2443 - acc: 0.5437 - val_loss: 3.2358 - val_acc: 0.5885\n",
      "Medel is training: epoch 29th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0384 - acc: 0.5913 - val_loss: 3.2839 - val_acc: 0.5820\n",
      "Medel is training: epoch 29th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1431 - acc: 0.6656 - val_loss: 3.0329 - val_acc: 0.5934\n",
      "Medel is training: epoch 29th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1923 - acc: 0.5490 - val_loss: 3.3046 - val_acc: 0.5682\n",
      "Medel is training: epoch 29th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9984 - acc: 0.5885 - val_loss: 3.0519 - val_acc: 0.6080\n",
      "Medel is training: epoch 29th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5351 - acc: 0.6389 - val_loss: 2.1466 - val_acc: 0.6775\n",
      "Medel is training: epoch 29th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6259 - acc: 0.6086 - val_loss: 3.1298 - val_acc: 0.5763\n",
      "Medel is training: epoch 29th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2023 - acc: 0.5460 - val_loss: 3.0779 - val_acc: 0.6094\n",
      "Medel is training: epoch 29th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9777 - acc: 0.5972 - val_loss: 3.2141 - val_acc: 0.5866\n",
      "Medel is training: epoch 29th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1186 - acc: 0.6739 - val_loss: 2.2949 - val_acc: 0.6495\n",
      "Medel is training: epoch 29th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8828 - acc: 0.5844 - val_loss: 3.6511 - val_acc: 0.5166\n",
      "Medel is training: epoch 29th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9816 - acc: 0.5857 - val_loss: 3.1489 - val_acc: 0.5982\n",
      "Medel is training: epoch 29th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9227 - acc: 0.6066 - val_loss: 2.3861 - val_acc: 0.6660\n",
      "Medel is training: epoch 29th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0576 - acc: 0.6721 - val_loss: 2.8408 - val_acc: 0.6127\n",
      "Medel is training: epoch 29th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0345 - acc: 0.5700 - val_loss: 3.6475 - val_acc: 0.5164\n",
      "Medel is training: epoch 29th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8524 - acc: 0.6064 - val_loss: 2.9365 - val_acc: 0.6284\n",
      "Medel is training: epoch 29th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0108 - acc: 0.5955 - val_loss: 2.4802 - val_acc: 0.6497\n",
      "Medel is training: epoch 29th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0078 - acc: 0.6780 - val_loss: 2.8332 - val_acc: 0.5983\n",
      "Medel is training: epoch 29th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9539 - acc: 0.5788 - val_loss: 3.8837 - val_acc: 0.5084\n",
      "Medel is training: epoch 29th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8779 - acc: 0.6026 - val_loss: 3.1179 - val_acc: 0.6003\n",
      "Medel is training: epoch 29th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9189 - acc: 0.6060 - val_loss: 1.9710 - val_acc: 0.6870\n",
      "Medel is training: epoch 29th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0520 - acc: 0.6789 - val_loss: 2.7581 - val_acc: 0.6063\n",
      "Medel is training: epoch 29th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9539 - acc: 0.5783 - val_loss: 3.5285 - val_acc: 0.5304\n",
      "Medel is training: epoch 29th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9290 - acc: 0.5907 - val_loss: 3.2562 - val_acc: 0.5931\n",
      "Medel is training: epoch 30th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5150 - acc: 0.5083 - val_loss: 3.6306 - val_acc: 0.5283\n",
      "Medel is training: epoch 30th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2662 - acc: 0.5553 - val_loss: 2.4056 - val_acc: 0.6145\n",
      "Medel is training: epoch 30th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0649 - acc: 0.5435 - val_loss: 3.5919 - val_acc: 0.5209\n",
      "Medel is training: epoch 30th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 3.2316 - acc: 0.5583 - val_loss: 3.4885 - val_acc: 0.5525\n",
      "Medel is training: epoch 30th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8130 - acc: 0.5905 - val_loss: 3.3845 - val_acc: 0.5472\n",
      "Medel is training: epoch 30th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4423 - acc: 0.5095 - val_loss: 3.2701 - val_acc: 0.5794\n",
      "Medel is training: epoch 30th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2820 - acc: 0.5507 - val_loss: 3.5144 - val_acc: 0.5519\n",
      "Medel is training: epoch 30th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7048 - acc: 0.5908 - val_loss: 3.4501 - val_acc: 0.5351\n",
      "Medel is training: epoch 30th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3924 - acc: 0.5220 - val_loss: 3.3327 - val_acc: 0.5717\n",
      "Medel is training: epoch 30th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1727 - acc: 0.5649 - val_loss: 2.2707 - val_acc: 0.6479\n",
      "Medel is training: epoch 30th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9417 - acc: 0.5724 - val_loss: 3.9298 - val_acc: 0.4896\n",
      "Medel is training: epoch 30th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2642 - acc: 0.5491 - val_loss: 3.4332 - val_acc: 0.5549\n",
      "Medel is training: epoch 30th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9629 - acc: 0.5867 - val_loss: 2.4507 - val_acc: 0.6224\n",
      "Medel is training: epoch 30th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1965 - acc: 0.5419 - val_loss: 4.1999 - val_acc: 0.4512\n",
      "Medel is training: epoch 30th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1105 - acc: 0.5745 - val_loss: 3.4790 - val_acc: 0.5543\n",
      "Medel is training: epoch 30th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7887 - acc: 0.5983 - val_loss: 2.5309 - val_acc: 0.6271\n",
      "Medel is training: epoch 30th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1106 - acc: 0.5518 - val_loss: 3.5873 - val_acc: 0.5204\n",
      "Medel is training: epoch 30th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0846 - acc: 0.5774 - val_loss: 3.5410 - val_acc: 0.5456\n",
      "Medel is training: epoch 30th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7477 - acc: 0.6060 - val_loss: 2.4677 - val_acc: 0.6224\n",
      "Medel is training: epoch 30th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1224 - acc: 0.5528 - val_loss: 3.8191 - val_acc: 0.4913\n",
      "Medel is training: epoch 30th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0266 - acc: 0.5876 - val_loss: 3.2664 - val_acc: 0.5809\n",
      "Medel is training: epoch 30th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8097 - acc: 0.6082 - val_loss: 2.3161 - val_acc: 0.6452\n",
      "Medel is training: epoch 30th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9532 - acc: 0.5670 - val_loss: 3.5576 - val_acc: 0.5314\n",
      "Medel is training: epoch 30th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1384 - acc: 0.5670 - val_loss: 3.2482 - val_acc: 0.5863\n",
      "Medel is training: epoch 30th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9955 - acc: 0.5909 - val_loss: 2.0781 - val_acc: 0.6812\n",
      "Medel is training: epoch 30th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6412 - acc: 0.6056 - val_loss: 3.0529 - val_acc: 0.5850\n",
      "Medel is training: epoch 30th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2256 - acc: 0.5446 - val_loss: 3.2444 - val_acc: 0.5876\n",
      "Medel is training: epoch 30th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0345 - acc: 0.5904 - val_loss: 3.2870 - val_acc: 0.5805\n",
      "Medel is training: epoch 30th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1294 - acc: 0.6670 - val_loss: 3.0270 - val_acc: 0.5930\n",
      "Medel is training: epoch 30th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1793 - acc: 0.5484 - val_loss: 3.2990 - val_acc: 0.5679\n",
      "Medel is training: epoch 30th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9935 - acc: 0.5876 - val_loss: 3.0654 - val_acc: 0.6059\n",
      "Medel is training: epoch 30th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5196 - acc: 0.6417 - val_loss: 2.1437 - val_acc: 0.6781\n",
      "Medel is training: epoch 30th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6081 - acc: 0.6102 - val_loss: 3.1256 - val_acc: 0.5772\n",
      "Medel is training: epoch 30th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1869 - acc: 0.5469 - val_loss: 3.0742 - val_acc: 0.6083\n",
      "Medel is training: epoch 30th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9668 - acc: 0.5981 - val_loss: 3.2096 - val_acc: 0.5851\n",
      "Medel is training: epoch 30th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0997 - acc: 0.6758 - val_loss: 2.2772 - val_acc: 0.6518\n",
      "Medel is training: epoch 30th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8606 - acc: 0.5826 - val_loss: 3.6428 - val_acc: 0.5172\n",
      "Medel is training: epoch 30th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9716 - acc: 0.5861 - val_loss: 3.1474 - val_acc: 0.5973\n",
      "Medel is training: epoch 30th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9135 - acc: 0.6067 - val_loss: 2.3815 - val_acc: 0.6675\n",
      "Medel is training: epoch 30th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0382 - acc: 0.6765 - val_loss: 2.8269 - val_acc: 0.6134\n",
      "Medel is training: epoch 30th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0197 - acc: 0.5706 - val_loss: 3.6523 - val_acc: 0.5164\n",
      "Medel is training: epoch 30th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.8368 - acc: 0.6065 - val_loss: 2.9489 - val_acc: 0.6264\n",
      "Medel is training: epoch 30th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0055 - acc: 0.5951 - val_loss: 2.4800 - val_acc: 0.6491\n",
      "Medel is training: epoch 30th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9851 - acc: 0.6805 - val_loss: 2.8283 - val_acc: 0.5983\n",
      "Medel is training: epoch 30th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9413 - acc: 0.5771 - val_loss: 3.8820 - val_acc: 0.5078\n",
      "Medel is training: epoch 30th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8659 - acc: 0.6009 - val_loss: 3.1172 - val_acc: 0.5992\n",
      "Medel is training: epoch 30th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9098 - acc: 0.6062 - val_loss: 1.9577 - val_acc: 0.6876\n",
      "Medel is training: epoch 30th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0442 - acc: 0.6789 - val_loss: 2.7481 - val_acc: 0.6072\n",
      "Medel is training: epoch 30th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9346 - acc: 0.5776 - val_loss: 3.5083 - val_acc: 0.5304\n",
      "Medel is training: epoch 30th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9170 - acc: 0.5908 - val_loss: 3.2473 - val_acc: 0.5942\n",
      "Medel is training: epoch 31th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.5036 - acc: 0.5096 - val_loss: 3.6286 - val_acc: 0.5280\n",
      "Medel is training: epoch 31th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2553 - acc: 0.5556 - val_loss: 2.3908 - val_acc: 0.6178\n",
      "Medel is training: epoch 31th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0477 - acc: 0.5452 - val_loss: 3.5912 - val_acc: 0.5237\n",
      "Medel is training: epoch 31th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2286 - acc: 0.5576 - val_loss: 3.4880 - val_acc: 0.5525\n",
      "Medel is training: epoch 31th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7974 - acc: 0.5921 - val_loss: 3.3719 - val_acc: 0.5486\n",
      "Medel is training: epoch 31th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4262 - acc: 0.5115 - val_loss: 3.2546 - val_acc: 0.5814\n",
      "Medel is training: epoch 31th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2707 - acc: 0.5513 - val_loss: 3.5190 - val_acc: 0.5509\n",
      "Medel is training: epoch 31th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6851 - acc: 0.5901 - val_loss: 3.4370 - val_acc: 0.5351\n",
      "Medel is training: epoch 31th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3628 - acc: 0.5224 - val_loss: 3.3324 - val_acc: 0.5713\n",
      "Medel is training: epoch 31th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1566 - acc: 0.5645 - val_loss: 2.2602 - val_acc: 0.6479\n",
      "Medel is training: epoch 31th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9192 - acc: 0.5728 - val_loss: 3.8988 - val_acc: 0.4879\n",
      "Medel is training: epoch 31th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2505 - acc: 0.5502 - val_loss: 3.4258 - val_acc: 0.5575\n",
      "Medel is training: epoch 31th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9473 - acc: 0.5866 - val_loss: 2.4302 - val_acc: 0.6242\n",
      "Medel is training: epoch 31th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1794 - acc: 0.5413 - val_loss: 4.1842 - val_acc: 0.4491\n",
      "Medel is training: epoch 31th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1013 - acc: 0.5736 - val_loss: 3.4842 - val_acc: 0.5552\n",
      "Medel is training: epoch 31th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7704 - acc: 0.5980 - val_loss: 2.5111 - val_acc: 0.6302\n",
      "Medel is training: epoch 31th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0932 - acc: 0.5533 - val_loss: 3.5854 - val_acc: 0.5191\n",
      "Medel is training: epoch 31th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0667 - acc: 0.5775 - val_loss: 3.5375 - val_acc: 0.5466\n",
      "Medel is training: epoch 31th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7299 - acc: 0.6073 - val_loss: 2.4572 - val_acc: 0.6204\n",
      "Medel is training: epoch 31th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0997 - acc: 0.5542 - val_loss: 3.8114 - val_acc: 0.4916\n",
      "Medel is training: epoch 31th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0124 - acc: 0.5871 - val_loss: 3.2660 - val_acc: 0.5809\n",
      "Medel is training: epoch 31th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7956 - acc: 0.6087 - val_loss: 2.3081 - val_acc: 0.6438\n",
      "Medel is training: epoch 31th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9319 - acc: 0.5685 - val_loss: 3.5506 - val_acc: 0.5327\n",
      "Medel is training: epoch 31th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1187 - acc: 0.5680 - val_loss: 3.2515 - val_acc: 0.5854\n",
      "Medel is training: epoch 31th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9807 - acc: 0.5908 - val_loss: 2.0656 - val_acc: 0.6852\n",
      "Medel is training: epoch 31th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6243 - acc: 0.6050 - val_loss: 3.0464 - val_acc: 0.5840\n",
      "Medel is training: epoch 31th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2080 - acc: 0.5454 - val_loss: 3.2597 - val_acc: 0.5833\n",
      "Medel is training: epoch 31th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0201 - acc: 0.5909 - val_loss: 3.2849 - val_acc: 0.5823\n",
      "Medel is training: epoch 31th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1085 - acc: 0.6683 - val_loss: 3.0156 - val_acc: 0.5940\n",
      "Medel is training: epoch 31th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 3.1638 - acc: 0.5505 - val_loss: 3.2985 - val_acc: 0.5660\n",
      "Medel is training: epoch 31th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9767 - acc: 0.5890 - val_loss: 3.0581 - val_acc: 0.6053\n",
      "Medel is training: epoch 31th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5102 - acc: 0.6417 - val_loss: 2.1302 - val_acc: 0.6791\n",
      "Medel is training: epoch 31th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5924 - acc: 0.6097 - val_loss: 3.1199 - val_acc: 0.5794\n",
      "Medel is training: epoch 31th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1668 - acc: 0.5458 - val_loss: 3.0705 - val_acc: 0.6080\n",
      "Medel is training: epoch 31th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9597 - acc: 0.5981 - val_loss: 3.2157 - val_acc: 0.5830\n",
      "Medel is training: epoch 31th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0899 - acc: 0.6766 - val_loss: 2.2619 - val_acc: 0.6521\n",
      "Medel is training: epoch 31th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8596 - acc: 0.5834 - val_loss: 3.6414 - val_acc: 0.5178\n",
      "Medel is training: epoch 31th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9512 - acc: 0.5860 - val_loss: 3.1453 - val_acc: 0.5961\n",
      "Medel is training: epoch 31th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9016 - acc: 0.6063 - val_loss: 2.3755 - val_acc: 0.6669\n",
      "Medel is training: epoch 31th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0258 - acc: 0.6763 - val_loss: 2.8159 - val_acc: 0.6118\n",
      "Medel is training: epoch 31th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0014 - acc: 0.5707 - val_loss: 3.6347 - val_acc: 0.5174\n",
      "Medel is training: epoch 31th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8295 - acc: 0.6085 - val_loss: 2.9466 - val_acc: 0.6267\n",
      "Medel is training: epoch 31th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9928 - acc: 0.5955 - val_loss: 2.4799 - val_acc: 0.6494\n",
      "Medel is training: epoch 31th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9742 - acc: 0.6812 - val_loss: 2.8179 - val_acc: 0.5995\n",
      "Medel is training: epoch 31th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9175 - acc: 0.5794 - val_loss: 3.8760 - val_acc: 0.5090\n",
      "Medel is training: epoch 31th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8532 - acc: 0.6021 - val_loss: 3.1155 - val_acc: 0.5995\n",
      "Medel is training: epoch 31th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9037 - acc: 0.6057 - val_loss: 1.9534 - val_acc: 0.6882\n",
      "Medel is training: epoch 31th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0296 - acc: 0.6784 - val_loss: 2.7367 - val_acc: 0.6084\n",
      "Medel is training: epoch 31th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9168 - acc: 0.5777 - val_loss: 3.4989 - val_acc: 0.5310\n",
      "Medel is training: epoch 31th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9024 - acc: 0.5905 - val_loss: 3.2511 - val_acc: 0.5933\n",
      "Medel is training: epoch 32th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4736 - acc: 0.5095 - val_loss: 3.6349 - val_acc: 0.5283\n",
      "Medel is training: epoch 32th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2410 - acc: 0.5560 - val_loss: 2.3676 - val_acc: 0.6211\n",
      "Medel is training: epoch 32th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0193 - acc: 0.5470 - val_loss: 3.5888 - val_acc: 0.5234\n",
      "Medel is training: epoch 32th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2065 - acc: 0.5584 - val_loss: 3.4912 - val_acc: 0.5532\n",
      "Medel is training: epoch 32th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7824 - acc: 0.5920 - val_loss: 3.3691 - val_acc: 0.5458\n",
      "Medel is training: epoch 32th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4029 - acc: 0.5115 - val_loss: 3.2672 - val_acc: 0.5781\n",
      "Medel is training: epoch 32th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2594 - acc: 0.5507 - val_loss: 3.5202 - val_acc: 0.5523\n",
      "Medel is training: epoch 32th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6621 - acc: 0.5905 - val_loss: 3.4287 - val_acc: 0.5371\n",
      "Medel is training: epoch 32th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3458 - acc: 0.5229 - val_loss: 3.3296 - val_acc: 0.5704\n",
      "Medel is training: epoch 32th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1424 - acc: 0.5654 - val_loss: 2.2477 - val_acc: 0.6522\n",
      "Medel is training: epoch 32th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8959 - acc: 0.5729 - val_loss: 3.8915 - val_acc: 0.4886\n",
      "Medel is training: epoch 32th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2347 - acc: 0.5503 - val_loss: 3.4343 - val_acc: 0.5559\n",
      "Medel is training: epoch 32th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9343 - acc: 0.5864 - val_loss: 2.4194 - val_acc: 0.6284\n",
      "Medel is training: epoch 32th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1583 - acc: 0.5432 - val_loss: 4.1708 - val_acc: 0.4519\n",
      "Medel is training: epoch 32th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0865 - acc: 0.5749 - val_loss: 3.4840 - val_acc: 0.5549\n",
      "Medel is training: epoch 32th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7595 - acc: 0.5993 - val_loss: 2.4999 - val_acc: 0.6302\n",
      "Medel is training: epoch 32th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0728 - acc: 0.5539 - val_loss: 3.5695 - val_acc: 0.5188\n",
      "Medel is training: epoch 32th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 3.0522 - acc: 0.5791 - val_loss: 3.5379 - val_acc: 0.5466\n",
      "Medel is training: epoch 32th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7172 - acc: 0.6073 - val_loss: 2.4399 - val_acc: 0.6224\n",
      "Medel is training: epoch 32th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0815 - acc: 0.5545 - val_loss: 3.7996 - val_acc: 0.4916\n",
      "Medel is training: epoch 32th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0024 - acc: 0.5877 - val_loss: 3.2632 - val_acc: 0.5797\n",
      "Medel is training: epoch 32th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7836 - acc: 0.6084 - val_loss: 2.2947 - val_acc: 0.6442\n",
      "Medel is training: epoch 32th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9158 - acc: 0.5704 - val_loss: 3.5411 - val_acc: 0.5321\n",
      "Medel is training: epoch 32th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1147 - acc: 0.5683 - val_loss: 3.2489 - val_acc: 0.5842\n",
      "Medel is training: epoch 32th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9661 - acc: 0.5907 - val_loss: 2.0490 - val_acc: 0.6842\n",
      "Medel is training: epoch 32th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6050 - acc: 0.6058 - val_loss: 3.0389 - val_acc: 0.5837\n",
      "Medel is training: epoch 32th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1885 - acc: 0.5447 - val_loss: 3.2481 - val_acc: 0.5848\n",
      "Medel is training: epoch 32th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0087 - acc: 0.5908 - val_loss: 3.2886 - val_acc: 0.5808\n",
      "Medel is training: epoch 32th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0891 - acc: 0.6695 - val_loss: 3.0061 - val_acc: 0.5953\n",
      "Medel is training: epoch 32th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1390 - acc: 0.5508 - val_loss: 3.2955 - val_acc: 0.5648\n",
      "Medel is training: epoch 32th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9676 - acc: 0.5884 - val_loss: 3.0590 - val_acc: 0.6059\n",
      "Medel is training: epoch 32th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4936 - acc: 0.6433 - val_loss: 2.1133 - val_acc: 0.6807\n",
      "Medel is training: epoch 32th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5789 - acc: 0.6110 - val_loss: 3.1122 - val_acc: 0.5797\n",
      "Medel is training: epoch 32th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1453 - acc: 0.5479 - val_loss: 3.0894 - val_acc: 0.6038\n",
      "Medel is training: epoch 32th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9524 - acc: 0.5971 - val_loss: 3.2127 - val_acc: 0.5842\n",
      "Medel is training: epoch 32th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0731 - acc: 0.6773 - val_loss: 2.2554 - val_acc: 0.6534\n",
      "Medel is training: epoch 32th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8312 - acc: 0.5846 - val_loss: 3.6314 - val_acc: 0.5197\n",
      "Medel is training: epoch 32th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9374 - acc: 0.5869 - val_loss: 3.1504 - val_acc: 0.5970\n",
      "Medel is training: epoch 32th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8959 - acc: 0.6057 - val_loss: 2.3771 - val_acc: 0.6648\n",
      "Medel is training: epoch 32th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0139 - acc: 0.6739 - val_loss: 2.8059 - val_acc: 0.6140\n",
      "Medel is training: epoch 32th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9820 - acc: 0.5710 - val_loss: 3.6261 - val_acc: 0.5177\n",
      "Medel is training: epoch 32th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8127 - acc: 0.6081 - val_loss: 2.9460 - val_acc: 0.6261\n",
      "Medel is training: epoch 32th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9835 - acc: 0.5958 - val_loss: 2.4777 - val_acc: 0.6494\n",
      "Medel is training: epoch 32th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9646 - acc: 0.6834 - val_loss: 2.8110 - val_acc: 0.5986\n",
      "Medel is training: epoch 32th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8965 - acc: 0.5807 - val_loss: 3.8714 - val_acc: 0.5096\n",
      "Medel is training: epoch 32th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8400 - acc: 0.6027 - val_loss: 3.1123 - val_acc: 0.6015\n",
      "Medel is training: epoch 32th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8949 - acc: 0.6051 - val_loss: 1.9461 - val_acc: 0.6892\n",
      "Medel is training: epoch 32th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0151 - acc: 0.6788 - val_loss: 2.7258 - val_acc: 0.6081\n",
      "Medel is training: epoch 32th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8997 - acc: 0.5791 - val_loss: 3.4952 - val_acc: 0.5298\n",
      "Medel is training: epoch 32th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8868 - acc: 0.5917 - val_loss: 3.2514 - val_acc: 0.5942\n",
      "Medel is training: epoch 33th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4623 - acc: 0.5108 - val_loss: 3.6253 - val_acc: 0.5307\n",
      "Medel is training: epoch 33th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2277 - acc: 0.5558 - val_loss: 2.3650 - val_acc: 0.6207\n",
      "Medel is training: epoch 33th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0001 - acc: 0.5479 - val_loss: 3.5839 - val_acc: 0.5199\n",
      "Medel is training: epoch 33th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1995 - acc: 0.5591 - val_loss: 3.4976 - val_acc: 0.5539\n",
      "Medel is training: epoch 33th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7679 - acc: 0.5918 - val_loss: 3.3596 - val_acc: 0.5486\n",
      "Medel is training: epoch 33th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 3.3899 - acc: 0.5112 - val_loss: 3.2576 - val_acc: 0.5804\n",
      "Medel is training: epoch 33th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2479 - acc: 0.5530 - val_loss: 3.5180 - val_acc: 0.5516\n",
      "Medel is training: epoch 33th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6473 - acc: 0.5916 - val_loss: 3.4242 - val_acc: 0.5364\n",
      "Medel is training: epoch 33th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3333 - acc: 0.5230 - val_loss: 3.3330 - val_acc: 0.5720\n",
      "Medel is training: epoch 33th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1348 - acc: 0.5649 - val_loss: 2.2362 - val_acc: 0.6508\n",
      "Medel is training: epoch 33th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8783 - acc: 0.5737 - val_loss: 3.8853 - val_acc: 0.4889\n",
      "Medel is training: epoch 33th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2200 - acc: 0.5513 - val_loss: 3.4332 - val_acc: 0.5549\n",
      "Medel is training: epoch 33th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9281 - acc: 0.5878 - val_loss: 2.4137 - val_acc: 0.6277\n",
      "Medel is training: epoch 33th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1425 - acc: 0.5425 - val_loss: 4.1762 - val_acc: 0.4529\n",
      "Medel is training: epoch 33th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0740 - acc: 0.5757 - val_loss: 3.4831 - val_acc: 0.5533\n",
      "Medel is training: epoch 33th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7441 - acc: 0.6006 - val_loss: 2.4964 - val_acc: 0.6299\n",
      "Medel is training: epoch 33th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0574 - acc: 0.5541 - val_loss: 3.5658 - val_acc: 0.5184\n",
      "Medel is training: epoch 33th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0478 - acc: 0.5781 - val_loss: 3.5379 - val_acc: 0.5447\n",
      "Medel is training: epoch 33th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7043 - acc: 0.6087 - val_loss: 2.4350 - val_acc: 0.6228\n",
      "Medel is training: epoch 33th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0592 - acc: 0.5563 - val_loss: 3.7984 - val_acc: 0.4906\n",
      "Medel is training: epoch 33th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9897 - acc: 0.5870 - val_loss: 3.2586 - val_acc: 0.5791\n",
      "Medel is training: epoch 33th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7716 - acc: 0.6098 - val_loss: 2.2819 - val_acc: 0.6438\n",
      "Medel is training: epoch 33th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8881 - acc: 0.5714 - val_loss: 3.5318 - val_acc: 0.5330\n",
      "Medel is training: epoch 33th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0933 - acc: 0.5681 - val_loss: 3.2482 - val_acc: 0.5839\n",
      "Medel is training: epoch 33th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9545 - acc: 0.5911 - val_loss: 2.0485 - val_acc: 0.6802\n",
      "Medel is training: epoch 33th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5861 - acc: 0.6061 - val_loss: 3.0371 - val_acc: 0.5837\n",
      "Medel is training: epoch 33th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1706 - acc: 0.5451 - val_loss: 3.2574 - val_acc: 0.5836\n",
      "Medel is training: epoch 33th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9997 - acc: 0.5904 - val_loss: 3.2926 - val_acc: 0.5802\n",
      "Medel is training: epoch 33th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0766 - acc: 0.6693 - val_loss: 2.9930 - val_acc: 0.5943\n",
      "Medel is training: epoch 33th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1126 - acc: 0.5514 - val_loss: 3.2926 - val_acc: 0.5657\n",
      "Medel is training: epoch 33th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9556 - acc: 0.5883 - val_loss: 3.0580 - val_acc: 0.6053\n",
      "Medel is training: epoch 33th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4820 - acc: 0.6433 - val_loss: 2.1076 - val_acc: 0.6762\n",
      "Medel is training: epoch 33th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5572 - acc: 0.6121 - val_loss: 3.1136 - val_acc: 0.5800\n",
      "Medel is training: epoch 33th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1298 - acc: 0.5490 - val_loss: 3.0883 - val_acc: 0.6027\n",
      "Medel is training: epoch 33th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9443 - acc: 0.5967 - val_loss: 3.2106 - val_acc: 0.5845\n",
      "Medel is training: epoch 33th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0566 - acc: 0.6784 - val_loss: 2.2400 - val_acc: 0.6543\n",
      "Medel is training: epoch 33th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8167 - acc: 0.5854 - val_loss: 3.6341 - val_acc: 0.5187\n",
      "Medel is training: epoch 33th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9242 - acc: 0.5862 - val_loss: 3.1515 - val_acc: 0.5961\n",
      "Medel is training: epoch 33th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8810 - acc: 0.6063 - val_loss: 2.3748 - val_acc: 0.6678\n",
      "Medel is training: epoch 33th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9951 - acc: 0.6779 - val_loss: 2.7989 - val_acc: 0.6146\n",
      "Medel is training: epoch 33th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9653 - acc: 0.5709 - val_loss: 3.6282 - val_acc: 0.5177\n",
      "Medel is training: epoch 33th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7989 - acc: 0.6078 - val_loss: 2.9507 - val_acc: 0.6264\n",
      "Medel is training: epoch 33th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9742 - acc: 0.5961 - val_loss: 2.4732 - val_acc: 0.6482\n",
      "Medel is training: epoch 33th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.9483 - acc: 0.6836 - val_loss: 2.8022 - val_acc: 0.6020\n",
      "Medel is training: epoch 33th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8908 - acc: 0.5794 - val_loss: 3.8613 - val_acc: 0.5093\n",
      "Medel is training: epoch 33th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8235 - acc: 0.6043 - val_loss: 3.1099 - val_acc: 0.6012\n",
      "Medel is training: epoch 33th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8835 - acc: 0.6058 - val_loss: 1.9385 - val_acc: 0.6888\n",
      "Medel is training: epoch 33th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9958 - acc: 0.6844 - val_loss: 2.7123 - val_acc: 0.6103\n",
      "Medel is training: epoch 33th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8815 - acc: 0.5793 - val_loss: 3.4853 - val_acc: 0.5307\n",
      "Medel is training: epoch 33th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8769 - acc: 0.5913 - val_loss: 3.2485 - val_acc: 0.5939\n",
      "Medel is training: epoch 34th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4395 - acc: 0.5104 - val_loss: 3.6360 - val_acc: 0.5293\n",
      "Medel is training: epoch 34th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2180 - acc: 0.5565 - val_loss: 2.3370 - val_acc: 0.6236\n",
      "Medel is training: epoch 34th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9789 - acc: 0.5488 - val_loss: 3.5800 - val_acc: 0.5206\n",
      "Medel is training: epoch 34th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1801 - acc: 0.5600 - val_loss: 3.4896 - val_acc: 0.5522\n",
      "Medel is training: epoch 34th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7538 - acc: 0.5937 - val_loss: 3.3492 - val_acc: 0.5475\n",
      "Medel is training: epoch 34th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3691 - acc: 0.5116 - val_loss: 3.2579 - val_acc: 0.5768\n",
      "Medel is training: epoch 34th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2346 - acc: 0.5523 - val_loss: 3.5228 - val_acc: 0.5513\n",
      "Medel is training: epoch 34th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6283 - acc: 0.5950 - val_loss: 3.4221 - val_acc: 0.5364\n",
      "Medel is training: epoch 34th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3129 - acc: 0.5241 - val_loss: 3.3278 - val_acc: 0.5726\n",
      "Medel is training: epoch 34th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1249 - acc: 0.5653 - val_loss: 2.2360 - val_acc: 0.6504\n",
      "Medel is training: epoch 34th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8551 - acc: 0.5734 - val_loss: 3.8829 - val_acc: 0.4889\n",
      "Medel is training: epoch 34th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2117 - acc: 0.5506 - val_loss: 3.4399 - val_acc: 0.5542\n",
      "Medel is training: epoch 34th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9143 - acc: 0.5883 - val_loss: 2.4034 - val_acc: 0.6301\n",
      "Medel is training: epoch 34th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1178 - acc: 0.5451 - val_loss: 4.1773 - val_acc: 0.4549\n",
      "Medel is training: epoch 34th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0656 - acc: 0.5751 - val_loss: 3.4942 - val_acc: 0.5546\n",
      "Medel is training: epoch 34th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7322 - acc: 0.6010 - val_loss: 2.4885 - val_acc: 0.6326\n",
      "Medel is training: epoch 34th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0326 - acc: 0.5556 - val_loss: 3.5578 - val_acc: 0.5201\n",
      "Medel is training: epoch 34th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0355 - acc: 0.5788 - val_loss: 3.5333 - val_acc: 0.5441\n",
      "Medel is training: epoch 34th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6938 - acc: 0.6093 - val_loss: 2.4207 - val_acc: 0.6245\n",
      "Medel is training: epoch 34th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0448 - acc: 0.5569 - val_loss: 3.7874 - val_acc: 0.4897\n",
      "Medel is training: epoch 34th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9768 - acc: 0.5873 - val_loss: 3.2594 - val_acc: 0.5797\n",
      "Medel is training: epoch 34th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7578 - acc: 0.6112 - val_loss: 2.2652 - val_acc: 0.6475\n",
      "Medel is training: epoch 34th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8778 - acc: 0.5706 - val_loss: 3.5279 - val_acc: 0.5305\n",
      "Medel is training: epoch 34th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0796 - acc: 0.5683 - val_loss: 3.2550 - val_acc: 0.5833\n",
      "Medel is training: epoch 34th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9442 - acc: 0.5919 - val_loss: 2.0391 - val_acc: 0.6826\n",
      "Medel is training: epoch 34th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5662 - acc: 0.6080 - val_loss: 3.0297 - val_acc: 0.5856\n",
      "Medel is training: epoch 34th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1529 - acc: 0.5461 - val_loss: 3.2554 - val_acc: 0.5824\n",
      "Medel is training: epoch 34th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9915 - acc: 0.5907 - val_loss: 3.3002 - val_acc: 0.5780\n",
      "Medel is training: epoch 34th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0664 - acc: 0.6695 - val_loss: 2.9840 - val_acc: 0.5965\n",
      "Medel is training: epoch 34th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0998 - acc: 0.5498 - val_loss: 3.3017 - val_acc: 0.5635\n",
      "Medel is training: epoch 34th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9454 - acc: 0.5876 - val_loss: 3.0578 - val_acc: 0.6044\n",
      "Medel is training: epoch 34th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.4752 - acc: 0.6412 - val_loss: 2.0951 - val_acc: 0.6814\n",
      "Medel is training: epoch 34th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5375 - acc: 0.6132 - val_loss: 3.1075 - val_acc: 0.5797\n",
      "Medel is training: epoch 34th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1126 - acc: 0.5484 - val_loss: 3.0836 - val_acc: 0.6024\n",
      "Medel is training: epoch 34th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9345 - acc: 0.5974 - val_loss: 3.2194 - val_acc: 0.5839\n",
      "Medel is training: epoch 34th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0467 - acc: 0.6794 - val_loss: 2.2341 - val_acc: 0.6527\n",
      "Medel is training: epoch 34th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8064 - acc: 0.5856 - val_loss: 3.6353 - val_acc: 0.5200\n",
      "Medel is training: epoch 34th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9127 - acc: 0.5864 - val_loss: 3.1502 - val_acc: 0.5967\n",
      "Medel is training: epoch 34th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8733 - acc: 0.6073 - val_loss: 2.3732 - val_acc: 0.6615\n",
      "Medel is training: epoch 34th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9861 - acc: 0.6777 - val_loss: 2.7938 - val_acc: 0.6162\n",
      "Medel is training: epoch 34th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9481 - acc: 0.5721 - val_loss: 3.6237 - val_acc: 0.5168\n",
      "Medel is training: epoch 34th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7890 - acc: 0.6078 - val_loss: 2.9585 - val_acc: 0.6267\n",
      "Medel is training: epoch 34th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9673 - acc: 0.5948 - val_loss: 2.4753 - val_acc: 0.6488\n",
      "Medel is training: epoch 34th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9362 - acc: 0.6838 - val_loss: 2.7946 - val_acc: 0.6010\n",
      "Medel is training: epoch 34th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8715 - acc: 0.5820 - val_loss: 3.8643 - val_acc: 0.5093\n",
      "Medel is training: epoch 34th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8130 - acc: 0.6039 - val_loss: 3.1060 - val_acc: 0.6026\n",
      "Medel is training: epoch 34th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8730 - acc: 0.6059 - val_loss: 1.9316 - val_acc: 0.6901\n",
      "Medel is training: epoch 34th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9860 - acc: 0.6835 - val_loss: 2.7065 - val_acc: 0.6115\n",
      "Medel is training: epoch 34th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8665 - acc: 0.5796 - val_loss: 3.4842 - val_acc: 0.5329\n",
      "Medel is training: epoch 34th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8607 - acc: 0.5916 - val_loss: 3.2564 - val_acc: 0.5925\n",
      "Medel is training: epoch 35th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4213 - acc: 0.5102 - val_loss: 3.6407 - val_acc: 0.5273\n",
      "Medel is training: epoch 35th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2059 - acc: 0.5565 - val_loss: 2.3374 - val_acc: 0.6207\n",
      "Medel is training: epoch 35th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9578 - acc: 0.5502 - val_loss: 3.5868 - val_acc: 0.5220\n",
      "Medel is training: epoch 35th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1769 - acc: 0.5611 - val_loss: 3.4934 - val_acc: 0.5529\n",
      "Medel is training: epoch 35th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7399 - acc: 0.5959 - val_loss: 3.3424 - val_acc: 0.5448\n",
      "Medel is training: epoch 35th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3509 - acc: 0.5120 - val_loss: 3.2505 - val_acc: 0.5788\n",
      "Medel is training: epoch 35th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2199 - acc: 0.5521 - val_loss: 3.5185 - val_acc: 0.5523\n",
      "Medel is training: epoch 35th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6116 - acc: 0.5959 - val_loss: 3.4158 - val_acc: 0.5368\n",
      "Medel is training: epoch 35th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2953 - acc: 0.5253 - val_loss: 3.3300 - val_acc: 0.5723\n",
      "Medel is training: epoch 35th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1115 - acc: 0.5646 - val_loss: 2.2221 - val_acc: 0.6518\n",
      "Medel is training: epoch 35th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8438 - acc: 0.5745 - val_loss: 3.8508 - val_acc: 0.4903\n",
      "Medel is training: epoch 35th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1895 - acc: 0.5525 - val_loss: 3.4270 - val_acc: 0.5546\n",
      "Medel is training: epoch 35th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8998 - acc: 0.5875 - val_loss: 2.3813 - val_acc: 0.6315\n",
      "Medel is training: epoch 35th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1032 - acc: 0.5459 - val_loss: 4.1597 - val_acc: 0.4549\n",
      "Medel is training: epoch 35th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0526 - acc: 0.5755 - val_loss: 3.4922 - val_acc: 0.5540\n",
      "Medel is training: epoch 35th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7134 - acc: 0.6021 - val_loss: 2.4790 - val_acc: 0.6326\n",
      "Medel is training: epoch 35th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0208 - acc: 0.5548 - val_loss: 3.5623 - val_acc: 0.5171\n",
      "Medel is training: epoch 35th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0284 - acc: 0.5798 - val_loss: 3.5425 - val_acc: 0.5444\n",
      "Medel is training: epoch 35th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6748 - acc: 0.6088 - val_loss: 2.4083 - val_acc: 0.6258\n",
      "Medel is training: epoch 35th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 3.0357 - acc: 0.5545 - val_loss: 3.7854 - val_acc: 0.4893\n",
      "Medel is training: epoch 35th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9570 - acc: 0.5880 - val_loss: 3.2565 - val_acc: 0.5803\n",
      "Medel is training: epoch 35th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7470 - acc: 0.6096 - val_loss: 2.2559 - val_acc: 0.6472\n",
      "Medel is training: epoch 35th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8578 - acc: 0.5717 - val_loss: 3.5265 - val_acc: 0.5308\n",
      "Medel is training: epoch 35th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0691 - acc: 0.5682 - val_loss: 3.2521 - val_acc: 0.5824\n",
      "Medel is training: epoch 35th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9320 - acc: 0.5921 - val_loss: 2.0294 - val_acc: 0.6872\n",
      "Medel is training: epoch 35th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5558 - acc: 0.6086 - val_loss: 3.0176 - val_acc: 0.5853\n",
      "Medel is training: epoch 35th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1408 - acc: 0.5462 - val_loss: 3.2567 - val_acc: 0.5803\n",
      "Medel is training: epoch 35th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9820 - acc: 0.5905 - val_loss: 3.3001 - val_acc: 0.5762\n",
      "Medel is training: epoch 35th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0495 - acc: 0.6720 - val_loss: 2.9783 - val_acc: 0.5943\n",
      "Medel is training: epoch 35th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0789 - acc: 0.5517 - val_loss: 3.2932 - val_acc: 0.5660\n",
      "Medel is training: epoch 35th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9383 - acc: 0.5887 - val_loss: 3.0653 - val_acc: 0.6041\n",
      "Medel is training: epoch 35th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4666 - acc: 0.6420 - val_loss: 2.0947 - val_acc: 0.6784\n",
      "Medel is training: epoch 35th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5301 - acc: 0.6150 - val_loss: 3.0930 - val_acc: 0.5810\n",
      "Medel is training: epoch 35th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0958 - acc: 0.5490 - val_loss: 3.0721 - val_acc: 0.6056\n",
      "Medel is training: epoch 35th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9252 - acc: 0.5970 - val_loss: 3.2095 - val_acc: 0.5842\n",
      "Medel is training: epoch 35th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0279 - acc: 0.6796 - val_loss: 2.2185 - val_acc: 0.6578\n",
      "Medel is training: epoch 35th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7827 - acc: 0.5872 - val_loss: 3.6213 - val_acc: 0.5215\n",
      "Medel is training: epoch 35th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8992 - acc: 0.5880 - val_loss: 3.1561 - val_acc: 0.5973\n",
      "Medel is training: epoch 35th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8628 - acc: 0.6073 - val_loss: 2.3693 - val_acc: 0.6675\n",
      "Medel is training: epoch 35th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9707 - acc: 0.6755 - val_loss: 2.7731 - val_acc: 0.6162\n",
      "Medel is training: epoch 35th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9270 - acc: 0.5725 - val_loss: 3.6156 - val_acc: 0.5177\n",
      "Medel is training: epoch 35th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7750 - acc: 0.6083 - val_loss: 2.9539 - val_acc: 0.6252\n",
      "Medel is training: epoch 35th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9608 - acc: 0.5960 - val_loss: 2.4637 - val_acc: 0.6503\n",
      "Medel is training: epoch 35th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9157 - acc: 0.6866 - val_loss: 2.7828 - val_acc: 0.6032\n",
      "Medel is training: epoch 35th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8601 - acc: 0.5810 - val_loss: 3.8471 - val_acc: 0.5105\n",
      "Medel is training: epoch 35th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7980 - acc: 0.6046 - val_loss: 3.1062 - val_acc: 0.6015\n",
      "Medel is training: epoch 35th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8597 - acc: 0.6061 - val_loss: 1.9252 - val_acc: 0.6916\n",
      "Medel is training: epoch 35th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9674 - acc: 0.6832 - val_loss: 2.7007 - val_acc: 0.6091\n",
      "Medel is training: epoch 35th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8464 - acc: 0.5808 - val_loss: 3.4761 - val_acc: 0.5332\n",
      "Medel is training: epoch 35th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8501 - acc: 0.5919 - val_loss: 3.2621 - val_acc: 0.5925\n",
      "Medel is training: epoch 36th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.4006 - acc: 0.5110 - val_loss: 3.6313 - val_acc: 0.5323\n",
      "Medel is training: epoch 36th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1970 - acc: 0.5570 - val_loss: 2.3259 - val_acc: 0.6244\n",
      "Medel is training: epoch 36th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9450 - acc: 0.5509 - val_loss: 3.5768 - val_acc: 0.5206\n",
      "Medel is training: epoch 36th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1517 - acc: 0.5611 - val_loss: 3.5062 - val_acc: 0.5536\n",
      "Medel is training: epoch 36th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7241 - acc: 0.5955 - val_loss: 3.3392 - val_acc: 0.5448\n",
      "Medel is training: epoch 36th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3239 - acc: 0.5150 - val_loss: 3.2640 - val_acc: 0.5745\n",
      "Medel is training: epoch 36th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2131 - acc: 0.5521 - val_loss: 3.5230 - val_acc: 0.5506\n",
      "Medel is training: epoch 36th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.5921 - acc: 0.5961 - val_loss: 3.4130 - val_acc: 0.5351\n",
      "Medel is training: epoch 36th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2803 - acc: 0.5235 - val_loss: 3.3357 - val_acc: 0.5707\n",
      "Medel is training: epoch 36th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1033 - acc: 0.5663 - val_loss: 2.2165 - val_acc: 0.6518\n",
      "Medel is training: epoch 36th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8274 - acc: 0.5744 - val_loss: 3.8509 - val_acc: 0.4903\n",
      "Medel is training: epoch 36th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1806 - acc: 0.5524 - val_loss: 3.4326 - val_acc: 0.5529\n",
      "Medel is training: epoch 36th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8840 - acc: 0.5901 - val_loss: 2.3824 - val_acc: 0.6319\n",
      "Medel is training: epoch 36th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0828 - acc: 0.5464 - val_loss: 4.1711 - val_acc: 0.4552\n",
      "Medel is training: epoch 36th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0370 - acc: 0.5758 - val_loss: 3.4861 - val_acc: 0.5524\n",
      "Medel is training: epoch 36th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7076 - acc: 0.6024 - val_loss: 2.4747 - val_acc: 0.6327\n",
      "Medel is training: epoch 36th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9946 - acc: 0.5555 - val_loss: 3.5504 - val_acc: 0.5201\n",
      "Medel is training: epoch 36th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0092 - acc: 0.5800 - val_loss: 3.5403 - val_acc: 0.5431\n",
      "Medel is training: epoch 36th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6647 - acc: 0.6105 - val_loss: 2.4061 - val_acc: 0.6276\n",
      "Medel is training: epoch 36th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0147 - acc: 0.5557 - val_loss: 3.7751 - val_acc: 0.4903\n",
      "Medel is training: epoch 36th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9526 - acc: 0.5883 - val_loss: 3.2572 - val_acc: 0.5790\n",
      "Medel is training: epoch 36th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7355 - acc: 0.6092 - val_loss: 2.2420 - val_acc: 0.6516\n",
      "Medel is training: epoch 36th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8522 - acc: 0.5722 - val_loss: 3.5260 - val_acc: 0.5292\n",
      "Medel is training: epoch 36th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0567 - acc: 0.5687 - val_loss: 3.2499 - val_acc: 0.5836\n",
      "Medel is training: epoch 36th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9291 - acc: 0.5918 - val_loss: 2.0219 - val_acc: 0.6856\n",
      "Medel is training: epoch 36th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5415 - acc: 0.6090 - val_loss: 3.0138 - val_acc: 0.5843\n",
      "Medel is training: epoch 36th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1331 - acc: 0.5451 - val_loss: 3.2556 - val_acc: 0.5815\n",
      "Medel is training: epoch 36th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9744 - acc: 0.5919 - val_loss: 3.2889 - val_acc: 0.5780\n",
      "Medel is training: epoch 36th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0396 - acc: 0.6733 - val_loss: 2.9740 - val_acc: 0.5972\n",
      "Medel is training: epoch 36th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0747 - acc: 0.5509 - val_loss: 3.2883 - val_acc: 0.5673\n",
      "Medel is training: epoch 36th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9252 - acc: 0.5881 - val_loss: 3.0672 - val_acc: 0.6050\n",
      "Medel is training: epoch 36th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4514 - acc: 0.6444 - val_loss: 2.0829 - val_acc: 0.6749\n",
      "Medel is training: epoch 36th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5131 - acc: 0.6154 - val_loss: 3.0978 - val_acc: 0.5813\n",
      "Medel is training: epoch 36th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0867 - acc: 0.5486 - val_loss: 3.0728 - val_acc: 0.6065\n",
      "Medel is training: epoch 36th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9173 - acc: 0.5989 - val_loss: 3.2195 - val_acc: 0.5821\n",
      "Medel is training: epoch 36th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0205 - acc: 0.6805 - val_loss: 2.2112 - val_acc: 0.6566\n",
      "Medel is training: epoch 36th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7671 - acc: 0.5867 - val_loss: 3.6052 - val_acc: 0.5209\n",
      "Medel is training: epoch 36th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8809 - acc: 0.5869 - val_loss: 3.1515 - val_acc: 0.5973\n",
      "Medel is training: epoch 36th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8574 - acc: 0.6069 - val_loss: 2.3626 - val_acc: 0.6682\n",
      "Medel is training: epoch 36th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9603 - acc: 0.6800 - val_loss: 2.7713 - val_acc: 0.6143\n",
      "Medel is training: epoch 36th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9120 - acc: 0.5736 - val_loss: 3.6130 - val_acc: 0.5186\n",
      "Medel is training: epoch 36th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7590 - acc: 0.6087 - val_loss: 2.9553 - val_acc: 0.6261\n",
      "Medel is training: epoch 36th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9480 - acc: 0.5967 - val_loss: 2.4696 - val_acc: 0.6479\n",
      "Medel is training: epoch 36th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9057 - acc: 0.6880 - val_loss: 2.7753 - val_acc: 0.6035\n",
      "Medel is training: epoch 36th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8433 - acc: 0.5817 - val_loss: 3.8541 - val_acc: 0.5111\n",
      "Medel is training: epoch 36th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.7933 - acc: 0.6051 - val_loss: 3.1129 - val_acc: 0.6018\n",
      "Medel is training: epoch 36th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8575 - acc: 0.6057 - val_loss: 1.9188 - val_acc: 0.6876\n",
      "Medel is training: epoch 36th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9634 - acc: 0.6815 - val_loss: 2.6975 - val_acc: 0.6100\n",
      "Medel is training: epoch 36th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8384 - acc: 0.5811 - val_loss: 3.4696 - val_acc: 0.5329\n",
      "Medel is training: epoch 36th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8331 - acc: 0.5932 - val_loss: 3.2611 - val_acc: 0.5925\n",
      "Medel is training: epoch 37th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3867 - acc: 0.5124 - val_loss: 3.6424 - val_acc: 0.5266\n",
      "Medel is training: epoch 37th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1882 - acc: 0.5570 - val_loss: 2.3102 - val_acc: 0.6247\n",
      "Medel is training: epoch 37th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9236 - acc: 0.5501 - val_loss: 3.5774 - val_acc: 0.5217\n",
      "Medel is training: epoch 37th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1455 - acc: 0.5612 - val_loss: 3.4918 - val_acc: 0.5522\n",
      "Medel is training: epoch 37th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7095 - acc: 0.5950 - val_loss: 3.3340 - val_acc: 0.5445\n",
      "Medel is training: epoch 37th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3182 - acc: 0.5139 - val_loss: 3.2472 - val_acc: 0.5794\n",
      "Medel is training: epoch 37th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1983 - acc: 0.5523 - val_loss: 3.5321 - val_acc: 0.5496\n",
      "Medel is training: epoch 37th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5755 - acc: 0.5963 - val_loss: 3.4092 - val_acc: 0.5351\n",
      "Medel is training: epoch 37th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2569 - acc: 0.5253 - val_loss: 3.3418 - val_acc: 0.5691\n",
      "Medel is training: epoch 37th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0954 - acc: 0.5649 - val_loss: 2.2105 - val_acc: 0.6529\n",
      "Medel is training: epoch 37th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8022 - acc: 0.5764 - val_loss: 3.8425 - val_acc: 0.4913\n",
      "Medel is training: epoch 37th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1663 - acc: 0.5516 - val_loss: 3.4295 - val_acc: 0.5526\n",
      "Medel is training: epoch 37th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8742 - acc: 0.5903 - val_loss: 2.3676 - val_acc: 0.6340\n",
      "Medel is training: epoch 37th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0735 - acc: 0.5462 - val_loss: 4.1619 - val_acc: 0.4553\n",
      "Medel is training: epoch 37th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0248 - acc: 0.5748 - val_loss: 3.4879 - val_acc: 0.5536\n",
      "Medel is training: epoch 37th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6978 - acc: 0.6029 - val_loss: 2.4634 - val_acc: 0.6330\n",
      "Medel is training: epoch 37th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9780 - acc: 0.5555 - val_loss: 3.5404 - val_acc: 0.5201\n",
      "Medel is training: epoch 37th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9977 - acc: 0.5805 - val_loss: 3.5417 - val_acc: 0.5441\n",
      "Medel is training: epoch 37th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6591 - acc: 0.6093 - val_loss: 2.3896 - val_acc: 0.6293\n",
      "Medel is training: epoch 37th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9978 - acc: 0.5563 - val_loss: 3.7769 - val_acc: 0.4890\n",
      "Medel is training: epoch 37th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9392 - acc: 0.5882 - val_loss: 3.2553 - val_acc: 0.5794\n",
      "Medel is training: epoch 37th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7273 - acc: 0.6099 - val_loss: 2.2316 - val_acc: 0.6519\n",
      "Medel is training: epoch 37th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8332 - acc: 0.5727 - val_loss: 3.5173 - val_acc: 0.5295\n",
      "Medel is training: epoch 37th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0531 - acc: 0.5694 - val_loss: 3.2479 - val_acc: 0.5836\n",
      "Medel is training: epoch 37th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9156 - acc: 0.5929 - val_loss: 2.0047 - val_acc: 0.6885\n",
      "Medel is training: epoch 37th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5221 - acc: 0.6106 - val_loss: 3.0069 - val_acc: 0.5837\n",
      "Medel is training: epoch 37th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1099 - acc: 0.5462 - val_loss: 3.2531 - val_acc: 0.5809\n",
      "Medel is training: epoch 37th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9587 - acc: 0.5913 - val_loss: 3.2984 - val_acc: 0.5765\n",
      "Medel is training: epoch 37th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0136 - acc: 0.6725 - val_loss: 2.9658 - val_acc: 0.5943\n",
      "Medel is training: epoch 37th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0491 - acc: 0.5525 - val_loss: 3.2950 - val_acc: 0.5638\n",
      "Medel is training: epoch 37th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9115 - acc: 0.5888 - val_loss: 3.0665 - val_acc: 0.6050\n",
      "Medel is training: epoch 37th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4386 - acc: 0.6436 - val_loss: 2.0693 - val_acc: 0.6801\n",
      "Medel is training: epoch 37th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4920 - acc: 0.6153 - val_loss: 3.0901 - val_acc: 0.5800\n",
      "Medel is training: epoch 37th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 3.0741 - acc: 0.5495 - val_loss: 3.0846 - val_acc: 0.6024\n",
      "Medel is training: epoch 37th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8998 - acc: 0.5995 - val_loss: 3.2121 - val_acc: 0.5836\n",
      "Medel is training: epoch 37th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0010 - acc: 0.6818 - val_loss: 2.2032 - val_acc: 0.6569\n",
      "Medel is training: epoch 37th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7555 - acc: 0.5884 - val_loss: 3.6093 - val_acc: 0.5225\n",
      "Medel is training: epoch 37th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8767 - acc: 0.5868 - val_loss: 3.1551 - val_acc: 0.5967\n",
      "Medel is training: epoch 37th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8480 - acc: 0.6068 - val_loss: 2.3648 - val_acc: 0.6676\n",
      "Medel is training: epoch 37th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9388 - acc: 0.6811 - val_loss: 2.7695 - val_acc: 0.6159\n",
      "Medel is training: epoch 37th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8955 - acc: 0.5726 - val_loss: 3.6088 - val_acc: 0.5171\n",
      "Medel is training: epoch 37th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7492 - acc: 0.6078 - val_loss: 2.9624 - val_acc: 0.6272\n",
      "Medel is training: epoch 37th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9417 - acc: 0.5962 - val_loss: 2.4695 - val_acc: 0.6500\n",
      "Medel is training: epoch 37th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8927 - acc: 0.6872 - val_loss: 2.7698 - val_acc: 0.6035\n",
      "Medel is training: epoch 37th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8358 - acc: 0.5821 - val_loss: 3.8499 - val_acc: 0.5114\n",
      "Medel is training: epoch 37th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7856 - acc: 0.6047 - val_loss: 3.1139 - val_acc: 0.6003\n",
      "Medel is training: epoch 37th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8477 - acc: 0.6057 - val_loss: 1.9037 - val_acc: 0.6962\n",
      "Medel is training: epoch 37th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9439 - acc: 0.6847 - val_loss: 2.6890 - val_acc: 0.6109\n",
      "Medel is training: epoch 37th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8201 - acc: 0.5811 - val_loss: 3.4614 - val_acc: 0.5313\n",
      "Medel is training: epoch 37th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8226 - acc: 0.5926 - val_loss: 3.2542 - val_acc: 0.5942\n",
      "Medel is training: epoch 38th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3718 - acc: 0.5122 - val_loss: 3.6436 - val_acc: 0.5287\n",
      "Medel is training: epoch 38th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1766 - acc: 0.5579 - val_loss: 2.2946 - val_acc: 0.6259\n",
      "Medel is training: epoch 38th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9116 - acc: 0.5506 - val_loss: 3.5716 - val_acc: 0.5227\n",
      "Medel is training: epoch 38th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1319 - acc: 0.5616 - val_loss: 3.4938 - val_acc: 0.5529\n",
      "Medel is training: epoch 38th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6989 - acc: 0.5953 - val_loss: 3.3230 - val_acc: 0.5445\n",
      "Medel is training: epoch 38th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2946 - acc: 0.5129 - val_loss: 3.2597 - val_acc: 0.5774\n",
      "Medel is training: epoch 38th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1914 - acc: 0.5529 - val_loss: 3.5296 - val_acc: 0.5493\n",
      "Medel is training: epoch 38th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5547 - acc: 0.5971 - val_loss: 3.4098 - val_acc: 0.5361\n",
      "Medel is training: epoch 38th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2479 - acc: 0.5251 - val_loss: 3.3304 - val_acc: 0.5687\n",
      "Medel is training: epoch 38th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0807 - acc: 0.5645 - val_loss: 2.2026 - val_acc: 0.6532\n",
      "Medel is training: epoch 38th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7960 - acc: 0.5775 - val_loss: 3.8363 - val_acc: 0.4913\n",
      "Medel is training: epoch 38th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1512 - acc: 0.5529 - val_loss: 3.4279 - val_acc: 0.5542\n",
      "Medel is training: epoch 38th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8679 - acc: 0.5878 - val_loss: 2.3581 - val_acc: 0.6340\n",
      "Medel is training: epoch 38th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0536 - acc: 0.5469 - val_loss: 4.1554 - val_acc: 0.4529\n",
      "Medel is training: epoch 38th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0195 - acc: 0.5758 - val_loss: 3.4907 - val_acc: 0.5521\n",
      "Medel is training: epoch 38th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6797 - acc: 0.6033 - val_loss: 2.4594 - val_acc: 0.6340\n",
      "Medel is training: epoch 38th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9659 - acc: 0.5576 - val_loss: 3.5479 - val_acc: 0.5171\n",
      "Medel is training: epoch 38th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9902 - acc: 0.5796 - val_loss: 3.5452 - val_acc: 0.5456\n",
      "Medel is training: epoch 38th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6393 - acc: 0.6124 - val_loss: 2.3808 - val_acc: 0.6286\n",
      "Medel is training: epoch 38th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9764 - acc: 0.5570 - val_loss: 3.7716 - val_acc: 0.4897\n",
      "Medel is training: epoch 38th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9284 - acc: 0.5886 - val_loss: 3.2614 - val_acc: 0.5794\n",
      "Medel is training: epoch 38th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.7147 - acc: 0.6102 - val_loss: 2.2261 - val_acc: 0.6556\n",
      "Medel is training: epoch 38th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8172 - acc: 0.5736 - val_loss: 3.5118 - val_acc: 0.5298\n",
      "Medel is training: epoch 38th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0345 - acc: 0.5686 - val_loss: 3.2544 - val_acc: 0.5821\n",
      "Medel is training: epoch 38th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9060 - acc: 0.5918 - val_loss: 2.0055 - val_acc: 0.6845\n",
      "Medel is training: epoch 38th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5095 - acc: 0.6094 - val_loss: 2.9980 - val_acc: 0.5831\n",
      "Medel is training: epoch 38th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0948 - acc: 0.5465 - val_loss: 3.2420 - val_acc: 0.5833\n",
      "Medel is training: epoch 38th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9493 - acc: 0.5930 - val_loss: 3.3009 - val_acc: 0.5753\n",
      "Medel is training: epoch 38th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0061 - acc: 0.6746 - val_loss: 2.9521 - val_acc: 0.5953\n",
      "Medel is training: epoch 38th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0355 - acc: 0.5520 - val_loss: 3.2838 - val_acc: 0.5651\n",
      "Medel is training: epoch 38th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9047 - acc: 0.5884 - val_loss: 3.0579 - val_acc: 0.6032\n",
      "Medel is training: epoch 38th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4345 - acc: 0.6439 - val_loss: 2.0667 - val_acc: 0.6788\n",
      "Medel is training: epoch 38th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4867 - acc: 0.6153 - val_loss: 3.0894 - val_acc: 0.5800\n",
      "Medel is training: epoch 38th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0532 - acc: 0.5498 - val_loss: 3.0841 - val_acc: 0.6033\n",
      "Medel is training: epoch 38th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8958 - acc: 0.5981 - val_loss: 3.2089 - val_acc: 0.5851\n",
      "Medel is training: epoch 38th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9958 - acc: 0.6825 - val_loss: 2.1966 - val_acc: 0.6546\n",
      "Medel is training: epoch 38th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7393 - acc: 0.5886 - val_loss: 3.6082 - val_acc: 0.5209\n",
      "Medel is training: epoch 38th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8602 - acc: 0.5888 - val_loss: 3.1539 - val_acc: 0.5970\n",
      "Medel is training: epoch 38th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8372 - acc: 0.6076 - val_loss: 2.3576 - val_acc: 0.6682\n",
      "Medel is training: epoch 38th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9259 - acc: 0.6813 - val_loss: 2.7611 - val_acc: 0.6137\n",
      "Medel is training: epoch 38th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8897 - acc: 0.5728 - val_loss: 3.6050 - val_acc: 0.5189\n",
      "Medel is training: epoch 38th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7363 - acc: 0.6093 - val_loss: 2.9582 - val_acc: 0.6261\n",
      "Medel is training: epoch 38th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9299 - acc: 0.5967 - val_loss: 2.4696 - val_acc: 0.6497\n",
      "Medel is training: epoch 38th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8810 - acc: 0.6880 - val_loss: 2.7676 - val_acc: 0.6029\n",
      "Medel is training: epoch 38th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8161 - acc: 0.5827 - val_loss: 3.8315 - val_acc: 0.5117\n",
      "Medel is training: epoch 38th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7634 - acc: 0.6061 - val_loss: 3.1102 - val_acc: 0.6015\n",
      "Medel is training: epoch 38th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8435 - acc: 0.6056 - val_loss: 1.9073 - val_acc: 0.6916\n",
      "Medel is training: epoch 38th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9356 - acc: 0.6846 - val_loss: 2.6793 - val_acc: 0.6118\n",
      "Medel is training: epoch 38th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8051 - acc: 0.5811 - val_loss: 3.4495 - val_acc: 0.5325\n",
      "Medel is training: epoch 38th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8089 - acc: 0.5930 - val_loss: 3.2606 - val_acc: 0.5922\n",
      "Medel is training: epoch 39th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3525 - acc: 0.5121 - val_loss: 3.6418 - val_acc: 0.5300\n",
      "Medel is training: epoch 39th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1680 - acc: 0.5578 - val_loss: 2.2881 - val_acc: 0.6270\n",
      "Medel is training: epoch 39th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8880 - acc: 0.5551 - val_loss: 3.5675 - val_acc: 0.5217\n",
      "Medel is training: epoch 39th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1182 - acc: 0.5612 - val_loss: 3.5046 - val_acc: 0.5519\n",
      "Medel is training: epoch 39th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6863 - acc: 0.5982 - val_loss: 3.3183 - val_acc: 0.5434\n",
      "Medel is training: epoch 39th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2817 - acc: 0.5145 - val_loss: 3.2662 - val_acc: 0.5755\n",
      "Medel is training: epoch 39th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1852 - acc: 0.5530 - val_loss: 3.5429 - val_acc: 0.5493\n",
      "Medel is training: epoch 39th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5406 - acc: 0.5973 - val_loss: 3.4031 - val_acc: 0.5341\n",
      "Medel is training: epoch 39th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2328 - acc: 0.5261 - val_loss: 3.3310 - val_acc: 0.5700\n",
      "Medel is training: epoch 39th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 3.0693 - acc: 0.5661 - val_loss: 2.1971 - val_acc: 0.6543\n",
      "Medel is training: epoch 39th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7795 - acc: 0.5761 - val_loss: 3.8217 - val_acc: 0.4913\n",
      "Medel is training: epoch 39th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1414 - acc: 0.5527 - val_loss: 3.4365 - val_acc: 0.5510\n",
      "Medel is training: epoch 39th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8534 - acc: 0.5889 - val_loss: 2.3506 - val_acc: 0.6350\n",
      "Medel is training: epoch 39th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0346 - acc: 0.5468 - val_loss: 4.1435 - val_acc: 0.4549\n",
      "Medel is training: epoch 39th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0084 - acc: 0.5762 - val_loss: 3.4963 - val_acc: 0.5524\n",
      "Medel is training: epoch 39th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6692 - acc: 0.6037 - val_loss: 2.4539 - val_acc: 0.6316\n",
      "Medel is training: epoch 39th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9504 - acc: 0.5565 - val_loss: 3.5459 - val_acc: 0.5184\n",
      "Medel is training: epoch 39th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9820 - acc: 0.5808 - val_loss: 3.5517 - val_acc: 0.5450\n",
      "Medel is training: epoch 39th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6328 - acc: 0.6119 - val_loss: 2.3731 - val_acc: 0.6289\n",
      "Medel is training: epoch 39th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9655 - acc: 0.5576 - val_loss: 3.7739 - val_acc: 0.4906\n",
      "Medel is training: epoch 39th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9141 - acc: 0.5888 - val_loss: 3.2587 - val_acc: 0.5794\n",
      "Medel is training: epoch 39th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7040 - acc: 0.6120 - val_loss: 2.2199 - val_acc: 0.6536\n",
      "Medel is training: epoch 39th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7932 - acc: 0.5736 - val_loss: 3.5116 - val_acc: 0.5279\n",
      "Medel is training: epoch 39th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0168 - acc: 0.5697 - val_loss: 3.2549 - val_acc: 0.5821\n",
      "Medel is training: epoch 39th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8982 - acc: 0.5925 - val_loss: 1.9886 - val_acc: 0.6859\n",
      "Medel is training: epoch 39th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4941 - acc: 0.6106 - val_loss: 3.0022 - val_acc: 0.5818\n",
      "Medel is training: epoch 39th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0832 - acc: 0.5478 - val_loss: 3.2512 - val_acc: 0.5785\n",
      "Medel is training: epoch 39th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9443 - acc: 0.5921 - val_loss: 3.2957 - val_acc: 0.5774\n",
      "Medel is training: epoch 39th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9903 - acc: 0.6760 - val_loss: 2.9509 - val_acc: 0.5953\n",
      "Medel is training: epoch 39th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0146 - acc: 0.5539 - val_loss: 3.2840 - val_acc: 0.5660\n",
      "Medel is training: epoch 39th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8984 - acc: 0.5885 - val_loss: 3.0518 - val_acc: 0.6056\n",
      "Medel is training: epoch 39th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4221 - acc: 0.6444 - val_loss: 2.0547 - val_acc: 0.6801\n",
      "Medel is training: epoch 39th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4650 - acc: 0.6163 - val_loss: 3.0820 - val_acc: 0.5791\n",
      "Medel is training: epoch 39th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0379 - acc: 0.5499 - val_loss: 3.0887 - val_acc: 0.6000\n",
      "Medel is training: epoch 39th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8803 - acc: 0.5988 - val_loss: 3.2114 - val_acc: 0.5857\n",
      "Medel is training: epoch 39th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9818 - acc: 0.6813 - val_loss: 2.1904 - val_acc: 0.6594\n",
      "Medel is training: epoch 39th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7289 - acc: 0.5880 - val_loss: 3.5988 - val_acc: 0.5197\n",
      "Medel is training: epoch 39th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8509 - acc: 0.5887 - val_loss: 3.1502 - val_acc: 0.5979\n",
      "Medel is training: epoch 39th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8308 - acc: 0.6078 - val_loss: 2.3564 - val_acc: 0.6657\n",
      "Medel is training: epoch 39th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9163 - acc: 0.6819 - val_loss: 2.7516 - val_acc: 0.6171\n",
      "Medel is training: epoch 39th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8628 - acc: 0.5746 - val_loss: 3.5929 - val_acc: 0.5189\n",
      "Medel is training: epoch 39th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7310 - acc: 0.6085 - val_loss: 2.9605 - val_acc: 0.6267\n",
      "Medel is training: epoch 39th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9227 - acc: 0.5971 - val_loss: 2.4716 - val_acc: 0.6469\n",
      "Medel is training: epoch 39th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8733 - acc: 0.6892 - val_loss: 2.7609 - val_acc: 0.6045\n",
      "Medel is training: epoch 39th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8011 - acc: 0.5833 - val_loss: 3.8445 - val_acc: 0.5108\n",
      "Medel is training: epoch 39th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7570 - acc: 0.6059 - val_loss: 3.1239 - val_acc: 0.6003\n",
      "Medel is training: epoch 39th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8305 - acc: 0.6069 - val_loss: 1.9028 - val_acc: 0.6928\n",
      "Medel is training: epoch 39th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.9246 - acc: 0.6842 - val_loss: 2.6766 - val_acc: 0.6115\n",
      "Medel is training: epoch 39th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7997 - acc: 0.5805 - val_loss: 3.4515 - val_acc: 0.5340\n",
      "Medel is training: epoch 39th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7972 - acc: 0.5939 - val_loss: 3.2665 - val_acc: 0.5911\n",
      "Medel is training: epoch 40th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3441 - acc: 0.5128 - val_loss: 3.6341 - val_acc: 0.5307\n",
      "Medel is training: epoch 40th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1557 - acc: 0.5583 - val_loss: 2.2729 - val_acc: 0.6288\n",
      "Medel is training: epoch 40th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8789 - acc: 0.5538 - val_loss: 3.5702 - val_acc: 0.5193\n",
      "Medel is training: epoch 40th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1121 - acc: 0.5618 - val_loss: 3.5126 - val_acc: 0.5519\n",
      "Medel is training: epoch 40th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6718 - acc: 0.5975 - val_loss: 3.3112 - val_acc: 0.5441\n",
      "Medel is training: epoch 40th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2656 - acc: 0.5141 - val_loss: 3.2687 - val_acc: 0.5758\n",
      "Medel is training: epoch 40th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1745 - acc: 0.5529 - val_loss: 3.5391 - val_acc: 0.5496\n",
      "Medel is training: epoch 40th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5298 - acc: 0.5994 - val_loss: 3.4072 - val_acc: 0.5327\n",
      "Medel is training: epoch 40th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2198 - acc: 0.5259 - val_loss: 3.3345 - val_acc: 0.5691\n",
      "Medel is training: epoch 40th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0616 - acc: 0.5658 - val_loss: 2.1870 - val_acc: 0.6536\n",
      "Medel is training: epoch 40th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7659 - acc: 0.5769 - val_loss: 3.8232 - val_acc: 0.4910\n",
      "Medel is training: epoch 40th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1281 - acc: 0.5523 - val_loss: 3.4308 - val_acc: 0.5513\n",
      "Medel is training: epoch 40th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8374 - acc: 0.5904 - val_loss: 2.3401 - val_acc: 0.6357\n",
      "Medel is training: epoch 40th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0244 - acc: 0.5476 - val_loss: 4.1331 - val_acc: 0.4563\n",
      "Medel is training: epoch 40th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9947 - acc: 0.5756 - val_loss: 3.4979 - val_acc: 0.5537\n",
      "Medel is training: epoch 40th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6617 - acc: 0.6039 - val_loss: 2.4460 - val_acc: 0.6327\n",
      "Medel is training: epoch 40th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9441 - acc: 0.5581 - val_loss: 3.5268 - val_acc: 0.5181\n",
      "Medel is training: epoch 40th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9722 - acc: 0.5797 - val_loss: 3.5424 - val_acc: 0.5463\n",
      "Medel is training: epoch 40th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6162 - acc: 0.6123 - val_loss: 2.3644 - val_acc: 0.6300\n",
      "Medel is training: epoch 40th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9509 - acc: 0.5580 - val_loss: 3.7613 - val_acc: 0.4910\n",
      "Medel is training: epoch 40th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9077 - acc: 0.5879 - val_loss: 3.2590 - val_acc: 0.5797\n",
      "Medel is training: epoch 40th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6943 - acc: 0.6117 - val_loss: 2.2101 - val_acc: 0.6552\n",
      "Medel is training: epoch 40th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7857 - acc: 0.5753 - val_loss: 3.5144 - val_acc: 0.5292\n",
      "Medel is training: epoch 40th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0052 - acc: 0.5689 - val_loss: 3.2552 - val_acc: 0.5805\n",
      "Medel is training: epoch 40th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8877 - acc: 0.5933 - val_loss: 1.9854 - val_acc: 0.6889\n",
      "Medel is training: epoch 40th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4796 - acc: 0.6108 - val_loss: 2.9946 - val_acc: 0.5824\n",
      "Medel is training: epoch 40th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0701 - acc: 0.5471 - val_loss: 3.2708 - val_acc: 0.5745\n",
      "Medel is training: epoch 40th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9389 - acc: 0.5921 - val_loss: 3.3080 - val_acc: 0.5759\n",
      "Medel is training: epoch 40th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9793 - acc: 0.6747 - val_loss: 2.9442 - val_acc: 0.5943\n",
      "Medel is training: epoch 40th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0047 - acc: 0.5540 - val_loss: 3.2772 - val_acc: 0.5645\n",
      "Medel is training: epoch 40th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8822 - acc: 0.5894 - val_loss: 3.0613 - val_acc: 0.6035\n",
      "Medel is training: epoch 40th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4102 - acc: 0.6454 - val_loss: 2.0442 - val_acc: 0.6833\n",
      "Medel is training: epoch 40th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4549 - acc: 0.6188 - val_loss: 3.0846 - val_acc: 0.5800\n",
      "Medel is training: epoch 40th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0248 - acc: 0.5512 - val_loss: 3.0971 - val_acc: 0.5968\n",
      "Medel is training: epoch 40th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8732 - acc: 0.5998 - val_loss: 3.2094 - val_acc: 0.5848\n",
      "Medel is training: epoch 40th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.9750 - acc: 0.6787 - val_loss: 2.1751 - val_acc: 0.6607\n",
      "Medel is training: epoch 40th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7233 - acc: 0.5898 - val_loss: 3.5972 - val_acc: 0.5218\n",
      "Medel is training: epoch 40th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8327 - acc: 0.5897 - val_loss: 3.1538 - val_acc: 0.5979\n",
      "Medel is training: epoch 40th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8210 - acc: 0.6075 - val_loss: 2.3630 - val_acc: 0.6645\n",
      "Medel is training: epoch 40th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9090 - acc: 0.6800 - val_loss: 2.7480 - val_acc: 0.6162\n",
      "Medel is training: epoch 40th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8535 - acc: 0.5756 - val_loss: 3.5831 - val_acc: 0.5180\n",
      "Medel is training: epoch 40th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7195 - acc: 0.6090 - val_loss: 2.9696 - val_acc: 0.6255\n",
      "Medel is training: epoch 40th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9143 - acc: 0.5966 - val_loss: 2.4678 - val_acc: 0.6494\n",
      "Medel is training: epoch 40th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8667 - acc: 0.6881 - val_loss: 2.7530 - val_acc: 0.6032\n",
      "Medel is training: epoch 40th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7871 - acc: 0.5834 - val_loss: 3.8323 - val_acc: 0.5120\n",
      "Medel is training: epoch 40th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7441 - acc: 0.6051 - val_loss: 3.1169 - val_acc: 0.5995\n",
      "Medel is training: epoch 40th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1595 - acc: 0.5551 - val_loss: 3.5393 - val_acc: 0.5483\n",
      "Medel is training: epoch 41th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5181 - acc: 0.5993 - val_loss: 3.3993 - val_acc: 0.5351\n",
      "Medel is training: epoch 41th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2049 - acc: 0.5257 - val_loss: 3.3359 - val_acc: 0.5694\n",
      "Medel is training: epoch 41th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0521 - acc: 0.5658 - val_loss: 2.1836 - val_acc: 0.6550\n",
      "Medel is training: epoch 41th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7468 - acc: 0.5774 - val_loss: 3.8086 - val_acc: 0.4913\n",
      "Medel is training: epoch 41th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1139 - acc: 0.5528 - val_loss: 3.4347 - val_acc: 0.5523\n",
      "Medel is training: epoch 41th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8396 - acc: 0.5890 - val_loss: 2.3392 - val_acc: 0.6357\n",
      "Medel is training: epoch 41th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0090 - acc: 0.5496 - val_loss: 4.1259 - val_acc: 0.4552\n",
      "Medel is training: epoch 41th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9909 - acc: 0.5763 - val_loss: 3.4931 - val_acc: 0.5546\n",
      "Medel is training: epoch 41th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6495 - acc: 0.6058 - val_loss: 2.4416 - val_acc: 0.6333\n",
      "Medel is training: epoch 41th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9281 - acc: 0.5581 - val_loss: 3.5276 - val_acc: 0.5201\n",
      "Medel is training: epoch 41th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9597 - acc: 0.5811 - val_loss: 3.5452 - val_acc: 0.5459\n",
      "Medel is training: epoch 41th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6070 - acc: 0.6127 - val_loss: 2.3578 - val_acc: 0.6317\n",
      "Medel is training: epoch 41th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9354 - acc: 0.5580 - val_loss: 3.7662 - val_acc: 0.4903\n",
      "Medel is training: epoch 41th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8973 - acc: 0.5885 - val_loss: 3.2655 - val_acc: 0.5778\n",
      "Medel is training: epoch 41th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6830 - acc: 0.6117 - val_loss: 2.2003 - val_acc: 0.6543\n",
      "Medel is training: epoch 41th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7768 - acc: 0.5729 - val_loss: 3.5118 - val_acc: 0.5273\n",
      "Medel is training: epoch 41th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9952 - acc: 0.5700 - val_loss: 3.2667 - val_acc: 0.5811\n",
      "Medel is training: epoch 41th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8766 - acc: 0.5928 - val_loss: 1.9813 - val_acc: 0.6889\n",
      "Medel is training: epoch 41th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4759 - acc: 0.6110 - val_loss: 2.9857 - val_acc: 0.5831\n",
      "Medel is training: epoch 41th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0580 - acc: 0.5461 - val_loss: 3.2710 - val_acc: 0.5770\n",
      "Medel is training: epoch 41th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9239 - acc: 0.5925 - val_loss: 3.3134 - val_acc: 0.5741\n",
      "Medel is training: epoch 41th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9630 - acc: 0.6770 - val_loss: 2.9398 - val_acc: 0.5943\n",
      "Medel is training: epoch 41th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9974 - acc: 0.5553 - val_loss: 3.2829 - val_acc: 0.5666\n",
      "Medel is training: epoch 41th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8796 - acc: 0.5894 - val_loss: 3.0690 - val_acc: 0.6023\n",
      "Medel is training: epoch 41th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4029 - acc: 0.6452 - val_loss: 2.0412 - val_acc: 0.6823\n",
      "Medel is training: epoch 41th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4408 - acc: 0.6195 - val_loss: 3.0759 - val_acc: 0.5791\n",
      "Medel is training: epoch 41th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 3.0113 - acc: 0.5527 - val_loss: 3.0871 - val_acc: 0.6006\n",
      "Medel is training: epoch 41th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8652 - acc: 0.5989 - val_loss: 3.2096 - val_acc: 0.5833\n",
      "Medel is training: epoch 41th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9520 - acc: 0.6841 - val_loss: 2.1756 - val_acc: 0.6591\n",
      "Medel is training: epoch 41th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7119 - acc: 0.5899 - val_loss: 3.5952 - val_acc: 0.5228\n",
      "Medel is training: epoch 41th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8206 - acc: 0.5885 - val_loss: 3.1546 - val_acc: 0.5964\n",
      "Medel is training: epoch 41th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8110 - acc: 0.6084 - val_loss: 2.3519 - val_acc: 0.6663\n",
      "Medel is training: epoch 41th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8866 - acc: 0.6844 - val_loss: 2.7447 - val_acc: 0.6177\n",
      "Medel is training: epoch 41th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8434 - acc: 0.5745 - val_loss: 3.5864 - val_acc: 0.5192\n",
      "Medel is training: epoch 41th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7068 - acc: 0.6103 - val_loss: 2.9719 - val_acc: 0.6246\n",
      "Medel is training: epoch 41th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9053 - acc: 0.5974 - val_loss: 2.4625 - val_acc: 0.6509\n",
      "Medel is training: epoch 41th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8515 - acc: 0.6881 - val_loss: 2.7488 - val_acc: 0.6035\n",
      "Medel is training: epoch 41th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7690 - acc: 0.5859 - val_loss: 3.8363 - val_acc: 0.5132\n",
      "Medel is training: epoch 41th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7399 - acc: 0.6059 - val_loss: 3.1183 - val_acc: 0.5992\n",
      "Medel is training: epoch 41th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8177 - acc: 0.6064 - val_loss: 1.8923 - val_acc: 0.6934\n",
      "Medel is training: epoch 41th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9027 - acc: 0.6874 - val_loss: 2.6669 - val_acc: 0.6115\n",
      "Medel is training: epoch 41th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7684 - acc: 0.5838 - val_loss: 3.4396 - val_acc: 0.5334\n",
      "Medel is training: epoch 41th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7774 - acc: 0.5942 - val_loss: 3.2748 - val_acc: 0.5919\n",
      "Medel is training: epoch 42th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.3112 - acc: 0.5130 - val_loss: 3.6468 - val_acc: 0.5280\n",
      "Medel is training: epoch 42th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1403 - acc: 0.5584 - val_loss: 2.2494 - val_acc: 0.6343\n",
      "Medel is training: epoch 42th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8409 - acc: 0.5570 - val_loss: 3.5545 - val_acc: 0.5203\n",
      "Medel is training: epoch 42th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0898 - acc: 0.5616 - val_loss: 3.5127 - val_acc: 0.5486\n",
      "Medel is training: epoch 42th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6462 - acc: 0.5969 - val_loss: 3.3118 - val_acc: 0.5448\n",
      "Medel is training: epoch 42th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2362 - acc: 0.5142 - val_loss: 3.2685 - val_acc: 0.5755\n",
      "Medel is training: epoch 42th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1519 - acc: 0.5534 - val_loss: 3.5379 - val_acc: 0.5500\n",
      "Medel is training: epoch 42th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5048 - acc: 0.6004 - val_loss: 3.3955 - val_acc: 0.5358\n",
      "Medel is training: epoch 42th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1899 - acc: 0.5273 - val_loss: 3.3409 - val_acc: 0.5684\n",
      "Medel is training: epoch 42th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0404 - acc: 0.5654 - val_loss: 2.1819 - val_acc: 0.6554\n",
      "Medel is training: epoch 42th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7336 - acc: 0.5786 - val_loss: 3.8071 - val_acc: 0.4913\n",
      "Medel is training: epoch 42th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1041 - acc: 0.5530 - val_loss: 3.4468 - val_acc: 0.5493\n",
      "Medel is training: epoch 42th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8198 - acc: 0.5910 - val_loss: 2.3259 - val_acc: 0.6382\n",
      "Medel is training: epoch 42th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9906 - acc: 0.5483 - val_loss: 4.1139 - val_acc: 0.4556\n",
      "Medel is training: epoch 42th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9790 - acc: 0.5765 - val_loss: 3.4955 - val_acc: 0.5546\n",
      "Medel is training: epoch 42th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6414 - acc: 0.6052 - val_loss: 2.4343 - val_acc: 0.6347\n",
      "Medel is training: epoch 42th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9141 - acc: 0.5591 - val_loss: 3.5270 - val_acc: 0.5165\n",
      "Medel is training: epoch 42th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9531 - acc: 0.5797 - val_loss: 3.5490 - val_acc: 0.5453\n",
      "Medel is training: epoch 42th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6056 - acc: 0.6126 - val_loss: 2.3480 - val_acc: 0.6314\n",
      "Medel is training: epoch 42th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9241 - acc: 0.5588 - val_loss: 3.7554 - val_acc: 0.4890\n",
      "Medel is training: epoch 42th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8840 - acc: 0.5901 - val_loss: 3.2605 - val_acc: 0.5769\n",
      "Medel is training: epoch 42th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.6719 - acc: 0.6117 - val_loss: 2.1935 - val_acc: 0.6556\n",
      "Medel is training: epoch 42th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7602 - acc: 0.5740 - val_loss: 3.5059 - val_acc: 0.5285\n",
      "Medel is training: epoch 42th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9810 - acc: 0.5696 - val_loss: 3.2670 - val_acc: 0.5805\n",
      "Medel is training: epoch 42th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8648 - acc: 0.5939 - val_loss: 1.9764 - val_acc: 0.6859\n",
      "Medel is training: epoch 42th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4589 - acc: 0.6110 - val_loss: 2.9825 - val_acc: 0.5821\n",
      "Medel is training: epoch 42th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0452 - acc: 0.5474 - val_loss: 3.2483 - val_acc: 0.5803\n",
      "Medel is training: epoch 42th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9185 - acc: 0.5924 - val_loss: 3.3226 - val_acc: 0.5717\n",
      "Medel is training: epoch 42th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9541 - acc: 0.6773 - val_loss: 2.9418 - val_acc: 0.5946\n",
      "Medel is training: epoch 42th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9779 - acc: 0.5535 - val_loss: 3.2798 - val_acc: 0.5663\n",
      "Medel is training: epoch 42th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8722 - acc: 0.5887 - val_loss: 3.0732 - val_acc: 0.6006\n",
      "Medel is training: epoch 42th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3927 - acc: 0.6450 - val_loss: 2.0331 - val_acc: 0.6814\n",
      "Medel is training: epoch 42th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4284 - acc: 0.6188 - val_loss: 3.0754 - val_acc: 0.5772\n",
      "Medel is training: epoch 42th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9901 - acc: 0.5509 - val_loss: 3.1027 - val_acc: 0.5956\n",
      "Medel is training: epoch 42th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8643 - acc: 0.5989 - val_loss: 3.2121 - val_acc: 0.5833\n",
      "Medel is training: epoch 42th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9510 - acc: 0.6838 - val_loss: 2.1674 - val_acc: 0.6591\n",
      "Medel is training: epoch 42th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6867 - acc: 0.5905 - val_loss: 3.5908 - val_acc: 0.5228\n",
      "Medel is training: epoch 42th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8095 - acc: 0.5885 - val_loss: 3.1548 - val_acc: 0.5970\n",
      "Medel is training: epoch 42th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8016 - acc: 0.6090 - val_loss: 2.3499 - val_acc: 0.6669\n",
      "Medel is training: epoch 42th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8835 - acc: 0.6838 - val_loss: 2.7386 - val_acc: 0.6155\n",
      "Medel is training: epoch 42th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8332 - acc: 0.5752 - val_loss: 3.5741 - val_acc: 0.5192\n",
      "Medel is training: epoch 42th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7030 - acc: 0.6080 - val_loss: 2.9708 - val_acc: 0.6261\n",
      "Medel is training: epoch 42th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8945 - acc: 0.5974 - val_loss: 2.4596 - val_acc: 0.6491\n",
      "Medel is training: epoch 42th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8368 - acc: 0.6910 - val_loss: 2.7434 - val_acc: 0.6023\n",
      "Medel is training: epoch 42th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7723 - acc: 0.5841 - val_loss: 3.8349 - val_acc: 0.5105\n",
      "Medel is training: epoch 42th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7273 - acc: 0.6055 - val_loss: 3.1176 - val_acc: 0.5980\n",
      "Medel is training: epoch 42th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8041 - acc: 0.6065 - val_loss: 1.8858 - val_acc: 0.6956\n",
      "Medel is training: epoch 42th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8907 - acc: 0.6877 - val_loss: 2.6641 - val_acc: 0.6121\n",
      "Medel is training: epoch 42th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7597 - acc: 0.5828 - val_loss: 3.4342 - val_acc: 0.5319\n",
      "Medel is training: epoch 42th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7648 - acc: 0.5941 - val_loss: 3.2789 - val_acc: 0.5908\n",
      "Medel is training: epoch 43th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2852 - acc: 0.5136 - val_loss: 3.6454 - val_acc: 0.5307\n",
      "Medel is training: epoch 43th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1247 - acc: 0.5599 - val_loss: 2.2492 - val_acc: 0.6314\n",
      "Medel is training: epoch 43th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8233 - acc: 0.5555 - val_loss: 3.5522 - val_acc: 0.5206\n",
      "Medel is training: epoch 43th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0823 - acc: 0.5633 - val_loss: 3.5201 - val_acc: 0.5512\n",
      "Medel is training: epoch 43th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6376 - acc: 0.6000 - val_loss: 3.3182 - val_acc: 0.5421\n",
      "Medel is training: epoch 43th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2210 - acc: 0.5147 - val_loss: 3.2636 - val_acc: 0.5765\n",
      "Medel is training: epoch 43th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1480 - acc: 0.5536 - val_loss: 3.5412 - val_acc: 0.5493\n",
      "Medel is training: epoch 43th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4935 - acc: 0.6008 - val_loss: 3.3943 - val_acc: 0.5348\n",
      "Medel is training: epoch 43th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1739 - acc: 0.5270 - val_loss: 3.3387 - val_acc: 0.5668\n",
      "Medel is training: epoch 43th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 3.0360 - acc: 0.5672 - val_loss: 2.1724 - val_acc: 0.6550\n",
      "Medel is training: epoch 43th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7220 - acc: 0.5790 - val_loss: 3.7934 - val_acc: 0.4916\n",
      "Medel is training: epoch 43th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0947 - acc: 0.5537 - val_loss: 3.4445 - val_acc: 0.5480\n",
      "Medel is training: epoch 43th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8115 - acc: 0.5908 - val_loss: 2.3217 - val_acc: 0.6340\n",
      "Medel is training: epoch 43th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9779 - acc: 0.5492 - val_loss: 4.1332 - val_acc: 0.4552\n",
      "Medel is training: epoch 43th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9659 - acc: 0.5762 - val_loss: 3.4909 - val_acc: 0.5562\n",
      "Medel is training: epoch 43th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6187 - acc: 0.6063 - val_loss: 2.4337 - val_acc: 0.6341\n",
      "Medel is training: epoch 43th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9028 - acc: 0.5583 - val_loss: 3.5159 - val_acc: 0.5201\n",
      "Medel is training: epoch 43th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9408 - acc: 0.5823 - val_loss: 3.5477 - val_acc: 0.5469\n",
      "Medel is training: epoch 43th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5917 - acc: 0.6136 - val_loss: 2.3396 - val_acc: 0.6324\n",
      "Medel is training: epoch 43th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9036 - acc: 0.5601 - val_loss: 3.7695 - val_acc: 0.4893\n",
      "Medel is training: epoch 43th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8702 - acc: 0.5898 - val_loss: 3.2646 - val_acc: 0.5766\n",
      "Medel is training: epoch 43th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6648 - acc: 0.6119 - val_loss: 2.1916 - val_acc: 0.6549\n",
      "Medel is training: epoch 43th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7453 - acc: 0.5759 - val_loss: 3.5107 - val_acc: 0.5273\n",
      "Medel is training: epoch 43th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9656 - acc: 0.5690 - val_loss: 3.2685 - val_acc: 0.5799\n",
      "Medel is training: epoch 43th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8690 - acc: 0.5931 - val_loss: 1.9847 - val_acc: 0.6865\n",
      "Medel is training: epoch 43th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4420 - acc: 0.6141 - val_loss: 2.9764 - val_acc: 0.5850\n",
      "Medel is training: epoch 43th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0401 - acc: 0.5470 - val_loss: 3.2584 - val_acc: 0.5797\n",
      "Medel is training: epoch 43th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9134 - acc: 0.5923 - val_loss: 3.3185 - val_acc: 0.5714\n",
      "Medel is training: epoch 43th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9507 - acc: 0.6765 - val_loss: 2.9325 - val_acc: 0.5988\n",
      "Medel is training: epoch 43th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9652 - acc: 0.5550 - val_loss: 3.2828 - val_acc: 0.5682\n",
      "Medel is training: epoch 43th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8569 - acc: 0.5886 - val_loss: 3.0755 - val_acc: 0.6020\n",
      "Medel is training: epoch 43th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3857 - acc: 0.6462 - val_loss: 2.0298 - val_acc: 0.6830\n",
      "Medel is training: epoch 43th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4227 - acc: 0.6181 - val_loss: 3.0738 - val_acc: 0.5766\n",
      "Medel is training: epoch 43th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9817 - acc: 0.5524 - val_loss: 3.0941 - val_acc: 0.5962\n",
      "Medel is training: epoch 43th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8608 - acc: 0.5997 - val_loss: 3.2255 - val_acc: 0.5818\n",
      "Medel is training: epoch 43th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9370 - acc: 0.6846 - val_loss: 2.1666 - val_acc: 0.6597\n",
      "Medel is training: epoch 43th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6798 - acc: 0.5903 - val_loss: 3.5908 - val_acc: 0.5228\n",
      "Medel is training: epoch 43th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8086 - acc: 0.5884 - val_loss: 3.1544 - val_acc: 0.5976\n",
      "Medel is training: epoch 43th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8006 - acc: 0.6083 - val_loss: 2.3477 - val_acc: 0.6648\n",
      "Medel is training: epoch 43th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8679 - acc: 0.6838 - val_loss: 2.7296 - val_acc: 0.6159\n",
      "Medel is training: epoch 43th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8115 - acc: 0.5764 - val_loss: 3.5827 - val_acc: 0.5186\n",
      "Medel is training: epoch 43th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6848 - acc: 0.6084 - val_loss: 2.9766 - val_acc: 0.6267\n",
      "Medel is training: epoch 43th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8882 - acc: 0.5978 - val_loss: 2.4646 - val_acc: 0.6488\n",
      "Medel is training: epoch 43th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8288 - acc: 0.6901 - val_loss: 2.7436 - val_acc: 0.6004\n",
      "Medel is training: epoch 43th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7510 - acc: 0.5838 - val_loss: 3.8301 - val_acc: 0.5114\n",
      "Medel is training: epoch 43th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7165 - acc: 0.6059 - val_loss: 3.1247 - val_acc: 0.5975\n",
      "Medel is training: epoch 43th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8024 - acc: 0.6057 - val_loss: 1.8813 - val_acc: 0.6950\n",
      "Medel is training: epoch 43th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.8810 - acc: 0.6875 - val_loss: 2.6544 - val_acc: 0.6127\n",
      "Medel is training: epoch 43th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7350 - acc: 0.5839 - val_loss: 3.4352 - val_acc: 0.5325\n",
      "Medel is training: epoch 43th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7546 - acc: 0.5937 - val_loss: 3.2791 - val_acc: 0.5908\n",
      "Medel is training: epoch 44th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2841 - acc: 0.5134 - val_loss: 3.6444 - val_acc: 0.5290\n",
      "Medel is training: epoch 44th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1178 - acc: 0.5603 - val_loss: 2.2435 - val_acc: 0.6310\n",
      "Medel is training: epoch 44th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8113 - acc: 0.5562 - val_loss: 3.5489 - val_acc: 0.5210\n",
      "Medel is training: epoch 44th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0690 - acc: 0.5622 - val_loss: 3.5170 - val_acc: 0.5506\n",
      "Medel is training: epoch 44th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6238 - acc: 0.6003 - val_loss: 3.3043 - val_acc: 0.5448\n",
      "Medel is training: epoch 44th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2108 - acc: 0.5146 - val_loss: 3.2676 - val_acc: 0.5761\n",
      "Medel is training: epoch 44th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1332 - acc: 0.5542 - val_loss: 3.5445 - val_acc: 0.5490\n",
      "Medel is training: epoch 44th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4774 - acc: 0.6015 - val_loss: 3.3906 - val_acc: 0.5344\n",
      "Medel is training: epoch 44th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1606 - acc: 0.5279 - val_loss: 3.3445 - val_acc: 0.5665\n",
      "Medel is training: epoch 44th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0253 - acc: 0.5655 - val_loss: 2.1651 - val_acc: 0.6547\n",
      "Medel is training: epoch 44th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7032 - acc: 0.5801 - val_loss: 3.7822 - val_acc: 0.4913\n",
      "Medel is training: epoch 44th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0802 - acc: 0.5532 - val_loss: 3.4425 - val_acc: 0.5506\n",
      "Medel is training: epoch 44th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8016 - acc: 0.5915 - val_loss: 2.3159 - val_acc: 0.6329\n",
      "Medel is training: epoch 44th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9663 - acc: 0.5461 - val_loss: 4.1253 - val_acc: 0.4546\n",
      "Medel is training: epoch 44th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9534 - acc: 0.5771 - val_loss: 3.5021 - val_acc: 0.5543\n",
      "Medel is training: epoch 44th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6116 - acc: 0.6071 - val_loss: 2.4334 - val_acc: 0.6340\n",
      "Medel is training: epoch 44th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8908 - acc: 0.5597 - val_loss: 3.5237 - val_acc: 0.5198\n",
      "Medel is training: epoch 44th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9248 - acc: 0.5814 - val_loss: 3.5556 - val_acc: 0.5459\n",
      "Medel is training: epoch 44th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5808 - acc: 0.6134 - val_loss: 2.3346 - val_acc: 0.6334\n",
      "Medel is training: epoch 44th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8843 - acc: 0.5602 - val_loss: 3.7572 - val_acc: 0.4926\n",
      "Medel is training: epoch 44th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8567 - acc: 0.5894 - val_loss: 3.2679 - val_acc: 0.5788\n",
      "Medel is training: epoch 44th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6523 - acc: 0.6130 - val_loss: 2.1872 - val_acc: 0.6566\n",
      "Medel is training: epoch 44th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7349 - acc: 0.5761 - val_loss: 3.4928 - val_acc: 0.5295\n",
      "Medel is training: epoch 44th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9604 - acc: 0.5703 - val_loss: 3.2660 - val_acc: 0.5811\n",
      "Medel is training: epoch 44th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8525 - acc: 0.5936 - val_loss: 1.9705 - val_acc: 0.6892\n",
      "Medel is training: epoch 44th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4295 - acc: 0.6133 - val_loss: 2.9787 - val_acc: 0.5834\n",
      "Medel is training: epoch 44th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0096 - acc: 0.5482 - val_loss: 3.2449 - val_acc: 0.5815\n",
      "Medel is training: epoch 44th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9075 - acc: 0.5930 - val_loss: 3.3306 - val_acc: 0.5695\n",
      "Medel is training: epoch 44th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9389 - acc: 0.6782 - val_loss: 2.9222 - val_acc: 0.5969\n",
      "Medel is training: epoch 44th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9625 - acc: 0.5540 - val_loss: 3.2856 - val_acc: 0.5651\n",
      "Medel is training: epoch 44th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8520 - acc: 0.5888 - val_loss: 3.0709 - val_acc: 0.6026\n",
      "Medel is training: epoch 44th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3749 - acc: 0.6455 - val_loss: 2.0204 - val_acc: 0.6849\n",
      "Medel is training: epoch 44th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4113 - acc: 0.6183 - val_loss: 3.0716 - val_acc: 0.5763\n",
      "Medel is training: epoch 44th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9719 - acc: 0.5541 - val_loss: 3.1033 - val_acc: 0.5959\n",
      "Medel is training: epoch 44th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8554 - acc: 0.5981 - val_loss: 3.2125 - val_acc: 0.5836\n",
      "Medel is training: epoch 44th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.9296 - acc: 0.6852 - val_loss: 2.1569 - val_acc: 0.6604\n",
      "Medel is training: epoch 44th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6735 - acc: 0.5896 - val_loss: 3.5885 - val_acc: 0.5228\n",
      "Medel is training: epoch 44th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7940 - acc: 0.5899 - val_loss: 3.1579 - val_acc: 0.5973\n",
      "Medel is training: epoch 44th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7899 - acc: 0.6081 - val_loss: 2.3454 - val_acc: 0.6697\n",
      "Medel is training: epoch 44th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8646 - acc: 0.6842 - val_loss: 2.7283 - val_acc: 0.6152\n",
      "Medel is training: epoch 44th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7955 - acc: 0.5762 - val_loss: 3.5881 - val_acc: 0.5192\n",
      "Medel is training: epoch 44th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6759 - acc: 0.6113 - val_loss: 2.9771 - val_acc: 0.6264\n",
      "Medel is training: epoch 44th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8853 - acc: 0.5987 - val_loss: 2.4654 - val_acc: 0.6454\n",
      "Medel is training: epoch 44th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8217 - acc: 0.6910 - val_loss: 2.7357 - val_acc: 0.6026\n",
      "Medel is training: epoch 44th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7373 - acc: 0.5832 - val_loss: 3.8262 - val_acc: 0.5108\n",
      "Medel is training: epoch 44th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7101 - acc: 0.6071 - val_loss: 3.1132 - val_acc: 0.5986\n",
      "Medel is training: epoch 44th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7901 - acc: 0.6076 - val_loss: 1.8832 - val_acc: 0.6959\n",
      "Medel is training: epoch 44th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8729 - acc: 0.6872 - val_loss: 2.6558 - val_acc: 0.6140\n",
      "Medel is training: epoch 44th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7340 - acc: 0.5833 - val_loss: 3.4248 - val_acc: 0.5319\n",
      "Medel is training: epoch 44th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7473 - acc: 0.5944 - val_loss: 3.2740 - val_acc: 0.5908\n",
      "Medel is training: epoch 45th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2750 - acc: 0.5144 - val_loss: 3.6344 - val_acc: 0.5303\n",
      "Medel is training: epoch 45th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1079 - acc: 0.5601 - val_loss: 2.2288 - val_acc: 0.6325\n",
      "Medel is training: epoch 45th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7913 - acc: 0.5585 - val_loss: 3.5456 - val_acc: 0.5161\n",
      "Medel is training: epoch 45th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0521 - acc: 0.5633 - val_loss: 3.5271 - val_acc: 0.5509\n",
      "Medel is training: epoch 45th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6189 - acc: 0.5988 - val_loss: 3.3016 - val_acc: 0.5421\n",
      "Medel is training: epoch 45th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1978 - acc: 0.5167 - val_loss: 3.2812 - val_acc: 0.5711\n",
      "Medel is training: epoch 45th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1229 - acc: 0.5541 - val_loss: 3.5444 - val_acc: 0.5503\n",
      "Medel is training: epoch 45th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4594 - acc: 0.6018 - val_loss: 3.3970 - val_acc: 0.5341\n",
      "Medel is training: epoch 45th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1436 - acc: 0.5285 - val_loss: 3.3457 - val_acc: 0.5668\n",
      "Medel is training: epoch 45th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0160 - acc: 0.5667 - val_loss: 2.1621 - val_acc: 0.6589\n",
      "Medel is training: epoch 45th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6964 - acc: 0.5796 - val_loss: 3.7903 - val_acc: 0.4930\n",
      "Medel is training: epoch 45th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0646 - acc: 0.5529 - val_loss: 3.4530 - val_acc: 0.5471\n",
      "Medel is training: epoch 45th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7894 - acc: 0.5924 - val_loss: 2.3158 - val_acc: 0.6357\n",
      "Medel is training: epoch 45th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9512 - acc: 0.5479 - val_loss: 4.1211 - val_acc: 0.4539\n",
      "Medel is training: epoch 45th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9431 - acc: 0.5786 - val_loss: 3.5116 - val_acc: 0.5549\n",
      "Medel is training: epoch 45th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6059 - acc: 0.6067 - val_loss: 2.4216 - val_acc: 0.6344\n",
      "Medel is training: epoch 45th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8736 - acc: 0.5599 - val_loss: 3.5167 - val_acc: 0.5181\n",
      "Medel is training: epoch 45th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9164 - acc: 0.5820 - val_loss: 3.5550 - val_acc: 0.5459\n",
      "Medel is training: epoch 45th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5671 - acc: 0.6139 - val_loss: 2.3249 - val_acc: 0.6334\n",
      "Medel is training: epoch 45th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8784 - acc: 0.5606 - val_loss: 3.7561 - val_acc: 0.4887\n",
      "Medel is training: epoch 45th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8591 - acc: 0.5900 - val_loss: 3.2661 - val_acc: 0.5754\n",
      "Medel is training: epoch 45th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6468 - acc: 0.6125 - val_loss: 2.1783 - val_acc: 0.6553\n",
      "Medel is training: epoch 45th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7244 - acc: 0.5770 - val_loss: 3.4924 - val_acc: 0.5302\n",
      "Medel is training: epoch 45th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.9538 - acc: 0.5705 - val_loss: 3.2770 - val_acc: 0.5793\n",
      "Medel is training: epoch 45th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8434 - acc: 0.5940 - val_loss: 1.9531 - val_acc: 0.6909\n",
      "Medel is training: epoch 45th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4168 - acc: 0.6150 - val_loss: 2.9758 - val_acc: 0.5831\n",
      "Medel is training: epoch 45th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0015 - acc: 0.5486 - val_loss: 3.2542 - val_acc: 0.5785\n",
      "Medel is training: epoch 45th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8935 - acc: 0.5938 - val_loss: 3.3241 - val_acc: 0.5729\n",
      "Medel is training: epoch 45th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9270 - acc: 0.6800 - val_loss: 2.9215 - val_acc: 0.5985\n",
      "Medel is training: epoch 45th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9435 - acc: 0.5538 - val_loss: 3.2782 - val_acc: 0.5676\n",
      "Medel is training: epoch 45th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8402 - acc: 0.5895 - val_loss: 3.0735 - val_acc: 0.6038\n",
      "Medel is training: epoch 45th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3728 - acc: 0.6464 - val_loss: 2.0171 - val_acc: 0.6849\n",
      "Medel is training: epoch 45th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3923 - acc: 0.6204 - val_loss: 3.0693 - val_acc: 0.5788\n",
      "Medel is training: epoch 45th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9525 - acc: 0.5523 - val_loss: 3.1017 - val_acc: 0.5950\n",
      "Medel is training: epoch 45th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8455 - acc: 0.5989 - val_loss: 3.2227 - val_acc: 0.5827\n",
      "Medel is training: epoch 45th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9190 - acc: 0.6868 - val_loss: 2.1563 - val_acc: 0.6585\n",
      "Medel is training: epoch 45th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6574 - acc: 0.5899 - val_loss: 3.5829 - val_acc: 0.5221\n",
      "Medel is training: epoch 45th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7815 - acc: 0.5899 - val_loss: 3.1571 - val_acc: 0.5976\n",
      "Medel is training: epoch 45th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7791 - acc: 0.6086 - val_loss: 2.3478 - val_acc: 0.6633\n",
      "Medel is training: epoch 45th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8562 - acc: 0.6834 - val_loss: 2.7176 - val_acc: 0.6183\n",
      "Medel is training: epoch 45th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7843 - acc: 0.5764 - val_loss: 3.5853 - val_acc: 0.5192\n",
      "Medel is training: epoch 45th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6673 - acc: 0.6099 - val_loss: 2.9868 - val_acc: 0.6252\n",
      "Medel is training: epoch 45th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8769 - acc: 0.5983 - val_loss: 2.4705 - val_acc: 0.6472\n",
      "Medel is training: epoch 45th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8148 - acc: 0.6909 - val_loss: 2.7297 - val_acc: 0.6020\n",
      "Medel is training: epoch 45th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7280 - acc: 0.5857 - val_loss: 3.8169 - val_acc: 0.5108\n",
      "Medel is training: epoch 45th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6963 - acc: 0.6083 - val_loss: 3.1160 - val_acc: 0.5989\n",
      "Medel is training: epoch 45th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7839 - acc: 0.6062 - val_loss: 1.8830 - val_acc: 0.6943\n",
      "Medel is training: epoch 45th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8595 - acc: 0.6896 - val_loss: 2.6491 - val_acc: 0.6134\n",
      "Medel is training: epoch 45th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7224 - acc: 0.5838 - val_loss: 3.4219 - val_acc: 0.5331\n",
      "Medel is training: epoch 45th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7404 - acc: 0.5943 - val_loss: 3.2824 - val_acc: 0.5905\n",
      "Medel is training: epoch 46th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2493 - acc: 0.5151 - val_loss: 3.6374 - val_acc: 0.5320\n",
      "Medel is training: epoch 46th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0890 - acc: 0.5608 - val_loss: 2.2195 - val_acc: 0.6350\n",
      "Medel is training: epoch 46th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7846 - acc: 0.5571 - val_loss: 3.5455 - val_acc: 0.5189\n",
      "Medel is training: epoch 46th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0467 - acc: 0.5626 - val_loss: 3.5298 - val_acc: 0.5496\n",
      "Medel is training: epoch 46th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6020 - acc: 0.6011 - val_loss: 3.3012 - val_acc: 0.5451\n",
      "Medel is training: epoch 46th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1809 - acc: 0.5168 - val_loss: 3.2740 - val_acc: 0.5754\n",
      "Medel is training: epoch 46th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1115 - acc: 0.5545 - val_loss: 3.5420 - val_acc: 0.5480\n",
      "Medel is training: epoch 46th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4524 - acc: 0.6030 - val_loss: 3.3895 - val_acc: 0.5375\n",
      "Medel is training: epoch 46th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1336 - acc: 0.5285 - val_loss: 3.3484 - val_acc: 0.5668\n",
      "Medel is training: epoch 46th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0065 - acc: 0.5664 - val_loss: 2.1563 - val_acc: 0.6564\n",
      "Medel is training: epoch 46th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6803 - acc: 0.5794 - val_loss: 3.7763 - val_acc: 0.4933\n",
      "Medel is training: epoch 46th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 3.0545 - acc: 0.5541 - val_loss: 3.4601 - val_acc: 0.5490\n",
      "Medel is training: epoch 46th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7766 - acc: 0.5911 - val_loss: 2.3033 - val_acc: 0.6385\n",
      "Medel is training: epoch 46th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9409 - acc: 0.5508 - val_loss: 4.1109 - val_acc: 0.4525\n",
      "Medel is training: epoch 46th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9423 - acc: 0.5775 - val_loss: 3.5025 - val_acc: 0.5562\n",
      "Medel is training: epoch 46th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5893 - acc: 0.6069 - val_loss: 2.4148 - val_acc: 0.6358\n",
      "Medel is training: epoch 46th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8627 - acc: 0.5626 - val_loss: 3.5111 - val_acc: 0.5191\n",
      "Medel is training: epoch 46th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9135 - acc: 0.5810 - val_loss: 3.5547 - val_acc: 0.5466\n",
      "Medel is training: epoch 46th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5562 - acc: 0.6154 - val_loss: 2.3171 - val_acc: 0.6386\n",
      "Medel is training: epoch 46th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8687 - acc: 0.5602 - val_loss: 3.7640 - val_acc: 0.4910\n",
      "Medel is training: epoch 46th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8412 - acc: 0.5896 - val_loss: 3.2700 - val_acc: 0.5744\n",
      "Medel is training: epoch 46th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6403 - acc: 0.6129 - val_loss: 2.1674 - val_acc: 0.6556\n",
      "Medel is training: epoch 46th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7147 - acc: 0.5758 - val_loss: 3.4956 - val_acc: 0.5292\n",
      "Medel is training: epoch 46th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9368 - acc: 0.5716 - val_loss: 3.2763 - val_acc: 0.5793\n",
      "Medel is training: epoch 46th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8364 - acc: 0.5941 - val_loss: 1.9625 - val_acc: 0.6899\n",
      "Medel is training: epoch 46th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4105 - acc: 0.6136 - val_loss: 2.9628 - val_acc: 0.5831\n",
      "Medel is training: epoch 46th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9948 - acc: 0.5488 - val_loss: 3.2472 - val_acc: 0.5821\n",
      "Medel is training: epoch 46th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8888 - acc: 0.5930 - val_loss: 3.3270 - val_acc: 0.5698\n",
      "Medel is training: epoch 46th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9207 - acc: 0.6811 - val_loss: 2.9205 - val_acc: 0.5975\n",
      "Medel is training: epoch 46th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9318 - acc: 0.5551 - val_loss: 3.2747 - val_acc: 0.5666\n",
      "Medel is training: epoch 46th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8362 - acc: 0.5891 - val_loss: 3.0706 - val_acc: 0.6026\n",
      "Medel is training: epoch 46th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3565 - acc: 0.6470 - val_loss: 2.0055 - val_acc: 0.6865\n",
      "Medel is training: epoch 46th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3883 - acc: 0.6187 - val_loss: 3.0636 - val_acc: 0.5810\n",
      "Medel is training: epoch 46th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9466 - acc: 0.5547 - val_loss: 3.0878 - val_acc: 0.5988\n",
      "Medel is training: epoch 46th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8349 - acc: 0.5988 - val_loss: 3.2132 - val_acc: 0.5839\n",
      "Medel is training: epoch 46th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9056 - acc: 0.6857 - val_loss: 2.1426 - val_acc: 0.6594\n",
      "Medel is training: epoch 46th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6443 - acc: 0.5916 - val_loss: 3.5767 - val_acc: 0.5218\n",
      "Medel is training: epoch 46th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7711 - acc: 0.5911 - val_loss: 3.1646 - val_acc: 0.5961\n",
      "Medel is training: epoch 46th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7692 - acc: 0.6091 - val_loss: 2.3406 - val_acc: 0.6679\n",
      "Medel is training: epoch 46th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8416 - acc: 0.6868 - val_loss: 2.7126 - val_acc: 0.6183\n",
      "Medel is training: epoch 46th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7762 - acc: 0.5768 - val_loss: 3.5779 - val_acc: 0.5186\n",
      "Medel is training: epoch 46th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6573 - acc: 0.6097 - val_loss: 2.9962 - val_acc: 0.6258\n",
      "Medel is training: epoch 46th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8698 - acc: 0.5978 - val_loss: 2.4687 - val_acc: 0.6476\n",
      "Medel is training: epoch 46th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8063 - acc: 0.6907 - val_loss: 2.7365 - val_acc: 0.5970\n",
      "Medel is training: epoch 46th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7237 - acc: 0.5855 - val_loss: 3.8256 - val_acc: 0.5093\n",
      "Medel is training: epoch 46th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6898 - acc: 0.6077 - val_loss: 3.1207 - val_acc: 0.5980\n",
      "Medel is training: epoch 46th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7746 - acc: 0.6066 - val_loss: 1.8764 - val_acc: 0.6949\n",
      "Medel is training: epoch 46th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8471 - acc: 0.6903 - val_loss: 2.6462 - val_acc: 0.6134\n",
      "Medel is training: epoch 46th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7033 - acc: 0.5852 - val_loss: 3.4254 - val_acc: 0.5335\n",
      "Medel is training: epoch 46th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.7323 - acc: 0.5939 - val_loss: 3.2842 - val_acc: 0.5894\n",
      "Medel is training: epoch 47th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2441 - acc: 0.5150 - val_loss: 3.6421 - val_acc: 0.5287\n",
      "Medel is training: epoch 47th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0827 - acc: 0.5618 - val_loss: 2.2021 - val_acc: 0.6369\n",
      "Medel is training: epoch 47th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7649 - acc: 0.5602 - val_loss: 3.5376 - val_acc: 0.5199\n",
      "Medel is training: epoch 47th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0362 - acc: 0.5628 - val_loss: 3.5445 - val_acc: 0.5476\n",
      "Medel is training: epoch 47th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5993 - acc: 0.6000 - val_loss: 3.2991 - val_acc: 0.5417\n",
      "Medel is training: epoch 47th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1724 - acc: 0.5171 - val_loss: 3.2753 - val_acc: 0.5741\n",
      "Medel is training: epoch 47th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1113 - acc: 0.5535 - val_loss: 3.5412 - val_acc: 0.5467\n",
      "Medel is training: epoch 47th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4375 - acc: 0.6027 - val_loss: 3.3855 - val_acc: 0.5351\n",
      "Medel is training: epoch 47th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1223 - acc: 0.5295 - val_loss: 3.3476 - val_acc: 0.5665\n",
      "Medel is training: epoch 47th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9950 - acc: 0.5668 - val_loss: 2.1571 - val_acc: 0.6589\n",
      "Medel is training: epoch 47th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6752 - acc: 0.5810 - val_loss: 3.7693 - val_acc: 0.4950\n",
      "Medel is training: epoch 47th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0404 - acc: 0.5546 - val_loss: 3.4483 - val_acc: 0.5519\n",
      "Medel is training: epoch 47th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7717 - acc: 0.5933 - val_loss: 2.3000 - val_acc: 0.6361\n",
      "Medel is training: epoch 47th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9269 - acc: 0.5499 - val_loss: 4.1003 - val_acc: 0.4519\n",
      "Medel is training: epoch 47th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9217 - acc: 0.5778 - val_loss: 3.5123 - val_acc: 0.5559\n",
      "Medel is training: epoch 47th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5839 - acc: 0.6083 - val_loss: 2.4172 - val_acc: 0.6330\n",
      "Medel is training: epoch 47th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8540 - acc: 0.5600 - val_loss: 3.5136 - val_acc: 0.5198\n",
      "Medel is training: epoch 47th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9025 - acc: 0.5817 - val_loss: 3.5656 - val_acc: 0.5478\n",
      "Medel is training: epoch 47th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5561 - acc: 0.6132 - val_loss: 2.3106 - val_acc: 0.6361\n",
      "Medel is training: epoch 47th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8592 - acc: 0.5588 - val_loss: 3.7523 - val_acc: 0.4880\n",
      "Medel is training: epoch 47th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8330 - acc: 0.5893 - val_loss: 3.2612 - val_acc: 0.5788\n",
      "Medel is training: epoch 47th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6272 - acc: 0.6136 - val_loss: 2.1575 - val_acc: 0.6559\n",
      "Medel is training: epoch 47th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6987 - acc: 0.5762 - val_loss: 3.4897 - val_acc: 0.5295\n",
      "Medel is training: epoch 47th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9314 - acc: 0.5715 - val_loss: 3.2825 - val_acc: 0.5799\n",
      "Medel is training: epoch 47th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8254 - acc: 0.5954 - val_loss: 1.9468 - val_acc: 0.6932\n",
      "Medel is training: epoch 47th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3965 - acc: 0.6153 - val_loss: 2.9648 - val_acc: 0.5818\n",
      "Medel is training: epoch 47th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9791 - acc: 0.5488 - val_loss: 3.2468 - val_acc: 0.5776\n",
      "Medel is training: epoch 47th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8809 - acc: 0.5945 - val_loss: 3.3381 - val_acc: 0.5714\n",
      "Medel is training: epoch 47th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9090 - acc: 0.6801 - val_loss: 2.9229 - val_acc: 0.5940\n",
      "Medel is training: epoch 47th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9099 - acc: 0.5550 - val_loss: 3.2868 - val_acc: 0.5673\n",
      "Medel is training: epoch 47th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8205 - acc: 0.5898 - val_loss: 3.0725 - val_acc: 0.6047\n",
      "Medel is training: epoch 47th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3543 - acc: 0.6459 - val_loss: 2.0024 - val_acc: 0.6878\n",
      "Medel is training: epoch 47th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3764 - acc: 0.6203 - val_loss: 3.0614 - val_acc: 0.5766\n",
      "Medel is training: epoch 47th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9338 - acc: 0.5540 - val_loss: 3.1034 - val_acc: 0.5941\n",
      "Medel is training: epoch 47th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8283 - acc: 0.5995 - val_loss: 3.2149 - val_acc: 0.5848\n",
      "Medel is training: epoch 47th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.9045 - acc: 0.6858 - val_loss: 2.1465 - val_acc: 0.6613\n",
      "Medel is training: epoch 47th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6392 - acc: 0.5915 - val_loss: 3.5762 - val_acc: 0.5237\n",
      "Medel is training: epoch 47th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.7613 - acc: 0.5905 - val_loss: 3.1622 - val_acc: 0.5982\n",
      "Medel is training: epoch 47th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7633 - acc: 0.6091 - val_loss: 2.3363 - val_acc: 0.6682\n",
      "Medel is training: epoch 47th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8332 - acc: 0.6860 - val_loss: 2.7043 - val_acc: 0.6174\n",
      "Medel is training: epoch 47th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7631 - acc: 0.5766 - val_loss: 3.5592 - val_acc: 0.5168\n",
      "Medel is training: epoch 47th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6515 - acc: 0.6098 - val_loss: 2.9898 - val_acc: 0.6244\n",
      "Medel is training: epoch 47th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8547 - acc: 0.5978 - val_loss: 2.4562 - val_acc: 0.6476\n",
      "Medel is training: epoch 47th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7878 - acc: 0.6932 - val_loss: 2.7340 - val_acc: 0.5989\n",
      "Medel is training: epoch 47th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7068 - acc: 0.5867 - val_loss: 3.8247 - val_acc: 0.5111\n",
      "Medel is training: epoch 47th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6861 - acc: 0.6080 - val_loss: 3.1227 - val_acc: 0.5986\n",
      "Medel is training: epoch 47th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7688 - acc: 0.6076 - val_loss: 1.8704 - val_acc: 0.6992\n",
      "Medel is training: epoch 47th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8393 - acc: 0.6901 - val_loss: 2.6404 - val_acc: 0.6140\n",
      "Medel is training: epoch 47th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6932 - acc: 0.5864 - val_loss: 3.4175 - val_acc: 0.5337\n",
      "Medel is training: epoch 47th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7188 - acc: 0.5965 - val_loss: 3.2740 - val_acc: 0.5911\n",
      "Medel is training: epoch 48th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2242 - acc: 0.5168 - val_loss: 3.6380 - val_acc: 0.5283\n",
      "Medel is training: epoch 48th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0688 - acc: 0.5620 - val_loss: 2.2019 - val_acc: 0.6376\n",
      "Medel is training: epoch 48th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7537 - acc: 0.5587 - val_loss: 3.5461 - val_acc: 0.5189\n",
      "Medel is training: epoch 48th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0241 - acc: 0.5627 - val_loss: 3.5401 - val_acc: 0.5476\n",
      "Medel is training: epoch 48th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5875 - acc: 0.6016 - val_loss: 3.2962 - val_acc: 0.5410\n",
      "Medel is training: epoch 48th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1588 - acc: 0.5163 - val_loss: 3.2734 - val_acc: 0.5758\n",
      "Medel is training: epoch 48th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0934 - acc: 0.5543 - val_loss: 3.5477 - val_acc: 0.5477\n",
      "Medel is training: epoch 48th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4256 - acc: 0.6043 - val_loss: 3.3939 - val_acc: 0.5324\n",
      "Medel is training: epoch 48th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1073 - acc: 0.5296 - val_loss: 3.3585 - val_acc: 0.5658\n",
      "Medel is training: epoch 48th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9875 - acc: 0.5674 - val_loss: 2.1545 - val_acc: 0.6596\n",
      "Medel is training: epoch 48th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6559 - acc: 0.5804 - val_loss: 3.7764 - val_acc: 0.4957\n",
      "Medel is training: epoch 48th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0348 - acc: 0.5562 - val_loss: 3.4475 - val_acc: 0.5523\n",
      "Medel is training: epoch 48th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7588 - acc: 0.5928 - val_loss: 2.3016 - val_acc: 0.6385\n",
      "Medel is training: epoch 48th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9186 - acc: 0.5522 - val_loss: 4.1000 - val_acc: 0.4509\n",
      "Medel is training: epoch 48th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9175 - acc: 0.5779 - val_loss: 3.5077 - val_acc: 0.5552\n",
      "Medel is training: epoch 48th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5719 - acc: 0.6081 - val_loss: 2.4142 - val_acc: 0.6337\n",
      "Medel is training: epoch 48th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8352 - acc: 0.5612 - val_loss: 3.5132 - val_acc: 0.5175\n",
      "Medel is training: epoch 48th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9037 - acc: 0.5805 - val_loss: 3.5741 - val_acc: 0.5450\n",
      "Medel is training: epoch 48th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5427 - acc: 0.6145 - val_loss: 2.3042 - val_acc: 0.6351\n",
      "Medel is training: epoch 48th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8380 - acc: 0.5643 - val_loss: 3.7471 - val_acc: 0.4887\n",
      "Medel is training: epoch 48th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8315 - acc: 0.5905 - val_loss: 3.2696 - val_acc: 0.5772\n",
      "Medel is training: epoch 48th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6208 - acc: 0.6138 - val_loss: 2.1553 - val_acc: 0.6553\n",
      "Medel is training: epoch 48th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6889 - acc: 0.5778 - val_loss: 3.4869 - val_acc: 0.5295\n",
      "Medel is training: epoch 48th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9240 - acc: 0.5712 - val_loss: 3.2807 - val_acc: 0.5787\n",
      "Medel is training: epoch 48th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8210 - acc: 0.5944 - val_loss: 1.9480 - val_acc: 0.6909\n",
      "Medel is training: epoch 48th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.3813 - acc: 0.6161 - val_loss: 2.9677 - val_acc: 0.5840\n",
      "Medel is training: epoch 48th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9659 - acc: 0.5503 - val_loss: 3.2470 - val_acc: 0.5788\n",
      "Medel is training: epoch 48th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8699 - acc: 0.5947 - val_loss: 3.3309 - val_acc: 0.5720\n",
      "Medel is training: epoch 48th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8964 - acc: 0.6826 - val_loss: 2.9090 - val_acc: 0.5962\n",
      "Medel is training: epoch 48th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9050 - acc: 0.5557 - val_loss: 3.2832 - val_acc: 0.5688\n",
      "Medel is training: epoch 48th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8202 - acc: 0.5903 - val_loss: 3.0745 - val_acc: 0.6012\n",
      "Medel is training: epoch 48th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3385 - acc: 0.6472 - val_loss: 2.0008 - val_acc: 0.6856\n",
      "Medel is training: epoch 48th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3698 - acc: 0.6191 - val_loss: 3.0587 - val_acc: 0.5797\n",
      "Medel is training: epoch 48th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9263 - acc: 0.5539 - val_loss: 3.1014 - val_acc: 0.5947\n",
      "Medel is training: epoch 48th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8160 - acc: 0.5996 - val_loss: 3.2153 - val_acc: 0.5836\n",
      "Medel is training: epoch 48th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8938 - acc: 0.6859 - val_loss: 2.1428 - val_acc: 0.6620\n",
      "Medel is training: epoch 48th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6263 - acc: 0.5927 - val_loss: 3.5853 - val_acc: 0.5250\n",
      "Medel is training: epoch 48th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7507 - acc: 0.5910 - val_loss: 3.1631 - val_acc: 0.5985\n",
      "Medel is training: epoch 48th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7640 - acc: 0.6091 - val_loss: 2.3407 - val_acc: 0.6682\n",
      "Medel is training: epoch 48th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8240 - acc: 0.6883 - val_loss: 2.7042 - val_acc: 0.6168\n",
      "Medel is training: epoch 48th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7479 - acc: 0.5771 - val_loss: 3.5644 - val_acc: 0.5171\n",
      "Medel is training: epoch 48th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6486 - acc: 0.6104 - val_loss: 2.9911 - val_acc: 0.6261\n",
      "Medel is training: epoch 48th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8460 - acc: 0.5990 - val_loss: 2.4632 - val_acc: 0.6470\n",
      "Medel is training: epoch 48th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7866 - acc: 0.6925 - val_loss: 2.7335 - val_acc: 0.5985\n",
      "Medel is training: epoch 48th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7029 - acc: 0.5851 - val_loss: 3.8276 - val_acc: 0.5105\n",
      "Medel is training: epoch 48th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6719 - acc: 0.6073 - val_loss: 3.1132 - val_acc: 0.6004\n",
      "Medel is training: epoch 48th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7612 - acc: 0.6068 - val_loss: 1.8655 - val_acc: 0.6968\n",
      "Medel is training: epoch 48th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8315 - acc: 0.6920 - val_loss: 2.6409 - val_acc: 0.6130\n",
      "Medel is training: epoch 48th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6841 - acc: 0.5866 - val_loss: 3.4147 - val_acc: 0.5328\n",
      "Medel is training: epoch 48th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7064 - acc: 0.5949 - val_loss: 3.2795 - val_acc: 0.5922\n",
      "Medel is training: epoch 49th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.2063 - acc: 0.5173 - val_loss: 3.6427 - val_acc: 0.5267\n",
      "Medel is training: epoch 49th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0648 - acc: 0.5605 - val_loss: 2.1978 - val_acc: 0.6332\n",
      "Medel is training: epoch 49th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7401 - acc: 0.5606 - val_loss: 3.5437 - val_acc: 0.5172\n",
      "Medel is training: epoch 49th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0095 - acc: 0.5647 - val_loss: 3.5440 - val_acc: 0.5486\n",
      "Medel is training: epoch 49th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5747 - acc: 0.6005 - val_loss: 3.2877 - val_acc: 0.5455\n",
      "Medel is training: epoch 49th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1433 - acc: 0.5177 - val_loss: 3.2886 - val_acc: 0.5672\n",
      "Medel is training: epoch 49th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0900 - acc: 0.5545 - val_loss: 3.5476 - val_acc: 0.5480\n",
      "Medel is training: epoch 49th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4156 - acc: 0.6042 - val_loss: 3.3879 - val_acc: 0.5351\n",
      "Medel is training: epoch 49th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1018 - acc: 0.5287 - val_loss: 3.3541 - val_acc: 0.5652\n",
      "Medel is training: epoch 49th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9804 - acc: 0.5672 - val_loss: 2.1454 - val_acc: 0.6593\n",
      "Medel is training: epoch 49th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6462 - acc: 0.5817 - val_loss: 3.7803 - val_acc: 0.4930\n",
      "Medel is training: epoch 49th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0162 - acc: 0.5545 - val_loss: 3.4661 - val_acc: 0.5484\n",
      "Medel is training: epoch 49th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7510 - acc: 0.5928 - val_loss: 2.2909 - val_acc: 0.6357\n",
      "Medel is training: epoch 49th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.9028 - acc: 0.5519 - val_loss: 4.0981 - val_acc: 0.4529\n",
      "Medel is training: epoch 49th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9032 - acc: 0.5782 - val_loss: 3.5197 - val_acc: 0.5543\n",
      "Medel is training: epoch 49th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5593 - acc: 0.6087 - val_loss: 2.4083 - val_acc: 0.6333\n",
      "Medel is training: epoch 49th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8308 - acc: 0.5605 - val_loss: 3.5065 - val_acc: 0.5178\n",
      "Medel is training: epoch 49th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8874 - acc: 0.5816 - val_loss: 3.5675 - val_acc: 0.5437\n",
      "Medel is training: epoch 49th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5295 - acc: 0.6152 - val_loss: 2.2958 - val_acc: 0.6382\n",
      "Medel is training: epoch 49th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8316 - acc: 0.5642 - val_loss: 3.7420 - val_acc: 0.4897\n",
      "Medel is training: epoch 49th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8159 - acc: 0.5902 - val_loss: 3.2747 - val_acc: 0.5747\n",
      "Medel is training: epoch 49th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6121 - acc: 0.6147 - val_loss: 2.1488 - val_acc: 0.6582\n",
      "Medel is training: epoch 49th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6806 - acc: 0.5780 - val_loss: 3.4996 - val_acc: 0.5289\n",
      "Medel is training: epoch 49th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9083 - acc: 0.5724 - val_loss: 3.2828 - val_acc: 0.5793\n",
      "Medel is training: epoch 49th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8054 - acc: 0.5946 - val_loss: 1.9268 - val_acc: 0.6969\n",
      "Medel is training: epoch 49th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3723 - acc: 0.6155 - val_loss: 2.9651 - val_acc: 0.5834\n",
      "Medel is training: epoch 49th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9647 - acc: 0.5499 - val_loss: 3.2463 - val_acc: 0.5782\n",
      "Medel is training: epoch 49th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8617 - acc: 0.5943 - val_loss: 3.3314 - val_acc: 0.5717\n",
      "Medel is training: epoch 49th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8897 - acc: 0.6828 - val_loss: 2.9109 - val_acc: 0.5934\n",
      "Medel is training: epoch 49th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8839 - acc: 0.5573 - val_loss: 3.2797 - val_acc: 0.5685\n",
      "Medel is training: epoch 49th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8092 - acc: 0.5904 - val_loss: 3.0677 - val_acc: 0.6053\n",
      "Medel is training: epoch 49th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3306 - acc: 0.6463 - val_loss: 1.9978 - val_acc: 0.6846\n",
      "Medel is training: epoch 49th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3566 - acc: 0.6212 - val_loss: 3.0545 - val_acc: 0.5738\n",
      "Medel is training: epoch 49th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9048 - acc: 0.5548 - val_loss: 3.1072 - val_acc: 0.5944\n",
      "Medel is training: epoch 49th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8099 - acc: 0.6002 - val_loss: 3.2186 - val_acc: 0.5818\n",
      "Medel is training: epoch 49th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8834 - acc: 0.6880 - val_loss: 2.1349 - val_acc: 0.6629\n",
      "Medel is training: epoch 49th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6163 - acc: 0.5926 - val_loss: 3.5783 - val_acc: 0.5237\n",
      "Medel is training: epoch 49th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7474 - acc: 0.5918 - val_loss: 3.1622 - val_acc: 0.5946\n",
      "Medel is training: epoch 49th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7598 - acc: 0.6082 - val_loss: 2.3441 - val_acc: 0.6679\n",
      "Medel is training: epoch 49th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8170 - acc: 0.6871 - val_loss: 2.7101 - val_acc: 0.6174\n",
      "Medel is training: epoch 49th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7427 - acc: 0.5780 - val_loss: 3.5673 - val_acc: 0.5171\n",
      "Medel is training: epoch 49th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6316 - acc: 0.6099 - val_loss: 3.0026 - val_acc: 0.6246\n",
      "Medel is training: epoch 49th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8376 - acc: 0.5981 - val_loss: 2.4691 - val_acc: 0.6473\n",
      "Medel is training: epoch 49th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7739 - acc: 0.6947 - val_loss: 2.7231 - val_acc: 0.6010\n",
      "Medel is training: epoch 49th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6854 - acc: 0.5875 - val_loss: 3.8161 - val_acc: 0.5114\n",
      "Medel is training: epoch 49th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6654 - acc: 0.6077 - val_loss: 3.1214 - val_acc: 0.5972\n",
      "Medel is training: epoch 49th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7596 - acc: 0.6068 - val_loss: 1.8606 - val_acc: 0.6986\n",
      "Medel is training: epoch 49th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8218 - acc: 0.6925 - val_loss: 2.6427 - val_acc: 0.6109\n",
      "Medel is training: epoch 49th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6759 - acc: 0.5861 - val_loss: 3.4212 - val_acc: 0.5295\n",
      "Medel is training: epoch 49th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6941 - acc: 0.5963 - val_loss: 3.2776 - val_acc: 0.5911\n",
      "Medel is training: epoch 50th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1959 - acc: 0.5164 - val_loss: 3.6527 - val_acc: 0.5223\n",
      "Medel is training: epoch 50th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 3.0629 - acc: 0.5611 - val_loss: 2.1951 - val_acc: 0.6354\n",
      "Medel is training: epoch 50th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7395 - acc: 0.5592 - val_loss: 3.5553 - val_acc: 0.5223\n",
      "Medel is training: epoch 50th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0082 - acc: 0.5635 - val_loss: 3.5432 - val_acc: 0.5456\n",
      "Medel is training: epoch 50th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5745 - acc: 0.6018 - val_loss: 3.3001 - val_acc: 0.5417\n",
      "Medel is training: epoch 50th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1287 - acc: 0.5175 - val_loss: 3.2719 - val_acc: 0.5778\n",
      "Medel is training: epoch 50th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0859 - acc: 0.5535 - val_loss: 3.5554 - val_acc: 0.5460\n",
      "Medel is training: epoch 50th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4128 - acc: 0.6055 - val_loss: 3.3874 - val_acc: 0.5303\n",
      "Medel is training: epoch 50th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0877 - acc: 0.5298 - val_loss: 3.3575 - val_acc: 0.5632\n",
      "Medel is training: epoch 50th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9648 - acc: 0.5664 - val_loss: 2.1364 - val_acc: 0.6631\n",
      "Medel is training: epoch 50th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6320 - acc: 0.5821 - val_loss: 3.7782 - val_acc: 0.4899\n",
      "Medel is training: epoch 50th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0131 - acc: 0.5544 - val_loss: 3.4603 - val_acc: 0.5493\n",
      "Medel is training: epoch 50th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7437 - acc: 0.5940 - val_loss: 2.2832 - val_acc: 0.6392\n",
      "Medel is training: epoch 50th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8919 - acc: 0.5519 - val_loss: 4.0906 - val_acc: 0.4498\n",
      "Medel is training: epoch 50th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9003 - acc: 0.5788 - val_loss: 3.5188 - val_acc: 0.5556\n",
      "Medel is training: epoch 50th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5588 - acc: 0.6084 - val_loss: 2.4065 - val_acc: 0.6371\n",
      "Medel is training: epoch 50th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8078 - acc: 0.5620 - val_loss: 3.5002 - val_acc: 0.5194\n",
      "Medel is training: epoch 50th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8833 - acc: 0.5819 - val_loss: 3.5533 - val_acc: 0.5447\n",
      "Medel is training: epoch 50th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5235 - acc: 0.6171 - val_loss: 2.2889 - val_acc: 0.6396\n",
      "Medel is training: epoch 50th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8148 - acc: 0.5626 - val_loss: 3.7525 - val_acc: 0.4900\n",
      "Medel is training: epoch 50th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8080 - acc: 0.5896 - val_loss: 3.2701 - val_acc: 0.5747\n",
      "Medel is training: epoch 50th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5997 - acc: 0.6143 - val_loss: 2.1410 - val_acc: 0.6585\n",
      "Medel is training: epoch 50th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6754 - acc: 0.5781 - val_loss: 3.4977 - val_acc: 0.5305\n",
      "Medel is training: epoch 50th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9000 - acc: 0.5715 - val_loss: 3.2829 - val_acc: 0.5796\n",
      "Medel is training: epoch 50th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8059 - acc: 0.5948 - val_loss: 1.9329 - val_acc: 0.6922\n",
      "Medel is training: epoch 50th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3634 - acc: 0.6167 - val_loss: 2.9561 - val_acc: 0.5827\n",
      "Medel is training: epoch 50th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9497 - acc: 0.5495 - val_loss: 3.2634 - val_acc: 0.5730\n",
      "Medel is training: epoch 50th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8554 - acc: 0.5940 - val_loss: 3.3424 - val_acc: 0.5714\n",
      "Medel is training: epoch 50th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8797 - acc: 0.6815 - val_loss: 2.9056 - val_acc: 0.5953\n",
      "Medel is training: epoch 50th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8878 - acc: 0.5561 - val_loss: 3.2795 - val_acc: 0.5635\n",
      "Medel is training: epoch 50th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7982 - acc: 0.5904 - val_loss: 3.0754 - val_acc: 0.6015\n",
      "Medel is training: epoch 50th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3296 - acc: 0.6474 - val_loss: 1.9937 - val_acc: 0.6891\n",
      "Medel is training: epoch 50th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3515 - acc: 0.6197 - val_loss: 3.0605 - val_acc: 0.5779\n",
      "Medel is training: epoch 50th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9040 - acc: 0.5539 - val_loss: 3.1177 - val_acc: 0.5914\n",
      "Medel is training: epoch 50th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8042 - acc: 0.5989 - val_loss: 3.2189 - val_acc: 0.5821\n",
      "Medel is training: epoch 50th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8780 - acc: 0.6868 - val_loss: 2.1314 - val_acc: 0.6629\n",
      "Medel is training: epoch 50th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6067 - acc: 0.5925 - val_loss: 3.5793 - val_acc: 0.5228\n",
      "Medel is training: epoch 50th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7294 - acc: 0.5911 - val_loss: 3.1695 - val_acc: 0.5952\n",
      "Medel is training: epoch 50th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7439 - acc: 0.6097 - val_loss: 2.3400 - val_acc: 0.6636\n",
      "Medel is training: epoch 50th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.8192 - acc: 0.6879 - val_loss: 2.6959 - val_acc: 0.6183\n",
      "Medel is training: epoch 50th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7377 - acc: 0.5768 - val_loss: 3.5730 - val_acc: 0.5180\n",
      "Medel is training: epoch 50th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6206 - acc: 0.6113 - val_loss: 3.0005 - val_acc: 0.6258\n",
      "Medel is training: epoch 50th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8324 - acc: 0.5990 - val_loss: 2.4675 - val_acc: 0.6488\n",
      "Medel is training: epoch 50th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7679 - acc: 0.6943 - val_loss: 2.7271 - val_acc: 0.5964\n",
      "Medel is training: epoch 50th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6839 - acc: 0.5873 - val_loss: 3.8138 - val_acc: 0.5096\n",
      "Medel is training: epoch 50th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6589 - acc: 0.6082 - val_loss: 3.1144 - val_acc: 0.5989\n",
      "Medel is training: epoch 50th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7480 - acc: 0.6070 - val_loss: 1.8609 - val_acc: 0.6943\n",
      "Medel is training: epoch 50th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8147 - acc: 0.6914 - val_loss: 2.6435 - val_acc: 0.6100\n",
      "Medel is training: epoch 50th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6703 - acc: 0.5857 - val_loss: 3.4232 - val_acc: 0.5304\n",
      "Medel is training: epoch 50th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6843 - acc: 0.5958 - val_loss: 3.2885 - val_acc: 0.5891\n",
      "Medel is training: epoch 51th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1886 - acc: 0.5171 - val_loss: 3.6425 - val_acc: 0.5246\n",
      "Medel is training: epoch 51th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0465 - acc: 0.5614 - val_loss: 2.1948 - val_acc: 0.6339\n",
      "Medel is training: epoch 51th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7196 - acc: 0.5630 - val_loss: 3.5437 - val_acc: 0.5213\n",
      "Medel is training: epoch 51th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9977 - acc: 0.5642 - val_loss: 3.5488 - val_acc: 0.5473\n",
      "Medel is training: epoch 51th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5604 - acc: 0.6027 - val_loss: 3.2985 - val_acc: 0.5414\n",
      "Medel is training: epoch 51th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1223 - acc: 0.5185 - val_loss: 3.2813 - val_acc: 0.5725\n",
      "Medel is training: epoch 51th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0719 - acc: 0.5552 - val_loss: 3.5546 - val_acc: 0.5453\n",
      "Medel is training: epoch 51th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3949 - acc: 0.6072 - val_loss: 3.3801 - val_acc: 0.5293\n",
      "Medel is training: epoch 51th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0714 - acc: 0.5313 - val_loss: 3.3578 - val_acc: 0.5622\n",
      "Medel is training: epoch 51th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9575 - acc: 0.5684 - val_loss: 2.1375 - val_acc: 0.6617\n",
      "Medel is training: epoch 51th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6203 - acc: 0.5816 - val_loss: 3.7772 - val_acc: 0.4927\n",
      "Medel is training: epoch 51th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9968 - acc: 0.5568 - val_loss: 3.4641 - val_acc: 0.5503\n",
      "Medel is training: epoch 51th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7340 - acc: 0.5955 - val_loss: 2.2799 - val_acc: 0.6371\n",
      "Medel is training: epoch 51th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8771 - acc: 0.5527 - val_loss: 4.1002 - val_acc: 0.4492\n",
      "Medel is training: epoch 51th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8921 - acc: 0.5777 - val_loss: 3.5135 - val_acc: 0.5571\n",
      "Medel is training: epoch 51th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5463 - acc: 0.6096 - val_loss: 2.4024 - val_acc: 0.6350\n",
      "Medel is training: epoch 51th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8051 - acc: 0.5633 - val_loss: 3.5043 - val_acc: 0.5185\n",
      "Medel is training: epoch 51th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8693 - acc: 0.5828 - val_loss: 3.5651 - val_acc: 0.5428\n",
      "Medel is training: epoch 51th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5072 - acc: 0.6168 - val_loss: 2.2854 - val_acc: 0.6379\n",
      "Medel is training: epoch 51th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8107 - acc: 0.5636 - val_loss: 3.7580 - val_acc: 0.4884\n",
      "Medel is training: epoch 51th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7968 - acc: 0.5907 - val_loss: 3.2766 - val_acc: 0.5757\n",
      "Medel is training: epoch 51th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5977 - acc: 0.6132 - val_loss: 2.1402 - val_acc: 0.6556\n",
      "Medel is training: epoch 51th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6565 - acc: 0.5790 - val_loss: 3.5002 - val_acc: 0.5311\n",
      "Medel is training: epoch 51th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8922 - acc: 0.5712 - val_loss: 3.2848 - val_acc: 0.5772\n",
      "Medel is training: epoch 51th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7933 - acc: 0.5961 - val_loss: 1.9279 - val_acc: 0.6946\n",
      "Medel is training: epoch 51th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3551 - acc: 0.6166 - val_loss: 2.9582 - val_acc: 0.5840\n",
      "Medel is training: epoch 51th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9332 - acc: 0.5512 - val_loss: 3.2621 - val_acc: 0.5721\n",
      "Medel is training: epoch 51th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.8478 - acc: 0.5951 - val_loss: 3.3411 - val_acc: 0.5704\n",
      "Medel is training: epoch 51th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8746 - acc: 0.6806 - val_loss: 2.9059 - val_acc: 0.5978\n",
      "Medel is training: epoch 51th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8727 - acc: 0.5566 - val_loss: 3.2787 - val_acc: 0.5673\n",
      "Medel is training: epoch 51th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7923 - acc: 0.5906 - val_loss: 3.0848 - val_acc: 0.6003\n",
      "Medel is training: epoch 51th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3124 - acc: 0.6492 - val_loss: 1.9793 - val_acc: 0.6888\n",
      "Medel is training: epoch 51th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3445 - acc: 0.6202 - val_loss: 3.0556 - val_acc: 0.5791\n",
      "Medel is training: epoch 51th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8986 - acc: 0.5550 - val_loss: 3.1064 - val_acc: 0.5956\n",
      "Medel is training: epoch 51th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7973 - acc: 0.6002 - val_loss: 3.2236 - val_acc: 0.5824\n",
      "Medel is training: epoch 51th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8666 - acc: 0.6894 - val_loss: 2.1275 - val_acc: 0.6620\n",
      "Medel is training: epoch 51th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5933 - acc: 0.5934 - val_loss: 3.5700 - val_acc: 0.5228\n",
      "Medel is training: epoch 51th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7190 - acc: 0.5915 - val_loss: 3.1671 - val_acc: 0.5970\n",
      "Medel is training: epoch 51th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7446 - acc: 0.6089 - val_loss: 2.3368 - val_acc: 0.6694\n",
      "Medel is training: epoch 51th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7979 - acc: 0.6887 - val_loss: 2.6926 - val_acc: 0.6183\n",
      "Medel is training: epoch 51th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7190 - acc: 0.5779 - val_loss: 3.5690 - val_acc: 0.5189\n",
      "Medel is training: epoch 51th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6128 - acc: 0.6105 - val_loss: 3.0044 - val_acc: 0.6246\n",
      "Medel is training: epoch 51th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8270 - acc: 0.5984 - val_loss: 2.4579 - val_acc: 0.6500\n",
      "Medel is training: epoch 51th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7569 - acc: 0.6945 - val_loss: 2.7280 - val_acc: 0.5948\n",
      "Medel is training: epoch 51th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6665 - acc: 0.5885 - val_loss: 3.8164 - val_acc: 0.5108\n",
      "Medel is training: epoch 51th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6533 - acc: 0.6084 - val_loss: 3.1186 - val_acc: 0.5975\n",
      "Medel is training: epoch 51th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7482 - acc: 0.6066 - val_loss: 1.8589 - val_acc: 0.7010\n",
      "Medel is training: epoch 51th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8075 - acc: 0.6939 - val_loss: 2.6335 - val_acc: 0.6137\n",
      "Medel is training: epoch 51th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6442 - acc: 0.5879 - val_loss: 3.4111 - val_acc: 0.5301\n",
      "Medel is training: epoch 51th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6803 - acc: 0.5947 - val_loss: 3.2934 - val_acc: 0.5891\n",
      "Medel is training: epoch 52th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1685 - acc: 0.5180 - val_loss: 3.6499 - val_acc: 0.5230\n",
      "Medel is training: epoch 52th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0357 - acc: 0.5628 - val_loss: 2.1763 - val_acc: 0.6398\n",
      "Medel is training: epoch 52th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7059 - acc: 0.5625 - val_loss: 3.5438 - val_acc: 0.5210\n",
      "Medel is training: epoch 52th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9830 - acc: 0.5640 - val_loss: 3.5457 - val_acc: 0.5486\n",
      "Medel is training: epoch 52th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5491 - acc: 0.6026 - val_loss: 3.2951 - val_acc: 0.5400\n",
      "Medel is training: epoch 52th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1112 - acc: 0.5200 - val_loss: 3.2960 - val_acc: 0.5699\n",
      "Medel is training: epoch 52th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0565 - acc: 0.5548 - val_loss: 3.5558 - val_acc: 0.5473\n",
      "Medel is training: epoch 52th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3779 - acc: 0.6063 - val_loss: 3.3827 - val_acc: 0.5330\n",
      "Medel is training: epoch 52th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0629 - acc: 0.5310 - val_loss: 3.3696 - val_acc: 0.5593\n",
      "Medel is training: epoch 52th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9560 - acc: 0.5678 - val_loss: 2.1342 - val_acc: 0.6600\n",
      "Medel is training: epoch 52th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6114 - acc: 0.5862 - val_loss: 3.7803 - val_acc: 0.4927\n",
      "Medel is training: epoch 52th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9920 - acc: 0.5566 - val_loss: 3.4676 - val_acc: 0.5448\n",
      "Medel is training: epoch 52th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7203 - acc: 0.5945 - val_loss: 2.2771 - val_acc: 0.6375\n",
      "Medel is training: epoch 52th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8746 - acc: 0.5553 - val_loss: 4.0998 - val_acc: 0.4498\n",
      "Medel is training: epoch 52th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8814 - acc: 0.5775 - val_loss: 3.5318 - val_acc: 0.5536\n",
      "Medel is training: epoch 52th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.5392 - acc: 0.6106 - val_loss: 2.3960 - val_acc: 0.6385\n",
      "Medel is training: epoch 52th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7983 - acc: 0.5611 - val_loss: 3.5025 - val_acc: 0.5227\n",
      "Medel is training: epoch 52th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8541 - acc: 0.5833 - val_loss: 3.5626 - val_acc: 0.5447\n",
      "Medel is training: epoch 52th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5052 - acc: 0.6169 - val_loss: 2.2764 - val_acc: 0.6375\n",
      "Medel is training: epoch 52th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7993 - acc: 0.5644 - val_loss: 3.7520 - val_acc: 0.4906\n",
      "Medel is training: epoch 52th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7844 - acc: 0.5917 - val_loss: 3.2769 - val_acc: 0.5750\n",
      "Medel is training: epoch 52th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5799 - acc: 0.6154 - val_loss: 2.1325 - val_acc: 0.6569\n",
      "Medel is training: epoch 52th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6425 - acc: 0.5793 - val_loss: 3.5037 - val_acc: 0.5298\n",
      "Medel is training: epoch 52th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8847 - acc: 0.5711 - val_loss: 3.2909 - val_acc: 0.5753\n",
      "Medel is training: epoch 52th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7928 - acc: 0.5954 - val_loss: 1.9370 - val_acc: 0.6889\n",
      "Medel is training: epoch 52th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3446 - acc: 0.6188 - val_loss: 2.9527 - val_acc: 0.5834\n",
      "Medel is training: epoch 52th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9222 - acc: 0.5495 - val_loss: 3.2505 - val_acc: 0.5760\n",
      "Medel is training: epoch 52th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8375 - acc: 0.5932 - val_loss: 3.3377 - val_acc: 0.5717\n",
      "Medel is training: epoch 52th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8578 - acc: 0.6838 - val_loss: 2.8992 - val_acc: 0.5956\n",
      "Medel is training: epoch 52th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8595 - acc: 0.5591 - val_loss: 3.2711 - val_acc: 0.5654\n",
      "Medel is training: epoch 52th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7865 - acc: 0.5903 - val_loss: 3.0783 - val_acc: 0.6026\n",
      "Medel is training: epoch 52th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3003 - acc: 0.6474 - val_loss: 1.9804 - val_acc: 0.6872\n",
      "800/800 [==============================] - 9s - loss: 1.7542 - acc: 0.6940 - val_loss: 2.7222 - val_acc: 0.5976\n",
      "Medel is training: epoch 52th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6589 - acc: 0.5876 - val_loss: 3.8104 - val_acc: 0.5084\n",
      "Medel is training: epoch 52th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6363 - acc: 0.6085 - val_loss: 3.1209 - val_acc: 0.5966\n",
      "Medel is training: epoch 52th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7431 - acc: 0.6065 - val_loss: 1.8508 - val_acc: 0.6992\n",
      "Medel is training: epoch 52th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7981 - acc: 0.6924 - val_loss: 2.6427 - val_acc: 0.6112\n",
      "Medel is training: epoch 52th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6422 - acc: 0.5865 - val_loss: 3.4144 - val_acc: 0.5317\n",
      "Medel is training: epoch 52th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6768 - acc: 0.5960 - val_loss: 3.2937 - val_acc: 0.5888\n",
      "Medel is training: epoch 53th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1696 - acc: 0.5175 - val_loss: 3.6595 - val_acc: 0.5196\n",
      "Medel is training: epoch 53th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0311 - acc: 0.5621 - val_loss: 2.1850 - val_acc: 0.6376\n",
      "Medel is training: epoch 53th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6934 - acc: 0.5642 - val_loss: 3.5372 - val_acc: 0.5221\n",
      "Medel is training: epoch 53th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9851 - acc: 0.5636 - val_loss: 3.5538 - val_acc: 0.5475\n",
      "Medel is training: epoch 53th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5390 - acc: 0.6060 - val_loss: 3.2874 - val_acc: 0.5434\n",
      "Medel is training: epoch 53th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1004 - acc: 0.5204 - val_loss: 3.2913 - val_acc: 0.5742\n",
      "Medel is training: epoch 53th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0565 - acc: 0.5563 - val_loss: 3.5519 - val_acc: 0.5460\n",
      "Medel is training: epoch 53th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3741 - acc: 0.6067 - val_loss: 3.3784 - val_acc: 0.5307\n",
      "Medel is training: epoch 53th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0568 - acc: 0.5324 - val_loss: 3.3572 - val_acc: 0.5626\n",
      "Medel is training: epoch 53th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9456 - acc: 0.5675 - val_loss: 2.1255 - val_acc: 0.6628\n",
      "Medel is training: epoch 53th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6032 - acc: 0.5846 - val_loss: 3.7640 - val_acc: 0.4920\n",
      "Medel is training: epoch 53th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9725 - acc: 0.5562 - val_loss: 3.4657 - val_acc: 0.5480\n",
      "Medel is training: epoch 53th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7106 - acc: 0.5945 - val_loss: 2.2701 - val_acc: 0.6368\n",
      "Medel is training: epoch 53th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8577 - acc: 0.5536 - val_loss: 4.0996 - val_acc: 0.4519\n",
      "Medel is training: epoch 53th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8690 - acc: 0.5789 - val_loss: 3.5384 - val_acc: 0.5546\n",
      "Medel is training: epoch 53th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5245 - acc: 0.6110 - val_loss: 2.3942 - val_acc: 0.6361\n",
      "Medel is training: epoch 53th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7887 - acc: 0.5619 - val_loss: 3.5003 - val_acc: 0.5201\n",
      "Medel is training: epoch 53th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8566 - acc: 0.5814 - val_loss: 3.5568 - val_acc: 0.5453\n",
      "Medel is training: epoch 53th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4938 - acc: 0.6181 - val_loss: 2.2711 - val_acc: 0.6372\n",
      "Medel is training: epoch 53th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7861 - acc: 0.5648 - val_loss: 3.7488 - val_acc: 0.4897\n",
      "Medel is training: epoch 53th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7854 - acc: 0.5905 - val_loss: 3.2850 - val_acc: 0.5725\n",
      "Medel is training: epoch 53th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5835 - acc: 0.6146 - val_loss: 2.1253 - val_acc: 0.6573\n",
      "Medel is training: epoch 53th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6369 - acc: 0.5779 - val_loss: 3.4943 - val_acc: 0.5314\n",
      "Medel is training: epoch 53th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8733 - acc: 0.5719 - val_loss: 3.2918 - val_acc: 0.5796\n",
      "Medel is training: epoch 53th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7796 - acc: 0.5947 - val_loss: 1.9223 - val_acc: 0.6962\n",
      "Medel is training: epoch 53th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3311 - acc: 0.6187 - val_loss: 2.9513 - val_acc: 0.5872\n",
      "Medel is training: epoch 53th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9106 - acc: 0.5518 - val_loss: 3.2463 - val_acc: 0.5766\n",
      "Medel is training: epoch 53th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8316 - acc: 0.5941 - val_loss: 3.3462 - val_acc: 0.5683\n",
      "Medel is training: epoch 53th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8549 - acc: 0.6849 - val_loss: 2.9028 - val_acc: 0.5959\n",
      "Medel is training: epoch 53th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8446 - acc: 0.5574 - val_loss: 3.2802 - val_acc: 0.5663\n",
      "Medel is training: epoch 53th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7754 - acc: 0.5915 - val_loss: 3.0917 - val_acc: 0.6012\n",
      "Medel is training: epoch 53th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2957 - acc: 0.6493 - val_loss: 1.9747 - val_acc: 0.6878\n",
      "Medel is training: epoch 53th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3137 - acc: 0.6240 - val_loss: 3.0532 - val_acc: 0.5791\n",
      "Medel is training: epoch 53th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8717 - acc: 0.5545 - val_loss: 3.1295 - val_acc: 0.5882\n",
      "Medel is training: epoch 53th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7852 - acc: 0.5993 - val_loss: 3.2178 - val_acc: 0.5809\n",
      "Medel is training: epoch 53th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8494 - acc: 0.6903 - val_loss: 2.1176 - val_acc: 0.6639\n",
      "Medel is training: epoch 53th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5774 - acc: 0.5940 - val_loss: 3.5655 - val_acc: 0.5243\n",
      "Medel is training: epoch 53th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7016 - acc: 0.5924 - val_loss: 3.1671 - val_acc: 0.5967\n",
      "Medel is training: epoch 53th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7255 - acc: 0.6117 - val_loss: 2.3376 - val_acc: 0.6660\n",
      "Medel is training: epoch 53th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7823 - acc: 0.6888 - val_loss: 2.6788 - val_acc: 0.6180\n",
      "Medel is training: epoch 53th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6938 - acc: 0.5804 - val_loss: 3.5562 - val_acc: 0.5196\n",
      "Medel is training: epoch 53th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5931 - acc: 0.6114 - val_loss: 3.0031 - val_acc: 0.6241\n",
      "Medel is training: epoch 53th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8164 - acc: 0.5999 - val_loss: 2.4553 - val_acc: 0.6500\n",
      "Medel is training: epoch 53th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7455 - acc: 0.6964 - val_loss: 2.7135 - val_acc: 0.5970\n",
      "Medel is training: epoch 53th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6473 - acc: 0.5895 - val_loss: 3.8004 - val_acc: 0.5099\n",
      "Medel is training: epoch 53th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6307 - acc: 0.6092 - val_loss: 3.1191 - val_acc: 0.5978\n",
      "Medel is training: epoch 53th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7302 - acc: 0.6079 - val_loss: 1.8535 - val_acc: 0.6962\n",
      "Medel is training: epoch 53th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7860 - acc: 0.6953 - val_loss: 2.6296 - val_acc: 0.6121\n",
      "Medel is training: epoch 53th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6323 - acc: 0.5880 - val_loss: 3.4016 - val_acc: 0.5332\n",
      "Medel is training: epoch 53th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6634 - acc: 0.5973 - val_loss: 3.2889 - val_acc: 0.5877\n",
      "Medel is training: epoch 54th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1533 - acc: 0.5172 - val_loss: 3.6491 - val_acc: 0.5216\n",
      "Medel is training: epoch 54th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0211 - acc: 0.5637 - val_loss: 2.1697 - val_acc: 0.6361\n",
      "Medel is training: epoch 54th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.6834 - acc: 0.5635 - val_loss: 3.5415 - val_acc: 0.5203\n",
      "Medel is training: epoch 54th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9679 - acc: 0.5653 - val_loss: 3.5595 - val_acc: 0.5466\n",
      "Medel is training: epoch 54th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5260 - acc: 0.6045 - val_loss: 3.2915 - val_acc: 0.5441\n",
      "Medel is training: epoch 54th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0902 - acc: 0.5204 - val_loss: 3.2974 - val_acc: 0.5689\n",
      "Medel is training: epoch 54th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0464 - acc: 0.5556 - val_loss: 3.5560 - val_acc: 0.5457\n",
      "Medel is training: epoch 54th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3555 - acc: 0.6073 - val_loss: 3.3772 - val_acc: 0.5296\n",
      "Medel is training: epoch 54th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0398 - acc: 0.5326 - val_loss: 3.3636 - val_acc: 0.5626\n",
      "Medel is training: epoch 54th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9392 - acc: 0.5682 - val_loss: 2.1199 - val_acc: 0.6628\n",
      "Medel is training: epoch 54th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5879 - acc: 0.5858 - val_loss: 3.7715 - val_acc: 0.4920\n",
      "Medel is training: epoch 54th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9672 - acc: 0.5572 - val_loss: 3.4735 - val_acc: 0.5454\n",
      "Medel is training: epoch 54th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7092 - acc: 0.5954 - val_loss: 2.2673 - val_acc: 0.6389\n",
      "Medel is training: epoch 54th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8395 - acc: 0.5528 - val_loss: 4.0929 - val_acc: 0.4508\n",
      "Medel is training: epoch 54th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8624 - acc: 0.5791 - val_loss: 3.5342 - val_acc: 0.5521\n",
      "Medel is training: epoch 54th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5221 - acc: 0.6110 - val_loss: 2.3897 - val_acc: 0.6371\n",
      "Medel is training: epoch 54th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7715 - acc: 0.5633 - val_loss: 3.5006 - val_acc: 0.5204\n",
      "Medel is training: epoch 54th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8408 - acc: 0.5831 - val_loss: 3.5675 - val_acc: 0.5441\n",
      "Medel is training: epoch 54th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4886 - acc: 0.6154 - val_loss: 2.2672 - val_acc: 0.6393\n",
      "Medel is training: epoch 54th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7724 - acc: 0.5647 - val_loss: 3.7501 - val_acc: 0.4893\n",
      "Medel is training: epoch 54th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7725 - acc: 0.5909 - val_loss: 3.2835 - val_acc: 0.5726\n",
      "Medel is training: epoch 54th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5635 - acc: 0.6143 - val_loss: 2.1281 - val_acc: 0.6569\n",
      "Medel is training: epoch 54th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6170 - acc: 0.5797 - val_loss: 3.4899 - val_acc: 0.5318\n",
      "Medel is training: epoch 54th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8727 - acc: 0.5716 - val_loss: 3.2891 - val_acc: 0.5784\n",
      "Medel is training: epoch 54th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7738 - acc: 0.5944 - val_loss: 1.9268 - val_acc: 0.6932\n",
      "Medel is training: epoch 54th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3130 - acc: 0.6179 - val_loss: 2.9499 - val_acc: 0.5840\n",
      "Medel is training: epoch 54th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9043 - acc: 0.5509 - val_loss: 3.2648 - val_acc: 0.5724\n",
      "Medel is training: epoch 54th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8274 - acc: 0.5945 - val_loss: 3.3445 - val_acc: 0.5695\n",
      "Medel is training: epoch 54th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8470 - acc: 0.6831 - val_loss: 2.9035 - val_acc: 0.5950\n",
      "Medel is training: epoch 54th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8358 - acc: 0.5581 - val_loss: 3.2808 - val_acc: 0.5642\n",
      "Medel is training: epoch 54th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7748 - acc: 0.5919 - val_loss: 3.0807 - val_acc: 0.6032\n",
      "Medel is training: epoch 54th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2887 - acc: 0.6478 - val_loss: 1.9704 - val_acc: 0.6882\n",
      "Medel is training: epoch 54th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3105 - acc: 0.6212 - val_loss: 3.0563 - val_acc: 0.5779\n",
      "Medel is training: epoch 54th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8568 - acc: 0.5547 - val_loss: 3.1304 - val_acc: 0.5873\n",
      "Medel is training: epoch 54th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7731 - acc: 0.6002 - val_loss: 3.2216 - val_acc: 0.5812\n",
      "Medel is training: epoch 54th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8367 - acc: 0.6899 - val_loss: 2.1223 - val_acc: 0.6616\n",
      "Medel is training: epoch 54th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5695 - acc: 0.5956 - val_loss: 3.5668 - val_acc: 0.5243\n",
      "Medel is training: epoch 54th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6918 - acc: 0.5917 - val_loss: 3.1639 - val_acc: 0.5952\n",
      "Medel is training: epoch 54th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7177 - acc: 0.6107 - val_loss: 2.3253 - val_acc: 0.6715\n",
      "Medel is training: epoch 54th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7734 - acc: 0.6935 - val_loss: 2.6768 - val_acc: 0.6180\n",
      "Medel is training: epoch 54th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.6852 - acc: 0.5802 - val_loss: 3.5537 - val_acc: 0.5189\n",
      "Medel is training: epoch 54th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5920 - acc: 0.6110 - val_loss: 3.0102 - val_acc: 0.6235\n",
      "Medel is training: epoch 54th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8022 - acc: 0.5994 - val_loss: 2.4540 - val_acc: 0.6506\n",
      "Medel is training: epoch 54th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7388 - acc: 0.6968 - val_loss: 2.7209 - val_acc: 0.5995\n",
      "Medel is training: epoch 54th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6392 - acc: 0.5890 - val_loss: 3.8202 - val_acc: 0.5081\n",
      "Medel is training: epoch 54th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6309 - acc: 0.6094 - val_loss: 3.1279 - val_acc: 0.5960\n",
      "Medel is training: epoch 54th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7308 - acc: 0.6077 - val_loss: 1.8465 - val_acc: 0.7001\n",
      "Medel is training: epoch 54th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7787 - acc: 0.6944 - val_loss: 2.6341 - val_acc: 0.6124\n",
      "Medel is training: epoch 54th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6307 - acc: 0.5868 - val_loss: 3.4042 - val_acc: 0.5310\n",
      "Medel is training: epoch 54th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6580 - acc: 0.5960 - val_loss: 3.2981 - val_acc: 0.5868\n",
      "Medel is training: epoch 55th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1362 - acc: 0.5188 - val_loss: 3.6394 - val_acc: 0.5230\n",
      "Medel is training: epoch 55th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0154 - acc: 0.5622 - val_loss: 2.1662 - val_acc: 0.6358\n",
      "Medel is training: epoch 55th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6695 - acc: 0.5636 - val_loss: 3.5382 - val_acc: 0.5220\n",
      "Medel is training: epoch 55th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9651 - acc: 0.5640 - val_loss: 3.5566 - val_acc: 0.5462\n",
      "Medel is training: epoch 55th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5263 - acc: 0.6030 - val_loss: 3.2890 - val_acc: 0.5400\n",
      "Medel is training: epoch 55th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0767 - acc: 0.5199 - val_loss: 3.2871 - val_acc: 0.5732\n",
      "Medel is training: epoch 55th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0372 - acc: 0.5546 - val_loss: 3.5636 - val_acc: 0.5453\n",
      "Medel is training: epoch 55th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3444 - acc: 0.6071 - val_loss: 3.3753 - val_acc: 0.5290\n",
      "Medel is training: epoch 55th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0306 - acc: 0.5324 - val_loss: 3.3712 - val_acc: 0.5600\n",
      "Medel is training: epoch 55th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9323 - acc: 0.5683 - val_loss: 2.1217 - val_acc: 0.6628\n",
      "Medel is training: epoch 55th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5785 - acc: 0.5832 - val_loss: 3.7684 - val_acc: 0.4947\n",
      "Medel is training: epoch 55th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9607 - acc: 0.5574 - val_loss: 3.4741 - val_acc: 0.5467\n",
      "Medel is training: epoch 55th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6958 - acc: 0.5973 - val_loss: 2.2649 - val_acc: 0.6371\n",
      "Medel is training: epoch 55th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8372 - acc: 0.5543 - val_loss: 4.0878 - val_acc: 0.4498\n",
      "Medel is training: epoch 55th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8542 - acc: 0.5809 - val_loss: 3.5387 - val_acc: 0.5514\n",
      "Medel is training: epoch 55th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5098 - acc: 0.6118 - val_loss: 2.3886 - val_acc: 0.6351\n",
      "Medel is training: epoch 55th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7612 - acc: 0.5615 - val_loss: 3.5129 - val_acc: 0.5214\n",
      "Medel is training: epoch 55th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8356 - acc: 0.5829 - val_loss: 3.5702 - val_acc: 0.5422\n",
      "Medel is training: epoch 55th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4760 - acc: 0.6180 - val_loss: 2.2622 - val_acc: 0.6403\n",
      "Medel is training: epoch 55th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7606 - acc: 0.5661 - val_loss: 3.7480 - val_acc: 0.4913\n",
      "Medel is training: epoch 55th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7642 - acc: 0.5921 - val_loss: 3.2921 - val_acc: 0.5732\n",
      "Medel is training: epoch 55th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5601 - acc: 0.6154 - val_loss: 2.1168 - val_acc: 0.6562\n",
      "Medel is training: epoch 55th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6173 - acc: 0.5807 - val_loss: 3.4909 - val_acc: 0.5305\n",
      "Medel is training: epoch 55th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8582 - acc: 0.5720 - val_loss: 3.2860 - val_acc: 0.5784\n",
      "Medel is training: epoch 55th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7647 - acc: 0.5956 - val_loss: 1.9275 - val_acc: 0.6899\n",
      "Medel is training: epoch 55th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3134 - acc: 0.6195 - val_loss: 2.9488 - val_acc: 0.5843\n",
      "Medel is training: epoch 55th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8882 - acc: 0.5525 - val_loss: 3.2599 - val_acc: 0.5745\n",
      "Medel is training: epoch 55th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8186 - acc: 0.5949 - val_loss: 3.3385 - val_acc: 0.5708\n",
      "Medel is training: epoch 55th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.8403 - acc: 0.6855 - val_loss: 2.9005 - val_acc: 0.5943\n",
      "Medel is training: epoch 55th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8349 - acc: 0.5578 - val_loss: 3.2778 - val_acc: 0.5663\n",
      "Medel is training: epoch 55th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7647 - acc: 0.5910 - val_loss: 3.1015 - val_acc: 0.5982\n",
      "Medel is training: epoch 55th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2801 - acc: 0.6483 - val_loss: 1.9643 - val_acc: 0.6865\n",
      "Medel is training: epoch 55th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3006 - acc: 0.6232 - val_loss: 3.0543 - val_acc: 0.5766\n",
      "Medel is training: epoch 55th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8483 - acc: 0.5552 - val_loss: 3.1196 - val_acc: 0.5905\n",
      "Medel is training: epoch 55th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7740 - acc: 0.6002 - val_loss: 3.2230 - val_acc: 0.5821\n",
      "Medel is training: epoch 55th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8369 - acc: 0.6889 - val_loss: 2.1191 - val_acc: 0.6632\n",
      "Medel is training: epoch 55th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5512 - acc: 0.5948 - val_loss: 3.5764 - val_acc: 0.5243\n",
      "Medel is training: epoch 55th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6861 - acc: 0.5927 - val_loss: 3.1632 - val_acc: 0.5988\n",
      "Medel is training: epoch 55th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7070 - acc: 0.6111 - val_loss: 2.3318 - val_acc: 0.6688\n",
      "Medel is training: epoch 55th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7705 - acc: 0.6893 - val_loss: 2.6780 - val_acc: 0.6193\n",
      "Medel is training: epoch 55th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6712 - acc: 0.5798 - val_loss: 3.5495 - val_acc: 0.5180\n",
      "Medel is training: epoch 55th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5762 - acc: 0.6113 - val_loss: 3.0111 - val_acc: 0.6252\n",
      "Medel is training: epoch 55th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7904 - acc: 0.5993 - val_loss: 2.4647 - val_acc: 0.6488\n",
      "Medel is training: epoch 55th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7293 - acc: 0.6965 - val_loss: 2.7185 - val_acc: 0.5973\n",
      "Medel is training: epoch 55th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6297 - acc: 0.5890 - val_loss: 3.8080 - val_acc: 0.5069\n",
      "Medel is training: epoch 55th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6219 - acc: 0.6075 - val_loss: 3.1235 - val_acc: 0.5969\n",
      "Medel is training: epoch 55th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7158 - acc: 0.6078 - val_loss: 1.8426 - val_acc: 0.7035\n",
      "Medel is training: epoch 55th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7693 - acc: 0.6968 - val_loss: 2.6296 - val_acc: 0.6106\n",
      "Medel is training: epoch 55th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6132 - acc: 0.5884 - val_loss: 3.4116 - val_acc: 0.5292\n",
      "Medel is training: epoch 55th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6525 - acc: 0.5968 - val_loss: 3.2948 - val_acc: 0.5888\n",
      "Medel is training: epoch 56th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1270 - acc: 0.5185 - val_loss: 3.6401 - val_acc: 0.5220\n",
      "Medel is training: epoch 56th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9999 - acc: 0.5627 - val_loss: 2.1705 - val_acc: 0.6365\n",
      "Medel is training: epoch 56th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6552 - acc: 0.5649 - val_loss: 3.5338 - val_acc: 0.5221\n",
      "Medel is training: epoch 56th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9484 - acc: 0.5668 - val_loss: 3.5697 - val_acc: 0.5472\n",
      "Medel is training: epoch 56th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5119 - acc: 0.6048 - val_loss: 3.2883 - val_acc: 0.5414\n",
      "Medel is training: epoch 56th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0577 - acc: 0.5212 - val_loss: 3.3134 - val_acc: 0.5633\n",
      "Medel is training: epoch 56th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0329 - acc: 0.5543 - val_loss: 3.5603 - val_acc: 0.5453\n",
      "Medel is training: epoch 56th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3388 - acc: 0.6093 - val_loss: 3.3846 - val_acc: 0.5276\n",
      "Medel is training: epoch 56th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0238 - acc: 0.5329 - val_loss: 3.3709 - val_acc: 0.5603\n",
      "Medel is training: epoch 56th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9231 - acc: 0.5691 - val_loss: 2.1140 - val_acc: 0.6663\n",
      "Medel is training: epoch 56th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5707 - acc: 0.5854 - val_loss: 3.7684 - val_acc: 0.4927\n",
      "Medel is training: epoch 56th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9612 - acc: 0.5570 - val_loss: 3.4701 - val_acc: 0.5431\n",
      "Medel is training: epoch 56th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6917 - acc: 0.5965 - val_loss: 2.2469 - val_acc: 0.6389\n",
      "Medel is training: epoch 56th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8266 - acc: 0.5525 - val_loss: 4.0889 - val_acc: 0.4508\n",
      "Medel is training: epoch 56th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8479 - acc: 0.5793 - val_loss: 3.5303 - val_acc: 0.5540\n",
      "Medel is training: epoch 56th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5038 - acc: 0.6106 - val_loss: 2.3833 - val_acc: 0.6358\n",
      "Medel is training: epoch 56th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.7563 - acc: 0.5626 - val_loss: 3.5089 - val_acc: 0.5194\n",
      "Medel is training: epoch 56th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8290 - acc: 0.5832 - val_loss: 3.5677 - val_acc: 0.5434\n",
      "Medel is training: epoch 56th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4663 - acc: 0.6198 - val_loss: 2.2588 - val_acc: 0.6403\n",
      "Medel is training: epoch 56th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7528 - acc: 0.5654 - val_loss: 3.7487 - val_acc: 0.4870\n",
      "Medel is training: epoch 56th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7503 - acc: 0.5919 - val_loss: 3.2864 - val_acc: 0.5744\n",
      "Medel is training: epoch 56th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5472 - acc: 0.6160 - val_loss: 2.1114 - val_acc: 0.6602\n",
      "Medel is training: epoch 56th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5980 - acc: 0.5812 - val_loss: 3.4889 - val_acc: 0.5305\n",
      "Medel is training: epoch 56th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8440 - acc: 0.5720 - val_loss: 3.3050 - val_acc: 0.5772\n",
      "Medel is training: epoch 56th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7620 - acc: 0.5957 - val_loss: 1.9133 - val_acc: 0.6969\n",
      "Medel is training: epoch 56th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3067 - acc: 0.6189 - val_loss: 2.9451 - val_acc: 0.5847\n",
      "Medel is training: epoch 56th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8795 - acc: 0.5525 - val_loss: 3.2601 - val_acc: 0.5715\n",
      "Medel is training: epoch 56th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8092 - acc: 0.5936 - val_loss: 3.3524 - val_acc: 0.5692\n",
      "Medel is training: epoch 56th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8299 - acc: 0.6854 - val_loss: 2.8967 - val_acc: 0.5956\n",
      "Medel is training: epoch 56th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8205 - acc: 0.5579 - val_loss: 3.2825 - val_acc: 0.5660\n",
      "Medel is training: epoch 56th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7626 - acc: 0.5910 - val_loss: 3.0963 - val_acc: 0.5976\n",
      "Medel is training: epoch 56th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2852 - acc: 0.6479 - val_loss: 1.9590 - val_acc: 0.6901\n",
      "Medel is training: epoch 56th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2918 - acc: 0.6233 - val_loss: 3.0468 - val_acc: 0.5788\n",
      "Medel is training: epoch 56th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8437 - acc: 0.5582 - val_loss: 3.1328 - val_acc: 0.5873\n",
      "Medel is training: epoch 56th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7646 - acc: 0.5991 - val_loss: 3.2150 - val_acc: 0.5821\n",
      "Medel is training: epoch 56th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8248 - acc: 0.6908 - val_loss: 2.1045 - val_acc: 0.6677\n",
      "Medel is training: epoch 56th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5402 - acc: 0.5944 - val_loss: 3.5637 - val_acc: 0.5219\n",
      "Medel is training: epoch 56th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6817 - acc: 0.5923 - val_loss: 3.1711 - val_acc: 0.5937\n",
      "Medel is training: epoch 56th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7016 - acc: 0.6099 - val_loss: 2.3259 - val_acc: 0.6682\n",
      "Medel is training: epoch 56th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7590 - acc: 0.6924 - val_loss: 2.6773 - val_acc: 0.6146\n",
      "Medel is training: epoch 56th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6555 - acc: 0.5813 - val_loss: 3.5515 - val_acc: 0.5174\n",
      "Medel is training: epoch 56th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5690 - acc: 0.6118 - val_loss: 3.0106 - val_acc: 0.6249\n",
      "Medel is training: epoch 56th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7946 - acc: 0.5991 - val_loss: 2.4567 - val_acc: 0.6509\n",
      "Medel is training: epoch 56th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7216 - acc: 0.6978 - val_loss: 2.7127 - val_acc: 0.5992\n",
      "Medel is training: epoch 56th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6261 - acc: 0.5906 - val_loss: 3.8053 - val_acc: 0.5078\n",
      "Medel is training: epoch 56th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6171 - acc: 0.6081 - val_loss: 3.1287 - val_acc: 0.5969\n",
      "Medel is training: epoch 56th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7164 - acc: 0.6079 - val_loss: 1.8401 - val_acc: 0.7002\n",
      "Medel is training: epoch 56th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7634 - acc: 0.6961 - val_loss: 2.6193 - val_acc: 0.6127\n",
      "Medel is training: epoch 56th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6067 - acc: 0.5881 - val_loss: 3.3980 - val_acc: 0.5316\n",
      "Medel is training: epoch 56th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6400 - acc: 0.5958 - val_loss: 3.3012 - val_acc: 0.5860\n",
      "Medel is training: epoch 57th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1222 - acc: 0.5195 - val_loss: 3.6419 - val_acc: 0.5223\n",
      "Medel is training: epoch 57th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9969 - acc: 0.5629 - val_loss: 2.1596 - val_acc: 0.6387\n",
      "Medel is training: epoch 57th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6559 - acc: 0.5645 - val_loss: 3.5313 - val_acc: 0.5197\n",
      "Medel is training: epoch 57th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9465 - acc: 0.5647 - val_loss: 3.5691 - val_acc: 0.5456\n",
      "Medel is training: epoch 57th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.5090 - acc: 0.6049 - val_loss: 3.2873 - val_acc: 0.5414\n",
      "Medel is training: epoch 57th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0557 - acc: 0.5222 - val_loss: 3.2948 - val_acc: 0.5705\n",
      "Medel is training: epoch 57th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0203 - acc: 0.5549 - val_loss: 3.5607 - val_acc: 0.5454\n",
      "Medel is training: epoch 57th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3366 - acc: 0.6075 - val_loss: 3.3767 - val_acc: 0.5307\n",
      "Medel is training: epoch 57th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0123 - acc: 0.5329 - val_loss: 3.3633 - val_acc: 0.5580\n",
      "Medel is training: epoch 57th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9163 - acc: 0.5691 - val_loss: 2.1058 - val_acc: 0.6638\n",
      "Medel is training: epoch 57th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5555 - acc: 0.5871 - val_loss: 3.7693 - val_acc: 0.4940\n",
      "Medel is training: epoch 57th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9396 - acc: 0.5577 - val_loss: 3.4697 - val_acc: 0.5428\n",
      "Medel is training: epoch 57th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6865 - acc: 0.5952 - val_loss: 2.2475 - val_acc: 0.6396\n",
      "Medel is training: epoch 57th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8081 - acc: 0.5558 - val_loss: 4.0902 - val_acc: 0.4512\n",
      "Medel is training: epoch 57th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8426 - acc: 0.5793 - val_loss: 3.5377 - val_acc: 0.5498\n",
      "Medel is training: epoch 57th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4911 - acc: 0.6111 - val_loss: 2.3942 - val_acc: 0.6378\n",
      "Medel is training: epoch 57th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7378 - acc: 0.5655 - val_loss: 3.5059 - val_acc: 0.5191\n",
      "Medel is training: epoch 57th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8273 - acc: 0.5829 - val_loss: 3.5748 - val_acc: 0.5441\n",
      "Medel is training: epoch 57th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4689 - acc: 0.6181 - val_loss: 2.2540 - val_acc: 0.6382\n",
      "Medel is training: epoch 57th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7526 - acc: 0.5639 - val_loss: 3.7437 - val_acc: 0.4920\n",
      "Medel is training: epoch 57th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7500 - acc: 0.5910 - val_loss: 3.2812 - val_acc: 0.5738\n",
      "Medel is training: epoch 57th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5450 - acc: 0.6159 - val_loss: 2.1067 - val_acc: 0.6612\n",
      "Medel is training: epoch 57th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5950 - acc: 0.5811 - val_loss: 3.4820 - val_acc: 0.5321\n",
      "Medel is training: epoch 57th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8322 - acc: 0.5727 - val_loss: 3.3059 - val_acc: 0.5775\n",
      "Medel is training: epoch 57th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7511 - acc: 0.5958 - val_loss: 1.9155 - val_acc: 0.6952\n",
      "Medel is training: epoch 57th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3017 - acc: 0.6195 - val_loss: 2.9411 - val_acc: 0.5856\n",
      "Medel is training: epoch 57th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8717 - acc: 0.5525 - val_loss: 3.2460 - val_acc: 0.5760\n",
      "Medel is training: epoch 57th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8042 - acc: 0.5946 - val_loss: 3.3553 - val_acc: 0.5683\n",
      "Medel is training: epoch 57th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8202 - acc: 0.6857 - val_loss: 2.9009 - val_acc: 0.5966\n",
      "Medel is training: epoch 57th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8086 - acc: 0.5587 - val_loss: 3.2850 - val_acc: 0.5660\n",
      "Medel is training: epoch 57th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7488 - acc: 0.5925 - val_loss: 3.0869 - val_acc: 0.6024\n",
      "Medel is training: epoch 57th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2704 - acc: 0.6503 - val_loss: 1.9570 - val_acc: 0.6908\n",
      "Medel is training: epoch 57th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2813 - acc: 0.6234 - val_loss: 3.0429 - val_acc: 0.5794\n",
      "Medel is training: epoch 57th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8298 - acc: 0.5576 - val_loss: 3.1330 - val_acc: 0.5882\n",
      "Medel is training: epoch 57th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7570 - acc: 0.6000 - val_loss: 3.2198 - val_acc: 0.5818\n",
      "Medel is training: epoch 57th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8162 - acc: 0.6935 - val_loss: 2.1163 - val_acc: 0.6648\n",
      "Medel is training: epoch 57th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5355 - acc: 0.5930 - val_loss: 3.5735 - val_acc: 0.5212\n",
      "Medel is training: epoch 57th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6640 - acc: 0.5935 - val_loss: 3.1744 - val_acc: 0.5970\n",
      "Medel is training: epoch 57th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7027 - acc: 0.6116 - val_loss: 2.3259 - val_acc: 0.6697\n",
      "Medel is training: epoch 57th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7435 - acc: 0.6934 - val_loss: 2.6810 - val_acc: 0.6183\n",
      "Medel is training: epoch 57th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6554 - acc: 0.5798 - val_loss: 3.5564 - val_acc: 0.5168\n",
      "Medel is training: epoch 57th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5667 - acc: 0.6130 - val_loss: 3.0119 - val_acc: 0.6235\n",
      "Medel is training: epoch 57th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.7862 - acc: 0.5983 - val_loss: 2.4531 - val_acc: 0.6500\n",
      "Medel is training: epoch 57th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7096 - acc: 0.6963 - val_loss: 2.7071 - val_acc: 0.6020\n",
      "Medel is training: epoch 57th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6195 - acc: 0.5892 - val_loss: 3.8010 - val_acc: 0.5084\n",
      "Medel is training: epoch 57th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6027 - acc: 0.6109 - val_loss: 3.1180 - val_acc: 0.5975\n",
      "Medel is training: epoch 57th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7045 - acc: 0.6095 - val_loss: 1.8388 - val_acc: 0.7020\n",
      "Medel is training: epoch 57th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7609 - acc: 0.6957 - val_loss: 2.6273 - val_acc: 0.6109\n",
      "Medel is training: epoch 57th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6039 - acc: 0.5892 - val_loss: 3.3929 - val_acc: 0.5323\n",
      "Medel is training: epoch 57th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6357 - acc: 0.5965 - val_loss: 3.2955 - val_acc: 0.5877\n",
      "Medel is training: epoch 58th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.1079 - acc: 0.5194 - val_loss: 3.6510 - val_acc: 0.5213\n",
      "Medel is training: epoch 58th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9855 - acc: 0.5639 - val_loss: 2.1548 - val_acc: 0.6394\n",
      "Medel is training: epoch 58th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6352 - acc: 0.5665 - val_loss: 3.5351 - val_acc: 0.5224\n",
      "Medel is training: epoch 58th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9347 - acc: 0.5643 - val_loss: 3.5736 - val_acc: 0.5446\n",
      "Medel is training: epoch 58th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4975 - acc: 0.6054 - val_loss: 3.2939 - val_acc: 0.5390\n",
      "Medel is training: epoch 58th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0342 - acc: 0.5224 - val_loss: 3.3059 - val_acc: 0.5649\n",
      "Medel is training: epoch 58th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0116 - acc: 0.5568 - val_loss: 3.5701 - val_acc: 0.5450\n",
      "Medel is training: epoch 58th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3253 - acc: 0.6103 - val_loss: 3.3776 - val_acc: 0.5361\n",
      "Medel is training: epoch 58th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0106 - acc: 0.5339 - val_loss: 3.3741 - val_acc: 0.5567\n",
      "Medel is training: epoch 58th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9095 - acc: 0.5691 - val_loss: 2.1074 - val_acc: 0.6663\n",
      "Medel is training: epoch 58th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5494 - acc: 0.5865 - val_loss: 3.7602 - val_acc: 0.4930\n",
      "Medel is training: epoch 58th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9291 - acc: 0.5581 - val_loss: 3.4705 - val_acc: 0.5438\n",
      "Medel is training: epoch 58th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6782 - acc: 0.5964 - val_loss: 2.2458 - val_acc: 0.6382\n",
      "Medel is training: epoch 58th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8090 - acc: 0.5553 - val_loss: 4.0808 - val_acc: 0.4505\n",
      "Medel is training: epoch 58th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8314 - acc: 0.5793 - val_loss: 3.5339 - val_acc: 0.5502\n",
      "Medel is training: epoch 58th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4917 - acc: 0.6120 - val_loss: 2.3823 - val_acc: 0.6365\n",
      "Medel is training: epoch 58th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7326 - acc: 0.5661 - val_loss: 3.4991 - val_acc: 0.5211\n",
      "Medel is training: epoch 58th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8103 - acc: 0.5846 - val_loss: 3.5740 - val_acc: 0.5444\n",
      "Medel is training: epoch 58th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4529 - acc: 0.6190 - val_loss: 2.2538 - val_acc: 0.6403\n",
      "Medel is training: epoch 58th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7262 - acc: 0.5669 - val_loss: 3.7424 - val_acc: 0.4890\n",
      "Medel is training: epoch 58th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7349 - acc: 0.5941 - val_loss: 3.2881 - val_acc: 0.5735\n",
      "Medel is training: epoch 58th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5397 - acc: 0.6149 - val_loss: 2.1062 - val_acc: 0.6609\n",
      "Medel is training: epoch 58th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5866 - acc: 0.5829 - val_loss: 3.4884 - val_acc: 0.5305\n",
      "Medel is training: epoch 58th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8291 - acc: 0.5727 - val_loss: 3.3166 - val_acc: 0.5772\n",
      "Medel is training: epoch 58th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7487 - acc: 0.5966 - val_loss: 1.9180 - val_acc: 0.6949\n",
      "Medel is training: epoch 58th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2839 - acc: 0.6215 - val_loss: 2.9548 - val_acc: 0.5840\n",
      "Medel is training: epoch 58th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8591 - acc: 0.5528 - val_loss: 3.2567 - val_acc: 0.5772\n",
      "Medel is training: epoch 58th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8007 - acc: 0.5941 - val_loss: 3.3490 - val_acc: 0.5683\n",
      "Medel is training: epoch 58th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8086 - acc: 0.6861 - val_loss: 2.8996 - val_acc: 0.5953\n",
      "Medel is training: epoch 58th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7959 - acc: 0.5577 - val_loss: 3.2855 - val_acc: 0.5645\n",
      "Medel is training: epoch 58th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.7388 - acc: 0.5921 - val_loss: 3.0906 - val_acc: 0.6021\n",
      "Medel is training: epoch 58th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2662 - acc: 0.6508 - val_loss: 1.9574 - val_acc: 0.6888\n",
      "Medel is training: epoch 58th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2675 - acc: 0.6252 - val_loss: 3.0482 - val_acc: 0.5779\n",
      "Medel is training: epoch 58th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8171 - acc: 0.5580 - val_loss: 3.1430 - val_acc: 0.5870\n",
      "Medel is training: epoch 58th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7500 - acc: 0.6009 - val_loss: 3.2132 - val_acc: 0.5848\n",
      "Medel is training: epoch 58th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8092 - acc: 0.6919 - val_loss: 2.1076 - val_acc: 0.6648\n",
      "Medel is training: epoch 58th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5262 - acc: 0.5958 - val_loss: 3.5756 - val_acc: 0.5200\n",
      "Medel is training: epoch 58th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6514 - acc: 0.5940 - val_loss: 3.1728 - val_acc: 0.5943\n",
      "Medel is training: epoch 58th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6927 - acc: 0.6111 - val_loss: 2.3258 - val_acc: 0.6703\n",
      "Medel is training: epoch 58th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7441 - acc: 0.6917 - val_loss: 2.6716 - val_acc: 0.6193\n",
      "Medel is training: epoch 58th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6436 - acc: 0.5836 - val_loss: 3.5641 - val_acc: 0.5183\n",
      "Medel is training: epoch 58th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5596 - acc: 0.6125 - val_loss: 3.0208 - val_acc: 0.6220\n",
      "Medel is training: epoch 58th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7739 - acc: 0.5996 - val_loss: 2.4442 - val_acc: 0.6506\n",
      "Medel is training: epoch 58th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7001 - acc: 0.6981 - val_loss: 2.7076 - val_acc: 0.6038\n",
      "Medel is training: epoch 58th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6003 - acc: 0.5906 - val_loss: 3.7981 - val_acc: 0.5081\n",
      "Medel is training: epoch 58th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5993 - acc: 0.6091 - val_loss: 3.1232 - val_acc: 0.5952\n",
      "Medel is training: epoch 58th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7022 - acc: 0.6087 - val_loss: 1.8324 - val_acc: 0.7020\n",
      "Medel is training: epoch 58th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7472 - acc: 0.6959 - val_loss: 2.6283 - val_acc: 0.6115\n",
      "Medel is training: epoch 58th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5904 - acc: 0.5888 - val_loss: 3.3806 - val_acc: 0.5310\n",
      "Medel is training: epoch 58th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6181 - acc: 0.5983 - val_loss: 3.3048 - val_acc: 0.5857\n",
      "Medel is training: epoch 59th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0986 - acc: 0.5187 - val_loss: 3.6620 - val_acc: 0.5183\n",
      "Medel is training: epoch 59th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9795 - acc: 0.5649 - val_loss: 2.1555 - val_acc: 0.6358\n",
      "Medel is training: epoch 59th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6329 - acc: 0.5661 - val_loss: 3.5337 - val_acc: 0.5241\n",
      "Medel is training: epoch 59th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9280 - acc: 0.5663 - val_loss: 3.5705 - val_acc: 0.5443\n",
      "Medel is training: epoch 59th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4837 - acc: 0.6075 - val_loss: 3.2897 - val_acc: 0.5410\n",
      "Medel is training: epoch 59th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0349 - acc: 0.5221 - val_loss: 3.3046 - val_acc: 0.5669\n",
      "Medel is training: epoch 59th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0075 - acc: 0.5562 - val_loss: 3.5826 - val_acc: 0.5414\n",
      "Medel is training: epoch 59th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3092 - acc: 0.6117 - val_loss: 3.3900 - val_acc: 0.5290\n",
      "Medel is training: epoch 59th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9994 - acc: 0.5333 - val_loss: 3.3696 - val_acc: 0.5600\n",
      "Medel is training: epoch 59th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9017 - acc: 0.5700 - val_loss: 2.1096 - val_acc: 0.6659\n",
      "Medel is training: epoch 59th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5384 - acc: 0.5885 - val_loss: 3.7604 - val_acc: 0.4916\n",
      "Medel is training: epoch 59th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9231 - acc: 0.5571 - val_loss: 3.4675 - val_acc: 0.5464\n",
      "Medel is training: epoch 59th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6677 - acc: 0.5969 - val_loss: 2.2458 - val_acc: 0.6389\n",
      "Medel is training: epoch 59th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7961 - acc: 0.5557 - val_loss: 4.0779 - val_acc: 0.4498\n",
      "Medel is training: epoch 59th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8229 - acc: 0.5799 - val_loss: 3.5378 - val_acc: 0.5521\n",
      "Medel is training: epoch 59th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4818 - acc: 0.6128 - val_loss: 2.3761 - val_acc: 0.6365\n",
      "Medel is training: epoch 59th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7186 - acc: 0.5647 - val_loss: 3.5054 - val_acc: 0.5198\n",
      "Medel is training: epoch 59th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8021 - acc: 0.5844 - val_loss: 3.5802 - val_acc: 0.5437\n",
      "Medel is training: epoch 59th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.4520 - acc: 0.6175 - val_loss: 2.2448 - val_acc: 0.6413\n",
      "Medel is training: epoch 59th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7204 - acc: 0.5662 - val_loss: 3.7421 - val_acc: 0.4897\n",
      "Medel is training: epoch 59th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7301 - acc: 0.5920 - val_loss: 3.2959 - val_acc: 0.5722\n",
      "Medel is training: epoch 59th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5293 - acc: 0.6163 - val_loss: 2.1007 - val_acc: 0.6622\n",
      "Medel is training: epoch 59th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5750 - acc: 0.5825 - val_loss: 3.4866 - val_acc: 0.5314\n",
      "Medel is training: epoch 59th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8170 - acc: 0.5740 - val_loss: 3.2966 - val_acc: 0.5793\n",
      "Medel is training: epoch 59th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7350 - acc: 0.5980 - val_loss: 1.9124 - val_acc: 0.6955\n",
      "Medel is training: epoch 59th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2759 - acc: 0.6213 - val_loss: 2.9515 - val_acc: 0.5850\n",
      "Medel is training: epoch 59th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8537 - acc: 0.5517 - val_loss: 3.2600 - val_acc: 0.5742\n",
      "Medel is training: epoch 59th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7857 - acc: 0.5938 - val_loss: 3.3523 - val_acc: 0.5702\n",
      "Medel is training: epoch 59th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8087 - acc: 0.6852 - val_loss: 2.8974 - val_acc: 0.5965\n",
      "Medel is training: epoch 59th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7849 - acc: 0.5595 - val_loss: 3.2901 - val_acc: 0.5642\n",
      "Medel is training: epoch 59th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7392 - acc: 0.5912 - val_loss: 3.0944 - val_acc: 0.6018\n",
      "Medel is training: epoch 59th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2546 - acc: 0.6496 - val_loss: 1.9597 - val_acc: 0.6888\n",
      "Medel is training: epoch 59th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2684 - acc: 0.6251 - val_loss: 3.0508 - val_acc: 0.5782\n",
      "Medel is training: epoch 59th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8094 - acc: 0.5582 - val_loss: 3.1607 - val_acc: 0.5817\n",
      "Medel is training: epoch 59th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7437 - acc: 0.6007 - val_loss: 3.2208 - val_acc: 0.5845\n",
      "Medel is training: epoch 59th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.8033 - acc: 0.6907 - val_loss: 2.1091 - val_acc: 0.6648\n",
      "Medel is training: epoch 59th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5189 - acc: 0.5947 - val_loss: 3.5754 - val_acc: 0.5219\n",
      "Medel is training: epoch 59th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6591 - acc: 0.5942 - val_loss: 3.1724 - val_acc: 0.5946\n",
      "Medel is training: epoch 59th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6865 - acc: 0.6107 - val_loss: 2.3323 - val_acc: 0.6691\n",
      "Medel is training: epoch 59th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7404 - acc: 0.6923 - val_loss: 2.6714 - val_acc: 0.6190\n",
      "Medel is training: epoch 59th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6353 - acc: 0.5822 - val_loss: 3.5605 - val_acc: 0.5183\n",
      "Medel is training: epoch 59th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5541 - acc: 0.6129 - val_loss: 3.0173 - val_acc: 0.6246\n",
      "Medel is training: epoch 59th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7804 - acc: 0.5991 - val_loss: 2.4567 - val_acc: 0.6509\n",
      "Medel is training: epoch 59th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7070 - acc: 0.6982 - val_loss: 2.7059 - val_acc: 0.6029\n",
      "Medel is training: epoch 59th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5856 - acc: 0.5919 - val_loss: 3.8086 - val_acc: 0.5102\n",
      "Medel is training: epoch 59th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5896 - acc: 0.6116 - val_loss: 3.1261 - val_acc: 0.5952\n",
      "Medel is training: epoch 59th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6842 - acc: 0.6097 - val_loss: 1.8323 - val_acc: 0.7044\n",
      "Medel is training: epoch 59th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7445 - acc: 0.6959 - val_loss: 2.6247 - val_acc: 0.6146\n",
      "Medel is training: epoch 59th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5845 - acc: 0.5884 - val_loss: 3.3857 - val_acc: 0.5332\n",
      "Medel is training: epoch 59th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6258 - acc: 0.5978 - val_loss: 3.3087 - val_acc: 0.5848\n",
      "Medel is training: epoch 60th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0853 - acc: 0.5202 - val_loss: 3.6478 - val_acc: 0.5233\n",
      "Medel is training: epoch 60th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9673 - acc: 0.5629 - val_loss: 2.1544 - val_acc: 0.6376\n",
      "Medel is training: epoch 60th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6233 - acc: 0.5673 - val_loss: 3.5276 - val_acc: 0.5214\n",
      "Medel is training: epoch 60th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9090 - acc: 0.5667 - val_loss: 3.5870 - val_acc: 0.5446\n",
      "Medel is training: epoch 60th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4827 - acc: 0.6058 - val_loss: 3.2818 - val_acc: 0.5407\n",
      "Medel is training: epoch 60th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 3.0318 - acc: 0.5228 - val_loss: 3.3377 - val_acc: 0.5560\n",
      "Medel is training: epoch 60th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 3.0012 - acc: 0.5562 - val_loss: 3.5724 - val_acc: 0.5437\n",
      "Medel is training: epoch 60th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3024 - acc: 0.6113 - val_loss: 3.3792 - val_acc: 0.5296\n",
      "Medel is training: epoch 60th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9892 - acc: 0.5328 - val_loss: 3.3693 - val_acc: 0.5600\n",
      "Medel is training: epoch 60th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8920 - acc: 0.5688 - val_loss: 2.1087 - val_acc: 0.6691\n",
      "Medel is training: epoch 60th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5330 - acc: 0.5868 - val_loss: 3.7503 - val_acc: 0.4930\n",
      "Medel is training: epoch 60th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9142 - acc: 0.5574 - val_loss: 3.4570 - val_acc: 0.5461\n",
      "Medel is training: epoch 60th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6679 - acc: 0.5969 - val_loss: 2.2343 - val_acc: 0.6438\n",
      "Medel is training: epoch 60th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7734 - acc: 0.5574 - val_loss: 4.0785 - val_acc: 0.4478\n",
      "Medel is training: epoch 60th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8190 - acc: 0.5799 - val_loss: 3.5452 - val_acc: 0.5524\n",
      "Medel is training: epoch 60th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4710 - acc: 0.6137 - val_loss: 2.3776 - val_acc: 0.6389\n",
      "Medel is training: epoch 60th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7115 - acc: 0.5664 - val_loss: 3.5012 - val_acc: 0.5204\n",
      "Medel is training: epoch 60th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7997 - acc: 0.5851 - val_loss: 3.5827 - val_acc: 0.5437\n",
      "Medel is training: epoch 60th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.7287 - acc: 0.5756 - val_loss: 3.3248 - val_acc: 0.5769\n",
      "Medel is training: epoch 72th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6610 - acc: 0.5997 - val_loss: 1.8823 - val_acc: 0.6999\n",
      "Medel is training: epoch 72th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1746 - acc: 0.6287 - val_loss: 2.9295 - val_acc: 0.5872\n",
      "Medel is training: epoch 72th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7423 - acc: 0.5565 - val_loss: 3.2932 - val_acc: 0.5688\n",
      "Medel is training: epoch 72th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7186 - acc: 0.5947 - val_loss: 3.3744 - val_acc: 0.5692\n",
      "Medel is training: epoch 72th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7180 - acc: 0.6907 - val_loss: 2.8971 - val_acc: 0.5934\n",
      "Medel is training: epoch 72th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6769 - acc: 0.5633 - val_loss: 3.2906 - val_acc: 0.5629\n",
      "Medel is training: epoch 72th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6569 - acc: 0.5934 - val_loss: 3.1154 - val_acc: 0.6012\n",
      "Medel is training: epoch 72th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1736 - acc: 0.6541 - val_loss: 1.9230 - val_acc: 0.6959\n",
      "Medel is training: epoch 72th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1625 - acc: 0.6283 - val_loss: 3.0360 - val_acc: 0.5797\n",
      "Medel is training: epoch 72th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7004 - acc: 0.5588 - val_loss: 3.1729 - val_acc: 0.5849\n",
      "Medel is training: epoch 72th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6697 - acc: 0.6033 - val_loss: 3.2446 - val_acc: 0.5806\n",
      "Medel is training: epoch 72th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7268 - acc: 0.6966 - val_loss: 2.0985 - val_acc: 0.6664\n",
      "Medel is training: epoch 72th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4136 - acc: 0.5996 - val_loss: 3.5663 - val_acc: 0.5215\n",
      "Medel is training: epoch 72th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5597 - acc: 0.5975 - val_loss: 3.1893 - val_acc: 0.5929\n",
      "Medel is training: epoch 72th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6136 - acc: 0.6106 - val_loss: 2.3232 - val_acc: 0.6697\n",
      "Medel is training: epoch 72th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6499 - acc: 0.6997 - val_loss: 2.6476 - val_acc: 0.6218\n",
      "Medel is training: epoch 72th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5201 - acc: 0.5877 - val_loss: 3.5596 - val_acc: 0.5162\n",
      "Medel is training: epoch 72th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4638 - acc: 0.6152 - val_loss: 3.0424 - val_acc: 0.6235\n",
      "Medel is training: epoch 72th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7025 - acc: 0.5997 - val_loss: 2.4548 - val_acc: 0.6494\n",
      "Medel is training: epoch 72th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6215 - acc: 0.7048 - val_loss: 2.7007 - val_acc: 0.5995\n",
      "Medel is training: epoch 72th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4937 - acc: 0.5937 - val_loss: 3.7899 - val_acc: 0.5090\n",
      "Medel is training: epoch 72th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5139 - acc: 0.6126 - val_loss: 3.1344 - val_acc: 0.5960\n",
      "Medel is training: epoch 72th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6208 - acc: 0.6107 - val_loss: 1.8163 - val_acc: 0.7078\n",
      "Medel is training: epoch 72th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6579 - acc: 0.7023 - val_loss: 2.6132 - val_acc: 0.6155\n",
      "Medel is training: epoch 72th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4788 - acc: 0.5949 - val_loss: 3.3842 - val_acc: 0.5286\n",
      "Medel is training: epoch 72th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5393 - acc: 0.5991 - val_loss: 3.3244 - val_acc: 0.5848\n",
      "Medel is training: epoch 73th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9687 - acc: 0.5267 - val_loss: 3.6771 - val_acc: 0.5240\n",
      "Medel is training: epoch 73th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8822 - acc: 0.5668 - val_loss: 2.1098 - val_acc: 0.6405\n",
      "Medel is training: epoch 73th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4987 - acc: 0.5742 - val_loss: 3.5323 - val_acc: 0.5245\n",
      "Medel is training: epoch 73th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8261 - acc: 0.5705 - val_loss: 3.6014 - val_acc: 0.5446\n",
      "Medel is training: epoch 73th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3831 - acc: 0.6124 - val_loss: 3.2853 - val_acc: 0.5373\n",
      "Medel is training: epoch 73th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9018 - acc: 0.5248 - val_loss: 3.3155 - val_acc: 0.5646\n",
      "Medel is training: epoch 73th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9171 - acc: 0.5589 - val_loss: 3.6011 - val_acc: 0.5414\n",
      "Medel is training: epoch 73th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1840 - acc: 0.6223 - val_loss: 3.3879 - val_acc: 0.5307\n",
      "Medel is training: epoch 73th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8717 - acc: 0.5392 - val_loss: 3.3676 - val_acc: 0.5632\n",
      "Medel is training: epoch 73th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8052 - acc: 0.5716 - val_loss: 2.0691 - val_acc: 0.6734\n",
      "Medel is training: epoch 73th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4198 - acc: 0.5938 - val_loss: 3.7527 - val_acc: 0.4957\n",
      "Medel is training: epoch 73th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.8135 - acc: 0.5607 - val_loss: 3.4904 - val_acc: 0.5409\n",
      "Medel is training: epoch 73th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5738 - acc: 0.6008 - val_loss: 2.2030 - val_acc: 0.6413\n",
      "Medel is training: epoch 73th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6763 - acc: 0.5599 - val_loss: 4.0755 - val_acc: 0.4475\n",
      "Medel is training: epoch 73th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7216 - acc: 0.5827 - val_loss: 3.5591 - val_acc: 0.5514\n",
      "Medel is training: epoch 73th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3914 - acc: 0.6163 - val_loss: 2.3602 - val_acc: 0.6414\n",
      "Medel is training: epoch 73th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5987 - acc: 0.5685 - val_loss: 3.4952 - val_acc: 0.5188\n",
      "Medel is training: epoch 73th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7120 - acc: 0.5864 - val_loss: 3.6118 - val_acc: 0.5412\n",
      "Medel is training: epoch 73th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3501 - acc: 0.6227 - val_loss: 2.2201 - val_acc: 0.6423\n",
      "Medel is training: epoch 73th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6007 - acc: 0.5728 - val_loss: 3.7448 - val_acc: 0.4887\n",
      "Medel is training: epoch 73th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6330 - acc: 0.5975 - val_loss: 3.3192 - val_acc: 0.5688\n",
      "Medel is training: epoch 73th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4417 - acc: 0.6193 - val_loss: 2.0541 - val_acc: 0.6662\n",
      "Medel is training: epoch 73th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4562 - acc: 0.5879 - val_loss: 3.4749 - val_acc: 0.5314\n",
      "Medel is training: epoch 73th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7228 - acc: 0.5757 - val_loss: 3.3299 - val_acc: 0.5757\n",
      "Medel is training: epoch 73th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6583 - acc: 0.5979 - val_loss: 1.8784 - val_acc: 0.7012\n",
      "Medel is training: epoch 73th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1621 - acc: 0.6265 - val_loss: 2.9316 - val_acc: 0.5859\n",
      "Medel is training: epoch 73th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7283 - acc: 0.5570 - val_loss: 3.2813 - val_acc: 0.5733\n",
      "Medel is training: epoch 73th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7090 - acc: 0.5968 - val_loss: 3.3746 - val_acc: 0.5692\n",
      "Medel is training: epoch 73th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7085 - acc: 0.6933 - val_loss: 2.9018 - val_acc: 0.5893\n",
      "Medel is training: epoch 73th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6677 - acc: 0.5628 - val_loss: 3.2897 - val_acc: 0.5642\n",
      "Medel is training: epoch 73th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6484 - acc: 0.5952 - val_loss: 3.1278 - val_acc: 0.5988\n",
      "Medel is training: epoch 73th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1665 - acc: 0.6554 - val_loss: 1.9230 - val_acc: 0.6943\n",
      "Medel is training: epoch 73th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1580 - acc: 0.6297 - val_loss: 3.0458 - val_acc: 0.5782\n",
      "Medel is training: epoch 73th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6985 - acc: 0.5604 - val_loss: 3.1873 - val_acc: 0.5855\n",
      "Medel is training: epoch 73th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6690 - acc: 0.6024 - val_loss: 3.2542 - val_acc: 0.5807\n",
      "Medel is training: epoch 73th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7177 - acc: 0.6996 - val_loss: 2.0903 - val_acc: 0.6677\n",
      "Medel is training: epoch 73th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4123 - acc: 0.5996 - val_loss: 3.5583 - val_acc: 0.5209\n",
      "Medel is training: epoch 73th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5563 - acc: 0.5973 - val_loss: 3.1923 - val_acc: 0.5917\n",
      "Medel is training: epoch 73th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6027 - acc: 0.6126 - val_loss: 2.3258 - val_acc: 0.6700\n",
      "Medel is training: epoch 73th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6441 - acc: 0.7017 - val_loss: 2.6430 - val_acc: 0.6224\n",
      "Medel is training: epoch 73th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5242 - acc: 0.5868 - val_loss: 3.5784 - val_acc: 0.5171\n",
      "Medel is training: epoch 73th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4684 - acc: 0.6142 - val_loss: 3.0470 - val_acc: 0.6232\n",
      "Medel is training: epoch 73th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6905 - acc: 0.6008 - val_loss: 2.4510 - val_acc: 0.6528\n",
      "Medel is training: epoch 73th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6117 - acc: 0.7048 - val_loss: 2.7016 - val_acc: 0.5985\n",
      "Medel is training: epoch 73th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4858 - acc: 0.5927 - val_loss: 3.7940 - val_acc: 0.5078\n",
      "Medel is training: epoch 73th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5086 - acc: 0.6128 - val_loss: 3.1314 - val_acc: 0.5992\n",
      "Medel is training: epoch 73th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6134 - acc: 0.6111 - val_loss: 1.8213 - val_acc: 0.7072\n",
      "Medel is training: epoch 73th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6519 - acc: 0.7024 - val_loss: 2.6118 - val_acc: 0.6140\n",
      "Medel is training: epoch 73th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4739 - acc: 0.5926 - val_loss: 3.3928 - val_acc: 0.5286\n",
      "Medel is training: epoch 73th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.5261 - acc: 0.6006 - val_loss: 3.3335 - val_acc: 0.5820\n",
      "Medel is training: epoch 74th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9579 - acc: 0.5262 - val_loss: 3.6893 - val_acc: 0.5180\n",
      "Medel is training: epoch 74th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8744 - acc: 0.5670 - val_loss: 2.0966 - val_acc: 0.6438\n",
      "Medel is training: epoch 74th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4993 - acc: 0.5747 - val_loss: 3.5311 - val_acc: 0.5221\n",
      "Medel is training: epoch 74th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8185 - acc: 0.5698 - val_loss: 3.6007 - val_acc: 0.5436\n",
      "Medel is training: epoch 74th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3735 - acc: 0.6117 - val_loss: 3.2776 - val_acc: 0.5410\n",
      "Medel is training: epoch 74th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8956 - acc: 0.5255 - val_loss: 3.3344 - val_acc: 0.5576\n",
      "Medel is training: epoch 74th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9109 - acc: 0.5589 - val_loss: 3.5900 - val_acc: 0.5440\n",
      "Medel is training: epoch 74th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1859 - acc: 0.6199 - val_loss: 3.3688 - val_acc: 0.5300\n",
      "Medel is training: epoch 74th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8595 - acc: 0.5389 - val_loss: 3.3748 - val_acc: 0.5622\n",
      "Medel is training: epoch 74th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8077 - acc: 0.5715 - val_loss: 2.0758 - val_acc: 0.6745\n",
      "Medel is training: epoch 74th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4212 - acc: 0.5920 - val_loss: 3.7461 - val_acc: 0.4954\n",
      "Medel is training: epoch 74th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8063 - acc: 0.5609 - val_loss: 3.4925 - val_acc: 0.5393\n",
      "Medel is training: epoch 74th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5624 - acc: 0.5999 - val_loss: 2.2027 - val_acc: 0.6406\n",
      "Medel is training: epoch 74th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6710 - acc: 0.5605 - val_loss: 4.0707 - val_acc: 0.4471\n",
      "Medel is training: epoch 74th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7279 - acc: 0.5813 - val_loss: 3.5587 - val_acc: 0.5505\n",
      "Medel is training: epoch 74th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3744 - acc: 0.6206 - val_loss: 2.3625 - val_acc: 0.6386\n",
      "Medel is training: epoch 74th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5901 - acc: 0.5705 - val_loss: 3.4948 - val_acc: 0.5185\n",
      "Medel is training: epoch 74th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7051 - acc: 0.5878 - val_loss: 3.6111 - val_acc: 0.5431\n",
      "Medel is training: epoch 74th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3510 - acc: 0.6228 - val_loss: 2.2165 - val_acc: 0.6434\n",
      "Medel is training: epoch 74th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5870 - acc: 0.5725 - val_loss: 3.7493 - val_acc: 0.4871\n",
      "Medel is training: epoch 74th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6350 - acc: 0.5981 - val_loss: 3.3307 - val_acc: 0.5673\n",
      "Medel is training: epoch 74th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4365 - acc: 0.6179 - val_loss: 2.0503 - val_acc: 0.6653\n",
      "Medel is training: epoch 74th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4513 - acc: 0.5866 - val_loss: 3.4715 - val_acc: 0.5292\n",
      "Medel is training: epoch 74th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7161 - acc: 0.5769 - val_loss: 3.3349 - val_acc: 0.5741\n",
      "Medel is training: epoch 74th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6486 - acc: 0.6006 - val_loss: 1.8718 - val_acc: 0.7032\n",
      "Medel is training: epoch 74th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1567 - acc: 0.6277 - val_loss: 2.9317 - val_acc: 0.5847\n",
      "Medel is training: epoch 74th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7163 - acc: 0.5579 - val_loss: 3.3069 - val_acc: 0.5682\n",
      "Medel is training: epoch 74th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7050 - acc: 0.5967 - val_loss: 3.3872 - val_acc: 0.5680\n",
      "Medel is training: epoch 74th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7033 - acc: 0.6952 - val_loss: 2.8983 - val_acc: 0.5943\n",
      "Medel is training: epoch 74th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6582 - acc: 0.5624 - val_loss: 3.2938 - val_acc: 0.5645\n",
      "Medel is training: epoch 74th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6475 - acc: 0.5939 - val_loss: 3.1395 - val_acc: 0.5988\n",
      "Medel is training: epoch 74th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1712 - acc: 0.6530 - val_loss: 1.9202 - val_acc: 0.6979\n",
      "Medel is training: epoch 74th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1516 - acc: 0.6297 - val_loss: 3.0440 - val_acc: 0.5775\n",
      "Medel is training: epoch 74th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6960 - acc: 0.5613 - val_loss: 3.1883 - val_acc: 0.5820\n",
      "Medel is training: epoch 74th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6660 - acc: 0.6033 - val_loss: 3.2479 - val_acc: 0.5818\n",
      "Medel is training: epoch 74th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7153 - acc: 0.6987 - val_loss: 2.0966 - val_acc: 0.6658\n",
      "Medel is training: epoch 74th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4093 - acc: 0.6001 - val_loss: 3.5634 - val_acc: 0.5203\n",
      "Medel is training: epoch 74th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.5510 - acc: 0.5961 - val_loss: 3.1953 - val_acc: 0.5934\n",
      "Medel is training: epoch 74th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6009 - acc: 0.6140 - val_loss: 2.3192 - val_acc: 0.6703\n",
      "Medel is training: epoch 74th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6413 - acc: 0.7015 - val_loss: 2.6420 - val_acc: 0.6202\n",
      "Medel is training: epoch 74th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5121 - acc: 0.5883 - val_loss: 3.5674 - val_acc: 0.5186\n",
      "Medel is training: epoch 74th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4563 - acc: 0.6166 - val_loss: 3.0445 - val_acc: 0.6252\n",
      "Medel is training: epoch 74th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6869 - acc: 0.6003 - val_loss: 2.4510 - val_acc: 0.6512\n",
      "Medel is training: epoch 74th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6042 - acc: 0.7068 - val_loss: 2.7022 - val_acc: 0.5985\n",
      "Medel is training: epoch 74th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4811 - acc: 0.5938 - val_loss: 3.7927 - val_acc: 0.5090\n",
      "Medel is training: epoch 74th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5037 - acc: 0.6117 - val_loss: 3.1327 - val_acc: 0.5983\n",
      "Medel is training: epoch 74th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6075 - acc: 0.6106 - val_loss: 1.8194 - val_acc: 0.7047\n",
      "Medel is training: epoch 74th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6514 - acc: 0.7039 - val_loss: 2.6144 - val_acc: 0.6143\n",
      "Medel is training: epoch 74th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4622 - acc: 0.5933 - val_loss: 3.3973 - val_acc: 0.5274\n",
      "Medel is training: epoch 74th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5169 - acc: 0.6015 - val_loss: 3.3271 - val_acc: 0.5831\n",
      "Medel is training: epoch 75th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9437 - acc: 0.5272 - val_loss: 3.6942 - val_acc: 0.5180\n",
      "Medel is training: epoch 75th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8665 - acc: 0.5676 - val_loss: 2.1067 - val_acc: 0.6453\n",
      "Medel is training: epoch 75th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4869 - acc: 0.5740 - val_loss: 3.5349 - val_acc: 0.5228\n",
      "Medel is training: epoch 75th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8149 - acc: 0.5699 - val_loss: 3.6170 - val_acc: 0.5432\n",
      "Medel is training: epoch 75th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3695 - acc: 0.6137 - val_loss: 3.2924 - val_acc: 0.5376\n",
      "Medel is training: epoch 75th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8859 - acc: 0.5253 - val_loss: 3.3250 - val_acc: 0.5606\n",
      "Medel is training: epoch 75th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9055 - acc: 0.5592 - val_loss: 3.6078 - val_acc: 0.5391\n",
      "Medel is training: epoch 75th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1798 - acc: 0.6198 - val_loss: 3.3837 - val_acc: 0.5279\n",
      "Medel is training: epoch 75th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8642 - acc: 0.5374 - val_loss: 3.3806 - val_acc: 0.5632\n",
      "Medel is training: epoch 75th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7954 - acc: 0.5717 - val_loss: 2.0709 - val_acc: 0.6755\n",
      "Medel is training: epoch 75th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4016 - acc: 0.5964 - val_loss: 3.7450 - val_acc: 0.4930\n",
      "Medel is training: epoch 75th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8024 - acc: 0.5622 - val_loss: 3.4919 - val_acc: 0.5422\n",
      "Medel is training: epoch 75th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5656 - acc: 0.6010 - val_loss: 2.1999 - val_acc: 0.6452\n",
      "Medel is training: epoch 75th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6533 - acc: 0.5639 - val_loss: 4.0722 - val_acc: 0.4475\n",
      "Medel is training: epoch 75th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7121 - acc: 0.5829 - val_loss: 3.5564 - val_acc: 0.5505\n",
      "Medel is training: epoch 75th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3770 - acc: 0.6175 - val_loss: 2.3612 - val_acc: 0.6423\n",
      "Medel is training: epoch 75th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5880 - acc: 0.5695 - val_loss: 3.4917 - val_acc: 0.5178\n",
      "Medel is training: epoch 75th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7076 - acc: 0.5863 - val_loss: 3.6099 - val_acc: 0.5406\n",
      "Medel is training: epoch 75th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3426 - acc: 0.6249 - val_loss: 2.2118 - val_acc: 0.6451\n",
      "Medel is training: epoch 75th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5886 - acc: 0.5726 - val_loss: 3.7380 - val_acc: 0.4887\n",
      "Medel is training: epoch 75th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6327 - acc: 0.5975 - val_loss: 3.3303 - val_acc: 0.5648\n",
      "Medel is training: epoch 75th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4162 - acc: 0.6207 - val_loss: 2.0458 - val_acc: 0.6666\n",
      "Medel is training: epoch 75th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4443 - acc: 0.5871 - val_loss: 3.4760 - val_acc: 0.5295\n",
      "Medel is training: epoch 75th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7014 - acc: 0.5778 - val_loss: 3.3338 - val_acc: 0.5747\n",
      "Medel is training: epoch 75th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6428 - acc: 0.5999 - val_loss: 1.8713 - val_acc: 0.7025\n",
      "Medel is training: epoch 75th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.1478 - acc: 0.6301 - val_loss: 2.9271 - val_acc: 0.5831\n",
      "Medel is training: epoch 75th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7157 - acc: 0.5581 - val_loss: 3.2917 - val_acc: 0.5691\n",
      "Medel is training: epoch 75th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6917 - acc: 0.5973 - val_loss: 3.3851 - val_acc: 0.5662\n",
      "Medel is training: epoch 75th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7032 - acc: 0.6922 - val_loss: 2.8968 - val_acc: 0.5924\n",
      "Medel is training: epoch 75th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6634 - acc: 0.5618 - val_loss: 3.2921 - val_acc: 0.5679\n",
      "Medel is training: epoch 75th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6363 - acc: 0.5960 - val_loss: 3.1413 - val_acc: 0.5985\n",
      "Medel is training: epoch 75th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1602 - acc: 0.6524 - val_loss: 1.9286 - val_acc: 0.6959\n",
      "Medel is training: epoch 75th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1437 - acc: 0.6285 - val_loss: 3.0337 - val_acc: 0.5779\n",
      "Medel is training: epoch 75th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6746 - acc: 0.5621 - val_loss: 3.1798 - val_acc: 0.5849\n",
      "Medel is training: epoch 75th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6609 - acc: 0.6012 - val_loss: 3.2644 - val_acc: 0.5801\n",
      "Medel is training: epoch 75th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7161 - acc: 0.6979 - val_loss: 2.0954 - val_acc: 0.6658\n",
      "Medel is training: epoch 75th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4016 - acc: 0.6009 - val_loss: 3.5663 - val_acc: 0.5194\n",
      "Medel is training: epoch 75th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5385 - acc: 0.5967 - val_loss: 3.2002 - val_acc: 0.5899\n",
      "Medel is training: epoch 75th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5951 - acc: 0.6139 - val_loss: 2.3256 - val_acc: 0.6724\n",
      "Medel is training: epoch 75th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6249 - acc: 0.7033 - val_loss: 2.6401 - val_acc: 0.6177\n",
      "Medel is training: epoch 75th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4956 - acc: 0.5890 - val_loss: 3.5589 - val_acc: 0.5168\n",
      "Medel is training: epoch 75th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4479 - acc: 0.6162 - val_loss: 3.0524 - val_acc: 0.6246\n",
      "Medel is training: epoch 75th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6875 - acc: 0.6005 - val_loss: 2.4594 - val_acc: 0.6488\n",
      "Medel is training: epoch 75th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5980 - acc: 0.7072 - val_loss: 2.7062 - val_acc: 0.6010\n",
      "Medel is training: epoch 75th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4657 - acc: 0.5946 - val_loss: 3.7929 - val_acc: 0.5111\n",
      "Medel is training: epoch 75th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4864 - acc: 0.6133 - val_loss: 3.1440 - val_acc: 0.5966\n",
      "Medel is training: epoch 75th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6016 - acc: 0.6106 - val_loss: 1.8210 - val_acc: 0.7063\n",
      "Medel is training: epoch 75th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6383 - acc: 0.7043 - val_loss: 2.6146 - val_acc: 0.6137\n",
      "Medel is training: epoch 75th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4679 - acc: 0.5942 - val_loss: 3.3979 - val_acc: 0.5250\n",
      "Medel is training: epoch 75th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5074 - acc: 0.6010 - val_loss: 3.3303 - val_acc: 0.5828\n",
      "Medel is training: epoch 76th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9425 - acc: 0.5258 - val_loss: 3.6826 - val_acc: 0.5217\n",
      "Medel is training: epoch 76th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8649 - acc: 0.5681 - val_loss: 2.1069 - val_acc: 0.6398\n",
      "Medel is training: epoch 76th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4786 - acc: 0.5750 - val_loss: 3.5321 - val_acc: 0.5225\n",
      "Medel is training: epoch 76th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8113 - acc: 0.5719 - val_loss: 3.6127 - val_acc: 0.5449\n",
      "Medel is training: epoch 76th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3639 - acc: 0.6118 - val_loss: 3.2793 - val_acc: 0.5393\n",
      "Medel is training: epoch 76th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8824 - acc: 0.5246 - val_loss: 3.3299 - val_acc: 0.5603\n",
      "Medel is training: epoch 76th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8890 - acc: 0.5600 - val_loss: 3.6003 - val_acc: 0.5434\n",
      "Medel is training: epoch 76th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1681 - acc: 0.6178 - val_loss: 3.3712 - val_acc: 0.5327\n",
      "Medel is training: epoch 76th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8639 - acc: 0.5377 - val_loss: 3.3683 - val_acc: 0.5632\n",
      "Medel is training: epoch 76th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7936 - acc: 0.5704 - val_loss: 2.0672 - val_acc: 0.6752\n",
      "Medel is training: epoch 76th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3920 - acc: 0.5930 - val_loss: 3.7554 - val_acc: 0.4967\n",
      "Medel is training: epoch 76th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7945 - acc: 0.5632 - val_loss: 3.4920 - val_acc: 0.5396\n",
      "Medel is training: epoch 76th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5416 - acc: 0.6037 - val_loss: 2.1976 - val_acc: 0.6462\n",
      "Medel is training: epoch 76th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.6480 - acc: 0.5601 - val_loss: 4.0628 - val_acc: 0.4464\n",
      "Medel is training: epoch 76th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7168 - acc: 0.5812 - val_loss: 3.5572 - val_acc: 0.5479\n",
      "Medel is training: epoch 76th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3707 - acc: 0.6194 - val_loss: 2.3607 - val_acc: 0.6400\n",
      "Medel is training: epoch 76th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5826 - acc: 0.5714 - val_loss: 3.4984 - val_acc: 0.5231\n",
      "Medel is training: epoch 76th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6903 - acc: 0.5867 - val_loss: 3.6155 - val_acc: 0.5374\n",
      "Medel is training: epoch 76th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3424 - acc: 0.6216 - val_loss: 2.2137 - val_acc: 0.6441\n",
      "Medel is training: epoch 76th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5726 - acc: 0.5738 - val_loss: 3.7453 - val_acc: 0.4887\n",
      "Medel is training: epoch 76th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6163 - acc: 0.5988 - val_loss: 3.3349 - val_acc: 0.5648\n",
      "Medel is training: epoch 76th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4262 - acc: 0.6207 - val_loss: 2.0488 - val_acc: 0.6676\n",
      "Medel is training: epoch 76th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4246 - acc: 0.5879 - val_loss: 3.4822 - val_acc: 0.5324\n",
      "Medel is training: epoch 76th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7024 - acc: 0.5777 - val_loss: 3.3435 - val_acc: 0.5735\n",
      "Medel is training: epoch 76th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6378 - acc: 0.5995 - val_loss: 1.8677 - val_acc: 0.7042\n",
      "Medel is training: epoch 76th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1470 - acc: 0.6281 - val_loss: 2.9291 - val_acc: 0.5856\n",
      "Medel is training: epoch 76th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7110 - acc: 0.5588 - val_loss: 3.3029 - val_acc: 0.5663\n",
      "Medel is training: epoch 76th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6796 - acc: 0.5970 - val_loss: 3.3822 - val_acc: 0.5677\n",
      "Medel is training: epoch 76th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6955 - acc: 0.6926 - val_loss: 2.9028 - val_acc: 0.5912\n",
      "Medel is training: epoch 76th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6397 - acc: 0.5641 - val_loss: 3.2944 - val_acc: 0.5670\n",
      "Medel is training: epoch 76th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6339 - acc: 0.5965 - val_loss: 3.1281 - val_acc: 0.5997\n",
      "Medel is training: epoch 76th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1554 - acc: 0.6545 - val_loss: 1.9250 - val_acc: 0.6966\n",
      "Medel is training: epoch 76th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1388 - acc: 0.6306 - val_loss: 3.0356 - val_acc: 0.5769\n",
      "Medel is training: epoch 76th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6714 - acc: 0.5612 - val_loss: 3.1939 - val_acc: 0.5817\n",
      "Medel is training: epoch 76th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6520 - acc: 0.6023 - val_loss: 3.2517 - val_acc: 0.5818\n",
      "Medel is training: epoch 76th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.7012 - acc: 0.6972 - val_loss: 2.0980 - val_acc: 0.6667\n",
      "Medel is training: epoch 76th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3853 - acc: 0.6014 - val_loss: 3.5724 - val_acc: 0.5225\n",
      "Medel is training: epoch 76th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5345 - acc: 0.5993 - val_loss: 3.2119 - val_acc: 0.5881\n",
      "Medel is training: epoch 76th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5883 - acc: 0.6122 - val_loss: 2.3242 - val_acc: 0.6724\n",
      "Medel is training: epoch 76th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6192 - acc: 0.7004 - val_loss: 2.6376 - val_acc: 0.6180\n",
      "Medel is training: epoch 76th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4894 - acc: 0.5878 - val_loss: 3.5662 - val_acc: 0.5165\n",
      "Medel is training: epoch 76th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4488 - acc: 0.6156 - val_loss: 3.0539 - val_acc: 0.6218\n",
      "Medel is training: epoch 76th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6773 - acc: 0.6017 - val_loss: 2.4487 - val_acc: 0.6524\n",
      "Medel is training: epoch 76th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5908 - acc: 0.7065 - val_loss: 2.7004 - val_acc: 0.6007\n",
      "Medel is training: epoch 76th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4688 - acc: 0.5939 - val_loss: 3.7874 - val_acc: 0.5090\n",
      "Medel is training: epoch 76th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4860 - acc: 0.6123 - val_loss: 3.1469 - val_acc: 0.5966\n",
      "Medel is training: epoch 76th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6058 - acc: 0.6094 - val_loss: 1.8170 - val_acc: 0.7075\n",
      "Medel is training: epoch 76th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6328 - acc: 0.7031 - val_loss: 2.6160 - val_acc: 0.6127\n",
      "Medel is training: epoch 76th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4430 - acc: 0.5943 - val_loss: 3.3903 - val_acc: 0.5280\n",
      "Medel is training: epoch 76th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5083 - acc: 0.6007 - val_loss: 3.3351 - val_acc: 0.5826\n",
      "Medel is training: epoch 77th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9333 - acc: 0.5243 - val_loss: 3.6956 - val_acc: 0.5180\n",
      "Medel is training: epoch 77th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.8635 - acc: 0.5678 - val_loss: 2.0917 - val_acc: 0.6457\n",
      "Medel is training: epoch 77th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4705 - acc: 0.5765 - val_loss: 3.5351 - val_acc: 0.5200\n",
      "Medel is training: epoch 77th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7956 - acc: 0.5706 - val_loss: 3.6112 - val_acc: 0.5452\n",
      "Medel is training: epoch 77th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3667 - acc: 0.6138 - val_loss: 3.2828 - val_acc: 0.5407\n",
      "Medel is training: epoch 77th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8632 - acc: 0.5265 - val_loss: 3.3361 - val_acc: 0.5620\n",
      "Medel is training: epoch 77th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8914 - acc: 0.5593 - val_loss: 3.6103 - val_acc: 0.5401\n",
      "Medel is training: epoch 77th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1627 - acc: 0.6205 - val_loss: 3.3790 - val_acc: 0.5337\n",
      "Medel is training: epoch 77th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8544 - acc: 0.5386 - val_loss: 3.3779 - val_acc: 0.5619\n",
      "Medel is training: epoch 77th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7954 - acc: 0.5719 - val_loss: 2.0658 - val_acc: 0.6769\n",
      "Medel is training: epoch 77th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3905 - acc: 0.5958 - val_loss: 3.7692 - val_acc: 0.4940\n",
      "Medel is training: epoch 77th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7893 - acc: 0.5610 - val_loss: 3.4971 - val_acc: 0.5383\n",
      "Medel is training: epoch 77th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5436 - acc: 0.6028 - val_loss: 2.1972 - val_acc: 0.6445\n",
      "Medel is training: epoch 77th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6427 - acc: 0.5629 - val_loss: 4.0805 - val_acc: 0.4485\n",
      "Medel is training: epoch 77th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7081 - acc: 0.5816 - val_loss: 3.5509 - val_acc: 0.5470\n",
      "Medel is training: epoch 77th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3645 - acc: 0.6205 - val_loss: 2.3620 - val_acc: 0.6400\n",
      "Medel is training: epoch 77th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5773 - acc: 0.5701 - val_loss: 3.4924 - val_acc: 0.5188\n",
      "Medel is training: epoch 77th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6859 - acc: 0.5875 - val_loss: 3.6068 - val_acc: 0.5384\n",
      "Medel is training: epoch 77th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3356 - acc: 0.6245 - val_loss: 2.2162 - val_acc: 0.6413\n",
      "Medel is training: epoch 77th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5654 - acc: 0.5727 - val_loss: 3.7501 - val_acc: 0.4897\n",
      "Medel is training: epoch 77th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6093 - acc: 0.5973 - val_loss: 3.3349 - val_acc: 0.5666\n",
      "Medel is training: epoch 77th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4111 - acc: 0.6213 - val_loss: 2.0478 - val_acc: 0.6686\n",
      "Medel is training: epoch 77th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4301 - acc: 0.5875 - val_loss: 3.4800 - val_acc: 0.5327\n",
      "Medel is training: epoch 77th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6954 - acc: 0.5780 - val_loss: 3.3508 - val_acc: 0.5753\n",
      "Medel is training: epoch 77th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6263 - acc: 0.6000 - val_loss: 1.8570 - val_acc: 0.7049\n",
      "Medel is training: epoch 77th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1379 - acc: 0.6280 - val_loss: 2.9369 - val_acc: 0.5818\n",
      "Medel is training: epoch 77th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7004 - acc: 0.5591 - val_loss: 3.3095 - val_acc: 0.5660\n",
      "Medel is training: epoch 77th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6843 - acc: 0.5964 - val_loss: 3.3862 - val_acc: 0.5680\n",
      "Medel is training: epoch 77th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6937 - acc: 0.6938 - val_loss: 2.9046 - val_acc: 0.5937\n",
      "Medel is training: epoch 77th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6488 - acc: 0.5651 - val_loss: 3.2947 - val_acc: 0.5666\n",
      "Medel is training: epoch 77th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6295 - acc: 0.5954 - val_loss: 3.1333 - val_acc: 0.6000\n",
      "Medel is training: epoch 77th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1510 - acc: 0.6554 - val_loss: 1.9215 - val_acc: 0.6969\n",
      "Medel is training: epoch 77th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1373 - acc: 0.6322 - val_loss: 3.0352 - val_acc: 0.5794\n",
      "Medel is training: epoch 77th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6587 - acc: 0.5623 - val_loss: 3.1849 - val_acc: 0.5846\n",
      "Medel is training: epoch 77th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6385 - acc: 0.6028 - val_loss: 3.2562 - val_acc: 0.5827\n",
      "Medel is training: epoch 77th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6996 - acc: 0.6981 - val_loss: 2.0923 - val_acc: 0.6664\n",
      "Medel is training: epoch 77th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3743 - acc: 0.6004 - val_loss: 3.5853 - val_acc: 0.5213\n",
      "Medel is training: epoch 77th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5303 - acc: 0.5977 - val_loss: 3.2006 - val_acc: 0.5911\n",
      "Medel is training: epoch 77th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5876 - acc: 0.6125 - val_loss: 2.3256 - val_acc: 0.6664\n",
      "Medel is training: epoch 77th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.6175 - acc: 0.7006 - val_loss: 2.6472 - val_acc: 0.6177\n",
      "Medel is training: epoch 77th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4835 - acc: 0.5881 - val_loss: 3.5623 - val_acc: 0.5165\n",
      "Medel is training: epoch 77th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4297 - acc: 0.6172 - val_loss: 3.0486 - val_acc: 0.6241\n",
      "Medel is training: epoch 77th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6815 - acc: 0.6013 - val_loss: 2.4451 - val_acc: 0.6509\n",
      "Medel is training: epoch 77th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5936 - acc: 0.7074 - val_loss: 2.6988 - val_acc: 0.5985\n",
      "Medel is training: epoch 77th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4593 - acc: 0.5955 - val_loss: 3.8018 - val_acc: 0.5099\n",
      "Medel is training: epoch 77th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4864 - acc: 0.6135 - val_loss: 3.1477 - val_acc: 0.5963\n",
      "Medel is training: epoch 77th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5954 - acc: 0.6105 - val_loss: 1.8144 - val_acc: 0.7096\n",
      "Medel is training: epoch 77th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6269 - acc: 0.7066 - val_loss: 2.6173 - val_acc: 0.6134\n",
      "Medel is training: epoch 77th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4349 - acc: 0.5952 - val_loss: 3.3970 - val_acc: 0.5271\n",
      "Medel is training: epoch 77th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5016 - acc: 0.6020 - val_loss: 3.3370 - val_acc: 0.5840\n",
      "Medel is training: epoch 78th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9290 - acc: 0.5248 - val_loss: 3.6960 - val_acc: 0.5210\n",
      "Medel is training: epoch 78th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8516 - acc: 0.5669 - val_loss: 2.0886 - val_acc: 0.6482\n",
      "Medel is training: epoch 78th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4551 - acc: 0.5754 - val_loss: 3.5392 - val_acc: 0.5238\n",
      "Medel is training: epoch 78th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7972 - acc: 0.5700 - val_loss: 3.6194 - val_acc: 0.5433\n",
      "Medel is training: epoch 78th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3499 - acc: 0.6144 - val_loss: 3.2891 - val_acc: 0.5386\n",
      "Medel is training: epoch 78th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8658 - acc: 0.5270 - val_loss: 3.3314 - val_acc: 0.5610\n",
      "Medel is training: epoch 78th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8792 - acc: 0.5598 - val_loss: 3.6074 - val_acc: 0.5384\n",
      "Medel is training: epoch 78th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1552 - acc: 0.6196 - val_loss: 3.3792 - val_acc: 0.5293\n",
      "Medel is training: epoch 78th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8380 - acc: 0.5397 - val_loss: 3.3872 - val_acc: 0.5629\n",
      "Medel is training: epoch 78th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7865 - acc: 0.5715 - val_loss: 2.0641 - val_acc: 0.6776\n",
      "Medel is training: epoch 78th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3848 - acc: 0.5946 - val_loss: 3.7578 - val_acc: 0.4950\n",
      "Medel is training: epoch 78th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7878 - acc: 0.5616 - val_loss: 3.5021 - val_acc: 0.5393\n",
      "Medel is training: epoch 78th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5392 - acc: 0.6014 - val_loss: 2.1986 - val_acc: 0.6462\n",
      "Medel is training: epoch 78th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6396 - acc: 0.5614 - val_loss: 4.0729 - val_acc: 0.4498\n",
      "Medel is training: epoch 78th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6974 - acc: 0.5828 - val_loss: 3.5547 - val_acc: 0.5492\n",
      "Medel is training: epoch 78th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3517 - acc: 0.6217 - val_loss: 2.3654 - val_acc: 0.6393\n",
      "Medel is training: epoch 78th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5536 - acc: 0.5706 - val_loss: 3.5050 - val_acc: 0.5188\n",
      "Medel is training: epoch 78th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6738 - acc: 0.5888 - val_loss: 3.6153 - val_acc: 0.5393\n",
      "Medel is training: epoch 78th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3279 - acc: 0.6248 - val_loss: 2.2141 - val_acc: 0.6451\n",
      "Medel is training: epoch 78th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5671 - acc: 0.5739 - val_loss: 3.7453 - val_acc: 0.4861\n",
      "Medel is training: epoch 78th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5999 - acc: 0.5987 - val_loss: 3.3340 - val_acc: 0.5679\n",
      "Medel is training: epoch 78th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4073 - acc: 0.6202 - val_loss: 2.0440 - val_acc: 0.6686\n",
      "Medel is training: epoch 78th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4209 - acc: 0.5897 - val_loss: 3.4781 - val_acc: 0.5321\n",
      "Medel is training: epoch 78th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6925 - acc: 0.5786 - val_loss: 3.3533 - val_acc: 0.5726\n",
      "Medel is training: epoch 78th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6436 - acc: 0.5993 - val_loss: 1.8684 - val_acc: 0.6992\n",
      "Medel is training: epoch 78th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1263 - acc: 0.6290 - val_loss: 2.9327 - val_acc: 0.5824\n",
      "Medel is training: epoch 78th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6905 - acc: 0.5596 - val_loss: 3.3106 - val_acc: 0.5673\n",
      "Medel is training: epoch 78th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.6751 - acc: 0.5978 - val_loss: 3.3898 - val_acc: 0.5674\n",
      "Medel is training: epoch 78th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6890 - acc: 0.6933 - val_loss: 2.9141 - val_acc: 0.5912\n",
      "Medel is training: epoch 78th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6338 - acc: 0.5652 - val_loss: 3.2973 - val_acc: 0.5666\n",
      "Medel is training: epoch 78th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6228 - acc: 0.5970 - val_loss: 3.1343 - val_acc: 0.5982\n",
      "Medel is training: epoch 78th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1376 - acc: 0.6543 - val_loss: 1.9205 - val_acc: 0.6979\n",
      "Medel is training: epoch 78th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1361 - acc: 0.6289 - val_loss: 3.0433 - val_acc: 0.5794\n",
      "Medel is training: epoch 78th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6559 - acc: 0.5616 - val_loss: 3.1834 - val_acc: 0.5846\n",
      "Medel is training: epoch 78th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6429 - acc: 0.6031 - val_loss: 3.2594 - val_acc: 0.5806\n",
      "Medel is training: epoch 78th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6908 - acc: 0.6989 - val_loss: 2.0880 - val_acc: 0.6681\n",
      "Medel is training: epoch 78th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3702 - acc: 0.6024 - val_loss: 3.5775 - val_acc: 0.5241\n",
      "Medel is training: epoch 78th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5265 - acc: 0.5976 - val_loss: 3.2037 - val_acc: 0.5899\n",
      "Medel is training: epoch 78th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5812 - acc: 0.6136 - val_loss: 2.3242 - val_acc: 0.6724\n",
      "Medel is training: epoch 78th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6085 - acc: 0.7060 - val_loss: 2.6496 - val_acc: 0.6187\n",
      "Medel is training: epoch 78th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4896 - acc: 0.5879 - val_loss: 3.5693 - val_acc: 0.5183\n",
      "Medel is training: epoch 78th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4281 - acc: 0.6164 - val_loss: 3.0574 - val_acc: 0.6206\n",
      "Medel is training: epoch 78th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6677 - acc: 0.6019 - val_loss: 2.4512 - val_acc: 0.6494\n",
      "Medel is training: epoch 78th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5832 - acc: 0.7043 - val_loss: 2.6962 - val_acc: 0.5998\n",
      "Medel is training: epoch 78th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4471 - acc: 0.5961 - val_loss: 3.7908 - val_acc: 0.5090\n",
      "Medel is training: epoch 78th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4736 - acc: 0.6137 - val_loss: 3.1515 - val_acc: 0.5940\n",
      "Medel is training: epoch 78th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5883 - acc: 0.6102 - val_loss: 1.8158 - val_acc: 0.7087\n",
      "Medel is training: epoch 78th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6216 - acc: 0.7061 - val_loss: 2.6063 - val_acc: 0.6134\n",
      "Medel is training: epoch 78th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4353 - acc: 0.5959 - val_loss: 3.3985 - val_acc: 0.5277\n",
      "Medel is training: epoch 78th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4939 - acc: 0.5993 - val_loss: 3.3324 - val_acc: 0.5834\n",
      "Medel is training: epoch 79th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.9148 - acc: 0.5263 - val_loss: 3.6969 - val_acc: 0.5237\n",
      "Medel is training: epoch 79th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8477 - acc: 0.5685 - val_loss: 2.0946 - val_acc: 0.6453\n",
      "Medel is training: epoch 79th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4419 - acc: 0.5776 - val_loss: 3.5370 - val_acc: 0.5228\n",
      "Medel is training: epoch 79th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7867 - acc: 0.5696 - val_loss: 3.6207 - val_acc: 0.5443\n",
      "Medel is training: epoch 79th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3451 - acc: 0.6131 - val_loss: 3.2814 - val_acc: 0.5407\n",
      "Medel is training: epoch 79th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8524 - acc: 0.5280 - val_loss: 3.3286 - val_acc: 0.5617\n",
      "Medel is training: epoch 79th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8748 - acc: 0.5598 - val_loss: 3.5981 - val_acc: 0.5414\n",
      "Medel is training: epoch 79th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1448 - acc: 0.6227 - val_loss: 3.3741 - val_acc: 0.5293\n",
      "Medel is training: epoch 79th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8224 - acc: 0.5403 - val_loss: 3.3911 - val_acc: 0.5616\n",
      "Medel is training: epoch 79th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7728 - acc: 0.5726 - val_loss: 2.0670 - val_acc: 0.6752\n",
      "Medel is training: epoch 79th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3766 - acc: 0.5942 - val_loss: 3.7669 - val_acc: 0.4917\n",
      "Medel is training: epoch 79th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7819 - acc: 0.5612 - val_loss: 3.5113 - val_acc: 0.5353\n",
      "Medel is training: epoch 79th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5285 - acc: 0.6013 - val_loss: 2.2052 - val_acc: 0.6459\n",
      "Medel is training: epoch 79th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6211 - acc: 0.5653 - val_loss: 4.0983 - val_acc: 0.4488\n",
      "Medel is training: epoch 79th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6929 - acc: 0.5835 - val_loss: 3.5570 - val_acc: 0.5463\n",
      "Medel is training: epoch 79th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.3484 - acc: 0.6193 - val_loss: 2.3607 - val_acc: 0.6407\n",
      "Medel is training: epoch 79th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5648 - acc: 0.5695 - val_loss: 3.4982 - val_acc: 0.5172\n",
      "Medel is training: epoch 79th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6811 - acc: 0.5867 - val_loss: 3.6143 - val_acc: 0.5387\n",
      "Medel is training: epoch 79th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3170 - acc: 0.6249 - val_loss: 2.2074 - val_acc: 0.6444\n",
      "Medel is training: epoch 79th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5538 - acc: 0.5748 - val_loss: 3.7437 - val_acc: 0.4874\n",
      "Medel is training: epoch 79th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5997 - acc: 0.5968 - val_loss: 3.3422 - val_acc: 0.5666\n",
      "Medel is training: epoch 79th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4045 - acc: 0.6203 - val_loss: 2.0428 - val_acc: 0.6689\n",
      "Medel is training: epoch 79th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4076 - acc: 0.5908 - val_loss: 3.4742 - val_acc: 0.5321\n",
      "Medel is training: epoch 79th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6831 - acc: 0.5784 - val_loss: 3.3518 - val_acc: 0.5757\n",
      "Medel is training: epoch 79th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6225 - acc: 0.5998 - val_loss: 1.8620 - val_acc: 0.7025\n",
      "Medel is training: epoch 79th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1214 - acc: 0.6298 - val_loss: 2.9426 - val_acc: 0.5814\n",
      "Medel is training: epoch 79th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6839 - acc: 0.5586 - val_loss: 3.2912 - val_acc: 0.5703\n",
      "Medel is training: epoch 79th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6806 - acc: 0.5961 - val_loss: 3.3918 - val_acc: 0.5647\n",
      "Medel is training: epoch 79th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6814 - acc: 0.6958 - val_loss: 2.9113 - val_acc: 0.5870\n",
      "Medel is training: epoch 79th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6314 - acc: 0.5653 - val_loss: 3.2869 - val_acc: 0.5666\n",
      "Medel is training: epoch 79th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6239 - acc: 0.5958 - val_loss: 3.1413 - val_acc: 0.5976\n",
      "Medel is training: epoch 79th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1414 - acc: 0.6560 - val_loss: 1.9161 - val_acc: 0.6943\n",
      "Medel is training: epoch 79th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.1244 - acc: 0.6314 - val_loss: 3.0407 - val_acc: 0.5797\n",
      "Medel is training: epoch 79th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6459 - acc: 0.5623 - val_loss: 3.1816 - val_acc: 0.5835\n",
      "Medel is training: epoch 79th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6405 - acc: 0.6051 - val_loss: 3.2681 - val_acc: 0.5774\n",
      "Medel is training: epoch 79th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6908 - acc: 0.6991 - val_loss: 2.0936 - val_acc: 0.6668\n",
      "Medel is training: epoch 79th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3690 - acc: 0.6004 - val_loss: 3.5853 - val_acc: 0.5200\n",
      "Medel is training: epoch 79th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5272 - acc: 0.5969 - val_loss: 3.2004 - val_acc: 0.5917\n",
      "Medel is training: epoch 79th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5750 - acc: 0.6138 - val_loss: 2.3319 - val_acc: 0.6676\n",
      "Medel is training: epoch 79th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6116 - acc: 0.7029 - val_loss: 2.6476 - val_acc: 0.6174\n",
      "Medel is training: epoch 79th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4709 - acc: 0.5883 - val_loss: 3.5710 - val_acc: 0.5180\n",
      "Medel is training: epoch 79th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4217 - acc: 0.6173 - val_loss: 3.0527 - val_acc: 0.6220\n",
      "Medel is training: epoch 79th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6706 - acc: 0.6032 - val_loss: 2.4566 - val_acc: 0.6494\n",
      "Medel is training: epoch 79th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5858 - acc: 0.7042 - val_loss: 2.7005 - val_acc: 0.5973\n",
      "Medel is training: epoch 79th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4466 - acc: 0.5965 - val_loss: 3.7872 - val_acc: 0.5075\n",
      "Medel is training: epoch 79th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4651 - acc: 0.6137 - val_loss: 3.1533 - val_acc: 0.5957\n",
      "Medel is training: epoch 79th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5890 - acc: 0.6111 - val_loss: 1.8143 - val_acc: 0.7081\n",
      "Medel is training: epoch 79th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6225 - acc: 0.7017 - val_loss: 2.6193 - val_acc: 0.6115\n",
      "Medel is training: epoch 79th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "150/800 [====>.........................] - ETA: 7s - loss: 2.5324 - acc: 0.5822"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.5309 - acc: 0.5700 - val_loss: 4.1082 - val_acc: 0.4512\n",
      "Medel is training: epoch 92th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6300 - acc: 0.5855 - val_loss: 3.5876 - val_acc: 0.5384\n",
      "Medel is training: epoch 92th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2845 - acc: 0.6243 - val_loss: 2.3561 - val_acc: 0.6461\n",
      "Medel is training: epoch 92th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4813 - acc: 0.5754 - val_loss: 3.5010 - val_acc: 0.5168\n",
      "Medel is training: epoch 92th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6060 - acc: 0.5903 - val_loss: 3.6388 - val_acc: 0.5371\n",
      "Medel is training: epoch 92th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2589 - acc: 0.6298 - val_loss: 2.1969 - val_acc: 0.6492\n",
      "Medel is training: epoch 92th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4876 - acc: 0.5774 - val_loss: 3.7570 - val_acc: 0.4903\n",
      "Medel is training: epoch 92th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5220 - acc: 0.6011 - val_loss: 3.3923 - val_acc: 0.5641\n",
      "Medel is training: epoch 92th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3472 - acc: 0.6234 - val_loss: 2.0241 - val_acc: 0.6732\n",
      "Medel is training: epoch 92th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3286 - acc: 0.5939 - val_loss: 3.4903 - val_acc: 0.5285\n",
      "Medel is training: epoch 92th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6188 - acc: 0.5781 - val_loss: 3.3712 - val_acc: 0.5711\n",
      "Medel is training: epoch 92th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5609 - acc: 0.6040 - val_loss: 1.8693 - val_acc: 0.7025\n",
      "Medel is training: epoch 92th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0487 - acc: 0.6329 - val_loss: 2.9437 - val_acc: 0.5840\n",
      "Medel is training: epoch 92th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5951 - acc: 0.5646 - val_loss: 3.3151 - val_acc: 0.5697\n",
      "Medel is training: epoch 92th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6123 - acc: 0.5991 - val_loss: 3.4167 - val_acc: 0.5632\n",
      "Medel is training: epoch 92th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6169 - acc: 0.6988 - val_loss: 2.9204 - val_acc: 0.5889\n",
      "Medel is training: epoch 92th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5457 - acc: 0.5686 - val_loss: 3.2918 - val_acc: 0.5670\n",
      "Medel is training: epoch 92th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5592 - acc: 0.5969 - val_loss: 3.1618 - val_acc: 0.5941\n",
      "Medel is training: epoch 92th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0825 - acc: 0.6557 - val_loss: 1.9056 - val_acc: 0.6956\n",
      "Medel is training: epoch 92th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0496 - acc: 0.6340 - val_loss: 3.0483 - val_acc: 0.5797\n",
      "Medel is training: epoch 92th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5784 - acc: 0.5652 - val_loss: 3.2222 - val_acc: 0.5781\n",
      "Medel is training: epoch 92th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5905 - acc: 0.6024 - val_loss: 3.2906 - val_acc: 0.5765\n",
      "Medel is training: epoch 92th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6316 - acc: 0.7023 - val_loss: 2.0873 - val_acc: 0.6652\n",
      "Medel is training: epoch 92th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2920 - acc: 0.6034 - val_loss: 3.6038 - val_acc: 0.5216\n",
      "Medel is training: epoch 92th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4566 - acc: 0.6004 - val_loss: 3.2163 - val_acc: 0.5920\n",
      "Medel is training: epoch 92th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5229 - acc: 0.6152 - val_loss: 2.3339 - val_acc: 0.6715\n",
      "Medel is training: epoch 92th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5488 - acc: 0.7093 - val_loss: 2.6416 - val_acc: 0.6152\n",
      "Medel is training: epoch 92th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3971 - acc: 0.5933 - val_loss: 3.5966 - val_acc: 0.5174\n",
      "Medel is training: epoch 92th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3650 - acc: 0.6178 - val_loss: 3.0783 - val_acc: 0.6200\n",
      "Medel is training: epoch 92th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6163 - acc: 0.6031 - val_loss: 2.4740 - val_acc: 0.6507\n",
      "Medel is training: epoch 92th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5259 - acc: 0.7128 - val_loss: 2.7160 - val_acc: 0.5967\n",
      "Medel is training: epoch 92th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3690 - acc: 0.6013 - val_loss: 3.7979 - val_acc: 0.5099\n",
      "Medel is training: epoch 92th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4118 - acc: 0.6167 - val_loss: 3.1729 - val_acc: 0.5963\n",
      "Medel is training: epoch 92th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5382 - acc: 0.6105 - val_loss: 1.8136 - val_acc: 0.7072\n",
      "Medel is training: epoch 92th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5609 - acc: 0.7068 - val_loss: 2.6099 - val_acc: 0.6134\n",
      "Medel is training: epoch 92th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3644 - acc: 0.5979 - val_loss: 3.4006 - val_acc: 0.5301\n",
      "Medel is training: epoch 92th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4205 - acc: 0.6062 - val_loss: 3.3620 - val_acc: 0.5814\n",
      "Medel is training: epoch 93th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8146 - acc: 0.5297 - val_loss: 3.7357 - val_acc: 0.5200\n",
      "Medel is training: epoch 93th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.7822 - acc: 0.5685 - val_loss: 2.0748 - val_acc: 0.6523\n",
      "Medel is training: epoch 93th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3657 - acc: 0.5816 - val_loss: 3.5657 - val_acc: 0.5228\n",
      "Medel is training: epoch 93th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7098 - acc: 0.5725 - val_loss: 3.6555 - val_acc: 0.5413\n",
      "Medel is training: epoch 93th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2727 - acc: 0.6185 - val_loss: 3.2980 - val_acc: 0.5380\n",
      "Medel is training: epoch 93th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7646 - acc: 0.5316 - val_loss: 3.3458 - val_acc: 0.5596\n",
      "Medel is training: epoch 93th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8026 - acc: 0.5615 - val_loss: 3.6268 - val_acc: 0.5348\n",
      "Medel is training: epoch 93th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0614 - acc: 0.6295 - val_loss: 3.3843 - val_acc: 0.5272\n",
      "Medel is training: epoch 93th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7483 - acc: 0.5436 - val_loss: 3.4031 - val_acc: 0.5668\n",
      "Medel is training: epoch 93th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7046 - acc: 0.5729 - val_loss: 2.0590 - val_acc: 0.6762\n",
      "Medel is training: epoch 93th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2952 - acc: 0.6003 - val_loss: 3.7657 - val_acc: 0.4944\n",
      "Medel is training: epoch 93th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6943 - acc: 0.5655 - val_loss: 3.5201 - val_acc: 0.5409\n",
      "Medel is training: epoch 93th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4584 - acc: 0.6061 - val_loss: 2.1842 - val_acc: 0.6484\n",
      "Medel is training: epoch 93th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5298 - acc: 0.5700 - val_loss: 4.1002 - val_acc: 0.4488\n",
      "Medel is training: epoch 93th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6222 - acc: 0.5872 - val_loss: 3.5849 - val_acc: 0.5467\n",
      "Medel is training: epoch 93th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2824 - acc: 0.6226 - val_loss: 2.3612 - val_acc: 0.6462\n",
      "Medel is training: epoch 93th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4683 - acc: 0.5777 - val_loss: 3.5052 - val_acc: 0.5139\n",
      "Medel is training: epoch 93th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6040 - acc: 0.5901 - val_loss: 3.6386 - val_acc: 0.5378\n",
      "Medel is training: epoch 93th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2516 - acc: 0.6281 - val_loss: 2.1994 - val_acc: 0.6454\n",
      "Medel is training: epoch 93th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4747 - acc: 0.5789 - val_loss: 3.7531 - val_acc: 0.4867\n",
      "Medel is training: epoch 93th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5207 - acc: 0.5992 - val_loss: 3.3833 - val_acc: 0.5660\n",
      "Medel is training: epoch 93th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3343 - acc: 0.6263 - val_loss: 2.0261 - val_acc: 0.6712\n",
      "Medel is training: epoch 93th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3266 - acc: 0.5959 - val_loss: 3.4933 - val_acc: 0.5331\n",
      "Medel is training: epoch 93th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5994 - acc: 0.5809 - val_loss: 3.3726 - val_acc: 0.5741\n",
      "Medel is training: epoch 93th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5557 - acc: 0.6010 - val_loss: 1.8718 - val_acc: 0.7012\n",
      "Medel is training: epoch 93th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0384 - acc: 0.6372 - val_loss: 2.9545 - val_acc: 0.5798\n",
      "Medel is training: epoch 93th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6041 - acc: 0.5637 - val_loss: 3.3315 - val_acc: 0.5676\n",
      "Medel is training: epoch 93th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6035 - acc: 0.5995 - val_loss: 3.4236 - val_acc: 0.5662\n",
      "Medel is training: epoch 93th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6090 - acc: 0.6994 - val_loss: 2.9355 - val_acc: 0.5864\n",
      "Medel is training: epoch 93th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5278 - acc: 0.5694 - val_loss: 3.3010 - val_acc: 0.5666\n",
      "Medel is training: epoch 93th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5489 - acc: 0.5979 - val_loss: 3.1600 - val_acc: 0.5973\n",
      "Medel is training: epoch 93th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0762 - acc: 0.6568 - val_loss: 1.9038 - val_acc: 0.6953\n",
      "Medel is training: epoch 93th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0375 - acc: 0.6382 - val_loss: 3.0458 - val_acc: 0.5779\n",
      "Medel is training: epoch 93th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5636 - acc: 0.5671 - val_loss: 3.2215 - val_acc: 0.5811\n",
      "Medel is training: epoch 93th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5840 - acc: 0.6033 - val_loss: 3.2857 - val_acc: 0.5768\n",
      "Medel is training: epoch 93th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6260 - acc: 0.7023 - val_loss: 2.0893 - val_acc: 0.6658\n",
      "Medel is training: epoch 93th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2827 - acc: 0.6050 - val_loss: 3.5847 - val_acc: 0.5204\n",
      "Medel is training: epoch 93th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4342 - acc: 0.6027 - val_loss: 3.2186 - val_acc: 0.5920\n",
      "Medel is training: epoch 93th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5094 - acc: 0.6158 - val_loss: 2.3353 - val_acc: 0.6673\n",
      "Medel is training: epoch 93th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.5465 - acc: 0.7054 - val_loss: 2.6467 - val_acc: 0.6162\n",
      "Medel is training: epoch 93th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3763 - acc: 0.5925 - val_loss: 3.5940 - val_acc: 0.5153\n",
      "Medel is training: epoch 93th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3552 - acc: 0.6196 - val_loss: 3.0881 - val_acc: 0.6200\n",
      "Medel is training: epoch 93th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6090 - acc: 0.6039 - val_loss: 2.4800 - val_acc: 0.6470\n",
      "Medel is training: epoch 93th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5221 - acc: 0.7098 - val_loss: 2.7198 - val_acc: 0.5982\n",
      "Medel is training: epoch 93th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3588 - acc: 0.6003 - val_loss: 3.7901 - val_acc: 0.5090\n",
      "Medel is training: epoch 93th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4063 - acc: 0.6165 - val_loss: 3.1778 - val_acc: 0.5949\n",
      "Medel is training: epoch 93th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5302 - acc: 0.6137 - val_loss: 1.8143 - val_acc: 0.7096\n",
      "Medel is training: epoch 93th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5476 - acc: 0.7100 - val_loss: 2.6136 - val_acc: 0.6155\n",
      "Medel is training: epoch 93th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3567 - acc: 0.5994 - val_loss: 3.4007 - val_acc: 0.5277\n",
      "Medel is training: epoch 93th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4128 - acc: 0.6056 - val_loss: 3.3711 - val_acc: 0.5826\n",
      "Medel is training: epoch 94th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8180 - acc: 0.5302 - val_loss: 3.7372 - val_acc: 0.5227\n",
      "Medel is training: epoch 94th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7746 - acc: 0.5689 - val_loss: 2.0760 - val_acc: 0.6489\n",
      "Medel is training: epoch 94th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3504 - acc: 0.5849 - val_loss: 3.5723 - val_acc: 0.5211\n",
      "Medel is training: epoch 94th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7114 - acc: 0.5732 - val_loss: 3.6677 - val_acc: 0.5403\n",
      "Medel is training: epoch 94th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2655 - acc: 0.6209 - val_loss: 3.3024 - val_acc: 0.5363\n",
      "Medel is training: epoch 94th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7418 - acc: 0.5329 - val_loss: 3.3330 - val_acc: 0.5643\n",
      "Medel is training: epoch 94th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7995 - acc: 0.5624 - val_loss: 3.6261 - val_acc: 0.5374\n",
      "Medel is training: epoch 94th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0596 - acc: 0.6258 - val_loss: 3.3862 - val_acc: 0.5228\n",
      "Medel is training: epoch 94th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7275 - acc: 0.5435 - val_loss: 3.4012 - val_acc: 0.5674\n",
      "Medel is training: epoch 94th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7043 - acc: 0.5749 - val_loss: 2.0540 - val_acc: 0.6783\n",
      "Medel is training: epoch 94th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2846 - acc: 0.5994 - val_loss: 3.7493 - val_acc: 0.4927\n",
      "Medel is training: epoch 94th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6892 - acc: 0.5665 - val_loss: 3.5277 - val_acc: 0.5409\n",
      "Medel is training: epoch 94th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4503 - acc: 0.6046 - val_loss: 2.1811 - val_acc: 0.6466\n",
      "Medel is training: epoch 94th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5225 - acc: 0.5711 - val_loss: 4.0911 - val_acc: 0.4488\n",
      "Medel is training: epoch 94th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6159 - acc: 0.5864 - val_loss: 3.5867 - val_acc: 0.5457\n",
      "Medel is training: epoch 94th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2750 - acc: 0.6238 - val_loss: 2.3544 - val_acc: 0.6445\n",
      "Medel is training: epoch 94th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4716 - acc: 0.5764 - val_loss: 3.5149 - val_acc: 0.5152\n",
      "Medel is training: epoch 94th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6009 - acc: 0.5899 - val_loss: 3.6438 - val_acc: 0.5365\n",
      "Medel is training: epoch 94th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2523 - acc: 0.6278 - val_loss: 2.1985 - val_acc: 0.6485\n",
      "Medel is training: epoch 94th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4620 - acc: 0.5785 - val_loss: 3.7581 - val_acc: 0.4906\n",
      "Medel is training: epoch 94th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5237 - acc: 0.6003 - val_loss: 3.3847 - val_acc: 0.5663\n",
      "Medel is training: epoch 94th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3292 - acc: 0.6230 - val_loss: 2.0237 - val_acc: 0.6732\n",
      "Medel is training: epoch 94th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3087 - acc: 0.5941 - val_loss: 3.4864 - val_acc: 0.5324\n",
      "Medel is training: epoch 94th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5967 - acc: 0.5804 - val_loss: 3.3646 - val_acc: 0.5704\n",
      "Medel is training: epoch 94th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5509 - acc: 0.6032 - val_loss: 1.8695 - val_acc: 0.6999\n",
      "Medel is training: epoch 94th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0372 - acc: 0.6353 - val_loss: 2.9500 - val_acc: 0.5802\n",
      "Medel is training: epoch 94th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6028 - acc: 0.5642 - val_loss: 3.3404 - val_acc: 0.5682\n",
      "Medel is training: epoch 94th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.6027 - acc: 0.5998 - val_loss: 3.4126 - val_acc: 0.5665\n",
      "Medel is training: epoch 94th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6067 - acc: 0.6999 - val_loss: 2.9206 - val_acc: 0.5896\n",
      "Medel is training: epoch 94th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5275 - acc: 0.5701 - val_loss: 3.2996 - val_acc: 0.5638\n",
      "Medel is training: epoch 94th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5487 - acc: 0.5961 - val_loss: 3.1706 - val_acc: 0.5917\n",
      "Medel is training: epoch 94th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0732 - acc: 0.6576 - val_loss: 1.9042 - val_acc: 0.6963\n",
      "Medel is training: epoch 94th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0375 - acc: 0.6358 - val_loss: 3.0534 - val_acc: 0.5800\n",
      "Medel is training: epoch 94th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5528 - acc: 0.5658 - val_loss: 3.2344 - val_acc: 0.5764\n",
      "Medel is training: epoch 94th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5831 - acc: 0.6055 - val_loss: 3.2895 - val_acc: 0.5750\n",
      "Medel is training: epoch 94th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6273 - acc: 0.7022 - val_loss: 2.0869 - val_acc: 0.6677\n",
      "Medel is training: epoch 94th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2823 - acc: 0.6044 - val_loss: 3.5987 - val_acc: 0.5207\n",
      "Medel is training: epoch 94th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4451 - acc: 0.5998 - val_loss: 3.2234 - val_acc: 0.5923\n",
      "Medel is training: epoch 94th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4981 - acc: 0.6157 - val_loss: 2.3375 - val_acc: 0.6703\n",
      "Medel is training: epoch 94th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5435 - acc: 0.7061 - val_loss: 2.6546 - val_acc: 0.6177\n",
      "Medel is training: epoch 94th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3680 - acc: 0.5955 - val_loss: 3.5872 - val_acc: 0.5189\n",
      "Medel is training: epoch 94th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3540 - acc: 0.6199 - val_loss: 3.0924 - val_acc: 0.6203\n",
      "Medel is training: epoch 94th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5989 - acc: 0.6039 - val_loss: 2.4796 - val_acc: 0.6488\n",
      "Medel is training: epoch 94th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5120 - acc: 0.7135 - val_loss: 2.7212 - val_acc: 0.5979\n",
      "Medel is training: epoch 94th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3495 - acc: 0.5991 - val_loss: 3.7974 - val_acc: 0.5102\n",
      "Medel is training: epoch 94th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3964 - acc: 0.6168 - val_loss: 3.1855 - val_acc: 0.5937\n",
      "Medel is training: epoch 94th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5210 - acc: 0.6115 - val_loss: 1.8159 - val_acc: 0.7069\n",
      "Medel is training: epoch 94th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5406 - acc: 0.7108 - val_loss: 2.6185 - val_acc: 0.6134\n",
      "Medel is training: epoch 94th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3389 - acc: 0.5997 - val_loss: 3.4137 - val_acc: 0.5262\n",
      "Medel is training: epoch 94th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4151 - acc: 0.6048 - val_loss: 3.3798 - val_acc: 0.5800\n",
      "Medel is training: epoch 95th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.8146 - acc: 0.5282 - val_loss: 3.7496 - val_acc: 0.5187\n",
      "Medel is training: epoch 95th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7781 - acc: 0.5699 - val_loss: 2.0770 - val_acc: 0.6493\n",
      "Medel is training: epoch 95th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3417 - acc: 0.5821 - val_loss: 3.5652 - val_acc: 0.5204\n",
      "Medel is training: epoch 95th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7079 - acc: 0.5741 - val_loss: 3.6646 - val_acc: 0.5433\n",
      "Medel is training: epoch 95th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2592 - acc: 0.6189 - val_loss: 3.2918 - val_acc: 0.5421\n",
      "Medel is training: epoch 95th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7416 - acc: 0.5317 - val_loss: 3.3611 - val_acc: 0.5550\n",
      "Medel is training: epoch 95th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7907 - acc: 0.5626 - val_loss: 3.6303 - val_acc: 0.5404\n",
      "Medel is training: epoch 95th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0435 - acc: 0.6275 - val_loss: 3.3788 - val_acc: 0.5272\n",
      "Medel is training: epoch 95th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7291 - acc: 0.5439 - val_loss: 3.4114 - val_acc: 0.5632\n",
      "Medel is training: epoch 95th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7007 - acc: 0.5747 - val_loss: 2.0513 - val_acc: 0.6812\n",
      "Medel is training: epoch 95th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2867 - acc: 0.6008 - val_loss: 3.7636 - val_acc: 0.4937\n",
      "Medel is training: epoch 95th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6885 - acc: 0.5642 - val_loss: 3.5318 - val_acc: 0.5386\n",
      "Medel is training: epoch 95th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4517 - acc: 0.6057 - val_loss: 2.1741 - val_acc: 0.6459\n",
      "Medel is training: epoch 95th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5272 - acc: 0.5698 - val_loss: 4.1142 - val_acc: 0.4495\n",
      "Medel is training: epoch 95th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6121 - acc: 0.5866 - val_loss: 3.5966 - val_acc: 0.5416\n",
      "Medel is training: epoch 95th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.2689 - acc: 0.6237 - val_loss: 2.3595 - val_acc: 0.6468\n",
      "Medel is training: epoch 95th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4598 - acc: 0.5774 - val_loss: 3.5201 - val_acc: 0.5146\n",
      "Medel is training: epoch 95th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6068 - acc: 0.5888 - val_loss: 3.6397 - val_acc: 0.5365\n",
      "Medel is training: epoch 95th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2379 - acc: 0.6319 - val_loss: 2.1953 - val_acc: 0.6451\n",
      "Medel is training: epoch 95th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4482 - acc: 0.5808 - val_loss: 3.7640 - val_acc: 0.4887\n",
      "Medel is training: epoch 95th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5159 - acc: 0.6007 - val_loss: 3.3891 - val_acc: 0.5644\n",
      "Medel is training: epoch 95th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3345 - acc: 0.6244 - val_loss: 2.0203 - val_acc: 0.6749\n",
      "Medel is training: epoch 95th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3075 - acc: 0.5969 - val_loss: 3.4909 - val_acc: 0.5327\n",
      "Medel is training: epoch 95th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5966 - acc: 0.5811 - val_loss: 3.3592 - val_acc: 0.5738\n",
      "Medel is training: epoch 95th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5481 - acc: 0.6013 - val_loss: 1.8720 - val_acc: 0.6999\n",
      "Medel is training: epoch 95th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0312 - acc: 0.6355 - val_loss: 2.9482 - val_acc: 0.5805\n",
      "Medel is training: epoch 95th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5929 - acc: 0.5615 - val_loss: 3.3421 - val_acc: 0.5666\n",
      "Medel is training: epoch 95th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5961 - acc: 0.5988 - val_loss: 3.4267 - val_acc: 0.5641\n",
      "Medel is training: epoch 95th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6025 - acc: 0.6985 - val_loss: 2.9217 - val_acc: 0.5864\n",
      "Medel is training: epoch 95th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5170 - acc: 0.5699 - val_loss: 3.3036 - val_acc: 0.5620\n",
      "Medel is training: epoch 95th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5465 - acc: 0.5974 - val_loss: 3.1737 - val_acc: 0.5941\n",
      "Medel is training: epoch 95th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0653 - acc: 0.6586 - val_loss: 1.9030 - val_acc: 0.6953\n",
      "Medel is training: epoch 95th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0216 - acc: 0.6366 - val_loss: 3.0481 - val_acc: 0.5769\n",
      "Medel is training: epoch 95th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5465 - acc: 0.5665 - val_loss: 3.2131 - val_acc: 0.5832\n",
      "Medel is training: epoch 95th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5738 - acc: 0.6039 - val_loss: 3.2838 - val_acc: 0.5786\n",
      "Medel is training: epoch 95th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6151 - acc: 0.7043 - val_loss: 2.0864 - val_acc: 0.6645\n",
      "Medel is training: epoch 95th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2752 - acc: 0.6064 - val_loss: 3.6003 - val_acc: 0.5170\n",
      "Medel is training: epoch 95th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4236 - acc: 0.6024 - val_loss: 3.2325 - val_acc: 0.5917\n",
      "Medel is training: epoch 95th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5078 - acc: 0.6166 - val_loss: 2.3378 - val_acc: 0.6697\n",
      "Medel is training: epoch 95th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5343 - acc: 0.7055 - val_loss: 2.6492 - val_acc: 0.6140\n",
      "Medel is training: epoch 95th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3689 - acc: 0.5940 - val_loss: 3.5982 - val_acc: 0.5162\n",
      "Medel is training: epoch 95th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3430 - acc: 0.6224 - val_loss: 3.0952 - val_acc: 0.6197\n",
      "Medel is training: epoch 95th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6034 - acc: 0.6031 - val_loss: 2.4735 - val_acc: 0.6476\n",
      "Medel is training: epoch 95th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5075 - acc: 0.7128 - val_loss: 2.7166 - val_acc: 0.5964\n",
      "Medel is training: epoch 95th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3412 - acc: 0.6006 - val_loss: 3.7981 - val_acc: 0.5120\n",
      "Medel is training: epoch 95th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3945 - acc: 0.6165 - val_loss: 3.1763 - val_acc: 0.5966\n",
      "Medel is training: epoch 95th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5209 - acc: 0.6132 - val_loss: 1.8124 - val_acc: 0.7090\n",
      "Medel is training: epoch 95th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5446 - acc: 0.7059 - val_loss: 2.6188 - val_acc: 0.6115\n",
      "Medel is training: epoch 95th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3422 - acc: 0.5992 - val_loss: 3.4053 - val_acc: 0.5271\n",
      "Medel is training: epoch 95th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4031 - acc: 0.6047 - val_loss: 3.3670 - val_acc: 0.5834\n",
      "Medel is training: epoch 96th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7965 - acc: 0.5312 - val_loss: 3.7664 - val_acc: 0.5163\n",
      "Medel is training: epoch 96th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7644 - acc: 0.5696 - val_loss: 2.0694 - val_acc: 0.6486\n",
      "Medel is training: epoch 96th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3345 - acc: 0.5841 - val_loss: 3.5731 - val_acc: 0.5232\n",
      "Medel is training: epoch 96th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.6936 - acc: 0.5746 - val_loss: 3.6521 - val_acc: 0.5400\n",
      "Medel is training: epoch 96th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2506 - acc: 0.6232 - val_loss: 3.2978 - val_acc: 0.5400\n",
      "Medel is training: epoch 96th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7384 - acc: 0.5340 - val_loss: 3.3391 - val_acc: 0.5606\n",
      "Medel is training: epoch 96th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7910 - acc: 0.5637 - val_loss: 3.6331 - val_acc: 0.5361\n",
      "Medel is training: epoch 96th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0412 - acc: 0.6293 - val_loss: 3.3872 - val_acc: 0.5259\n",
      "Medel is training: epoch 96th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7237 - acc: 0.5428 - val_loss: 3.4094 - val_acc: 0.5671\n",
      "Medel is training: epoch 96th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6910 - acc: 0.5737 - val_loss: 2.0455 - val_acc: 0.6808\n",
      "Medel is training: epoch 96th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2713 - acc: 0.6021 - val_loss: 3.7667 - val_acc: 0.4930\n",
      "Medel is training: epoch 96th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6848 - acc: 0.5653 - val_loss: 3.5295 - val_acc: 0.5405\n",
      "Medel is training: epoch 96th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4422 - acc: 0.6056 - val_loss: 2.1797 - val_acc: 0.6469\n",
      "Medel is training: epoch 96th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5152 - acc: 0.5696 - val_loss: 4.1043 - val_acc: 0.4491\n",
      "Medel is training: epoch 96th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6128 - acc: 0.5863 - val_loss: 3.5945 - val_acc: 0.5409\n",
      "Medel is training: epoch 96th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2558 - acc: 0.6243 - val_loss: 2.3520 - val_acc: 0.6489\n",
      "Medel is training: epoch 96th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4517 - acc: 0.5781 - val_loss: 3.5179 - val_acc: 0.5136\n",
      "Medel is training: epoch 96th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5926 - acc: 0.5902 - val_loss: 3.6407 - val_acc: 0.5381\n",
      "Medel is training: epoch 96th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2322 - acc: 0.6315 - val_loss: 2.1898 - val_acc: 0.6465\n",
      "Medel is training: epoch 96th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4593 - acc: 0.5816 - val_loss: 3.7658 - val_acc: 0.4867\n",
      "Medel is training: epoch 96th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5096 - acc: 0.5998 - val_loss: 3.3842 - val_acc: 0.5682\n",
      "Medel is training: epoch 96th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3239 - acc: 0.6246 - val_loss: 2.0197 - val_acc: 0.6723\n",
      "Medel is training: epoch 96th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3094 - acc: 0.5938 - val_loss: 3.4902 - val_acc: 0.5343\n",
      "Medel is training: epoch 96th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5854 - acc: 0.5826 - val_loss: 3.3689 - val_acc: 0.5732\n",
      "Medel is training: epoch 96th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5503 - acc: 0.6043 - val_loss: 1.8721 - val_acc: 0.7022\n",
      "Medel is training: epoch 96th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0236 - acc: 0.6362 - val_loss: 2.9569 - val_acc: 0.5766\n",
      "Medel is training: epoch 96th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5841 - acc: 0.5637 - val_loss: 3.3302 - val_acc: 0.5712\n",
      "Medel is training: epoch 96th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6016 - acc: 0.5985 - val_loss: 3.4265 - val_acc: 0.5622\n",
      "Medel is training: epoch 96th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6081 - acc: 0.6991 - val_loss: 2.9272 - val_acc: 0.5871\n",
      "Medel is training: epoch 96th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5120 - acc: 0.5695 - val_loss: 3.3045 - val_acc: 0.5676\n",
      "Medel is training: epoch 96th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5405 - acc: 0.5975 - val_loss: 3.1593 - val_acc: 0.5964\n",
      "Medel is training: epoch 96th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0757 - acc: 0.6582 - val_loss: 1.9102 - val_acc: 0.6946\n",
      "Medel is training: epoch 96th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0280 - acc: 0.6379 - val_loss: 3.0516 - val_acc: 0.5769\n",
      "Medel is training: epoch 96th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5518 - acc: 0.5661 - val_loss: 3.2372 - val_acc: 0.5749\n",
      "Medel is training: epoch 96th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5778 - acc: 0.6032 - val_loss: 3.2895 - val_acc: 0.5744\n",
      "Medel is training: epoch 96th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6109 - acc: 0.7028 - val_loss: 2.0878 - val_acc: 0.6636\n",
      "Medel is training: epoch 96th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2671 - acc: 0.6058 - val_loss: 3.5945 - val_acc: 0.5201\n",
      "Medel is training: epoch 96th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4333 - acc: 0.5998 - val_loss: 3.2249 - val_acc: 0.5908\n",
      "Medel is training: epoch 96th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4998 - acc: 0.6147 - val_loss: 2.3324 - val_acc: 0.6727\n",
      "Medel is training: epoch 96th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5239 - acc: 0.7083 - val_loss: 2.6492 - val_acc: 0.6190\n",
      "Medel is training: epoch 96th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3704 - acc: 0.5932 - val_loss: 3.5838 - val_acc: 0.5162\n",
      "Medel is training: epoch 96th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.3451 - acc: 0.6207 - val_loss: 3.0920 - val_acc: 0.6212\n",
      "Medel is training: epoch 96th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5965 - acc: 0.6039 - val_loss: 2.4729 - val_acc: 0.6494\n",
      "Medel is training: epoch 96th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5137 - acc: 0.7137 - val_loss: 2.7160 - val_acc: 0.6020\n",
      "Medel is training: epoch 96th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3395 - acc: 0.6003 - val_loss: 3.7736 - val_acc: 0.5105\n",
      "Medel is training: epoch 96th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3911 - acc: 0.6146 - val_loss: 3.1814 - val_acc: 0.5949\n",
      "Medel is training: epoch 96th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5133 - acc: 0.6130 - val_loss: 1.8110 - val_acc: 0.7081\n",
      "Medel is training: epoch 96th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5446 - acc: 0.7089 - val_loss: 2.6154 - val_acc: 0.6124\n",
      "Medel is training: epoch 96th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3385 - acc: 0.5995 - val_loss: 3.4061 - val_acc: 0.5247\n",
      "Medel is training: epoch 96th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4021 - acc: 0.6051 - val_loss: 3.3661 - val_acc: 0.5831\n",
      "Medel is training: epoch 97th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7941 - acc: 0.5298 - val_loss: 3.7446 - val_acc: 0.5203\n",
      "Medel is training: epoch 97th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7625 - acc: 0.5709 - val_loss: 2.0745 - val_acc: 0.6501\n",
      "Medel is training: epoch 97th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3279 - acc: 0.5870 - val_loss: 3.5696 - val_acc: 0.5211\n",
      "Medel is training: epoch 97th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6929 - acc: 0.5745 - val_loss: 3.6608 - val_acc: 0.5406\n",
      "Medel is training: epoch 97th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2550 - acc: 0.6193 - val_loss: 3.2882 - val_acc: 0.5397\n",
      "Medel is training: epoch 97th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7377 - acc: 0.5360 - val_loss: 3.3306 - val_acc: 0.5630\n",
      "Medel is training: epoch 97th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7872 - acc: 0.5621 - val_loss: 3.6321 - val_acc: 0.5384\n",
      "Medel is training: epoch 97th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0324 - acc: 0.6280 - val_loss: 3.3893 - val_acc: 0.5252\n",
      "Medel is training: epoch 97th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7179 - acc: 0.5430 - val_loss: 3.4165 - val_acc: 0.5645\n",
      "Medel is training: epoch 97th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6926 - acc: 0.5745 - val_loss: 2.0457 - val_acc: 0.6815\n",
      "Medel is training: epoch 97th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2704 - acc: 0.6038 - val_loss: 3.7679 - val_acc: 0.4947\n",
      "Medel is training: epoch 97th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6835 - acc: 0.5655 - val_loss: 3.5277 - val_acc: 0.5389\n",
      "Medel is training: epoch 97th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4472 - acc: 0.6058 - val_loss: 2.1763 - val_acc: 0.6466\n",
      "Medel is training: epoch 97th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5115 - acc: 0.5705 - val_loss: 4.1029 - val_acc: 0.4529\n",
      "Medel is training: epoch 97th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6004 - acc: 0.5852 - val_loss: 3.5817 - val_acc: 0.5419\n",
      "Medel is training: epoch 97th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2535 - acc: 0.6254 - val_loss: 2.3494 - val_acc: 0.6465\n",
      "Medel is training: epoch 97th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4458 - acc: 0.5780 - val_loss: 3.5041 - val_acc: 0.5182\n",
      "Medel is training: epoch 97th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5878 - acc: 0.5905 - val_loss: 3.6512 - val_acc: 0.5337\n",
      "Medel is training: epoch 97th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2341 - acc: 0.6299 - val_loss: 2.1916 - val_acc: 0.6496\n",
      "Medel is training: epoch 97th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4504 - acc: 0.5788 - val_loss: 3.7666 - val_acc: 0.4893\n",
      "Medel is training: epoch 97th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5038 - acc: 0.6016 - val_loss: 3.3829 - val_acc: 0.5657\n",
      "Medel is training: epoch 97th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3235 - acc: 0.6240 - val_loss: 2.0146 - val_acc: 0.6736\n",
      "Medel is training: epoch 97th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2962 - acc: 0.5959 - val_loss: 3.5014 - val_acc: 0.5321\n",
      "Medel is training: epoch 97th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5753 - acc: 0.5831 - val_loss: 3.3732 - val_acc: 0.5741\n",
      "Medel is training: epoch 97th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5401 - acc: 0.6024 - val_loss: 1.8682 - val_acc: 0.7039\n",
      "Medel is training: epoch 97th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0145 - acc: 0.6365 - val_loss: 2.9559 - val_acc: 0.5795\n",
      "Medel is training: epoch 97th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5689 - acc: 0.5655 - val_loss: 3.3371 - val_acc: 0.5694\n",
      "Medel is training: epoch 97th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5850 - acc: 0.5994 - val_loss: 3.4339 - val_acc: 0.5650\n",
      "Medel is training: epoch 97th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5986 - acc: 0.7016 - val_loss: 2.9332 - val_acc: 0.5861\n",
      "Medel is training: epoch 97th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.5069 - acc: 0.5697 - val_loss: 3.3146 - val_acc: 0.5645\n",
      "Medel is training: epoch 97th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5290 - acc: 0.5993 - val_loss: 3.1611 - val_acc: 0.5964\n",
      "Medel is training: epoch 97th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0578 - acc: 0.6583 - val_loss: 1.9091 - val_acc: 0.6933\n",
      "Medel is training: epoch 97th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0224 - acc: 0.6380 - val_loss: 3.0491 - val_acc: 0.5791\n",
      "Medel is training: epoch 97th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5396 - acc: 0.5672 - val_loss: 3.2446 - val_acc: 0.5752\n",
      "Medel is training: epoch 97th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5689 - acc: 0.6040 - val_loss: 3.2876 - val_acc: 0.5771\n",
      "Medel is training: epoch 97th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6058 - acc: 0.7049 - val_loss: 2.0743 - val_acc: 0.6693\n",
      "Medel is training: epoch 97th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2626 - acc: 0.6063 - val_loss: 3.6006 - val_acc: 0.5204\n",
      "Medel is training: epoch 97th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4236 - acc: 0.6027 - val_loss: 3.2264 - val_acc: 0.5896\n",
      "Medel is training: epoch 97th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4965 - acc: 0.6164 - val_loss: 2.3345 - val_acc: 0.6670\n",
      "Medel is training: epoch 97th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5284 - acc: 0.7092 - val_loss: 2.6484 - val_acc: 0.6183\n",
      "Medel is training: epoch 97th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3584 - acc: 0.5949 - val_loss: 3.5957 - val_acc: 0.5174\n",
      "Medel is training: epoch 97th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3303 - acc: 0.6195 - val_loss: 3.1032 - val_acc: 0.6163\n",
      "Medel is training: epoch 97th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5898 - acc: 0.6044 - val_loss: 2.4880 - val_acc: 0.6470\n",
      "Medel is training: epoch 97th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5036 - acc: 0.7142 - val_loss: 2.7233 - val_acc: 0.5979\n",
      "Medel is training: epoch 97th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3402 - acc: 0.5985 - val_loss: 3.7982 - val_acc: 0.5072\n",
      "Medel is training: epoch 97th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3828 - acc: 0.6160 - val_loss: 3.1898 - val_acc: 0.5940\n",
      "Medel is training: epoch 97th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5136 - acc: 0.6148 - val_loss: 1.8074 - val_acc: 0.7102\n",
      "Medel is training: epoch 97th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5433 - acc: 0.7085 - val_loss: 2.6149 - val_acc: 0.6106\n",
      "Medel is training: epoch 97th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3258 - acc: 0.6010 - val_loss: 3.4094 - val_acc: 0.5262\n",
      "Medel is training: epoch 97th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3988 - acc: 0.6074 - val_loss: 3.3674 - val_acc: 0.5843\n",
      "Medel is training: epoch 98th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7874 - acc: 0.5309 - val_loss: 3.7717 - val_acc: 0.5150\n",
      "Medel is training: epoch 98th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7536 - acc: 0.5723 - val_loss: 2.0733 - val_acc: 0.6464\n",
      "Medel is training: epoch 98th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3255 - acc: 0.5845 - val_loss: 3.5671 - val_acc: 0.5214\n",
      "Medel is training: epoch 98th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6862 - acc: 0.5737 - val_loss: 3.6710 - val_acc: 0.5383\n",
      "Medel is training: epoch 98th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2403 - acc: 0.6220 - val_loss: 3.3112 - val_acc: 0.5362\n",
      "Medel is training: epoch 98th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7223 - acc: 0.5318 - val_loss: 3.3557 - val_acc: 0.5570\n",
      "Medel is training: epoch 98th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7731 - acc: 0.5640 - val_loss: 3.6369 - val_acc: 0.5374\n",
      "Medel is training: epoch 98th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0205 - acc: 0.6312 - val_loss: 3.3844 - val_acc: 0.5286\n",
      "Medel is training: epoch 98th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7119 - acc: 0.5455 - val_loss: 3.4257 - val_acc: 0.5600\n",
      "Medel is training: epoch 98th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6802 - acc: 0.5758 - val_loss: 2.0577 - val_acc: 0.6801\n",
      "Medel is training: epoch 98th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2636 - acc: 0.6015 - val_loss: 3.7889 - val_acc: 0.4933\n",
      "Medel is training: epoch 98th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6728 - acc: 0.5663 - val_loss: 3.5406 - val_acc: 0.5357\n",
      "Medel is training: epoch 98th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4376 - acc: 0.6054 - val_loss: 2.1873 - val_acc: 0.6448\n",
      "Medel is training: epoch 98th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5112 - acc: 0.5681 - val_loss: 4.1197 - val_acc: 0.4525\n",
      "Medel is training: epoch 98th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5975 - acc: 0.5881 - val_loss: 3.5882 - val_acc: 0.5419\n",
      "Medel is training: epoch 98th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2505 - acc: 0.6252 - val_loss: 2.3502 - val_acc: 0.6472\n",
      "Medel is training: epoch 98th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4327 - acc: 0.5768 - val_loss: 3.5030 - val_acc: 0.5178\n",
      "Medel is training: epoch 98th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.5795 - acc: 0.5913 - val_loss: 3.6452 - val_acc: 0.5356\n",
      "Medel is training: epoch 98th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2250 - acc: 0.6310 - val_loss: 2.1975 - val_acc: 0.6444\n",
      "Medel is training: epoch 98th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4352 - acc: 0.5814 - val_loss: 3.7719 - val_acc: 0.4851\n",
      "Medel is training: epoch 98th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4995 - acc: 0.5993 - val_loss: 3.3924 - val_acc: 0.5675\n",
      "Medel is training: epoch 98th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3043 - acc: 0.6262 - val_loss: 2.0125 - val_acc: 0.6743\n",
      "Medel is training: epoch 98th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2874 - acc: 0.5955 - val_loss: 3.5085 - val_acc: 0.5318\n",
      "Medel is training: epoch 98th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5834 - acc: 0.5825 - val_loss: 3.3799 - val_acc: 0.5723\n",
      "Medel is training: epoch 98th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5355 - acc: 0.6049 - val_loss: 1.8822 - val_acc: 0.6969\n",
      "Medel is training: epoch 98th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0195 - acc: 0.6362 - val_loss: 2.9550 - val_acc: 0.5776\n",
      "Medel is training: epoch 98th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5772 - acc: 0.5642 - val_loss: 3.3513 - val_acc: 0.5679\n",
      "Medel is training: epoch 98th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5817 - acc: 0.5996 - val_loss: 3.4356 - val_acc: 0.5656\n",
      "Medel is training: epoch 98th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5803 - acc: 0.7022 - val_loss: 2.9340 - val_acc: 0.5896\n",
      "Medel is training: epoch 98th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5016 - acc: 0.5713 - val_loss: 3.3206 - val_acc: 0.5642\n",
      "Medel is training: epoch 98th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5311 - acc: 0.5968 - val_loss: 3.1668 - val_acc: 0.5994\n",
      "Medel is training: epoch 98th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0575 - acc: 0.6606 - val_loss: 1.9048 - val_acc: 0.6937\n",
      "Medel is training: epoch 98th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0102 - acc: 0.6385 - val_loss: 3.0479 - val_acc: 0.5778\n",
      "Medel is training: epoch 98th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5409 - acc: 0.5684 - val_loss: 3.2376 - val_acc: 0.5761\n",
      "Medel is training: epoch 98th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5685 - acc: 0.6037 - val_loss: 3.3054 - val_acc: 0.5735\n",
      "Medel is training: epoch 98th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6086 - acc: 0.7059 - val_loss: 2.0807 - val_acc: 0.6649\n",
      "Medel is training: epoch 98th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2500 - acc: 0.6074 - val_loss: 3.6020 - val_acc: 0.5170\n",
      "Medel is training: epoch 98th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4252 - acc: 0.6014 - val_loss: 3.2388 - val_acc: 0.5902\n",
      "Medel is training: epoch 98th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4927 - acc: 0.6160 - val_loss: 2.3316 - val_acc: 0.6724\n",
      "Medel is training: epoch 98th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5157 - acc: 0.7101 - val_loss: 2.6577 - val_acc: 0.6149\n",
      "Medel is training: epoch 98th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3503 - acc: 0.5942 - val_loss: 3.5804 - val_acc: 0.5168\n",
      "Medel is training: epoch 98th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3406 - acc: 0.6193 - val_loss: 3.0874 - val_acc: 0.6183\n",
      "Medel is training: epoch 98th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5849 - acc: 0.6041 - val_loss: 2.4704 - val_acc: 0.6488\n",
      "Medel is training: epoch 98th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4933 - acc: 0.7142 - val_loss: 2.7198 - val_acc: 0.6004\n",
      "Medel is training: epoch 98th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3255 - acc: 0.5999 - val_loss: 3.7995 - val_acc: 0.5117\n",
      "Medel is training: epoch 98th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3780 - acc: 0.6165 - val_loss: 3.1844 - val_acc: 0.5955\n",
      "Medel is training: epoch 98th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5084 - acc: 0.6132 - val_loss: 1.8083 - val_acc: 0.7123\n",
      "Medel is training: epoch 98th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5338 - acc: 0.7085 - val_loss: 2.6277 - val_acc: 0.6091\n",
      "Medel is training: epoch 98th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3246 - acc: 0.5995 - val_loss: 3.4115 - val_acc: 0.5280\n",
      "Medel is training: epoch 98th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3900 - acc: 0.6049 - val_loss: 3.3615 - val_acc: 0.5860\n",
      "Medel is training: epoch 99th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7827 - acc: 0.5325 - val_loss: 3.7587 - val_acc: 0.5183\n",
      "Medel is training: epoch 99th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7513 - acc: 0.5704 - val_loss: 2.0656 - val_acc: 0.6541\n",
      "Medel is training: epoch 99th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3131 - acc: 0.5871 - val_loss: 3.5753 - val_acc: 0.5214\n",
      "Medel is training: epoch 99th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6960 - acc: 0.5744 - val_loss: 3.6718 - val_acc: 0.5403\n",
      "Medel is training: epoch 99th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2385 - acc: 0.6215 - val_loss: 3.3066 - val_acc: 0.5373\n",
      "Medel is training: epoch 99th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 2.7109 - acc: 0.5351 - val_loss: 3.3563 - val_acc: 0.5590\n",
      "Medel is training: epoch 99th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7762 - acc: 0.5634 - val_loss: 3.6452 - val_acc: 0.5358\n",
      "Medel is training: epoch 99th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0276 - acc: 0.6300 - val_loss: 3.3867 - val_acc: 0.5259\n",
      "Medel is training: epoch 99th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6991 - acc: 0.5447 - val_loss: 3.4224 - val_acc: 0.5635\n",
      "Medel is training: epoch 99th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6821 - acc: 0.5753 - val_loss: 2.0517 - val_acc: 0.6791\n",
      "Medel is training: epoch 99th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2623 - acc: 0.6019 - val_loss: 3.7657 - val_acc: 0.4947\n",
      "Medel is training: epoch 99th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6735 - acc: 0.5677 - val_loss: 3.5374 - val_acc: 0.5389\n",
      "Medel is training: epoch 99th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4387 - acc: 0.6067 - val_loss: 2.1847 - val_acc: 0.6470\n",
      "Medel is training: epoch 99th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5052 - acc: 0.5707 - val_loss: 4.1124 - val_acc: 0.4502\n",
      "Medel is training: epoch 99th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5907 - acc: 0.5865 - val_loss: 3.6051 - val_acc: 0.5409\n",
      "Medel is training: epoch 99th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2491 - acc: 0.6255 - val_loss: 2.3491 - val_acc: 0.6465\n",
      "Medel is training: epoch 99th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4321 - acc: 0.5769 - val_loss: 3.5083 - val_acc: 0.5188\n",
      "Medel is training: epoch 99th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5748 - acc: 0.5906 - val_loss: 3.6560 - val_acc: 0.5327\n",
      "Medel is training: epoch 99th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2270 - acc: 0.6303 - val_loss: 2.1873 - val_acc: 0.6479\n",
      "Medel is training: epoch 99th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4186 - acc: 0.5838 - val_loss: 3.7793 - val_acc: 0.4913\n",
      "Medel is training: epoch 99th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4932 - acc: 0.6015 - val_loss: 3.3999 - val_acc: 0.5678\n",
      "Medel is training: epoch 99th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3105 - acc: 0.6260 - val_loss: 2.0147 - val_acc: 0.6716\n",
      "Medel is training: epoch 99th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2889 - acc: 0.5963 - val_loss: 3.4960 - val_acc: 0.5314\n",
      "Medel is training: epoch 99th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5638 - acc: 0.5821 - val_loss: 3.3767 - val_acc: 0.5741\n",
      "Medel is training: epoch 99th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5337 - acc: 0.6047 - val_loss: 1.8714 - val_acc: 0.7005\n",
      "Medel is training: epoch 99th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0084 - acc: 0.6399 - val_loss: 2.9554 - val_acc: 0.5776\n",
      "Medel is training: epoch 99th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5676 - acc: 0.5640 - val_loss: 3.3360 - val_acc: 0.5703\n",
      "Medel is training: epoch 99th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5805 - acc: 0.5983 - val_loss: 3.4441 - val_acc: 0.5656\n",
      "Medel is training: epoch 99th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5877 - acc: 0.7019 - val_loss: 2.9401 - val_acc: 0.5842\n",
      "Medel is training: epoch 99th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4980 - acc: 0.5699 - val_loss: 3.3083 - val_acc: 0.5632\n",
      "Medel is training: epoch 99th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5331 - acc: 0.5967 - val_loss: 3.1664 - val_acc: 0.5976\n",
      "Medel is training: epoch 99th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0495 - acc: 0.6588 - val_loss: 1.9031 - val_acc: 0.6943\n",
      "Medel is training: epoch 99th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0061 - acc: 0.6399 - val_loss: 3.0416 - val_acc: 0.5791\n",
      "Medel is training: epoch 99th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5281 - acc: 0.5689 - val_loss: 3.2326 - val_acc: 0.5790\n",
      "Medel is training: epoch 99th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5627 - acc: 0.6052 - val_loss: 3.2933 - val_acc: 0.5750\n",
      "Medel is training: epoch 99th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6072 - acc: 0.7037 - val_loss: 2.0864 - val_acc: 0.6658\n",
      "Medel is training: epoch 99th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2554 - acc: 0.6063 - val_loss: 3.5954 - val_acc: 0.5194\n",
      "Medel is training: epoch 99th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4184 - acc: 0.6027 - val_loss: 3.2400 - val_acc: 0.5896\n",
      "Medel is training: epoch 99th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4826 - acc: 0.6161 - val_loss: 2.3366 - val_acc: 0.6694\n",
      "Medel is training: epoch 99th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5200 - acc: 0.7089 - val_loss: 2.6434 - val_acc: 0.6165\n",
      "Medel is training: epoch 99th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3458 - acc: 0.5955 - val_loss: 3.5988 - val_acc: 0.5171\n",
      "Medel is training: epoch 99th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3202 - acc: 0.6198 - val_loss: 3.0985 - val_acc: 0.6189\n",
      "Medel is training: epoch 99th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5843 - acc: 0.6035 - val_loss: 2.4744 - val_acc: 0.6482\n",
      "Medel is training: epoch 99th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 9s - loss: 1.4990 - acc: 0.7120 - val_loss: 2.7163 - val_acc: 0.6004\n",
      "Medel is training: epoch 99th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3292 - acc: 0.6012 - val_loss: 3.7975 - val_acc: 0.5114\n",
      "Medel is training: epoch 99th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3769 - acc: 0.6177 - val_loss: 3.1823 - val_acc: 0.5957\n",
      "Medel is training: epoch 99th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5051 - acc: 0.6144 - val_loss: 1.8094 - val_acc: 0.7106\n",
      "Medel is training: epoch 99th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5288 - acc: 0.7102 - val_loss: 2.6201 - val_acc: 0.6161\n",
      "Medel is training: epoch 99th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3251 - acc: 0.5998 - val_loss: 3.4097 - val_acc: 0.5262\n",
      "Medel is training: epoch 99th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3854 - acc: 0.6073 - val_loss: 3.3674 - val_acc: 0.5851\n",
      "Medel is training: epoch 100th 0/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7737 - acc: 0.5324 - val_loss: 3.7608 - val_acc: 0.5210\n",
      "Medel is training: epoch 100th 1000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7428 - acc: 0.5716 - val_loss: 2.0773 - val_acc: 0.6504\n",
      "Medel is training: epoch 100th 2000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3135 - acc: 0.5836 - val_loss: 3.5775 - val_acc: 0.5190\n",
      "Medel is training: epoch 100th 3000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6754 - acc: 0.5736 - val_loss: 3.6726 - val_acc: 0.5406\n",
      "Medel is training: epoch 100th 4000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2387 - acc: 0.6209 - val_loss: 3.3056 - val_acc: 0.5424\n",
      "Medel is training: epoch 100th 5000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7026 - acc: 0.5345 - val_loss: 3.3566 - val_acc: 0.5570\n",
      "Medel is training: epoch 100th 6000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.7740 - acc: 0.5629 - val_loss: 3.6424 - val_acc: 0.5387\n",
      "Medel is training: epoch 100th 7000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0306 - acc: 0.6303 - val_loss: 3.3949 - val_acc: 0.5259\n",
      "Medel is training: epoch 100th 8000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6952 - acc: 0.5449 - val_loss: 3.4209 - val_acc: 0.5658\n",
      "Medel is training: epoch 100th 9000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6723 - acc: 0.5754 - val_loss: 2.0522 - val_acc: 0.6773\n",
      "Medel is training: epoch 100th 10000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2382 - acc: 0.6043 - val_loss: 3.7832 - val_acc: 0.4923\n",
      "Medel is training: epoch 100th 11000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.6557 - acc: 0.5671 - val_loss: 3.5449 - val_acc: 0.5389\n",
      "Medel is training: epoch 100th 12000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4315 - acc: 0.6069 - val_loss: 2.1773 - val_acc: 0.6466\n",
      "Medel is training: epoch 100th 13000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4935 - acc: 0.5703 - val_loss: 4.1180 - val_acc: 0.4519\n",
      "Medel is training: epoch 100th 14000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5833 - acc: 0.5875 - val_loss: 3.6043 - val_acc: 0.5381\n",
      "Medel is training: epoch 100th 15000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2503 - acc: 0.6244 - val_loss: 2.3452 - val_acc: 0.6482\n",
      "Medel is training: epoch 100th 16000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4261 - acc: 0.5781 - val_loss: 3.5154 - val_acc: 0.5175\n",
      "Medel is training: epoch 100th 17000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5812 - acc: 0.5908 - val_loss: 3.6586 - val_acc: 0.5352\n",
      "Medel is training: epoch 100th 18000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2217 - acc: 0.6311 - val_loss: 2.1868 - val_acc: 0.6489\n",
      "Medel is training: epoch 100th 19000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4243 - acc: 0.5822 - val_loss: 3.7699 - val_acc: 0.4900\n",
      "Medel is training: epoch 100th 20000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4900 - acc: 0.6004 - val_loss: 3.3938 - val_acc: 0.5687\n",
      "Medel is training: epoch 100th 21000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3058 - acc: 0.6260 - val_loss: 2.0113 - val_acc: 0.6776\n",
      "Medel is training: epoch 100th 22000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2731 - acc: 0.5987 - val_loss: 3.4952 - val_acc: 0.5305\n",
      "Medel is training: epoch 100th 23000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5697 - acc: 0.5831 - val_loss: 3.3795 - val_acc: 0.5729\n",
      "Medel is training: epoch 100th 24000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5157 - acc: 0.6047 - val_loss: 1.8724 - val_acc: 0.7022\n",
      "Medel is training: epoch 100th 25000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0040 - acc: 0.6364 - val_loss: 2.9576 - val_acc: 0.5769\n",
      "Medel is training: epoch 100th 26000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5581 - acc: 0.5665 - val_loss: 3.3598 - val_acc: 0.5645\n",
      "Medel is training: epoch 100th 27000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5809 - acc: 0.5988 - val_loss: 3.4472 - val_acc: 0.5650\n",
      "Medel is training: epoch 100th 28000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5709 - acc: 0.7032 - val_loss: 2.9291 - val_acc: 0.5896\n",
      "Medel is training: epoch 100th 29000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4837 - acc: 0.5708 - val_loss: 3.3124 - val_acc: 0.5629\n",
      "Medel is training: epoch 100th 30000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5266 - acc: 0.5972 - val_loss: 3.1682 - val_acc: 0.5973\n",
      "Medel is training: epoch 100th 31000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0537 - acc: 0.6594 - val_loss: 1.9039 - val_acc: 0.6927\n",
      "Medel is training: epoch 100th 32000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.0002 - acc: 0.6387 - val_loss: 3.0511 - val_acc: 0.5782\n",
      "Medel is training: epoch 100th 33000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5143 - acc: 0.5680 - val_loss: 3.2323 - val_acc: 0.5796\n",
      "Medel is training: epoch 100th 34000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5543 - acc: 0.6053 - val_loss: 3.2919 - val_acc: 0.5750\n",
      "Medel is training: epoch 100th 35000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.6023 - acc: 0.7042 - val_loss: 2.0855 - val_acc: 0.6665\n",
      "Medel is training: epoch 100th 36000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.2467 - acc: 0.6080 - val_loss: 3.6004 - val_acc: 0.5182\n",
      "Medel is training: epoch 100th 37000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4033 - acc: 0.6035 - val_loss: 3.2468 - val_acc: 0.5896\n",
      "Medel is training: epoch 100th 38000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4792 - acc: 0.6150 - val_loss: 2.3468 - val_acc: 0.6697\n",
      "Medel is training: epoch 100th 39000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5049 - acc: 0.7111 - val_loss: 2.6420 - val_acc: 0.6137\n",
      "Medel is training: epoch 100th 40000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3482 - acc: 0.5945 - val_loss: 3.5986 - val_acc: 0.5168\n",
      "Medel is training: epoch 100th 41000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3253 - acc: 0.6210 - val_loss: 3.1033 - val_acc: 0.6180\n",
      "Medel is training: epoch 100th 42000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.5805 - acc: 0.6047 - val_loss: 2.4666 - val_acc: 0.6509\n",
      "Medel is training: epoch 100th 43000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.4893 - acc: 0.7149 - val_loss: 2.7116 - val_acc: 0.6026\n",
      "Medel is training: epoch 100th 44000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3236 - acc: 0.6002 - val_loss: 3.7807 - val_acc: 0.5108\n",
      "Medel is training: epoch 100th 45000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3637 - acc: 0.6177 - val_loss: 3.1891 - val_acc: 0.5929\n",
      "Medel is training: epoch 100th 46000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.4978 - acc: 0.6135 - val_loss: 1.8053 - val_acc: 0.7093\n",
      "Medel is training: epoch 100th 47000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 1.5232 - acc: 0.7083 - val_loss: 2.6122 - val_acc: 0.6143\n",
      "Medel is training: epoch 100th 48000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3185 - acc: 0.6006 - val_loss: 3.4093 - val_acc: 0.5244\n",
      "Medel is training: epoch 100th 49000/50000 samples\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 9s - loss: 2.3896 - acc: 0.6054 - val_loss: 3.3759 - val_acc: 0.5791\n"
     ]
    }
   ],
   "source": [
    "\n",
    "len_of_transformed_article_data_train = len(transformed_article_data_train2)\n",
    "\n",
    "for p in range(1,EPOCHS+1):\n",
    "    for item in range(0, len_of_transformed_article_data_train, 1000):\n",
    "        if item + 1000 >= len_of_transformed_article_data_train:\n",
    "            last_item = len_of_transformed_article_data_train\n",
    "        else:\n",
    "            last_item = item + 1000\n",
    "        \n",
    "        summary=transformed_summary_data_train2[item:last_item]\n",
    "        \n",
    "        summary_one_hot = (np.arange(transformed_summary_data_train2.max()+1) == summary[...,None]).astype(int)# One Hot \n",
    "        \n",
    "        print('Medel is training: epoch {}th {}/{} samples'.format(p, item, len_of_transformed_article_data_train))\n",
    "        model_with_attention.fit(transformed_article_data_train2[item:last_item], summary_one_hot, batch_size=BATCH_SIZE, nb_epoch=1,verbose=1,validation_split=0.2,shuffle = True)\n",
    "    model_with_attention.save_weights('./with_attention_weights_folder2/checkpoint_epoch_{}.hdf5'.format(p))   \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "# model_json = model.to_json()\n",
    "# with open(\"./with_attention_model_json_folder1/with_attention_model_copy.json\", \"w\") as json_file:\n",
    "#    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation using Rouge Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate your model as before, using Rouge score. Ideally, your scores for the model with attention should be better than the model without attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "article_text_test2 =  open('data/test_article.txt', 'r')\n",
    "summary_text_test2 =  open('data/test_title.txt', 'r')\n",
    "\n",
    "\n",
    "articleTest_data2=article_text_test2.read().splitlines()\n",
    "summaryTest_data2=summary_text_test2.read().splitlines()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to find the words that are in list 1 but not in list 2\n",
    "def words_in_doc1_not_doc2(doc1,doc2):\n",
    "    import numpy as np\n",
    "    tokenizer1 = Tokenizer()\n",
    "    tokenizer1.fit_on_texts(doc1)\n",
    "    counts1=dict(tokenizer1.word_counts)\n",
    "\n",
    "    tokenizer2 = Tokenizer()\n",
    "    tokenizer2.fit_on_texts(doc2)\n",
    "    counts2=dict(tokenizer2.word_counts)\n",
    "    \n",
    "    count1_list = list(counts1)\n",
    "    count2_lsit = list(counts2)\n",
    "    \n",
    "    main_list = np.setdiff1d(count1_list,count2_lsit)\n",
    "    \n",
    "    return list(main_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_word_to_unk = words_in_doc1_not_doc2(articleTest_data2,articleTrain_data2)\n",
    "target_word_to_unk = target_word_to_unk + ['<unk>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1516"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_word_to_unk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace words not in training dataset as 'unk'\n",
    "\n",
    "def replace_with_unk(replaced_word_list, doc):\n",
    "    new_list = []\n",
    "    for i in range(0,len(doc)):\n",
    "        for j in range(0,len(replaced_word_list)):\n",
    "            doc[i] = doc[i].replace(replaced_word_list[j],'unk')\n",
    "        new_list.append(doc[i])\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_articleTest_data2 = replace_with_unk(target_word_to_unk, articleTest_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test = words_in_doc1_not_doc2(new_articleTest_data2,articleTrain_data2)\n",
    "# success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace '<unk>' with 'unk'\n",
    "def standard_unk(doc):\n",
    "    new_list = []\n",
    "    for i in range(0,len(doc)):\n",
    "        doc[i] = doc[i].replace('<unk>','unk')\n",
    "        new_list.append(doc[i])\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_summaryTest_data2 = standard_unk(summaryTest_data2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7000"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_articleTest_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import test data\n",
    "# TO-DO \n",
    "\n",
    "\n",
    "\n",
    "testing_article_data2 = load_data(new_articleTest_data2,new_summaryTest_data2,MAX_LEN,VOCAB_SIZE)\n",
    "\n",
    "\n",
    "\n",
    "transformed_article_data_test2 = testing_article_data2[0]\n",
    "Vocab_size_of_article_test2 = testing_article_data2[1]\n",
    "word2idx_article_test2 = testing_article_data2[2]\n",
    "dx2word_articl_test2 = testing_article_data2[3]\n",
    "transformed_summary_data_test2 = testing_article_data2[4]\n",
    "Vocab_size_of_summary_test2 = testing_article_data2[5]\n",
    "word2idx_summary_test2 = testing_article_data2[6]\n",
    "idx2word_summary_test2 = testing_article_data2[7]\n",
    "# idx2word_summary_test2[6]  DON'T USE THIS ONE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "#load last 10 models\n",
    "#model_with_attention.load_weights(\"./with_attention_weights_folder2/checkpoint_epoch_90.hdf5\")\n",
    "#model_with_attention.load_weights(\"./with_attention_weights_folder2/checkpoint_epoch_91.hdf5\")\n",
    "#model_with_attention.load_weights(\"./with_attention_weights_folder2/checkpoint_epoch_92.hdf5\")\n",
    "#model_with_attention.load_weights(\"./with_attention_weights_folder2/checkpoint_epoch_93.hdf5\")\n",
    "#model_with_attention.load_weights(\"./with_attention_weights_folder2/checkpoint_epoch_94.hdf5\")\n",
    "#model_with_attention.load_weights(\"./with_attention_weights_folder2/checkpoint_epoch_95.hdf5\")\n",
    "# model_with_attention.load_weights(\"./with_attention_weights_folder2/checkpoint_epoch_96.hdf5\")\n",
    "# model_with_attention.load_weights(\"./with_attention_weights_folder2/checkpoint_epoch_97.hdf5\")\n",
    "# model_with_attention.load_weights(\"./with_attention_weights_folder2/checkpoint_epoch_98.hdf5\")\n",
    "#model_with_attention.load_weights(\"./with_attention_weights_folder2/checkpoint_epoch_99.hdf5\")\n",
    "\n",
    "model_with_attention.load_weights(\"./with_attention_weights_folder2/checkpoint_epoch_99.hdf5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "y_hat = model_with_attention.predict(transformed_article_data_test2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# function to inverse a dictionary\n",
    "def inverse_dictionary(dic):\n",
    "    new_dic = {v: k for k, v in dic.items()}\n",
    "    return new_dic\n",
    "\n",
    "# decode a one hot encoded string\n",
    "def one_hot_decode(encoded_seq):\n",
    "    return [argmax(vector) for vector in encoded_seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary_test_word_id = inverse_dictionary(word2idx_summary_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# new_summaryTest_data2\n",
    "\n",
    "#idx2word_summary_test2\n",
    "# word2idx_summary_train2['unk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2idx_summary_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2idx_summary_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx_summary_test2['unk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to convert one hot to words\n",
    "def one_hot_to_words(one_hot, MAX_LEN, dic):\n",
    "    list1 = []\n",
    "    for i in range(0,len(one_hot)):\n",
    "        value = one_hot_decode(one_hot[i])\n",
    "        list1.append(value)\n",
    "        \n",
    "    list2 = []\n",
    "    for i in range(0,len(one_hot)):\n",
    "        list3 = []\n",
    "        for j in range(0,MAX_LEN):\n",
    "            content = dic[list1[i][j]]\n",
    "            list3.append(content)\n",
    "        list2.append(list3)\n",
    "    return list2\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_summary_list = one_hot_to_words(y_hat, MAX_LEN, summary_test_word_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7000"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted_summary_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TO-DO\n",
    "def import_Test_data(sum_T):\n",
    "\n",
    "    summary_pad_data=[]   \n",
    "    for i in range(len(sum_T)):\n",
    "        ha=text_to_word_sequence(sum_T[i],filters='',lower=True,split=\" \") \n",
    "        summary_pad_data.append(ha)  \n",
    "    \n",
    "    return summary_pad_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7000"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import test data \n",
    "real_summary_raw=import_Test_data(new_summaryTest_data2)\n",
    "\n",
    "len(real_summary_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to modify to fitted format for rouge\n",
    "def prepare_inputs_for_rouge(prediction_raw, real_raw):\n",
    "    prediction = [[' '.join(k)] for k in prediction_raw]\n",
    "    real = [[' '.join(k)] for k in real_raw]\n",
    "    \n",
    "    hypothesis = []\n",
    "    for i in range(0,len(prediction)):\n",
    "        value = prediction[i][0]\n",
    "        hypothesis.append(value)\n",
    "        \n",
    "    reference = []\n",
    "    for i in range(0,len(real)):\n",
    "        value = real[i][0]\n",
    "        reference.append(value)\n",
    "        \n",
    "    return hypothesis, reference\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hypothesis, reference =  prepare_inputs_for_rouge(predicted_summary_list, real_summary_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7000"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7000"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'f': 0.027920653074155203,\n",
       "  'p': 0.051319047619047618,\n",
       "  'r': 0.020154272035154387},\n",
       " 'rouge-2': {'f': 0.00056054324591932347,\n",
       "  'p': 0.00088605442176870736,\n",
       "  'r': 0.00044873281480424331},\n",
       " 'rouge-l': {'f': 0.0063151952486442285,\n",
       "  'p': 0.0059340659340659345,\n",
       "  'r': 0.02079843057269528}}"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge = Rouge()\n",
    "Rouge_Score = rouge.get_scores(hypothesis, reference,avg=True)\n",
    "Rouge_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perplexity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we evaluate our models on ROUGE score, we don't train our neural networks to learn better ROUGE score for the fact that ROUGE score is a complicated nonconvex function. How does our model learn then? In information theory, Perplexity is a measure of how good a model is.\n",
    "\n",
    "Perplexity                     $$ = 2^{{-\\sum _{x}p(x)\\log _{2}p(x)}}$$ \n",
    "            \n",
    "Lower the perplexity, better the model. Justify why our model learns well with our loss function? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perplexity is the expontiation of the entropy. Entropy is a clearcut quantity. Entropy is a measure of average number of bits required to encode the outcome of the ramdom variable. When p(x) is high, the model has high probability to make prediction correctly.The larger the p(x) is, the smaller the perplexity is. The smaller the the value of perplexity is, the better the model is. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now plot the attention weights for a sentence and it's output. If a grid cell is white in the plot, it means that during summary, the word on x-axis corresponds to the word on y-axis. You are provided with a Visualizer class for helping you out. Make sure you install matplotlib using sudo pip3 install matplotlib and also install python3-tk using sudo apt-get install python3-tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Visualizer(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "            Visualizes attention maps\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "    def set_models(self, pred_model, proba_model):\n",
    "        \"\"\"\n",
    "            Sets the models to use\n",
    "            :param pred_model: the prediction model\n",
    "            :param proba_model: the model that outputs the activation maps\n",
    "        \"\"\"\n",
    "        self.pred_model = pred_model\n",
    "        self.proba_model = proba_model\n",
    "\n",
    "    def attention_map(self, text, padded_data_vec, y_idx_to_word):\n",
    "        \"\"\"\n",
    "            Displays the attention weights graph\n",
    "            param: input sentence\n",
    "            param: padded_data_vector for prediction\n",
    "            param: idx2word dictionary for titles\n",
    "        \"\"\"\n",
    "        input_length = len(text.split())\n",
    "        \n",
    "        # get the output sequence\n",
    "        prediction = np.argmax(pred_model.predict(padded_data_vec), axis=2)[0]\n",
    "        text_ = text.split()\n",
    "        valids = [y_idx_to_word[index] for index in prediction if index > 0]\n",
    "        sequence = ' '.join(valids)\n",
    "        predicted_text = sequence.split()\n",
    "        output_length = len(predicted_text)\n",
    "        #get the weights\n",
    "        activation_map = np.squeeze(self.proba_model.predict(padded_data_vec))[\n",
    "            0:output_length, 0:input_length]\n",
    "        \n",
    "        plt.clf()\n",
    "        f = plt.figure(figsize=(8, 8.5))\n",
    "        ax = f.add_subplot(1, 1, 1)\n",
    "\n",
    "        # add image\n",
    "        i = ax.imshow(activation_map, interpolation='nearest', cmap='gray')\n",
    "        \n",
    "        # add colorbar\n",
    "        cbaxes = f.add_axes([0.2, 0, 0.6, 0.03])\n",
    "        cbar = f.colorbar(i, cax=cbaxes, orientation='horizontal')\n",
    "        cbar.ax.set_xlabel('Probability', labelpad=2)\n",
    "\n",
    "        # add labels\n",
    "        ax.set_yticks(range(output_length))\n",
    "        ax.set_yticklabels(predicted_text[:output_length])\n",
    "        \n",
    "        ax.set_xticks(range(input_length))\n",
    "        ax.set_xticklabels(text_[:input_length], rotation=45)\n",
    "        \n",
    "        ax.set_xlabel('Input Sequence')\n",
    "        ax.set_ylabel('Output Sequence')\n",
    "\n",
    "        # add grid and legend\n",
    "        ax.grid()\n",
    "        \n",
    "        f.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can initialize Visualizer class as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "viz = Visualizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizer has two methods.\n",
    "- set_models \n",
    "- attention_map\n",
    "\n",
    "The set_models takes in prediction model and probability model as inputs. In *create_UniLSTMwithAttention*, the model with *return_probabilities = False* which you already used in the training is the prediction model. For initializing probability model, call *create_UniLSTMwithAttention* with *return_probabilities = True* and initialize the weights with weights of prediction model. Now you can call set_models in this manner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 26, 30)            240000    \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 26, 30)            7320      \n",
      "_________________________________________________________________\n",
      "AttentionDecoder (AttentionD (None, 26, 8000)          65216250  \n",
      "=================================================================\n",
      "Total params: 65,463,570\n",
      "Trainable params: 65,463,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# prob_model=create_UniLSTMwithAttention(sum_voc_len_attention2,MAX_LEN,art_voc_len_attention2,MAX_LEN,HIDDEN_DIM,NUM_LAYERS,return_probabilities = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "# model_json = prob_model.to_json()\n",
    "# with open(\"./last_part_model/prob_model_model.json\", \"w\") as json_file:\n",
    "#    json_file.write(model_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prob_model.set_weights(model_with_attention.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_model = model_with_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "viz.set_models(model_with_attention,prob_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "attention_map creates the weights map for you. You need to give a sample sentence, a test_data_vector on which we call call model.predict and your output idx2word dictionary. You can call it as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'london share prices up at midday'"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#viz.attention_map(text,test_data_vector,idx2word)\n",
    "# idx2word_summary_test2\n",
    "# \n",
    "vector1 = np.matrix(transformed_article_data_test2[0])\n",
    "reference[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# idx2word_summary_test2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the above Visualizer to visualize attention weights for 15 sentences, as instructed in the Analysis section of the accompanying HW document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7febc4dfada0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7febc4dfa240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TO-DO  1\n",
    "viz.attention_map(reference[0],vector1,idx2word_summary_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2\n",
    "vector2 = np.matrix(transformed_article_data_test2[1105])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7febc4dee4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7febc4dd1160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "viz.attention_map(reference[1105],vector2,idx2word_summary_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7febc4dbfe48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7febc4dc10f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3\n",
    "\n",
    "vector2 = np.matrix(transformed_article_data_test2[2411])\n",
    "viz.attention_map(reference[2411],vector2,idx2word_summary_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7febc4e1d390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7febc4e0f748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4\n",
    "\n",
    "vector2 = np.matrix(transformed_article_data_test2[2545])\n",
    "viz.attention_map(reference[2545],vector2,idx2word_summary_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7febc50d1630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7febc4f40240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5\n",
    "\n",
    "vector2 = np.matrix(transformed_article_data_test2[2608])\n",
    "viz.attention_map(reference[2608],vector2,idx2word_summary_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7febc4fc7470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7febc4f925c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 6    4827, 5962, 6595, 6927\n",
    "\n",
    "vector2 = np.matrix(transformed_article_data_test2[3064])\n",
    "viz.attention_map(reference[3064],vector2,idx2word_summary_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7febc5310b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7febc5325400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 7    , 5962, 6595, 6927\n",
    "\n",
    "vector2 = np.matrix(transformed_article_data_test2[4827])\n",
    "viz.attention_map(reference[4827],vector2,idx2word_summary_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7febc4fb6160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7febc51e8f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 8   , 5962, 6595, 6927\n",
    "\n",
    "vector2 = np.matrix(transformed_article_data_test2[5962])\n",
    "viz.attention_map(reference[5962],vector2,idx2word_summary_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7febc52b0e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7febc556a588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 9   , 5962, 6595, 6927\n",
    "\n",
    "vector2 = np.matrix(transformed_article_data_test2[6595])\n",
    "viz.attention_map(reference[6595],vector2,idx2word_summary_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7febc5a380b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7febc5a3cf28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 10   , 5962, 6595, 6927\n",
    "\n",
    "vector2 = np.matrix(transformed_article_data_test2[6927])\n",
    "viz.attention_map(reference[6927],vector2,idx2word_summary_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feb69e3b9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7febc46d2160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 11   \n",
    "\n",
    "vector2 = np.matrix(transformed_article_data_test2[5])\n",
    "viz.attention_map(reference[5],vector2,idx2word_summary_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feb69df76a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feb69deee10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 12   \n",
    "\n",
    "vector2 = np.matrix(transformed_article_data_test2[10])\n",
    "viz.attention_map(reference[10],vector2,idx2word_summary_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feb69ddbcf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feb69dd9be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 13   \n",
    "\n",
    "vector2 = np.matrix(transformed_article_data_test2[20])\n",
    "viz.attention_map(reference[20],vector2,idx2word_summary_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feb69d45550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feb69d2e748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 14  \n",
    "\n",
    "vector2 = np.matrix(transformed_article_data_test2[1000])\n",
    "viz.attention_map(reference[1000],vector2,idx2word_summary_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feb69cac5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feb69caa080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 15  \n",
    "\n",
    "vector2 = np.matrix(transformed_article_data_test2[6000])\n",
    "viz.attention_map(reference[6000],vector2,idx2word_summary_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the predictions are pretty good. Some of them, one word could have strong relationship with all of the other words. The ligher part shows that the attention weights shows that the systems is woking here. The ligher part shows that correspoing words in x and y axis has more probability to related to each other. The prediction works here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unidirectional LSTM Encoder Decoder With Attention and Beam Search (Extra Credit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models that you implemented till now had greedy decoder. Now implement a Decoder with Beam Search and show improved results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "MAX_LEN = 26\n",
    "VOCAB_SIZE = 8000\n",
    "\n",
    "\n",
    "BATCH_SIZE = 150 \n",
    "NUM_LAYERS = 1\n",
    "HIDDEN_DIM = 30\n",
    "EPOCHS = 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TO-DO \n",
    "article_text_train3 =  open('data/train_article.txt', 'r')\n",
    "summary_text_train3 =  open('data/train_title.txt', 'r')\n",
    "\n",
    "articleTrain_data3=article_text_train3.read().splitlines()\n",
    "summaryTrain_data3=summary_text_train3.read().splitlines()\n",
    "\n",
    "training_article_data3 = load_data(articleTrain_data3,summaryTrain_data3,MAX_LEN,VOCAB_SIZE)\n",
    "\n",
    "transformed_article_data_train3 = training_article_data3[0]\n",
    "Vocab_size_of_article_train3 = training_article_data3[1]\n",
    "word2idx_article_train3 = training_article_data3[2]\n",
    "dx2word_articl_train3 = training_article_data3[3]\n",
    "transformed_summary_data_train3 = training_article_data3[4]\n",
    "Vocab_size_of_summary_train3 = training_article_data3[5]\n",
    "word2idx_summary_train3 = training_article_data3[6]\n",
    "idx2word_summary_train3 = training_article_data3[7]\n",
    "\n",
    "# idx2word_summary_test2[6]  DON'T USE THIS ONE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from attention_decoder import AttentionDecoder\n",
    "\n",
    "def create_UniLSTMwithAttention(X_vocab_len, X_max_len, y_vocab_len, y_max_len, hidden_size, num_layers, return_probabilities = False):\n",
    "\n",
    "    # TO-DO\n",
    "    model = Sequential()\n",
    "    # Add embedding layer\n",
    "    model.add(Embedding(input_dim=X_vocab_len, output_dim=hidden_size,  input_length=MAX_LEN,mask_zero=True,trainable=True))\n",
    "    # add LSTM encoder layer\n",
    "    for _ in range (num_layers):\n",
    "        model.add(LSTM(hidden_size,return_sequences=True, dropout=0.2,recurrent_dropout=0.2))    \n",
    "    # Add attention decoder layer\n",
    "    model.add(BeamSearchDecoder(hidden_size, X_vocab_len))\n",
    "    # Add compile layer\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "    # Add summary layer\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
